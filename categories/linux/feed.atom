<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linux on Morfitronik</title>
    <link>https://morfikov.github.io/categories/linux/</link>
    <description>Recent content in Linux on Morfitronik</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pl-PL</language>
    <lastBuildDate>Sat, 04 Sep 2021 12:36:00 +0200</lastBuildDate><atom:link href="https://morfikov.github.io/categories/linux/feed.atom" rel="self" type="application/atom+xml" />
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Kontrola podświetlenia klawiatury via UDEV (backlight)</title>
      <link>https://morfikov.github.io/post/kontrola-podswietlenia-klawiatury-via-udev-backlight/</link>
      <pubDate>Sat, 04 Sep 2021 12:36:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/kontrola-podswietlenia-klawiatury-via-udev-backlight/</guid>
      <description>&lt;p&gt;Ostatnio na &lt;a href=&#34;https://forum.linuxmint.pl/showthread.php?tid=1739&amp;amp;pid=13156&#34;&gt;polskim forum linux mint pojawił się wątek&lt;/a&gt;, w którym jeden z użytkowników miał
problem z ogarnięciem podświetlania klawiatury. Chodzi generalnie o start komputera z włączonym
backlight&#39;em klawiatury, przez co trzeba to podświetlenie manualnie wyłączać za każdym razem po
uruchomieniu się systemu. W przypadku mojego laptopa Lenovo ThinkPad T430, taka sytuacja co prawda
nie występuje i system uruchamia się naturalnie ze zgaszoną klawiaturą. Niemniej jednak,
zainteresował mnie ten problem tyle, że w drugą stronę -- chodzi o możliwość startu systemu z
włączonym podświetleniem klawiatury, bo ustawienia BIOS/EFI/UEFI mojego laptopa tego aspektu pracy
komputera nie są w stanie w żaden sposób skonfigurować. Okazało się, że zaimplementowanie tego typu
funkcjonalności nie jest jakoś specjalnie trudne i można bez większego trudu ogarnąć backlight
klawiatury przy pomocy prostej reguły dla UDEV&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Migracja z apt-key w Debian linux</title>
      <link>https://morfikov.github.io/post/migracja-z-apt-key-w-debian-linux/</link>
      <pubDate>Sat, 21 Aug 2021 14:35:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/migracja-z-apt-key-w-debian-linux/</guid>
      <description>&lt;p&gt;Z okazji wypuszczenia parę dni temu nowego Debiana, przeglądałem sobie &lt;a href=&#34;https://www.debian.org/releases/bullseye/amd64/release-notes/ch-information.en.html&#34;&gt;notki dla wydania
stabilnego&lt;/a&gt; pod kątem aktualizacji z buster (10) -&amp;gt; bullseye (11). Niby ja i tak korzystam cały
czas z unstable/experimental i zwykle jestem na bieżąco ze zmianami wprowadzanymi w tej dystrybucji
linux&#39;a ale też zawsze coś może umknąć uwadze z perspektywy wielu miesięcy czy nawet kilku lat
(a dokładnie 25 miesięcy). Sporo z tych rzeczy, które w tych podlinkowanych notatkach wyczytałem,
miałem już załatwione wcześniej ale zapomniałem rozprawić się z repozytoriami APT. Konkretnie
chodzi tutaj o odejście od &lt;code&gt;apt-key&lt;/code&gt; , czyli narzędzia, które w Debianie używane jest do dodawania
kluczy GPG do systemowego keyring&#39;a APT. Te klucze zwykle wykorzystywane są do weryfikacji sygnatur
złożonych pod zewnętrznymi repozytoriami, a że ja mam ich sporo, to musiałem się nieco zagłębić w
temat i ustalić w jaki sposób od następnego wydania Debiana (bookworm/12) będzie się te klucze GPG
od takich repozytoriów ogarniać. No i właśnie o tym będzie ten poniższy kawałek artykułu.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Analiza systemu plików EXT4 pod kątem formatowania większych dysków pod linux</title>
      <link>https://morfikov.github.io/post/analiza-systemu-plikow-ext4-pod-katem-formatowania-wiekszych-dyskow-pod-linux/</link>
      <pubDate>Sun, 25 Jul 2021 18:40:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/analiza-systemu-plikow-ext4-pod-katem-formatowania-wiekszych-dyskow-pod-linux/</guid>
      <description>&lt;p&gt;Zapewne każdy użytkownik linux&#39;a tworzył na dysku HDD/SSD partycje sformatowane systemem plików
EXT4. Prawdopodobnie też zastanawiało nas pytanie odnośnie ilości zajmowanego miejsca przez
strukturę samego systemu plików, zwłaszcza w przypadku dysków o sporych rozmiarach (setki GiB, czy
nawet kilka TiB). Jako, że musiałem ostatnio zmigrować kolekcję filmów ze strych dysków na
jeden większy, który miał zostać podłączony pod Raspberry Pi z działającym Kodi na bazie LibreELEC,
to przy okazji postanowiłem ten dysk sformatować w taki sposób, w jaki powinno się do tego zadania
podchodzić wiedząc, że ma się do czynienia z dużym dyskiem, na którym będą przechowywane głównie
duże pliki. Celem tego artykułu jest pokazanie jakie błędy przy tworzeniu systemu plików EXT4 można
popełnić przez posiadanie niezbyt wystarczającej wiedzy z jego zakresu, oraz jak te błędy
wyeliminować przed rozpoczęciem korzystania z tak nie do końca poprawnie przygotowanego do pracy
dysku twardego&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Energy Performance Bias (EPB) i jego wpływ na wydajność CPU Intela pod linux</title>
      <link>https://morfikov.github.io/post/energy-performance-bias-epb-i-jego-wplyw-na-wydajnosc-cpu-intela-pod-linux/</link>
      <pubDate>Fri, 30 Apr 2021 22:10:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/energy-performance-bias-epb-i-jego-wplyw-na-wydajnosc-cpu-intela-pod-linux/</guid>
      <description>&lt;p&gt;Przeglądając ostatnio log systemowy, zauważyłem, że pojawia się w nim komunikat &lt;code&gt;kernel: ENERGY_PERF_BIAS: Set to &#39;normal&#39;, was &#39;performance&#39;&lt;/code&gt; . Co prawda korzystam z laptopa i cokolwiek
związane z energią ustawione w trybie wydajności nie zawsze zdaje się być optymalnym rozwiązaniem
ale też moja maszyna zwykle jest podpięta do źródła zasilania i przydałoby się, by była ona
skonfigurowana właśnie bardziej w stronę profilu wydajności niż oszczędności energii. Ten powyższy
komunikat informuje nas zaś, że system zmienił ustawienia z &lt;code&gt;performance&lt;/code&gt; (tryb wydajności) na
&lt;code&gt;normal&lt;/code&gt; (jakiś bliżej nieokreślony tryb normalny). Chodzi naturalnie o ustawienia trybu pracy
procesora Intel. Postanowiłem zatem poszukać informacji na temat tego czym jest ten cały Energy
Performance Bias (EPB) i jak go skonfigurować w odpowiedni sposób pod linux.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Aktualizacja firmware drukarki HP LaserJet P2055dn pod linux</title>
      <link>https://morfikov.github.io/post/aktualizacja-firmware-drukarki-hp-laserjet-p2055dn-pod-linux/</link>
      <pubDate>Wed, 27 Jan 2021 19:10:00 +0100</pubDate>
      
      <guid>https://morfikov.github.io/post/aktualizacja-firmware-drukarki-hp-laserjet-p2055dn-pod-linux/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio drukarką laserową Hewlett Packard (HP) LaserJet P2055dn, zauważyłem, że ma ona
wgrany dość stary firmware. Naturalnie sama drukarka do najmłodszych nie należy, bo została
wyprodukowana w 2011 roku ale skoro na stronie producenta jest dostępna nowsza wersja
oprogramowania dla tego urządzenia, to przydałoby się je do tej drukarki wgrać. Problem jednak
pojawia się w przypadku takich osób jak ja, tj. tych, które korzystają w swoim środowisku pracy z
maszyn mających na pokładzie system operacyjny z rodziny jakieś dystrybucji linux&#39;a, np. Debian czy
Ubuntu. Producent drukarki udostępnia stosowne narzędzia do aktualizacji firmware ale tylko i
wyłącznie dla OS z gatunku Windows. Co mają zrobić osoby, które z Windows&#39;a nie korzystają, a
chciałyby przy tym mieć aktualny firmware w drukarkach HP? Możemy spróbować postawić maszynę
wirtualną na bazie QEMU/KVM, tam zainstalować Windows&#39;a i udostępnić w obrębie tej maszyny
wirtualnej drukarkę, której firmware mamy zamiar aktualizować.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Zastosowanie KSM w maszynach wirtualnych QEMU/KVM</title>
      <link>https://morfikov.github.io/post/zastosowanie-ksm-w-maszynach-wirtualnych-qemu-kvm/</link>
      <pubDate>Sun, 18 Oct 2020 10:45:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/zastosowanie-ksm-w-maszynach-wirtualnych-qemu-kvm/</guid>
      <description>&lt;p&gt;Użytkownicy linux&#39;a, którzy korzystają z &lt;a href=&#34;/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/&#34;&gt;mechanizmu wirtualizacji QEMU/KVM&lt;/a&gt;, wiedzą, że takie
maszyny wirtualne potrafią zjadać dość sporo pamięci operacyjnej. Im więcej takich maszyn zostanie
uruchomionych w obrębie danego hosta, tym większe ryzyko, że nam tego RAM&#39;u zwyczajnie zabraknie.
Można oczywiście ratować się dokupieniem dodatkowych modułów pamięci ale też nie zawsze taki zabieg
będzie możliwy, zwłaszcza w przypadku domowych stacji roboczych pokroju desktop/laptop. Szukając
rozwiązania tego problemu natrafiłem na coś, co nazywa się Kernel Samepage Merging. W skrócie, KSM
to mechanizm, który ma na celu współdzielenie takich samych stron pamięci operacyjnej przez kilka
procesów. W ten sposób można (przynajmniej teoretycznie) dość znacznie obniżyć zużycie RAM,
zwłaszcza w przypadku korzystania na maszynach wirtualnych z tych samych systemów operacyjnych.
Przydałoby się zatem ocenić jak bardzo KSM wpłynie na wykorzystanie pamięci i czy będzie z niego
jakiś większy użytek zarówno przy korzystaniu z maszyn wirtualnych, czy też w codziennym użytkowaniu
komputera.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Tworzenie kopii zapasowej linux&#39;a z BorgBackup</title>
      <link>https://morfikov.github.io/post/tworzenie-kopii-zapasowej-linux-z-borgbackup/</link>
      <pubDate>Thu, 08 Oct 2020 19:05:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/tworzenie-kopii-zapasowej-linux-z-borgbackup/</guid>
      <description>&lt;p&gt;Gdy chodzi o bezpieczeństwo danych przechowywanych na nośnikach pamięci masowych, takich jak dyski
twarde, to użytkownicy linux&#39;a często piszą sobie skrypty shell&#39;owe mające na celu przeprowadzić
backup całego nośnika lub też jego konkretnych plików/katalogów. Zwykle zaprzęgany jest do pracy
&lt;code&gt;rsync&lt;/code&gt; , który bez problemu jest w stanie  zsynchronizować zawartość dwóch folderów (źródłowego i
docelowego) i po tym procesie wołany jest także &lt;code&gt;tar&lt;/code&gt; mający na celu skompresować pliki backup&#39;u,
tak by zajmowały mniej miejsca. Nie mam nic do tego rozwiązania, bo sam też przez lata z niego
korzystałem ale ma ono całą masę wad. Przede wszystkim, ten mechanizm nie bierze pod uwagę zmian w
samych plikach, czyli tworzy kopię tego co mu się poda i w taki sposób mamy wiele paczek &lt;code&gt;.tar.gz&lt;/code&gt; ,
które zajmują sporo miejsca. Kolejną sprawą jest brak zabezpieczenia przed nieuprawnionym dostępem
do plików kopii zapasowej, np. przy pomocy szyfrowania. W ten sposób trzeba posiłkować się
zewnętrznymi rozwiązaniami, np. pełne szyfrowanie dysku za sprawą LUKS/dm-crypt, co nie zawsze jest
możliwe i też bardzo komplikuje cały proces tworzenia kopii zapasowej, zwłaszcza na zewnętrznych
nośnikach czy zdalnych hostach w sieci. Ostatnio jednak trafiłem na &lt;a href=&#34;https://borgbackup.readthedocs.io/&#34;&gt;narzędzie BorgBackup&lt;/a&gt;, które
to dość znacznie upraszcza cały proces tworzenia backup&#39;u plików na linux, a takie cechy jak
szyfrowanie, kompresja i deduplikacja danych są w borg zaimplementowane standardowo. Postanowiłem
zatem zmigrować z mojego skryptowego systemu tworzenia kopii zapasowych na rzecz borg&#39;a i spisać
przy okazji te użyteczniejsze informacje dotyczące posługiwania się tym narzędziem&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Uwierzytelnianie odpowiedzi z serwerów czasu NTP przy pomocy NTS</title>
      <link>https://morfikov.github.io/post/uwierzytelnianie-odpowiedzi-z-serwerow-czasu-ntp-przy-pomocy-nts/</link>
      <pubDate>Sun, 27 Sep 2020 12:29:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/uwierzytelnianie-odpowiedzi-z-serwerow-czasu-ntp-przy-pomocy-nts/</guid>
      <description>&lt;p&gt;Przepisując ostatnio stare artykuły dotyczące &lt;a href=&#34;/post/szyfrowany-dns-z-dnscrypt-proxy-i-dnsmasq-na-debian-linux/&#34;&gt;zabezpieczenia zapytań DNS za sprawą wdrożenia na
linux dnsmasq i dnscrypt-proxy&lt;/a&gt;, natknąłem się &lt;a href=&#34;https://blog.cloudflare.com/secure-time/&#34;&gt;na informację&lt;/a&gt;, że nie tylko komunikacja DNS
w obecnych czasach w sporej mierze nie jest zaszyfrowana. W zasadzie każda maszyna podłączona do
internetu potrzebuje dysponować w miarę dokładnym czasem. By ten czas był dokładny, wymyślono
mechanizm synchronizacji czasu przez wysyłanie zapytań do serwerów NTP (&lt;a href=&#34;https://pl.wikipedia.org/wiki/Network_Time_Protocol&#34;&gt;Network Time Protocol&lt;/a&gt;).
Niemniej jednak, odpowiedzi z tych serwerów czasu nie są w żaden sposób zabezpieczone i praktycznie
każdy na drodze tych pakietów może nam zmienić ustawienia czasu w systemie (MITM). W taki sposób
możemy zostać cofnięci w czasie, co z kolei może oznaczać, że system zaakceptuje certyfikaty SSL/TLS
czy też &lt;a href=&#34;https://trimstray.github.io/posts/2019-07-21-nginx-optymalizacja_sesji_ssl-tls/#ssl_session_tickets&#34;&gt;klucze/bilety sesji&lt;/a&gt; (używane do wznawiania sesji TLS), które już dawno temu wygasły
lub/i zostały w jakiś sposób skompromitowane. Pchnięcie nas do przodu w czasie również oznacza
problemy, bo możemy zaakceptować certyfikat, który jeszcze nie zaczął być ważny. To z kolei otwiera
drogę do odszyfrowania połączeń z serwisami WWW, a przecie nie po to szyfrujemy ruch, by go ktoś bez
większego problemu odszyfrował. Dlatego też powinniśmy zadbać o to, by informacje o aktualnym czasie
otrzymywane z sieci docierały do nas z wiarygodnego źródła i były w jakiś sposób uwierzytelnione.
Na Debianie standardowo do synchronizacji czasu wykorzystywany jest &lt;code&gt;systemd-timesyncd&lt;/code&gt; ale &lt;a href=&#34;https://github.com/systemd/systemd/issues/9481&#34;&gt;nie
wspiera on póki co protokołu NTS&lt;/a&gt;. Trzeba będzie zatem się go pozbyć i zastąpić go demonem &lt;code&gt;ntpd&lt;/code&gt;
z pakietu &lt;code&gt;ntpsec&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Szyfrowany DNS z dnscrypt-proxy i dnsmasq na Debian linux</title>
      <link>https://morfikov.github.io/post/szyfrowany-dns-z-dnscrypt-proxy-i-dnsmasq-na-debian-linux/</link>
      <pubDate>Sat, 19 Sep 2020 14:13:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/szyfrowany-dns-z-dnscrypt-proxy-i-dnsmasq-na-debian-linux/</guid>
      <description>&lt;p&gt;Ostatnio na forum dug.net.pl jeden z użytkowników &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=31524&#34;&gt;miał dość spory problem&lt;/a&gt; z ogarnięciem
zadania polegającego na zaszyfrowaniu zapytań DNS z wykorzystaniem &lt;a href=&#34;https://dnscrypt.info/&#34;&gt;dnscrypt-proxy&lt;/a&gt; i
&lt;a href=&#34;http://www.thekelleys.org.uk/dnsmasq/doc.html&#34;&gt;dnsmasq&lt;/a&gt;. Ładnych parę lat temu opisywałem &lt;a href=&#34;/tags/resolver/&#34;&gt;jak skonfigurować te dwa narzędzia na Debianie&lt;/a&gt;
(i też na OpenWRT), choć od tamtego czasu w świecie linux&#39;owym trochę rzeczy się pozmieniało. Dla
przykładu, dnscrypt-proxy przeszedł gruntowną przebudowę, no i też systemd jest w powszechniejszym
użyciu niż to miało miejsce w tamtych czasach, przez co w sporej części przypadków usługi takie jak
&lt;code&gt;systemd-networkd.service&lt;/code&gt; czy &lt;code&gt;systemd-resolved.service&lt;/code&gt; są już włączone domyślnie. Zatem sporo
informacji zawartych w tych napisanych przeze mnie artykułach już niekoniecznie może znaleźć
obecnie zastosowanie. Dlatego też pomyślałem, że nadszedł już czas, by ździebko zaktualizować tamte
wpisy. Ostatecznie stanęło jednak na tym, by w oparciu o te artykuły napisać kompletnie nowy tekst
na temat szyfrowania zapytań DNS na linux przy wykorzystaniu oprogramowania &lt;code&gt;dnscrypt-proxy&lt;/code&gt; oraz
&lt;code&gt;dnsmasq&lt;/code&gt; i zawrzeć w nim te wszystkie ciekawsze informacje, które udało mi się pozyskać przez te
ostatnie lata w kwestii poprawy bezpieczeństwa i prywatności przy przeglądaniu stron WWW.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Systemowy GPG/GnuPG w Thunderbird 78&#43; na linux</title>
      <link>https://morfikov.github.io/post/systemowy-gpg-gnupg-w-thunderbird-78-na-linux/</link>
      <pubDate>Mon, 07 Sep 2020 20:15:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/systemowy-gpg-gnupg-w-thunderbird-78-na-linux/</guid>
      <description>&lt;p&gt;Jakiś już czas temu Mozilla ogłosiła, że Thunderbird od wersji 78 będzie posiadał natywne wsparcie
dla szyfrowania wiadomości z wykorzystaniem kluczy GPG/PGP, przez co &lt;a href=&#34;https://enigmail.net/index.php/en/&#34;&gt;dodatek Enigmail&lt;/a&gt; będzie
już zwyczajnie zbędny. Dziś z kolei czytam sobie o &lt;a href=&#34;https://blog.thunderbird.net/2020/09/openpgp-in-thunderbird-78/&#34;&gt;zakończeniu wsparcia dla wersji 68&lt;/a&gt; tego
klienta pocztowego, które będzie miało miejsce z końcem września 2020, czyli został już niespełna
miesiąc i ta starsza wersja Thunderbird&#39;a nie będzie już dostawać łat bezpieczeństwa. Pewne jest
zatem, że dystrybucje linux&#39;a w niedługim czasie pchną wersję 78 do głównych repozytoriów. W
Debianie, wersja 78 Thunderbird&#39;a od dłuższego czasu jest dostępna w gałęzi eksperymentalnej i można
było ją już wcześniej sobie zainstalować, jeśli ktoś wyrażał taką chęć. Gdy ja ostatni raz
testowałem wersję 78, to nie była ona zbytnio do użytku ale wygląda na to, że większość
niedogodności, których mi się udało doświadczyć, została już wyeliminowana. Pozostał w zasadzie
jeden problem, tj. Thunderbird domyślnie używa własnego keyring&#39;a kluczy GPG/PGP, w efekcie czego
systemowy GPG/GnuPG nie jest w ogóle wykorzystywany. Taki san rzeczy sprawia, że będziemy mieć dwie
różne bazy danych kluczy (jedna dla Thunderbird&#39;a, a druga dla reszty linux&#39;a), co może trochę
irytować. Na szczęście jest opcja wymuszenia na TB, by korzystał on z systemowego keyring&#39;a kluczy
GPG/PGP i celem tego artykułu jest pokazanie właśnie jak tego typu zabieg przeprowadzić.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak zmusić jeden proces do korzystania z VPN na linux (OpenVPN)</title>
      <link>https://morfikov.github.io/post/jak-zmusic-jeden-proces-do-korzystania-z-vpn-na-linux-openvpn/</link>
      <pubDate>Wed, 02 Sep 2020 18:36:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zmusic-jeden-proces-do-korzystania-z-vpn-na-linux-openvpn/</guid>
      <description>&lt;p&gt;Parę dni temu &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=31514&#34;&gt;na forum dug.net.pl pojawiło się zapytanie&lt;/a&gt; dotyczące skonfigurowania linux&#39;a w
taki sposób, by ten umożliwił pojedynczemu procesowi w systemie (i tylko jemu) korzystanie z VPN,
podczas gdy wszystkie pozostałe aplikacje korzystają ze standardowego łącza internetowego naszego
ISP. Oczywiście to niekoniecznie musi być tylko jeden proces, bo to zagadnienie można rozciągnąć
też na większą grupę procesów jednego lub więcej użytkowników. By to zadanie zrealizować, trzeba
zdać sobie sprawę z faktu, że każdy proces w linux ma swojego właściciela, a ten właściciel
przynależy do co najmniej jednej grupy. Dzięki takiemu rozwiązaniu, każdy proces w systemie ma
przypisany m.in. identyfikator użytkownika (UID) oraz identyfikatory grup (GID), z którymi działa i
na podstawie których to linux przyznaje uprawienia dostępu do różnych części systemu, np. urządzeń
czy plików na dysku. W ten sposób możemy bardzo prosto ograniczyć dostęp do określonych zasobów
konkretnym użytkownikom (bardziej ich procesom). Problem się zaczyna w przypadku sieci, gdzie w
zasadzie dostęp do internetu ma domyślnie przyznany każdy proces. Naturalnie możemy skonfigurować
filtr pakietów i zezwolić tylko części aplikacji na dostęp do sieci ale w dalszym ciągu, gdy tylko
odpalimy VPN (w tym przypadku OpenVPN), to każdy proces mający prawo wysyłać pakiety sieciowe
będzie je przesyłał z automatu przez VPN, jak tylko to połączenie zostanie zestawione. Istnieje
jednak sposób, by nauczyć linux&#39;a aby tylko procesy określonych użytkowników czy grup miały dostęp
do VPN i gdy to połączenie zostanie zerwane, to te procesy nie będą mogły korzystać ze
standardowego łącza internetowego. Trzeba jednak zaprzęgnąć do pracy &lt;code&gt;iptables&lt;/code&gt; / &lt;code&gt;nftables&lt;/code&gt; ,
tablice routingu oraz nieco inaczej skonfigurować klienta OpenVPN.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Zarządzanie Raspberry Pi 4B z LibreELEC przez VNC/SPICE</title>
      <link>https://morfikov.github.io/post/zarzadzanie-raspberry-pi-4b-z-libreelec-przez-vnc-spice/</link>
      <pubDate>Tue, 25 Aug 2020 20:08:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/zarzadzanie-raspberry-pi-4b-z-libreelec-przez-vnc-spice/</guid>
      <description>&lt;p&gt;Do konfiguracji &lt;a href=&#34;https://libreelec.tv/&#34;&gt;systemu LibreELEC&lt;/a&gt;, który jest zainstalowany na moim Raspberry Pi 4B nie
potrzebuję żadnego monitora czy wyświetlacza, a wszystkie prace administracyjne związane z tym
małym komputerem ogarniam po SSH. Niemniej jednak, są pewne rzeczy, których się po SSH nie da
skonfigurować. Chodzi generalnie o konfigurację Kodi i sprawy związane z domowa wideoteką. Ten
Raspberry Pi 4B jest podłączony do TV, zatem bez problemu można przez graficzny interfejs Kodi
skonfigurować to, co potrzeba. Niemniej jednak konfigurowanie Kodi przez aplikację na Androida
(&lt;a href=&#34;https://kodi.wiki/view/Kore&#34;&gt;Kore&lt;/a&gt;) nie należy do najłatwiejszych zadań. Nie uśmiecha mi się też ciągle latać z myszą i
klawiaturą w celu podłączania ich do portów USB maliny. Nie mam też w zasadzie zewnętrznego
monitora HDMI, bo od lat używam jedynie laptopów. Pomyślałem zatem, by zrobić użytek z protokołu
&lt;a href=&#34;https://en.wikipedia.org/wiki/Virtual_Network_Computing&#34;&gt;VNC&lt;/a&gt;/&lt;a href=&#34;https://en.wikipedia.org/wiki/Simple_Protocol_for_Independent_Computing_Environments&#34;&gt;SPICE&lt;/a&gt; i przesłać obraz z Raspberry Pi 4B przez sieć do mojego laptopa. W ten sposób
odpadłoby mi ciągłe przemieszczanie się między pokojami i byłbym w stanie podejrzeć obraz TV na
ekranie monitora w moim laptopie przy jednoczesnym zachowaniu możliwości używania myszy i
klawiatury, co by mi bardzo zaoszczędziło czas przy konfiguracji Kodi.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Raspberry Pi, LibreELEC, Kodi i zdalne logi via rsyslog</title>
      <link>https://morfikov.github.io/post/raspberry-pi-libreelec-kodi-i-zdalne-logi-via-rsyslog/</link>
      <pubDate>Tue, 25 Aug 2020 19:21:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/raspberry-pi-libreelec-kodi-i-zdalne-logi-via-rsyslog/</guid>
      <description>&lt;p&gt;Parę lat temu, gdy pojawił się u mnie w domu bezprzewodowy router WiFi, postanowiłem wgrać na niego
linux&#39;a w postaci OpenWRT. Pierwszym kluczowym elementem konfiguracyjnym tego urządzenia było
&lt;a href=&#34;/post/logread-czyli-system-logowania-w-openwrt/&#34;&gt;przesłanie jego logów systemowych przez sieć&lt;/a&gt; do mojego laptopa, tak by wszystkie
zarejestrowane komunikaty zostały wyświetlone na konsoli mojego komputera z zainstalowanym Debianem.
W ten sposób nie musiałem się co chwila logować na router po SSH (czy też przez panel webowy), by
sprawdzić czy aby na pewno z tym urządzeniem jest wszystko w porządku. Teraz, po nabyciu Raspberry
Pi 4B i wgraniu na niego &lt;a href=&#34;https://libreelec.tv/&#34;&gt;LibreELEC&lt;/a&gt; z preinstalowanym Kodi, mam dokładnie to samo zadanie do
zrealizowania. Trzeba zatem znaleźć sposób na przesłanie wszystkich logów generowanych przez system
LibreELEC do demona &lt;code&gt;rsyslogd&lt;/code&gt; , który jest uruchomiony na zdalnej maszynie.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak włączyć stabilne adresy prywatne w IPv6 na linux</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-stabilne-adresy-prywatne-w-ipv6-na-linux/</link>
      <pubDate>Wed, 19 Aug 2020 19:31:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-stabilne-adresy-prywatne-w-ipv6-na-linux/</guid>
      <description>&lt;p&gt;Jakiś już czas temu opisywałem &lt;a href=&#34;/post/jak-wlaczyc-ipv6-privacy-extensions-w-debianie-slaac/&#34;&gt;jak włączyć rozszerzenia prywatności IPv6 na Debianie&lt;/a&gt; (IPv6
Privacy Extensions) w przypadku korzystania z mechanizmu automatycznej konfiguracji adresacji
hostów SLAAC (StateLess Address AutoConfiguration). Miało to za zadanie poprawić nieco prywatność
osób podłączonych do internetu za sprawą protokołu IPv6, bo generowane adresy IP standardowo
zawierają adresy MAC kart sieciowych (&lt;a href=&#34;https://en.wikipedia.org/wiki/MAC_address&#34;&gt;identyfikator EUI64&lt;/a&gt;). Parę dni temu dowiedziałem się, że
w linux można również aktywować inny mechanizm zwany stabilnymi adresami prywatnymi
(&lt;a href=&#34;https://tools.ietf.org/html/rfc7217&#34;&gt;stable-privacy addresses&lt;/a&gt;), które to wykorzystują inny system przy generowaniu identyfikatorów
interfejsów sieciowych. Ten mechanizm sprawia, że część adresu IPv6 odpowiedzialna za identyfikację
hosta ma losowe, choć stabilne wartości, które nie mają nic wspólnego z adresem MAC karty sieciowej
naszego komputera. W ten sposób możemy ukrócić śledzenie nas w sieci na podstawie adresu IPv6.
Poniższy artykuł ma za zadanie pomóc skonfigurować nam te stabilne adresy prywatne na linux oraz
pokazać w jaki sposób są one w stanie pomóc naszej prywatności.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak odszyfrować linux&#39;a przy pomocy telefonu z Androidem</title>
      <link>https://morfikov.github.io/post/jak-odszyfrowac-linux-przy-pomocy-telefonu-z-androidem/</link>
      <pubDate>Sat, 15 Aug 2020 02:43:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-odszyfrowac-linux-przy-pomocy-telefonu-z-androidem/</guid>
      <description>&lt;p&gt;Zaszyfrowane systemy (desktopy/laptopy) mają jeden poważny problem, gdy chodzi o zapewnianie
bezpieczeństwa chronionym plikom przechowywanym na dyskach twardych. Gdy siedzimy obok naszej
maszyny, możemy czuć się bezpiecznie, bo przecież nikt nie może się włamać do jej systemu bez
naszej wiedzy. Nawet jeśli ktoś będzie próbował się dostać do naszego PC, to istnieje spora szansa,
że takie działanie zostałoby natychmiast przez nas wykryte, przez co moglibyśmy w odpowiedni sposób
zareagować na zaistniałe zagrożenie. Co jednak w przypadku, gdy zostawiamy przykładowo naszego
laptopa samego? Nawet jeśli zablokujemy mu ekran, wyłączymy go albo zahibernujemy, to ta maszyna
wciąż nie jest odpowiednio zabezpieczona, by uniemożliwić osobom postronnym dostęp do naszych
wrażliwych danych. Problem leży w fizycznym dostępie do sprzętu, który ludzie mogą uzyskać, gdy nas
nie ma w pobliżu naszego komputera. W taki sposób osoby trzecie mogą wykorzystać fakt, że tracimy
maszynę z oczu i być w stanie zastawić na nas różne pułapki. By uniknąć zagrożenia związanego z
zostawieniem laptopa/desktopa bez nadzoru, nie możemy w zasadzie pozostawiać tego urządzenia samego,
co jest zadaniem praktycznie nie do wykonania. Komputery stacjonarne czy nawet laptopy nie są
urządzeniami o małych gabarytach i zwykle nie możemy ich wszędzie zabrać ze sobą, w przeciwieństwie
do smartfonów. Postanowiłem zatem tak skonfigurować swojego linux&#39;a, by jego zaszyfrowany dysk
(LUKS + LVM) można było odszyfrować jedynie przy pomocy mojego telefonu z Androidem, z którym w
zasadzie się nie rozstaję.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Migracja bloga z Jekyll na Hugo i jego publikacja w GitHub Pages</title>
      <link>https://morfikov.github.io/post/migracja-bloga-z-jekyll-na-hugo-i-jego-publikacja-w-github-pages/</link>
      <pubDate>Thu, 13 Aug 2020 23:50:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/migracja-bloga-z-jekyll-na-hugo-i-jego-publikacja-w-github-pages/</guid>
      <description>&lt;p&gt;Prawdopodobnie zauważyliście drobne zmiany w wyglądzie tego bloga oraz pewnie też cześć osób miała
w ostatnim czasie problemy z uzyskaniem do niego dostępu. Odpowiedzialne za zaistniałą sytuację są
&lt;a href=&#34;https://docs.github.com/en/github/working-with-github-pages/about-github-pages#usage-limits&#34;&gt;limity narzucone przez GitHub Pages&lt;/a&gt;. Zakładają one maksymalny rozmiar repozytorium pod stronę
WWW w granicach 1 GiB oraz czas budowania takiego serwisu krótszy niż 10 minut. Limit miejsca na
pliki przekroczony został w zasadzie w chwili przeniesienia bloga WordPress na GitHub Pages.
Natomiast parę dni temu został przekroczony limit czasu budowania tego projektu. Do momentu
transformacji, niniejszy blog działał w oparciu o &lt;a href=&#34;https://jekyllrb.com/&#34;&gt;Jekyll&lt;/a&gt;, który generował w zasadzie statyczny
kod HTML ze zwykłych plików tekstowych (np. artykuły pisane w &lt;a href=&#34;https://www.markdownguide.org/&#34;&gt;MarkDown&lt;/a&gt;). &lt;a href=&#34;https://pages.github.com/&#34;&gt;GitHub Pages
posiada wsparcie dla Jekyll&lt;/a&gt;, przez co taką stronę WWW można bardzo prosto wdrożyć. Niemniej
jednak, cały ten mechanizm generowania projektu w obrębie infrastruktury GitHub&#39;a zajmuje bardzo
dużo czasu. Po rozmowie z supportem okazało się, że gdyby chodziło o miejsce na pliki, to mogli by
nagiąć reguły i nie było by problemu ale nie dadzą rady tego zrobić w przypadku przekroczenia czasu
generowania projektu. Dlatego też trzeba było zrezygnować z Jekyll&#39;a i poszukać dla niego jakiejś
alternatywy. Padło na &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;, który w odróżnieniu od Jekyll&#39;a nie jest jako tako wspierany przez
GitHub i by &lt;a href=&#34;https://gohugo.io/hosting-and-deployment/hosting-on-github/&#34;&gt;stronę wygenerowaną przez Hugo podpiąć pod GitHub Pages&lt;/a&gt; trzeba się trochę wysilić,
bo ten proces nie jest automatyczny i właśnie o tym jak dokonać migracji z Jekyll na Hugo w
kontekście GitHub Pages będzie ten poniższy artykuł.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak włączyć w Firefox ESNI (Encrypted SNI)</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-w-firefox-esni-encrypted-sni/</link>
      <pubDate>Mon, 10 Aug 2020 18:15:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-w-firefox-esni-encrypted-sni/</guid>
      <description>&lt;p&gt;Obecnie szyfrowanie zapytań DNS staje się powoli normą za sprawą protokołu DoH (&lt;a href=&#34;https://en.wikipedia.org/wiki/DNS_over_HTTPS&#34;&gt;DNS over HTTPS&lt;/a&gt;)
lub DoT (&lt;a href=&#34;https://en.wikipedia.org/wiki/DNS_over_TLS&#34;&gt;DNS over TLS&lt;/a&gt;). Można by zatem pomyśleć, że wraz z implementacją szyfrowania tego
kluczowego dla działania internetu protokołu (przynajmniej z naszego ludzkiego punktu widzenia),
poprawie ulegnie również nasza prywatność w kwestii odwiedzanych przez nas stron WWW. Niemniej
jednak, w dalszym ciągu można bez problemu wyciągnąć adresy domen, które zamierzamy odwiedzić. Nie
ma przy tym żadnego znaczenia ile stron jest hostowanych na danym adresie IP, ani nawet fakt, że
ruch do serwera WWW będzie szyfrowany (w pasku adresu wpiszemy &lt;code&gt;https://&lt;/code&gt; ) z wykorzystaniem
protokołu SSL/TLS (w tym również TLS v1.3). Wszystko przez rozszerzenie SNI (&lt;a href=&#34;https://en.wikipedia.org/wiki/Server_Name_Indication&#34;&gt;Server Name
Indication&lt;/a&gt;), którego to zadaniem jest umożliwienie jednemu serwerowi na prezentowanie wielu
certyfikatów hostowanych w jego obrębie domen. Dzięki takiemu rozwiązaniu, każda domena może
szyfrować ruch niezależnie od siebie na linii serwer&amp;lt;-&amp;gt;klient (używać innych kluczy szyfrujących).
Niemniej jednak, podczas nawiązywania szyfrowanego połączenia, w pakiecie ClientHello przesyłanym
do takiego serwera musi znaleźć się nazwa domeny, której to certyfikat serwer będzie musiał nam
przedstawić. Niestety ten pakiet jest przesyłany przez sieć otwartym tekstem, przez co każdy, kto
podsłuchuje naszą komunikację (w tym też nasz ISP), bez problemu może ustalić na jakie strony
internetowe wchodzimy. Ostatnimi czasy jednak pojawiły się dwa rozszerzenia ECH (&lt;a href=&#34;https://en.wikipedia.org/wiki/Server_Name_Indication#Encrypted_Client_Hello&#34;&gt;Encrypted Client
Hello&lt;/a&gt;) oraz ESNI (&lt;a href=&#34;https://tools.ietf.org/html/draft-ietf-tls-esni-07&#34;&gt;Encrypted SNI&lt;/a&gt;), które mają zaadresować problemy związane z prywatnością
przez pełne zaszyfrowanie pakietu ClientHello lub też zaszyfrowanie jedynie pola SNI w tym pakiecie.
Póki co, prace nad tymi rozszerzeniami nie są jeszcze skończone ale Firefox w połączeniu z
CloudFlare powoli testują ESNI. Postanowiłem zatem dobrowolnie przyłączyć się do grupy testerów i
wdrożyć na swoim linux&#39;ie to rozszerzenie ESNI dla przeglądarki Firefox.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak zmienić rozmiar obrazu maszyny wirtualnej QEMU/KVM</title>
      <link>https://morfikov.github.io/post/jak-zmienic-rozmiar-obrazu-maszyny-wirtualnej-qemu-kvm/</link>
      <pubDate>Sun, 09 Aug 2020 13:45:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zmienic-rozmiar-obrazu-maszyny-wirtualnej-qemu-kvm/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio &lt;a href=&#34;/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/&#34;&gt;maszynami wirtualnymi na bazie QEMU/KVM&lt;/a&gt;, zauważyłem, że sugerowany rozmiar
pliku &lt;code&gt;.qcow2&lt;/code&gt; waha się w okolicach 25 GiB. Nie jest to może jakoś specjalnie dużo ale mało to też
nie jest, zwłaszcza jeśli tworzymy maszyny wirtualne na dysku swojego laptopa. Co jeśli
przeholowaliśmy z szacunkami co do rozmiaru takiego obrazu i po zainstalowaniu systemu operacyjnego
gościa okazało się, że w sumie to ten obraz można by zmniejszyć o połowę? Albo też i w drugą stronę,
tj. co w przypadku, gdy stworzony obraz maszyny wirtualnej okazał się zbyt mały i teraz zachodzi
potrzeba jego powiększenia? Czy w takiej sytuacji musimy na nowo tworzyć maszynę wirtualną
odpowiednio zwiększając lub zmniejszając jej przestrzeń na pliki? A może istnieje jakiś sposób na
zmianę rozmiaru tych istniejących już obrazów maszyn wirtualnych? Postaramy się ten fakt
zweryfikować, a cały proces zostanie opisany przy wykorzystaniu systemu Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Konfiguracja HugePages pod maszyny wirtualne QEMU/KVM</title>
      <link>https://morfikov.github.io/post/konfiguracja-hugepages-pod-maszyny-wirtualne-qemu-kvm/</link>
      <pubDate>Sun, 09 Aug 2020 11:11:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-hugepages-pod-maszyny-wirtualne-qemu-kvm/</guid>
      <description>&lt;p&gt;W linux rozmiar stron pamięci operacyjnej RAM ma domyślnie 4096 bajtów (4 KiB). Maszyny wirtualne
QEMU/KVM mają to do siebie, że wykorzystują dość spore zasoby pamięci (wile GiB), przez co mały
rozmiar strony może niekorzystnie wpływać na wydajność systemów gościa. Chodzi generalnie o to, że
rozrostowi ulega tablica stron, której przeszukiwanie jest czasochłonną operacją. By temu zaradzić,
wymyślono TLB (&lt;a href=&#34;https://en.wikipedia.org/wiki/Translation_lookaside_buffer&#34;&gt;Translation Lookaside Buffer&lt;/a&gt;), który ulokowany jest albo w CPU albo gdzieś
pomiędzy CPU i główną pamięcią operacyjną. TLB to mały ale za to bardzo szybki cache. W przypadku
systemów z duża ilością pamięci RAM, niewielki rozmiar TLB sprawia, że odpowiedzi na zapytania nie
są brane z cache, tylko system wraca do przeszukiwania normalnej tablicy stron zlokalizowanej w
pamięci RAM (TLB miss). Taka sytuacja jest bardzo kosztowna, spowalnia cały system i dlatego trzeba
jej unikać. Na szczęście jest &lt;a href=&#34;https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt&#34;&gt;mechanizm HugePages&lt;/a&gt;, który pozwala na zwiększenie rozmiaru
strony pamięci z domyślnych 4 KiB do 2 MiB lub nawet do 1 GiB w zależności od właściwości głównego
procesora. W tym artykule postaramy się skonfigurować HugePages na potrzeby maszyn wirtualnych dla
systemu Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Wirtualizacja QEMU/KVM (libvirt) na Debian Linux</title>
      <link>https://morfikov.github.io/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/</link>
      <pubDate>Sat, 08 Aug 2020 14:55:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/</guid>
      <description>&lt;p&gt;Prawdopodobnie dla większości użytkowników linux&#39;a, wirtualizacja kojarzy się w zasadzie z jednym
oprogramowaniem, tj. VirtualBox. &lt;a href=&#34;https://www.virtualbox.org/&#34;&gt;Niby strona VBox&#39;a podaje, że jest on na licencji GPL-2&lt;/a&gt; ale
w Debianie nie ma go w głównym repozytorium (jest on obecny w sekcji &lt;code&gt;contrib&lt;/code&gt; ). Problem z
VirtualBox&#39;em jest taki, że &lt;a href=&#34;https://salsa.debian.org/pkg-virtualbox-team/virtualbox/-/blob/master/debian/copyright&#34;&gt;wymaga on kompilatora Open Watcom&lt;/a&gt;, który już wolnym
oprogramowaniem nie jest. VBox też nie jest jedynym oprogramowaniem, które na linux można
wykorzystać w roli hiperwizora do obsługi maszyn wirtualnych. Jest o wiele lepsze rozwiązanie,
mianowicie QEMU, które jest w stanie zrobić użytek z maszyny wirtualnej kernela (Kernel Virtual
Machine, KVM) i realizować dokładnie to samo zadanie, które zwykł ogarniać VirtualBox.
Wirtualizacja na bazie QEMU/KVM jest w pełni OpenSource, co ucieszy pewnie fanów wolnego i
otwartego oprogramowania, choć zarządzanie maszynami wirtualnymi odbywa się za sprawą konsoli.
Oczywiście, osoby które korzystają z VirtualBox&#39;a zdają sobie sprawę, że to narzędzie oferuje
graficzny menadżer maszyn wirtualnych (Virtual Machine Manager, VMM), który usprawnia i znacznie
ułatwia zarządzanie wirtualnymi maszynami. Jeśli GUI jest dla nas ważnym elementem środowiska pracy
i nie uśmiecha nam się konfigurować maszyn wirtualnych przy pomocy terminala, to jest i dobra
wiadomość dla takich osób, bo istnieje &lt;code&gt;virt-manager&lt;/code&gt; , który jest dość rozbudowanym menadżerem
maszyn wirtualnych pozwalającym na ich tworzenie, konfigurowanie i zarządzanie nimi przy
wykorzystaniu graficznego interfejsu użytkownika. W tym artykule postaramy się skonfigurować
naszego Debiana w taki sposób, by przygotować go do pracy z maszynami wirtualnymi posługując się
&lt;code&gt;qemu&lt;/code&gt;/&lt;code&gt;libvirt&lt;/code&gt;/&lt;code&gt;virt-manager&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
