<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linux on Morfitronik</title>
    <link>https://morfikov.github.io/categories/linux/</link>
    <description>Recent content in Linux on Morfitronik</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pl-PL</language>
    <lastBuildDate>Mon, 10 Aug 2020 18:15:00 +0000</lastBuildDate>
    
	<atom:link href="https://morfikov.github.io/categories/linux/feed.xml" rel="self" type="application/rss" />
    
    
    <item>
      <title>Jak włączyć w Firefox ESNI (Encrypted SNI)</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-w-firefox-esni-encrypted-sni/</link>
      <pubDate>Mon, 10 Aug 2020 18:15:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-w-firefox-esni-encrypted-sni/</guid>
      <description>&lt;p&gt;Obecnie szyfrowanie zapytań DNS staje się powoli normą za sprawą protokołu DoH (&lt;a href=&#34;https://en.wikipedia.org/wiki/DNS_over_HTTPS&#34;&gt;DNS over HTTPS&lt;/a&gt;)
lub DoT (&lt;a href=&#34;https://en.wikipedia.org/wiki/DNS_over_TLS&#34;&gt;DNS over TLS&lt;/a&gt;). Można by zatem pomyśleć, że wraz z implementacją szyfrowania tego
kluczowego dla działania internetu protokołu (przynajmniej z naszego ludzkiego punktu widzenia),
poprawie ulegnie również nasza prywatność w kwestii odwiedzanych przez nas stron WWW. Niemniej
jednak, w dalszym ciągu można bez problemu wyciągnąć adresy domen, które zamierzamy odwiedzić. Nie
ma przy tym żadnego znaczenia ile stron jest hostowanych na danym adresie IP, ani nawet fakt, że
ruch do serwera WWW będzie szyfrowany (w pasku adresu wpiszemy &lt;code&gt;https://&lt;/code&gt; ) z wykorzystaniem
protokołu SSL/TLS (w tym również TLS v1.3). Wszystko przez rozszerzenie SNI (&lt;a href=&#34;https://en.wikipedia.org/wiki/Server_Name_Indication&#34;&gt;Server Name
Indication&lt;/a&gt;), którego to zadaniem jest umożliwienie jednemu serwerowi na prezentowanie wielu
certyfikatów hostowanych w jego obrębie domen. Dzięki takiemu rozwiązaniu, każda domena może
szyfrować ruch niezależnie od siebie na linii serwer&amp;lt;-&amp;gt;klient (używać innych kluczy szyfrujących).
Niemniej jednak, podczas nawiązywania szyfrowanego połączenia, w pakiecie ClientHello przesyłanym
do takiego serwera musi znaleźć się nazwa domeny, której to certyfikat serwer będzie musiał nam
przedstawić. Niestety ten pakiet jest przesyłany przez sieć otwartym tekstem, przez co każdy, kto
podsłuchuje naszą komunikację (w tym też nasz ISP), bez problemu może ustalić na jakie strony
internetowe wchodzimy. Ostatnimi czasy jednak pojawiły się dwa rozszerzenia ECH (&lt;a href=&#34;https://en.wikipedia.org/wiki/Server_Name_Indication#Encrypted_Client_Hello&#34;&gt;Encrypted Client
Hello&lt;/a&gt;) oraz ESNI (&lt;a href=&#34;https://tools.ietf.org/html/draft-ietf-tls-esni-07&#34;&gt;Encrypted SNI&lt;/a&gt;), które mają zaadresować problemy związane z prywatnością
przez pełne zaszyfrowanie pakietu ClientHello lub też zaszyfrowanie jedynie pola SNI w tym pakiecie.
Póki co, prace nad tymi rozszerzeniami nie są jeszcze skończone ale Firefox w połączeniu z
CloudFlare powoli testują ESNI. Postanowiłem zatem dobrowolnie przyłączyć się do grupy testerów i
wdrożyć na swoim linux&#39;ie to rozszerzenie ESNI dla przeglądarki Firefox.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zmienić rozmiar obrazu maszyny wirtualnej QEMU/KVM</title>
      <link>https://morfikov.github.io/post/jak-zmienic-rozmiar-obrazu-maszyny-wirtualnej-qemu-kvm/</link>
      <pubDate>Sun, 09 Aug 2020 13:45:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zmienic-rozmiar-obrazu-maszyny-wirtualnej-qemu-kvm/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio &lt;a href=&#34;https://morfikov.github.io
/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/&#34;&gt;maszynami wirtualnymi na bazie QEMU/KVM&lt;/a&gt;, zauważyłem, że sugerowany rozmiar
pliku &lt;code&gt;.qcow2&lt;/code&gt; waha się w okolicach 25 GiB. Nie jest to może jakoś specjalnie dużo ale mało to też
nie jest, zwłaszcza jeśli tworzymy maszyny wirtualne na dysku swojego laptopa. Co jeśli
przeholowaliśmy z szacunkami co do rozmiaru takiego obrazu i po zainstalowaniu systemu operacyjnego
gościa okazało się, że w sumie to ten obraz można by zmniejszyć o połowę? Albo też i w drugą stronę,
tj. co w przypadku, gdy stworzony obraz maszyny wirtualnej okazał się zbyt mały i teraz zachodzi
potrzeba jego powiększenia? Czy w takiej sytuacji musimy na nowo tworzyć maszynę wirtualną
odpowiednio zwiększając lub zmniejszając jej przestrzeń na pliki? A może istnieje jakiś sposób na
zmianę rozmiaru tych istniejących już obrazów maszyn wirtualnych? Postaramy się ten fakt
zweryfikować, a cały proces zostanie opisany przy wykorzystaniu systemu Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja HugePages pod maszyny wirtualne QEMU/KVM</title>
      <link>https://morfikov.github.io/post/konfiguracja-hugepages-pod-maszyny-wirtualne-qemu-kvm/</link>
      <pubDate>Sun, 09 Aug 2020 11:11:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-hugepages-pod-maszyny-wirtualne-qemu-kvm/</guid>
      <description>&lt;p&gt;W linux rozmiar stron pamięci operacyjnej RAM ma domyślnie 4096 bajtów (4 KiB). Maszyny wirtualne
QEMU/KVM mają to do siebie, że wykorzystują dość spore zasoby pamięci (wile GiB), przez co mały
rozmiar strony może niekorzystnie wpływać na wydajność systemów gościa. Chodzi generalnie o to, że
rozrostowi ulega tablica stron, której przeszukiwanie jest czasochłonną operacją. By temu zaradzić,
wymyślono TLB (&lt;a href=&#34;https://en.wikipedia.org/wiki/Translation_lookaside_buffer&#34;&gt;Translation Lookaside Buffer&lt;/a&gt;), który ulokowany jest albo w CPU albo gdzieś
pomiędzy CPU i główną pamięcią operacyjną. TLB to mały ale za to bardzo szybki cache. W przypadku
systemów z duża ilością pamięci RAM, niewielki rozmiar TLB sprawia, że odpowiedzi na zapytania nie
są brane z cache, tylko system wraca do przeszukiwania normalnej tablicy stron zlokalizowanej w
pamięci RAM (TLB miss). Taka sytuacja jest bardzo kosztowna, spowalnia cały system i dlatego trzeba
jej unikać. Na szczęście jest &lt;a href=&#34;https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt&#34;&gt;mechanizm HugePages&lt;/a&gt;, który pozwala na zwiększenie rozmiaru
strony pamięci z domyślnych 4 KiB do 2 MiB lub nawet do 1 GiB w zależności od właściwości głównego
procesora. W tym artykule postaramy się skonfigurować HugePages na potrzeby maszyn wirtualnych dla
systemu Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wirtualizacja QEMU/KVM (libvirt) na Debian Linux</title>
      <link>https://morfikov.github.io/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/</link>
      <pubDate>Sat, 08 Aug 2020 14:55:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/</guid>
      <description>&lt;p&gt;Prawdopodobnie dla większości użytkowników linux&#39;a, wirtualizacja kojarzy się w zasadzie z jednym
oprogramowaniem, tj. VirtualBox. &lt;a href=&#34;https://www.virtualbox.org/&#34;&gt;Niby strona VBox&#39;a podaje, że jest on na licencji GPL-2&lt;/a&gt; ale
w Debianie nie ma go w głównym repozytorium (jest on obecny w sekcji &lt;code&gt;contrib&lt;/code&gt; ). Problem z
VirtualBox&#39;em jest taki, że &lt;a href=&#34;https://salsa.debian.org/pkg-virtualbox-team/virtualbox/-/blob/master/debian/copyright&#34;&gt;wymaga on kompilatora Open Watcom&lt;/a&gt;, który już wolnym
oprogramowaniem nie jest. VBox też nie jest jedynym oprogramowaniem, które na linux można
wykorzystać w roli hiperwizora do obsługi maszyn wirtualnych. Jest o wiele lepsze rozwiązanie,
mianowicie QEMU, które jest w stanie zrobić użytek z maszyny wirtualnej kernela (Kernel Virtual
Machine, KVM) i realizować dokładnie to samo zadanie, które zwykł ogarniać VirtualBox.
Wirtualizacja na bazie QEMU/KVM jest w pełni OpenSource, co ucieszy pewnie fanów wolnego i
otwartego oprogramowania, choć zarządzanie maszynami wirtualnymi odbywa się za sprawą konsoli.
Oczywiście, osoby które korzystają z VirtualBox&#39;a zdają sobie sprawę, że to narzędzie oferuje
graficzny menadżer maszyn wirtualnych (Virtual Machine Manager, VMM), który usprawnia i znacznie
ułatwia zarządzanie wirtualnymi maszynami. Jeśli GUI jest dla nas ważnym elementem środowiska pracy
i nie uśmiecha nam się konfigurować maszyn wirtualnych przy pomocy terminala, to jest i dobra
wiadomość dla takich osób, bo istnieje &lt;code&gt;virt-manager&lt;/code&gt; , który jest dość rozbudowanym menadżerem
maszyn wirtualnych pozwalającym na ich tworzenie, konfigurowanie i zarządzanie nimi przy
wykorzystaniu graficznego interfejsu użytkownika. W tym artykule postaramy się skonfigurować
naszego Debiana w taki sposób, by przygotować go do pracy z maszynami wirtualnymi posługując się
&lt;code&gt;qemu&lt;/code&gt;/&lt;code&gt;libvirt&lt;/code&gt;/&lt;code&gt;virt-manager&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>BootHole nie taki straszny, o ile ma się własne klucze EFI/UEFI</title>
      <link>https://morfikov.github.io/post/boothole-nie-taki-straszny-o-ile-ma-sie-wlasne-klucze-efi-uefi/</link>
      <pubDate>Fri, 31 Jul 2020 21:07:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/boothole-nie-taki-straszny-o-ile-ma-sie-wlasne-klucze-efi-uefi/</guid>
      <description>&lt;p&gt;Dnia 29-07-2020 do publicznej wiadomości zostały podane informacje na temat podatności BootHole,
która to za sprawą bootloader&#39;a GRUB2 w różnych dystrybucjach linux&#39;a jest w stanie obejść
mechanizm bezpieczeństwa EFI/UEFI, tj. Secure Boot. &lt;a href=&#34;https://www.debian.org/security/2020-GRUB-UEFI-SecureBoot/&#34;&gt;Z informacji&lt;/a&gt;, które opublikował Debian,
sprawa nie wygląda miło jako, że poza aktualizacją GRUB2, shim, jądra linux, Fwupdate oraz Fwupd,
unieważnieniu podlegają również klucze dystrybucji Debian/Ubuntu, przez co praktycznie cały soft
podpisany tymi kluczami (w tym systemy live) przestaną działać w trybie Secure Boot. Czy jest się
czego obawiać i co użytkownik korzystający z mechanizmu SB powinien w takiej sytuacji zrobić?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problem z aktualizacją zmiennych PK, KEK, db i dbx via efi-updatevar</title>
      <link>https://morfikov.github.io/post/problem-z-aktualizacja-zmiennych-pk-kek-db-dbx-efi-updatevar/</link>
      <pubDate>Thu, 30 Jul 2020 20:30:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problem-z-aktualizacja-zmiennych-pk-kek-db-dbx-efi-updatevar/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/&#34;&gt;konfigurację własnych kluczy EFI/UEFI&lt;/a&gt;, którymi można zastąpić te
wbudowane standardowo w firmware naszego komputera. W tamtym artykule napotkałem jednak dość dziwny
problem, za sprawą którego nie można było zaktualizować zmiennych &lt;code&gt;PK&lt;/code&gt; , &lt;code&gt;KEK&lt;/code&gt; , &lt;code&gt;db&lt;/code&gt; i &lt;code&gt;dbx&lt;/code&gt; przy
pomocy &lt;code&gt;efi-updatevar&lt;/code&gt; z poziomu działającego linux&#39;a. Gdy próbowało się te zmienne przepisać,
dostawało się błąd typu &lt;code&gt;Operation not permitted&lt;/code&gt; . Niby system został uruchomiony w trybie &lt;code&gt;Setup Mode&lt;/code&gt; ale z jakiegoś powodu odmawiał on współpracy i trzeba było te zmienne aktualizować
bezpośrednio z poziomu firmware EFI/UEFI, co było trochę upierdliwe. Szukając wtedy informacji na
ten temat, jedyne co znalazłem, to fakt, że sporo osób ma podobny problem i najwyraźniej firmware
mojego laptopa jest ździebko niedorobiony, przez co &lt;code&gt;efi-updatevar&lt;/code&gt; nie mógł realizować swojego
zdania. Rzeczywistość okazała się nieco inna, a rozwiązanie samego problemu było wręcz banalne.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czym jest linux kernel driver binding</title>
      <link>https://morfikov.github.io/post/czym-jest-linux-kernel-driver-binding/</link>
      <pubDate>Tue, 28 Jul 2020 19:39:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czym-jest-linux-kernel-driver-binding/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio QEMU/KVM na swoim laptopie z zainstalowanym Debianem natrafiłem na ciekawe
zagadnienie związane z wirtualizacją, tj. z PCI passthrough. Nie chodzi mi tutaj o samą technikę
PCI passthrough ale o dobór sterowników do urządzeń działających pod kontrolą linux. Każdy sprzęt,
który ma działać w systemie, musi mieć załadowany w pamięci RAM stosowny moduł kernela. Te moduły
zwykle są ładowane automatycznie podczas pracy systemu, np. gdy podłączamy nowy sprzęt do komputera
(można też te moduły ładować i ręcznie via &lt;code&gt;modprobe&lt;/code&gt; ). Gdy nasz linux z jakiegoś powodu dobierze
niewłaściwy (z naszego punktu widzenia) moduł dla jakiegoś urządzenia, to możemy to urządzenie
odłączyć od komputera, a moduł bez problemu wyładować, po czym dokonać stosownych poprawek w
systemie. Problem zaczyna się w sytuacji, gdy mamy do czynienia ze sprzętem, którego nie da się od
komputera fizycznie odłączyć, np. wbudowana w płytę główną karta dźwiękowa, czy też wbudowana
grafika bezpośrednio w CPU. Podobnie sprawa wygląda w przypadku wkompilowania modułów na stałe w
kernel -- jak wyładować moduł, którego się nie da wyładować? By w takich sytuacjach zmienić
przypisany urządzeniu sterownik trzeba dodać parę plików w katalogach &lt;code&gt;/etc/modules-load.d/&lt;/code&gt; /
&lt;code&gt;/etc/modprobe.d/&lt;/code&gt; oraz zrestartować maszynę, tak by podczas fazy boot kernel dobrał sprzętowi
pożądane przez nas moduły i ich konfigurację. Niemniej jednak, istnieje prostszy sposób na zmianę
sterownika działającego w systemie sprzętu i to bez potrzeby fizycznego restartowania maszyny.
Chodzi o mechanizm ręcznego przypisywania urządzeń do konkretnych sterowników (&lt;a href=&#34;https://lwn.net/Articles/143397/&#34;&gt;manual driver
binding and unbinding&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Moduł LKRG (Linux Kernel Runtime Guard)</title>
      <link>https://morfikov.github.io/post/modul-lkrg-linux-kernel-runtime-guard/</link>
      <pubDate>Tue, 09 Jun 2020 20:56:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-lkrg-linux-kernel-runtime-guard/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/modul-tpe-trusted-path-execution-dla-kernela-linux/&#34;&gt;moduł TPE&lt;/a&gt; (Trusted Path Execution) dla kernela linux, który jest w
stanie dość znacznie poprawić bezpieczeństwo naszego systemu. Ostatnio jednak natknąłem się na
&lt;a href=&#34;https://www.openwall.com/lkrg/&#34;&gt;moduł LKRG&lt;/a&gt; (Linux Kernel Runtime Guard), którego to zadaniem jest stać na straży samego jądra
operacyjnego i chronić je w czasie rzeczywistym przed różnego rodzaju zagrożeniami poprzez
wykrywanie eksploitów wykorzystujących luki w jego mechanizmach bezpieczeństwa. Jako, że ja
bardzo lubię zbroić swojego Debiana, to postanowiłem się przyjrzeć nieco bliżej temu całemu LKRG i
sprawdzić jego użyteczność. Trzeba jednak wiedzieć, że LKRG jest dostarczany w formie osobnego
modułu zamiast łaty na kernel, przez co trzeba będzie także postarać się o automatyzację pewnych
rzeczy, m.in. procesu budowania modułu przy aktualizacji kernela via DKMS.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pendrive multiboot dla EFI/UEFI z Secure Boot</title>
      <link>https://morfikov.github.io/post/pendrive-multiboot-dla-efi-uefi-z-secure-boot/</link>
      <pubDate>Mon, 23 Mar 2020 21:50:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pendrive-multiboot-dla-efi-uefi-z-secure-boot/</guid>
      <description>&lt;p&gt;Przeniesienie mojego Debiana z laptopa mającego konfigurację BIOS i tablicę partycji MBR/MS-DOS do
maszyny wyposażonej w firmware EFI/UEFI nie było jakoś stosunkowo trudnym zadaniem. Nawet &lt;a href=&#34;https://morfikov.github.io
/post/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/&#34;&gt;kwestia
włączenia Secure Boot&lt;/a&gt; okazała się o wiele mniej skomplikowana niż w rzeczywistości mogłoby się
człowiekowi wydawać. Problem jednak pojawił się w przypadku płytek czy pendrive z systemami live.
Nie chodzi przy tym o uruchamianie nośników z dopiero co wypalonymi obrazami ISO/IMG, bo te również
nie sprawiają kłopotów. Chodzi bardziej o rozwiązanie multiboot, które oferuje wgranie wielu
obrazów live na jedno urządzenie i odpalanie tego systemu, który sobie użytkownik w danym momencie
zażyczy. Do tej pory korzystałem z &lt;a href=&#34;https://github.com/thias/glim&#34;&gt;projektu GLIM&lt;/a&gt; i może on posiada wsparcie dla EFI/UEFI ale
już wsparcia dla Secure Boot mu zabrakło. W efekcie w konfiguracji EFI/UEFI + Secure Boot, GLIM stał
się bezużyteczny i trzeba było rozejrzeć się za nieco innym rozwiązaniem. Okazało się, że nie
trzeba daleko szukać, bo &lt;a href=&#34;https://www.rodsbooks.com/refind/&#34;&gt;rEFInd&lt;/a&gt; jest w stanie natywnie uruchomić system z obrazu ISO
praktycznie każdej dystrybucji linux&#39;a (Ubuntu/Debian/Mint/GParted/CloneZilla) i w zasadzie trzeba
tylko nieco inaczej przygotować nośnik, by móc na nowo cieszyć się korzyściami jakie oferuje
pendrive multiboot.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak dodać własne klucze dla Secure Boot do firmware EFI/UEFI pod linux</title>
      <link>https://morfikov.github.io/post/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/</link>
      <pubDate>Mon, 16 Mar 2020 19:15:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/</guid>
      <description>&lt;p&gt;W środowiskach linux&#39;owych Secure Boot nie jest zbyt mile widziany i raczej postrzegany jako
źródło wszelkiego zła na świecie. Sporo użytkowników linux&#39;a dopatruje się w Secure Boot zamachu na
wolność decydowania o swoim sprzęcie, który ma być serwowany przez Microsoft. Niemniej jednak,
odsądzanie tego mechanizmu od czci i wiary jest moim zdaniem lekko nie na miejscu. Niewielu
użytkowników linux&#39;a zdaje sobie sprawę, że od prawie dekady istnieje taki wynalazek jak &lt;a href=&#34;https://github.com/rhboot/shim&#34;&gt;shim&lt;/a&gt;
(no i jest też &lt;a href=&#34;https://blog.hansenpartnership.com/linux-foundation-secure-boot-system-released/&#34;&gt;PreLoader&lt;/a&gt;), który umożliwia dystrybucjom linux&#39;a (jak i ich końcowym
użytkownikom) zaimplementowanie Secure Boot we własnym zakresie. Niemniej jednak, można całkowicie
się obejść bez tych dodatków usuwając wbudowane w firmware EFI/UEFI certyfikaty i dodając na ich
miejsce własnoręcznie wygenerowane klucze kryptograficzne. Takie podejście sprawia, że kod
podpisany tylko i wyłącznie przez nas będzie mógł zostać uruchomiony przez firmware komputera w
trybie Secure Boot, co może ździebko poprawić bezpieczeństwo naszego systemu. Poniższy artykuł ma
na celu pokazać w jaki sposób zastąpić wbudowane w firmware EFI/UEFI klucze swoimi własnymi przy
wykorzystaniu dystrybucji Debiana.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ograniczyć ładowanie baterii w laptopie ThinkPad T430</title>
      <link>https://morfikov.github.io/post/jak-ograniczyc-ladowanie-baterii-w-laptopie-thinkpad-t430/</link>
      <pubDate>Fri, 13 Mar 2020 18:30:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ograniczyc-ladowanie-baterii-w-laptopie-thinkpad-t430/</guid>
      <description>&lt;p&gt;Czy zastanawialiście się może dlaczego baterie w laptopach zużywają się mimo, że w pewnych
przypadkach nie są one praktycznie wykorzystywane? Rozważmy sobie ideę używania laptopa w roli
przeciętnego komputera stacjonarnego. W takiej sytuacji do laptopa ciągle jest podpięty przewód
zasilający, przez co bateria powinna być używana jedynie w momencie braku zasilania z sieci
energetycznej. Zatem niby pobieramy prąd z gniazdka ale bateria i tak się nam zużyje po pewnym
czasie. Niektórzy radzą, by wyciągnąć akumulator z laptopa i używać takiego komputera bez baterii.
Takie postępowanie ma w moim odczuciu jednak same wady i postanowiłem poszukać jakiegoś bardziej
cywilizowanego rozwiązania wzorowanego na &lt;a href=&#34;https://forum.xda-developers.com/android/apps-games/root-battery-charge-limit-t3557002&#34;&gt;aplikacji Battery Charge Limit&lt;/a&gt; spotykanego w
smartfonach z Androidem. Gdyby udało się ustalić limit ładowania akumulatora w moim ThinkPad T430
na max 40%, to wydłużyłoby dość znacznie żywotność jego baterii. Niekiedy oprogramowanie na windows
umożliwia tego typu funkcjonalność ale co w przypadku linux&#39;a? Czy da radę pod linux powstrzymać
laptopa od degradowania baterii za sprawą ładowania jej ciągle do 100%?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Brak bluetooth w ThinkPad T430 (BCM20702A1)</title>
      <link>https://morfikov.github.io/post/brak-bluetooth-w-thinkpad-t430/</link>
      <pubDate>Wed, 11 Mar 2020 21:03:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/brak-bluetooth-w-thinkpad-t430/</guid>
      <description>&lt;p&gt;W moim laptopie Lenovo ThinkPad T430 jest obecny bluetooth &lt;code&gt;Broadcom Corp. BCM20702 Bluetooth 4.0&lt;/code&gt;
o vid/pid &lt;code&gt;0a5c:21e6&lt;/code&gt; . Niestety to urządzenie nie działa za dobrze na Debianie z powodu braku
odpowiedniego firmware (plik &lt;code&gt;BCM20702A1-0a5c-21e6.hcd&lt;/code&gt; ), którego jak na złość nie ma w
repozytorium tej dystrybucji. Przydałoby się coś na to poradzić, by zmusić tę kartę/adapter do
pracy pod linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przygotować dysk pod instalację Debian linux z EFI/UEFI</title>
      <link>https://morfikov.github.io/post/jak-przygotowac-dysk-pod-instalacje-debian-linux-z-efi-uefi/</link>
      <pubDate>Tue, 10 Mar 2020 03:28:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przygotowac-dysk-pod-instalacje-debian-linux-z-efi-uefi/</guid>
      <description>&lt;p&gt;Instalacja linux&#39;a w trybie EFI/UEFI nieco inaczej wygląda niż tradycyjna instalacja systemu, zwana
często dla odróżnienia trybem BIOS, przynajmniej przy wykorzystaniu &lt;code&gt;debootstrap&lt;/code&gt; Jeśli kupujemy
nowego desktopa czy laptopa, to zwykle będziemy mieli na dysku twardym zainstalowanego windows&#39;a i
tym samym przygotowany cały układ partycji niezbędny do prawidłowego uruchomienia systemu w trybie
EFI/UEFI. Co jednak w przypadku, gdy kupimy komputer bez systemu operacyjnego? W takiej sytuacji
trzeba będzie ręcznie podzielić dysk na partycje oraz zainstalować menadżer rozruchu (rEFInd) lub
też bootloader (grub/grub2/syslinux/extlinux) i skonfigurować wszystkie te elementy samodzielnie.
Prawdopodobnie instalator Debiana jest w stanie za nas te kroki przeprowadzić automatycznie ale my
nie będziemy korzystać z automatycznych rozwiązań, bo one nieco odmóżdżają. Spróbujemy za to
stworzyć sobie uniwersalną konfigurację, która pozwoli nam zainstalować i odpalić dowolną
dystrybucję linux&#39;a w trybie EFI/UEFI.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana DPI w Openbox/Xorg dla monitora HiDPI</title>
      <link>https://morfikov.github.io/post/zmiana-dpi-w-openbox-xorg-dla-monitora-hidpi/</link>
      <pubDate>Sun, 08 Mar 2020 19:00:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-dpi-w-openbox-xorg-dla-monitora-hidpi/</guid>
      <description>&lt;p&gt;Jeśli mieliśmy do czynienia z monitorami wysokiej rozdzielczości, to za pewne natrafiliśmy na
problem zbyt małych czcionek, które czyniły interfejs aplikacji w naszym linux&#39;ie mało czytelnym. W
przypadku środowisk graficznych takich jak GNOME czy KDE5/Plasma5 skalowanie interfejsu i czcionek
powinno odbywać się automatycznie (&lt;a href=&#34;https://wiki.gnome.org/HowDoI/HiDpi&#34;&gt;jeśli nasz ekran ma 192+ DPI i rozdzielczość 1200+ pikseli&lt;/a&gt;)
lub też za sprawą drobnej zmiany w konfiguracji, tak by użytkownik mógł w miarę komfortowo
korzystać z systemu. O ile w przypadku tych pełnowymiarowych środowisk graficznych można w zasadzie
przełączyć tylko jedną opcję i wszystkie jego aplikacje powinny zostać z powodzeniem odpowiednio
zeskalowane, o tyle problem zaczyna się w momencie, gdy mamy mieszane aplikacje lub też zwyczajnie
używamy jedynie prostego menadżera okien dla Xserver&#39;a, np. Openbox i do tego jeszcze nasz
wyświetlacz ma mniejsze DPI niż 192. W takiej sytuacji konfiguracja interfejsu użytkownika i
czcionek dla ekranów wysokiej rozdzielczości może być nie lada wyzwaniem.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak załadować firmware karty WiFi przed initrd/initramfs</title>
      <link>https://morfikov.github.io/post/jak-zaladowac-firmware-karty-wifi-przed-initrd-initramfs/</link>
      <pubDate>Fri, 06 Mar 2020 02:45:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zaladowac-firmware-karty-wifi-przed-initrd-initramfs/</guid>
      <description>&lt;p&gt;Każdy kto ma laptopa wyposażonego w kartę WiFi, czy też ogólnie komputer posiadający bezprzewodową
sieciówkę, ten prawdopodobnie spotkał się z błędem podobnym do tego: &lt;code&gt;Direct firmware load for iwlwifi-6000g2a-6.ucode failed with error -2&lt;/code&gt; . W tym przypadku sprawa dotyczyła karty &lt;code&gt;Intel Corporation Centrino Advanced-N 6205 [Taylor Peak]&lt;/code&gt; działającej w oparciu o moduł kernela
&lt;code&gt;iwlwifi&lt;/code&gt; . W takich przypadkach zwykle wystarczy zainstalować firmware od określonego modułu i po
kłopocie. No i faktycznie w Debianie jest dostępny pakiet &lt;code&gt;firmware-iwlwifi&lt;/code&gt; , który zawiera ten
potrzebny plik &lt;code&gt;iwlwifi-6000g2a-6.ucode&lt;/code&gt; . Problem jednak w tym, że instalacja paczki z firmware
niekoniecznie może nam pomóc. Ten powyższy przykład nie jest odosobniony i czasami pliki z firmware
muszą być dostępne w chwili ładowania kernela do pamięci RAM czy też na etapie initramfs/initrd. W
takim przypadku zainstalowanie paczki z firmware w naszym linux&#39;ie nic nam nie da, bo pliki
rezydują na niezamontowanym jeszcze dysku. Jak zatem wybrnąć z tej wydawać by się było patowej
sytuacji?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Memtest86 dla EFI/UEFI i rEFInd</title>
      <link>https://morfikov.github.io/post/memtest86-dla-efi-uefi-i-refind/</link>
      <pubDate>Tue, 03 Mar 2020 04:05:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/memtest86-dla-efi-uefi-i-refind/</guid>
      <description>&lt;p&gt;Zapewne każdy z nas słyszał o narzędziu do testowania pamięci operacyjnej RAM zwanym memtest86. W
Debianie są dostępne dwa pakiety &lt;a href=&#34;https://tracker.debian.org/pkg/memtest86&#34;&gt;memtest86&lt;/a&gt; (&lt;a href=&#34;https://www.memtest86.com/&#34;&gt;strona projektu&lt;/a&gt;) oraz &lt;a href=&#34;https://tracker.debian.org/pkg/memtest86+&#34;&gt;memtest86+&lt;/a&gt;
(&lt;a href=&#34;http://www.memtest.org/&#34;&gt;strona projektu&lt;/a&gt;) , które można sobie zainstalować w systemie. Niemniej jednak, jak się
popatrzy na daty ostatnich wersji obu tych aplikacji (rok 2014), to mamy do czynienia z dość starym
oprogramowaniem. Tak czy inaczej, jeśli dany soft działa, to bez znaczenia powinno być jak stary on
jest. Problem w przypadku memtest86 dostarczanego w tych dwóch pakietach jest taki, że działa on w
zasadzie jedynie w konfiguracji BIOS, a nie EFI/UEFI. Dodatkowo, oryginalny memtest86 został
sprzedany PassMark&#39;owi, który &lt;a href=&#34;https://en.wikipedia.org/wiki/Memtest86&#34;&gt;od wersji 5.0 uczynił go własnościowym softem&lt;/a&gt;. To dlatego w
Debianie nie będzie już nowszej wersji memtest86. W dalszym ciągu memtest86 może działać w
konfiguracji EFI/UEFI ale potrzebna nam jest wersja, która to EFI/UEFI wspiera. Memtest86 zaczął
wspierać EFI/UEFI od wersji 5.0. Jeśli nam nie przeszkadza licencja własnościowa, to możemy sobie
przygotować memtest86, tak by można go było bez problemu odpalić z menadżera rozruchu &lt;a href=&#34;https://www.rodsbooks.com/refind/&#34;&gt;rEFInd&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Linux kernel EFI boot stub i zaszyfrowany Debian (LUKS&#43;LVM)</title>
      <link>https://morfikov.github.io/post/linux-kernel-efi-boot-stub-i-zaszyfrowany-debian-luks-lvm/</link>
      <pubDate>Mon, 02 Mar 2020 03:08:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/linux-kernel-efi-boot-stub-i-zaszyfrowany-debian-luks-lvm/</guid>
      <description>&lt;p&gt;Szukając informacji na temat uruchamiania mojego zaszyfrowanego Debiana (LUKSv2+LVM) na laptopie z
EFI/UEFI, natrafiłem na dość ciekawy mechanizm zwany &lt;a href=&#34;https://www.kernel.org/doc/Documentation/efi-stub.txt&#34;&gt;kernel EFI boot stub&lt;/a&gt;, czasem też zwany
kernel EFISTUB. Zadaniem tego mechanizmu jest uruchomienie linux&#39;a bezpośrednio z poziomu firmware
EFI z pominięciem czy też bez potrzeby stosowania dodatkowych menadżerów rozruchu (rEFInd) czy
bootloader&#39;ów (grub/grub2/syslinux/extlinux). Jakby nie patrzeć bardzo ciekawa alternatywa, która
wymaga, by się z nią zapoznać i ocenić jej przydatność pod kątem użyteczności.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przepisać linki initrd.img{,.old} i vmlinuz{,.old} z / do /boot/</title>
      <link>https://morfikov.github.io/post/jak-przepisac-linki-initrd-img-old-i-vmlinuz-old-do-boot/</link>
      <pubDate>Sun, 01 Mar 2020 20:30:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przepisac-linki-initrd-img-old-i-vmlinuz-old-do-boot/</guid>
      <description>&lt;p&gt;Mając możliwość skonfigurowania EFI/UEFI na moim laptopie, postanowiłem jak najbardziej się za to
przedsięwzięcie zabrać. Okazało się jednak, że w przypadku takiej dystrybucji linux&#39;a jak Debian,
to zadanie może być nieco problematyczne, zwłaszcza gdy chce się korzystać jedynie z menadżera
rozruchu jakim jest &lt;a href=&#34;https://www.rodsbooks.com/refind/&#34;&gt;rEFInd&lt;/a&gt;, czyli bez dodatkowego bootloader&#39;a (grub/grub2/syslinux/extlinux)
instalowanego bezpośrednio na dysku twardym i jednocześnie posiadając w pełni zaszyfrowany system
(LUKSv2 + LVM). Rzecz w tym, że w takiej sytuacji w konfiguracji rEFInd trzeba podawać ścieżki
bezpośrednio do plików &lt;code&gt;initrd.img&lt;/code&gt; oraz &lt;code&gt;vmlinuz&lt;/code&gt; (obecnych na partycji &lt;code&gt;/boot/&lt;/code&gt; ). W Debianie
nazwy tych plików mają format &lt;code&gt;initrd.img-x.x.x-x-amd64&lt;/code&gt; i &lt;code&gt;vmlinuz-x.x.x-x-amd64&lt;/code&gt; . Za każdym
razem, gdy wypuszczany jest nowy kernel, to ten numerek ( &lt;code&gt;x.x.x-x&lt;/code&gt; ) ulega zmianie, co pociąga za
sobą potrzebę ręcznego dostosowania konfiguracji rEFInd. Może i aktualizacje kernela w Debianie nie
są jakoś stosunkowo częste ale może istnieje sposób, by ten problem z dostosowaniem konfiguracji
rozwiązać?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Regulacja obrotów wentylatora w zależności od zmian temperatury w ThinkPad T430</title>
      <link>https://morfikov.github.io/post/regulacja-obrotow-wentylatora-w-zaleznosci-od-zmian-temperatury-w-thinkpad-t430/</link>
      <pubDate>Fri, 28 Feb 2020 23:00:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/regulacja-obrotow-wentylatora-w-zaleznosci-od-zmian-temperatury-w-thinkpad-t430/</guid>
      <description>&lt;p&gt;Ostatnio udało mi się nabyć dość niedrogo laptop Lenovo, a konkretnie był to model ThinkPad T430.
Maszyna jakby nie patrzeć jest bardzo kompatybilna z linux i w zasadzie nie mogę jej nic zarzucić,
przynajmniej póki co. Niemniej jednak, jest pewien szkopuł, który mnie zaczął ździebko irytować od
praktycznie samego początku jak tylko podłączyłem ten komputer do prądu. Chodzi o wentylator
chłodzący radiator procesora, który no troszkę daje o sobie znać i to mimo faktu, że temperatura
CPU jest w granicach 40 stopni. Przeglądając opcje w BIOS nie natrafiłem na nic co mogło by te
obroty wyregulować. Na szczęście w przypadku laptopów Lenovo można programowo zdefiniować obroty
wiatraka posługując się narzędziem &lt;a href=&#34;https://github.com/vmatare/thinkfan&#34;&gt;thinkfan&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pendrive multiboot z GRUB2 i obrazami ISO różnych dystrybucji Linux</title>
      <link>https://morfikov.github.io/post/pendrive-multiboot-z-grub2-i-obrazami-iso-roznych-dystrybucji-linux/</link>
      <pubDate>Fri, 08 Nov 2019 18:02:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pendrive-multiboot-z-grub2-i-obrazami-iso-roznych-dystrybucji-linux/</guid>
      <description>&lt;p&gt;Obrazy ISO różnych dystrybucji Linux, szczególnie te live, bywają niezastąpione w sytuacjach
kryzysowych. Dzięki takiej płytce CD/DVD czy pendrive (może być też i karta SD) można wybrnąć nawet
z najgorszych opresji bez potrzeby rezygnowania przy tym z graficznego środowiska pracy
podłączonego do internetu. Zwykle jednak użytkownicy są stawiani przed wyborem systemu, który mogą
sobie wgrać na zewnętrzny nośnik, by w późniejszym czasie przeprowadzać ewentualne prace naprawcze.
Chodzi generalnie o fakt, że taki obraz ISO czy IMG przy wgrywaniu konsumuje całe urządzenie bez
względu na jego rozmiar, i tak mając 32G pamięci na flash możemy wgrać w zasadzie tylko jeden
obraz, np. Debiana, a by wgrać obraz Ubuntu, to już trzeba albo osobnego pendrive albo nadpisać ten
poprzednio wgrany obraz. Takie rozwiązanie jest mało praktyczne i też generuje koszty. Na szczęście
można stworzyć boot&#39;owalny pendrive (w oparciu o GRUB/GRUB2), na którym można umieścić dowolną
ilość obrazów ISO i w fazie rozruchu wybrać sobie ten system, który nas interesuje, a wszystko
dzięki &lt;a href=&#34;https://github.com/thias/glim&#34;&gt;projektowi GLIM&lt;/a&gt; (GRUB Live ISO Multiboot).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak załadować profile AppArmor w fazie initrd/initramfs na Debian Linux</title>
      <link>https://morfikov.github.io/post/jak-zaladowac-profile-apparmor-w-fazie-initrd-initramfs-na-debian-linux/</link>
      <pubDate>Mon, 23 Sep 2019 19:05:21 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zaladowac-profile-apparmor-w-fazie-initrd-initramfs-na-debian-linux/</guid>
      <description>&lt;p&gt;Zapewne wielu użytkowników Debiana zdążyło już zauważyć, że od wydania 10 (Buster), AppArmor jest
włączony domyślnie. Nie powinien on raczej sprawiać żadnych problemów po doinstalowaniu pakietów
&lt;code&gt;apparmor-profiles&lt;/code&gt; oraz &lt;code&gt;apparmor-profiles-extra&lt;/code&gt; , które zawierają szereg profili pod różne
aplikacje użytkowe. Niemniej jednak, pewnych procesów nie da się ograniczyć przez AppArmor,
przynajmniej nie w standardowy sposób. Chodzi o to, że jeśli mamy już odpalony jakiś proces, to nie
ma możliwości zamknąć go w profilu AA do momentu aż zakończy on swoje działanie i zostanie
uruchomiony ponownie. Profile AppArmor&#39;a są ładowane podczas startu systemu w pewnym określonym
momencie ale szereg procesów systemowych startuje sporo wcześniej w stosunku do usługi AppArmor&#39;a.
W taki sposób nawet jeśli w późniejszym czasie profile zostaną załadowane, to i tak część procesów
nie będzie ograniczona bez względu na to czy zdefiniowaliśmy im zestaw reguł. Oczywiście można
próbować restartować usługi lub szeregować je po &lt;code&gt;apparmor.service&lt;/code&gt; ale nie zawsze tak się da
zrobić. Alternatywnym rozwiązaniem tego problemu jest ładowanie polityki AppArmor&#39;a w fazie
initrd/initramfs, czyli w momencie, w którym nasz system nie ma jeszcze nawet uruchomionego procesu
z PID z numerkiem &lt;code&gt;1&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Capability dac_read_search i dac_override w profilu AppArmor&#39;a</title>
      <link>https://morfikov.github.io/post/capability-dac_read_search-dac_override-w-profilu-apparmor/</link>
      <pubDate>Mon, 16 Sep 2019 18:20:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/capability-dac_read_search-dac_override-w-profilu-apparmor/</guid>
      <description>&lt;p&gt;Od jakiegoś czasu tworzę dla aplikacji w moim Debianie &lt;a href=&#34;https://gitlab.com/morfikov/debian-files/tree/master/configs/etc/apparmor.d&#34;&gt;profile pod AppArmor&lt;/a&gt;, tak by ograniczyć
programom swobodny dostęp do plików czy urządzeń. Tych profili zebrało się już trochę i podczas
pisania jednego z nich, zacząłem się zastanawiać czy wszystkie CAP&#39;y (linux capabilities), których
żądają procesy, są im faktycznie niezbędne do prawidłowego funkcjonowania. Chodzi póki co o
&lt;code&gt;dac_read_search&lt;/code&gt; i &lt;code&gt;dac_override&lt;/code&gt; . Co ciekawe, odmowa &lt;code&gt;dac_override&lt;/code&gt; w części aplikacji nie
powodowała żadnych negatywnych konsekwencji. Idąc dalej tym tropem, postanowiłem z paru profili AA
usunąć linijkę zawierającą &lt;code&gt;capability dac_override,&lt;/code&gt; zostawiając tym samym jedynie
&lt;code&gt;capability dac_read_search,&lt;/code&gt;  i zobaczyć co się stanie. Okazało się, że sporo programów już o
&lt;code&gt;dac_override&lt;/code&gt; nie prosi. Zatem co się zmieniło przez tych parę lat i czy ta zmiana dotyczy samych
aplikacji, a może kernela linux&#39;a?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wybudzanie linux&#39;a ze stanu uśpienia za sprawą myszy</title>
      <link>https://morfikov.github.io/post/wybudzanie-linuxa-ze-stanu-uspienia-za-sprawa-myszy/</link>
      <pubDate>Thu, 06 Jun 2019 16:10:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wybudzanie-linuxa-ze-stanu-uspienia-za-sprawa-myszy/</guid>
      <description>&lt;p&gt;Parę dni temu na jednych z forów, które czasem odwiedzam, &lt;a href=&#34;https://forum.linuxmint.pl/showthread.php?tid=323&#34;&gt;pojawił się wątek&lt;/a&gt; dotyczący problemu
jaki może nieść ze sobą budzenie linux&#39;a ze stanu uśpienia/wstrzymania (Suspend to RAM, STR) za
sprawą myszy. O ile w przypadku klawiatury sprawa wybudzania komputera zdaje się być dość oczywista,
to w przypadku tego małego gryzonia już niekoniecznie, bo wystarczy lekko mysz przemieścić po
blacie stołu czy innego biurka i system się nam wybudzi. Część komputerów ma stosowne opcje w
BIOS/UEFI i można za ich sprawą skonfigurować to jakie urządzenia będą mieć możliwość wybudzania
systemu. Niekiedy jednak, opcje w BIOS są tak ubogie, że nie mamy możliwości skonfigurowania tego
aspektu pracy naszej maszyny. Trzeba zatem w nieco inny sposób podejść do tego zagadnienia. Na
necie można się spotkać z radami odnośnie zapisu pliku &lt;code&gt;/proc/acpi/wakeup&lt;/code&gt; przez przesłanie do
niego czteroznakowych kodów, np. &lt;code&gt;EHC1&lt;/code&gt; czy &lt;code&gt;USB1&lt;/code&gt; . Takie rozwiązanie może nieść ze sobą negatywne
konsekwencje i powinno się go unikać. Lepszym rozwiązaniem jest napisanie reguły dla UDEV&#39;a dla
konkretnego urządzenia, gdzie będziemy mogli łatwo sterować (przez plik &lt;code&gt;power/wakeup&lt;/code&gt; ) tym czy
dane urządzenie ma mieć możliwość wybudzania systemu czy też nie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Montowanie dysków jako zwykły użytkownik z UDisks i PolicyKit</title>
      <link>https://morfikov.github.io/post/montowanie-dyskow-jako-zwykly-uzytkownik-z-udisks-i-policykit/</link>
      <pubDate>Fri, 26 Apr 2019 21:10:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/montowanie-dyskow-jako-zwykly-uzytkownik-z-udisks-i-policykit/</guid>
      <description>&lt;p&gt;Jeszcze nie tak dawno temu przeciętnej klasy desktop był wyposażony w pojedynczy i do tego
niewielkiej pojemności dysk twardy, który był w stanie pomieścić wszystkie pliki swojego
właściciela. Obecnie jednak większość maszyn ma tych nośników już kilka. Mowa tutaj nie tylko o
dyskach systemowych, które są fizycznie na stałe zamontowane w komputerze ale również o tych
wszystkich urządzeniach, które można podłączyć do portu USB. Polityka linux&#39;a wymusza, by wszystkie
nośniki pamięci masowej (HDD, SSD, pendrive czy też karty SD) były montowane w systemie jedynie
przez użytkowników posiadających uprawnienia administratora. Domyślnie taki przywilej ma jedynie
root. Zatem by uzyskać dostęp do danych na takim zewnętrznym nośniku musimy logować się na root&#39;a.
Jakby nie patrzeć ma to swoje plusy patrząc z perspektywy bezpieczeństwa, niemniej jednak czy
naprawdę potrzebny nam jest root do wgrania czegoś na nasz ulubiony pendrive? Widać nie tylko ja
zadawałem sobie takie pytanie i ktoś postanowił stworzyć narzędzie UDisks (lub jego nowszą wersję
UDisks2), które za pomocą mechanizmu PolicyKit (zwanym też PolKit) jest w stanie nadać stosowne
uprawnienia konkretnym użytkownikom systemu, przez co można określić zespół akcji, które będą oni w
stanie przeprowadzić bez potrzeby podawania hasła, np. montowanie czy odmontowanie zasobu.
Postanowiłem zatem zobaczyć jak ten duet sobie radzi na moim Debianie przy tradycyjnym użytkowaniu
systemu i ocenić jego stopień przydatności.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mechanizm trigger&#39;ów dla apt/aptitude w Debianie</title>
      <link>https://morfikov.github.io/post/mechanizm-trigger-dla-apt-aptitude-w-debianie/</link>
      <pubDate>Sun, 14 Apr 2019 00:10:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mechanizm-trigger-dla-apt-aptitude-w-debianie/</guid>
      <description>&lt;p&gt;Czasami pewna niestandardowa konfiguracja naszego linux&#39;a może sprawiać pewne problemy podczas
aktualizacji zainstalowanych w nim pakietów. Dla przykładu, wykorzystując mechanizm AppArmor do
okrojenia profilów Firefox&#39;a, muszę tworzyć osobne twarde dowiązania do binarki tej przeglądarki.
Te dowiązania mają taki problem, że jak usunie się plik, na który wskazywały, np. podczas
aktualizacji paczki, to utworzenie pliku w tym samym miejscu przez menadżer pakietów
&lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;aptitude&lt;/code&gt; nie sprawi, że te dowiązania zaczną ponownie funkcjonować poprawnie (tak jak to
jest w przypadku dowiązań symbolicznych). Z początku usuwałem te stare dowiązania i tworzyłem nowe
ale postanowiłem w końcu &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=30382&#34;&gt;poszukać rozwiązania&lt;/a&gt;,
które by zautomatyzowało cały ten proces i uczyniło go transparentnym dla użytkownika końcowego.
Tak natrafiłem na mechanizm Debianowych
trigger&#39;ów (&lt;a href=&#34;https://manpages.debian.org/unstable/dpkg-dev/deb-triggers.5.en.html&#34;&gt;deb-trigger&lt;/a&gt;),
które aktywują się za każdym razem ilekroć pliki w konkretnych ścieżkach są ruszane w jakiś sposób
przez menadżer pakietów. W tym artykule spróbujemy sobie zaprojektować taki trigger i obadać czy
może on nam się w ogóle do czegoś przydać&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Blokowanie niepożądanej komunikacji z nftables na linux</title>
      <link>https://morfikov.github.io/post/blokowanie-niepozadanej-komunikacji-z-nftables-na-linux/</link>
      <pubDate>Fri, 12 Apr 2019 20:53:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/blokowanie-niepozadanej-komunikacji-z-nftables-na-linux/</guid>
      <description>&lt;p&gt;Minęło już trochę czasu od momentu, w którym postanowiłem się przerzucić z &lt;code&gt;iptables&lt;/code&gt; na &lt;code&gt;nftables&lt;/code&gt;
w swoim Debianie i w zasadzie większość mechanizmów obronnych mojego laptopowego firewall&#39;a została
już z powodzeniem przeportowana na ten nowy filtr pakietów. Poza tymi starymi regułami próbuję
czasem ogarniać nieco bardziej wyrafinowane sposoby na unikanie zagrożeń sieciowych, choć
implementacja niektórych rzeczy nie zawsze jest taka oczywista, z tym, że niekoniecznie niemożliwa
do zrealizowana. Tak było w przypadku mechanizmu automatycznego blokowania hostów próbujących się
łączyć z daną maszyną, która sobie najwyraźniej tego nie życzy. Dla przykładu, jest serwer
udostępniający usługę SSH na porcie &lt;code&gt;11111&lt;/code&gt; i tylko ten port jest wystawiony na świat. Wszelkiego
rodzaju boty próbujące dostać się do maszyn linux&#39;owych próbkują z kolei głównie standardowe porty,
w tym przypadku &lt;code&gt;22&lt;/code&gt; . Ci użytkownicy, którzy powinni mieć dostęp do usługi SSH, wiedzą na jakim
porcie ona nasłuchuje. Można zatem założyć, że wszystkie połączenia na port &lt;code&gt;22&lt;/code&gt; będą dokonywane
przez boty albo przez użytkowników, którzy mają niecne zamiary. Wszystkie te połączenia można by
zatem zablokować tworząc mechanizm automatycznego banowania hostów w oparciu o czas ostatniej próby
połączenia, tak jak to zostało opisane mniej
więcej &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?pid=269383&#34;&gt;w tym wątku na forum&lt;/a&gt;. Problem w tym, że
tamto rozwiązanie dotyczy jedynie &lt;code&gt;iptables&lt;/code&gt; w połączeniu z &lt;code&gt;ipset&lt;/code&gt; , co nieco komplikuje wdrożenie
go w przypadku &lt;code&gt;nftables&lt;/code&gt; ale to zadanie jest jak najbardziej możliwe.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Unikanie SYN/ICMP/UDP/PING flood w linux z nftables</title>
      <link>https://morfikov.github.io/post/unikanie-syn-icmp-udp-ping-flood-w-linux-z-nftables/</link>
      <pubDate>Fri, 12 Apr 2019 20:12:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/unikanie-syn-icmp-udp-ping-flood-w-linux-z-nftables/</guid>
      <description>&lt;p&gt;Obecnie &lt;code&gt;nftables&lt;/code&gt; cierpi dość mocno z powodu pewnych problemów związanych z wydajnością przy
aplikowaniu reguł zapory sieciowej. Niemniej jednak, w stosunku do &lt;code&gt;iptables&lt;/code&gt; , &lt;code&gt;nftables&lt;/code&gt; posiada
tablicę &lt;code&gt;netdev&lt;/code&gt; , która jest w stanie nieco zyskać w oczach tych nieco bardziej wybrednych
użytkowników linux&#39;a. Chodzi generalnie o fakt, że ta tablica jest umieszczona zaraz na początku
drogi pakietów, tuż po odebraniu ich z NIC (interfejsu karty sieciowej), a biorąc pod uwagę fakt,
że ruch sieciowy, który nigdy ma nie trafić do naszej maszyny, powinien być zrzucany jak
najwcześniej (by nie marnować zasobów procesora i pamięci), to ta tablica wydaje się być idealnym
miejscem by zablokować cały niepożądany ruch przychodzący. Przy wykorzystaniu &lt;code&gt;iptables&lt;/code&gt; , takie
pakiety zrzuca się w tablicy &lt;code&gt;raw&lt;/code&gt; . Jeśli zaś chodzi o &lt;code&gt;nftables&lt;/code&gt; , to zrzucanie pakietów w
tablicy &lt;code&gt;netdev&lt;/code&gt; jest ponad dwu lub nawet trzykrotnie bardziej wydajne (szybsze i mniej
zasobożerne). Można zatem dość dobrze poradzić sobie z wszelkiego rodzaju atakami DOS/DDOS, np.
ICMP/PING flood czy SYN flood. Zastanawiające może być natomiast ogarnięcie ataku UDP flood ale
przed tym rodzajem ataku linux również jest w stanie się bez problemu ochronić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ograniczenie su do jednego użytkownika w Debianie</title>
      <link>https://morfikov.github.io/post/ograniczanie-su-do-jednego-uzytkownika-w-debianie/</link>
      <pubDate>Fri, 12 Apr 2019 19:40:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ograniczanie-su-do-jednego-uzytkownika-w-debianie/</guid>
      <description>&lt;p&gt;W dzisiejszych czasach dystrybucje linux&#39;a wykorzystują mechanizm &lt;code&gt;sudo&lt;/code&gt; do wykonywania operacji
jako administrator systemu. Zanika więc potrzeba stosowania polecenia &lt;code&gt;su&lt;/code&gt; , by zalogować się na
konto root i to z jego poziomu wykonywać wszystkie niezbędne rzeczy. Jednym z argumentów
zwolenników &lt;code&gt;sudo&lt;/code&gt; za takim sanem rzeczy jest możliwość nadania jedynie konkretnym użytkownikom w
systemie uprawnień do wykonywania poleceń jako administrator, podczas gdy inni użytkownicy
(niebędący w grupie &lt;code&gt;sudo&lt;/code&gt; ) nie mogą w ogóle korzystać z tego mechanizmu . No faktycznie, dostęp
do &lt;code&gt;su&lt;/code&gt; jest w zasadzie dla każdego użytkownika w systemie i tylko hasło konta admina dzieli ich od
uzyskania dość szerokich uprawnień. Niewiele jednak osób wie, że można skonfigurować &lt;code&gt;su&lt;/code&gt; w taki
sposób, by dostęp do niego mieli tylko ci
użytkownicy, &lt;a href=&#34;https://wiki.debian.org/WHEEL/PAM&#34;&gt;którzy powinni&lt;/a&gt;, np. ci obecni w grupie &lt;code&gt;wheel&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Badsector dysku HDD w kontenerze LUKS zawierającym LVM</title>
      <link>https://morfikov.github.io/post/badsector-dysku-hdd-w-kontenerze-luks-zawierajacym-lvm/</link>
      <pubDate>Sun, 31 Mar 2019 12:23:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/badsector-dysku-hdd-w-kontenerze-luks-zawierajacym-lvm/</guid>
      <description>&lt;p&gt;Podczas rutynowego skanu powierzchni dysków HDD w moim laptopie, S.M.A.R.T wykrył w jednym z nich
podejrzany blok, który zdawał się wyzionąć już ducha, przez co proces weryfikacji integralności
powierzchni dysku twardego nie był w stanie zakończyć się z powodzeniem. Komunikat zwracany przy
czytaniu padniętego sektora też był nieco dziwny: &lt;code&gt;bad/missing sense data, sb[]&lt;/code&gt; . Jakiś czas temu
już opisywałem
jak &lt;a href=&#34;https://morfikov.github.io
/post/uszkodzony-sektor-na-dysku-i-jego-realokoacja/&#34;&gt;realokować uszkodzony sektor dysku HDD&lt;/a&gt;
i w zasadzie wszystkie informacje zawarte w tamtym artykule można by wykorzystać do próby
poprawienia zaistniałego problemu, gdyby tylko nie fakt, że w tym przypadku badblock znalazł się w
obszarze voluminu logicznego LVM na partycji zaszyfrowanej przy pomocy mechanizmu LUKS. Taki
schemat układu partycji sprawia, że do realokowania błędnego bloku trzeba podejść nieco inaczej
uwzględniając w tym procesie kilka offset&#39;ów, bez których w zasadzie nic nie da się zrobić.
Postanowiłem zatem napisać na konkretnym przykładzie jak realokować badsector dysku, gdy do
czynienia mamy z zaszyfrowanym linux&#39;em zainstalowanym na voluminach LVM.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Format źródeł 3.0 (git) przy budowaniu paczek Debiana</title>
      <link>https://morfikov.github.io/post/format-zrodel-git-przy-budowaniu-paczek-debiana/</link>
      <pubDate>Wed, 27 Mar 2019 05:23:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/format-zrodel-git-przy-budowaniu-paczek-debiana/</guid>
      <description>&lt;p&gt;Pisząc jakiś czas
temu &lt;a href=&#34;https://morfikov.github.io
/post/poradnik-maintainera-czyli-jak-zrobic-pakiet-deb/&#34;&gt;poradnik na temat budowania paczek .deb&lt;/a&gt;
dla dystrybucji linux&#39;a Debian, poruszyłem w nim kwestię związaną z aktualizacją paczki, która
zawierała projekt utrzymywany w systemie kontroli wersji (CVS), np. git. Rozchodzi się tutaj o
format źródeł. Do niedawna myślałem, że są w zasadzie dwa formaty (tych, z których się zwykle
korzysta): &lt;code&gt;3.0 (native)&lt;/code&gt; oraz &lt;code&gt;3.0 (quilt)&lt;/code&gt; . Wszystkie moje pakiety budowane do tej pory miały
ten drugi format. Podglądając ostatnio kilka paczek &lt;code&gt;.deb&lt;/code&gt; , natrafiłem w jednej z nich na format
źródeł &lt;code&gt;3.0 (git)&lt;/code&gt; . Okazuje się, że ten format jest w stanie bardzo łatwo ogarnąć projekty
hostowane w takich serwisach jak GitHub, czy GitLab i można za jego sprawą nieco ułatwić sobie
życie. Wypadałoby zatem rzucić na niego okiem i ocenić go pod kątem przydatności przy budowaniu
pakietów dla Debiana.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problemy z plikiem wymiany SWAP przy hibernacji linux&#39;a</title>
      <link>https://morfikov.github.io/post/problemy-z-plikiem-wymiany-swap-przy-hibernacji-linuxa/</link>
      <pubDate>Sat, 23 Mar 2019 19:30:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problemy-z-plikiem-wymiany-swap-przy-hibernacji-linuxa/</guid>
      <description>&lt;p&gt;Po wyjaśnieniu paru rzeczy w kwestii przestrzeni wymiany, a
konkretnie [co jest lepsze: plik SWAP czy osobna partycja]({{ site.baseurl  }}/post/czy-w-linux-plik-swap-jest-lepszy-niz-partycja-wymiany/),
postanowiłem nieco zmienić układ partycji na dysku mojego laptopa (LUKS+LVM) i zaimplementować
sobie przestrzeń wymiany w postaci pliku SWAP. Standardowo jednak plik SWAP nie działa w przypadku
hibernacji linux&#39;a i kernel ma problemy z wybudzeniem maszyny z głębokiego snu. Jeśli zamierzamy
korzystać z hibernacji, to trzeba inaczej skonfigurować system, by nauczyć go korzystać z
przestrzeni wymiany w postaci pliku. W tym artykule rzucimy sobie okiem na ten niezbyt
skomplikowany proces.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Moduł TPE (Trusted Path Execution) dla kernela linux</title>
      <link>https://morfikov.github.io/post/modul-tpe-trusted-path-execution-dla-kernela-linux/</link>
      <pubDate>Fri, 22 Mar 2019 20:10:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-tpe-trusted-path-execution-dla-kernela-linux/</guid>
      <description>&lt;p&gt;Użytkownicy linux&#39;a są zwykle chronieni przez mechanizmy bezpieczeństwa, które ten system jest w
stanie zaoferować. Oczywiście deweloperzy różnych dystrybucji, np. Debiana, dokładają wszelkich
możliwych starań, by system jako całość był wstępnie skonfigurowany tak, by końcowy użytkownik nie
musiał za wiele majstrować przy zabezpieczeniach i mógł się czuć i być (przynajmniej względnie)
bezpieczny. No i faktycznie złowrogie oprogramowanie ma czasem spore problemy dostać się do maszyny,
którą operuje linux. Niemniej jednak, gdy już taki syf się do systemu dostanie, to zwykle niewiele
dzieli go od przejęcia kontroli nad komputerem. Może i część zabezpieczeń linux&#39;a zadziała i sprawi,
że taki wirus/trojan czy nawet zwykły skrypt będzie miał ograniczone pole manewru, to i tak będzie
on mógł przeprowadzić te akcje, które zwyczajny użytkownik systemu (nie root) jest zwykle w stanie
poczynić, np. odebrać dźwięk i video ze stosownych urządzeń i przesłać te dane przez sieć. My z
kolei możemy nawet tego faktu nie być świadomi. Jasne, że powinno się zwracać uwagę na to jakie
pliki się pobiera z internetu i nie uruchamiać wszystkiego lekkomyślnie ale też trzeba mieć na
uwadze fakt, że często jedna maszyna jest współdzielona, np. z członkami rodziny i oni już
niekoniecznie muszą władać zaawansowaną wiedza z zakresu IT, by przewidzieć wszystkie możliwe
zagrożenia czyhające na nich w sieci. Można za to postarać się, by uczynić naszą maszynę nieco
bardziej odporną na niezbyt przemyślane zachowania użytkowników jej systemu operacyjnego. Jednym z
kroków, które możemy podjąć, jest wdrożenie mechanizmu Trusted Path Execution (TPE), który póki co
jest dostępny jedynie w &lt;a href=&#34;https://patchwork.kernel.org/patch/9773791/&#34;&gt;formie patch&#39;a&lt;/a&gt; na kernel
linux&#39;a lub też jako jego &lt;a href=&#34;https://github.com/cormander/tpe-lkm&#34;&gt;osobny moduł&lt;/a&gt; oferujący sporo
więcej możliwości w stosunku do wspomnianej wcześniej łaty. W niniejszym artykule rzucimy sobie
okiem na ten cały mechanizm TPE i zobaczymy jak jest on w stanie uchronić nasz OS przed niezbyt
zaawansowaną ludzką inteligencją.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czy w linux plik SWAP jest lepszy niż partycja wymiany</title>
      <link>https://morfikov.github.io/post/czy-w-linux-plik-swap-jest-lepszy-niz-partycja-wymiany/</link>
      <pubDate>Fri, 22 Mar 2019 16:23:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czy-w-linux-plik-swap-jest-lepszy-niz-partycja-wymiany/</guid>
      <description>&lt;p&gt;Ostatnimi czasy, z racji rozwoju technologicznego, mamy do dyspozycji coraz to szybsze komputery,
co przekłada się w znacznym stopniu na prędkość wykonywania operacji przez ich systemy operacyjne.
Obecnie przeciętnej klasy desktop czy laptop jest już wyposażony w 16G czy nawet 32G pamięci
operacyjnej (w niedługim czasie
nawet &lt;a href=&#34;https://android.com.pl/news/200097-samsung-12-gb-ram-lpddr4x/&#34;&gt;smartfony będą posiadać 12G RAM&lt;/a&gt;).
Spada zatem zapotrzebowanie wykorzystania dysku twardego jako pamięci RAM. W linux używanie
dysku twardego jako rozszerzenie pamięci operacyjnej było i jest w dalszym ciągu realizowane za
sprawą przestrzeni wymiany SWAP. Ta przestrzeń wymiany może być zaimplementowana w postaci osobnej
partycji dysku twardego albo też jako plik umieszczony w obrębie systemu plików, np. ext4. Część
dystrybucji linux&#39;a decyduję się na porzucenie partycji wymiany na rzecz pliku SWAP. Czy taki krok
jest uzasadniony i czy korzystając aktualnie z partycji wymiany powinniśmy zmigrować na plik SWAP?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czym jest Online ext4 Metadata Check w linux&#39;owym LVM</title>
      <link>https://morfikov.github.io/post/czym-jest-online-ext4-metadata-check-w-linuxowym-lvm/</link>
      <pubDate>Sun, 17 Mar 2019 19:10:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czym-jest-online-ext4-metadata-check-w-linuxowym-lvm/</guid>
      <description>&lt;p&gt;Przeglądając dzisiaj rano logi systemowe wpadł mi w oczy komunikat, którego treść brzmiała mniej
więcej tak: &lt;code&gt;e2scrub Volume group &amp;quot;wd_blue_label&amp;quot; has insufficient free space (0 extents): 64 required&lt;/code&gt; , po którym z kolei można zanotować &lt;code&gt;e2scrub snapshot FAILED, will not check!&lt;/code&gt; oraz
&lt;code&gt;Failed to start Online ext4 Metadata Check for /media/Debian&lt;/code&gt; . Oczywiście ten punkt montowania to
nazwa partycji odnosząca się do jednego z dysków logicznych struktury LVM. Skąd się te błędy
wzięły? Przecież jeszcze do niedawna (przez ostatnich parę lat) wszystko z moim linux&#39;em
rezydującym na dysku (LUKS+LVM) było w porządku, a teraz nagle takie bardzo niepokojące błędy.
Czym jest w ogóle ten &lt;code&gt;e2scrub&lt;/code&gt; i czym jest ten cały &lt;code&gt;Online ext4 Metadata Check&lt;/code&gt; , który
najwyraźniej ma coś wspólnego ze sprawdzaniem systemu plików voluminów logicznych w locie? No i
najważniejsze chyba pytanie -- czemu to nie działa jak należy?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak na Debianie zrobić pakiet .deb zawierający moduł kernela linux (DKMS)</title>
      <link>https://morfikov.github.io/post/jak-na-debianie-zrobic-pakiet-deb-zawierajacy-modul-kernela-linux-dkms/</link>
      <pubDate>Sun, 17 Mar 2019 09:37:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-na-debianie-zrobic-pakiet-deb-zawierajacy-modul-kernela-linux-dkms/</guid>
      <description>&lt;p&gt;Kernel linux&#39;a jest dość złożonym organizmem, który może zostać rozbudowany przy pomocy dodatkowego
kodu ładowanego w postaci zewnętrznych modułów. Czasem ze względu na wczesny etap prac nad nową
funkcjonalnością jądra, taki moduł może zachowywać się dość nieprzewidywalnie, co przekreśla jego
szanse na pojawienie się w stabilnych wydaniach kernela. Czasem też z jakiegoś niezrozumiałego
powodu pewne rzeczy nie są celowo dodawane do jądra operacyjnego. Jedną z nich
jest &lt;a href=&#34;https://github.com/cormander/tpe-lkm&#34;&gt;moduł Trusted Path Execution&lt;/a&gt; (TPE), który jest w
stanie znacznie poprawić bezpieczeństwo systemu uniemożliwiając przeprowadzenie w nim szeregu
podejrzanych działań. W Debianie tego typu niedogodności związane z brakiem pewnych modułów można
obejść przez
zastosowanie &lt;a href=&#34;https://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support&#34;&gt;mechanizmu DKMS&lt;/a&gt;, który
przy instalacji modułu spoza głównego drzewa kernela linux&#39;a jest nam go w stanie automatycznie
zbudować. W repozytorium dystrybucji Debiana znajduje się już szereg pakietów z modułami (mają
końcówki &lt;code&gt;-dkms&lt;/code&gt; ) i w prosty sposób można je sobie doinstalować. Co jednak w przypadku, gdy mamy
moduł, którego nikt jeszcze nie przygotował i nie wrzucił do repozytorium? Co, gdy takich modułów
mamy kilka, a przy tym korzystamy z najnowszego stabilnego kernela, który jest aktualizowany
średnio co kilka dni? Ręczna budowa wszystkich zewnętrznych modułów za każdym razem jak tylko
wyjdzie nowsza wersja kernela, to nie najlepsze wyjście, zwłaszcza jak dojdzie nam do tego
aktualizacja samych modułów. Można za to zrobić sobie paczkę &lt;code&gt;.deb&lt;/code&gt; tak, by przy instalacji nowego
jądra operacyjnego, system nam automatycznie zbudował wszystkie dodatkowe moduły, których nasz
komputer wymaga do poprawnej pracy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czy linux&#39;owy firewall powinien blokować pakiety not-syn w stanie NEW</title>
      <link>https://morfikov.github.io/post/czy-linuxowy-firewall-powinien-blokowac-pakiety-not-syn-w-stanie-new/</link>
      <pubDate>Fri, 15 Mar 2019 18:02:21 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czy-linuxowy-firewall-powinien-blokowac-pakiety-not-syn-w-stanie-new/</guid>
      <description>&lt;p&gt;Od czasu do czasu w logu systemowym mojego Debiana można zanotować szereg pakietów przychodzących,
które są zrzucane przez linux&#39;owy firewall (&lt;code&gt;nftables&lt;/code&gt;/&lt;code&gt;iptables&lt;/code&gt; ). Po krótkiej analizie okazało
się, że są to pakiety protokołu TCP mające stan &lt;code&gt;NEW&lt;/code&gt; (czyli są to nowe połączenia) ale
niezawierające przy tym flagi &lt;code&gt;SYN&lt;/code&gt; . Mój laptop nie ma aktualnie przydzielonego zewnętrznego
routowalnego adresu IPv4/IPv6, więc nasunęło się pytanie o przyczynę takiego stanu
rzeczy -- przecie będąc za NAT, nikt spoza sieci nie powinien być w stanie nawiązać połączenia z
moją maszyną, a ewidentnie co się do jej bram dobija i to nie z adresu lokalnego. Niby mam też
odfiltrowane pakiety w stanie &lt;code&gt;INVALID&lt;/code&gt; (np. te mające niepoprawny zestaw flag) ale widać te
pakiety, o których mowa, nie zaliczają się do tego stanu, więc wygląda na to, że wszystko z nimi
jest w porządku. Czy tego typu pakiety TCP w stanie &lt;code&gt;NEW&lt;/code&gt; niemające ustawionej flagi &lt;code&gt;SYN&lt;/code&gt;
stanowią jakieś zagrożenie dla naszego komputera? Czy powinno się je zablokować, a może przepuścić
w filtrze pakietów? A jeśli zablokować, to czy zwykły &lt;code&gt;DROP&lt;/code&gt; wystarczy czy może powinno się te
pakiety potraktować przy pomocy &lt;code&gt;REJECT&lt;/code&gt; ?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak optymalnie podzielić dysk HDD/SSD na partycje pod linux</title>
      <link>https://morfikov.github.io/post/jak-optymalnie-podzielic-dysk-hdd-ssd-na-partycje-pod-linux/</link>
      <pubDate>Fri, 15 Mar 2019 17:05:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-optymalnie-podzielic-dysk-hdd-ssd-na-partycje-pod-linux/</guid>
      <description>&lt;p&gt;Ostatnio przeglądając nowe wpisy na forach trafiłem
na &lt;a href=&#34;https://forum.linuxmint.pl/showthread.php?tid=112&#34;&gt;pytanie o podział dysku&lt;/a&gt; pod instalację
linux&#39;a. Autorowi wątku chodziło o jak najlepszy podział dysku HDD ale najwyraźniej pogubił się on
w tym całym bałaganie informacyjnym, który tyczy się procesu partycjonowania nośnika pod kątem jego
optymalnego wykorzystania przez linux. Zagadnienie podziału dysków HDD/SSD nie jest zbytnio jakoś
skomplikowane, a mimo to wciąż pojawiają się pytania o poprawne przeprowadzenie tego procesu i to
pomimo faktu, że mamy obecnie już dość sporych rozmiarów dyski. To pytanie powoli przestaje mieć
jakikolwiek sens, przynajmniej jeśli chodzi o przeciętnego Kowalskiego instalującego linux&#39;a u
siebie na kompie (desktop/laptop). Postanowiłem jednak napisać parę słów na temat tego całego
podziału dysku na partycje, tak by dobrać optymalny ich rozmiar przy instalowaniu dowolnej
dystrybucji linux&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Brak wsparcia dla ipset w nftables</title>
      <link>https://morfikov.github.io/post/brak-wsparcia-dla-ipset-w-nftables/</link>
      <pubDate>Sat, 02 Mar 2019 02:21:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/brak-wsparcia-dla-ipset-w-nftables/</guid>
      <description>&lt;p&gt;Użytkownicy Debiana często w roli firewall&#39;a wykorzystują już dość leciwy &lt;code&gt;iptables&lt;/code&gt; . W zasadzie,
to tej implementacji linux&#39;owego filtra pakietów sieciowych nic nie dolega, no może poza szeregiem
wad konstrukcyjnych, które są obecnie tak ciężkie do zaadresowania, że w sumie trzeba by cały ten
&lt;code&gt;iptables&lt;/code&gt; napisać od początku. Wszystko przez rozwój internetu, za sprawą którego pojawiło się
zapotrzebowanie na tworzenie całej masy reguł (w postaci adresów/portów źródłowych/docelowych),
gdzie w standardowym &lt;code&gt;iptables&lt;/code&gt; trzeba tworzyć osobne wpisy. Im więcej reguł w filtrze, tym
przechodzenie pakietów przez zaporę sieciową trwa dłużej i wiąże się z mocnym obciążeniem dla
procesora (zwłaszcza, gdy tych reguł jest kilkadziesiąt tysięcy). By jakoś uporać się z tymi
problemami (nieznanymi w innych filtrach sieciowych) stworzono &lt;code&gt;ipset&lt;/code&gt; . I faktycznie odciążył on
mocno procesor maszyny ale i tak nie wyeliminował on podstawowych wad &lt;code&gt;iptables&lt;/code&gt; . Dlatego też
zaczęto szukać innego rozwiązania i tak pojawiła się alternatywa m.in. w postaci &lt;code&gt;nftables&lt;/code&gt; . W
przyszłym stabilnym Debianie (buster) &lt;code&gt;nftables&lt;/code&gt; będzie wykorzystywany jako domyślny filtr pakietów
i ci, który korzystali z &lt;code&gt;ipset&lt;/code&gt; mogą się nieco zdziwić, że &lt;code&gt;nftables&lt;/code&gt; nie posiada dla niego
wsparcia. Rzecz w tym, że &lt;code&gt;nftables&lt;/code&gt; potrafi natywnie obsługiwać listy adresów/portów i &lt;code&gt;ipset&lt;/code&gt;
nie jest mu w tym do niczego potrzebny.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przy pomocy USBguard zabezpieczyć porty USB przed złośliwymi urządzeniami</title>
      <link>https://morfikov.github.io/post/jak-przy-pomocy-usbguard-zabezpieczyc-porty-usb-przed-zlosliwymi-urzadzeniami/</link>
      <pubDate>Sun, 24 Feb 2019 12:00:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przy-pomocy-usbguard-zabezpieczyc-porty-usb-przed-zlosliwymi-urzadzeniami/</guid>
      <description>&lt;p&gt;Ostatnio na
Niebezpieczniku &lt;a href=&#34;https://niebezpiecznik.pl/post/zlosliwy-kabel-usb-ktory-zmienia-sie-w-klawiature-i-infekuje-twoj-komputer/&#34;&gt;pojawił się artykuł&lt;/a&gt;
na temat niezbyt przyjaznych urządzeń podłączanych do komputera za sprawą portów USB (opisanych na
przykładzie niepozornego przewodu) i tego jaką szkodę tego typu hardware może nam wyrządzić w
systemie. Ataki z wykorzystaniem podstawionych urządzeń zadziałają nawet na linux, choć pewnie cała
masa użytkowników wyznaje jeszcze mit, że ich komputer jest bezpieczny, bo przecie używają
alternatywnego systemu operacyjnego, który jest OpenSource i za priorytet obrał sobie szeroko
rozumiane bezpieczeństwo. Niestety nie jest tak różowo jakby mogło się co niektórym wydawać ale
można ten stan rzeczy naturalnie zmienić i nie trzeba przy tym rekompilować kernela z zamiarem
wyłączenia obsługi modułu USB, co ten opisany w podlinkowanym artykule atak oczywiście by również
powstrzymało. Zamiast tego możemy zainstalować sobie narzędzie &lt;code&gt;usbguard&lt;/code&gt; i przy jego pomocy
skonfigurować politykę podłączanych do portów USB urządzeń.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak włączyć dźwięk w kontenerze Docker&#39;a za sprawą PulseAudio</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-dzwiek-w-kontenerze-dockera-za-sprawa-pulseaudio/</link>
      <pubDate>Sat, 16 Feb 2019 13:22:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-dzwiek-w-kontenerze-dockera-za-sprawa-pulseaudio/</guid>
      <description>&lt;p&gt;Jakiś czas temu postanowiłem przetestować sposób zamknięcia graficznych aplikacji w kontenerze
Docker&#39;a. Całe rozwiązanie zostało opisane na
przykładzie &lt;a href=&#34;https://morfikov.github.io
/post/uruchamianie-graficznych-aplikacji-w-kontenerach-dockera/&#34;&gt;skonteneryzowania przeglądarki Firefox&lt;/a&gt;.
Ten opisany w podlinkowanym artykule pomysł był nawet całkiem przyzwoity ale nie nadaje się on, gdy
w grę wchodzą programy odtwarzające dźwięk. No może to za dużo powiedziane, że się nie nadaje, ale
z pewnością brakuje mu jednego istotnego elementu. Nawet ta przykładowa przeglądarka internetowa
jest w stanie odtwarzać dźwięki jeśli się odwiedzi stosowną stronę WWW. Standardowo jednak nic nie
usłyszymy w głośnikach, gdy odpalimy dajmy na to stronę YouTube i puścimy jakiś materiał video.
Dlatego też wypadałoby skonfigurować dźwięk i przesłać go do serwera PulseAudio, który będzie
odpalony na naszym linux&#39;owym hoście. Kiedyś już tego typu rozwiązanie nawet opisywałem na
przykładzie &lt;a href=&#34;https://morfikov.github.io
/post/pulseaudio-i-przesylanie-dzwieku-przez-siec/&#34;&gt;zintegrowania PulseAudio z kontenerami LXC&lt;/a&gt;.
Okazuje się, że tamto rozwiązanie znajduje również zastosowanie w przypadku Docker&#39;a. Trzeba tylko
nieco inaczej skonfigurować kontener i właśnie tej kwestii będzie dotyczył niniejszy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migracja z iptables na nftables w Debianie</title>
      <link>https://morfikov.github.io/post/migracja-z-iptables-na-nftables-w-debianie/</link>
      <pubDate>Sat, 16 Feb 2019 11:05:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/migracja-z-iptables-na-nftables-w-debianie/</guid>
      <description>&lt;p&gt;Zgodnie z &lt;a href=&#34;http://ral-arturo.org/2018/06/16/nfws2018.html&#34;&gt;informacją&lt;/a&gt;, która pojawiła się już ponad pół roku temu, dystrybucje linux&#39;a powoli
zaczynają odchodzić od &lt;code&gt;iptables&lt;/code&gt; . Prawdopodobnie w niedługim czasie &lt;code&gt;iptables&lt;/code&gt; zostanie już
całkowicie wyparty i zastąpiony przez &lt;code&gt;nftables&lt;/code&gt; , przynajmniej jeśli chodzi o desktopy. Nawet
&lt;a href=&#34;https://wiki.debian.org/nftables#Current_status&#34;&gt;Debian zakomunikował&lt;/a&gt;, że następne wydanie stabilne tej dystrybucji (Buster) będzie domyślnie
wykorzystywało &lt;code&gt;nftables&lt;/code&gt; . Wypadałoby zatem się przenieść na ten nowy framework i przygotować
sobie kilka podstawowych reguł firewall&#39;a, które zabezpieczoną naszą maszynę przed nieautoryzowanym
dostępem z sieci.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czy brak wsparcia dla SYNPROXY w nftables jest problemem</title>
      <link>https://morfikov.github.io/post/czy-brak-wsparcia-dla-synproxy-w-nftables-jest-problemem/</link>
      <pubDate>Sat, 16 Feb 2019 10:20:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czy-brak-wsparcia-dla-synproxy-w-nftables-jest-problemem/</guid>
      <description>&lt;p&gt;Przenosząc swoje reguły z &lt;code&gt;iptables&lt;/code&gt; na &lt;code&gt;nftables&lt;/code&gt; zauważyłem, że jedna z nich (gdyby tylko jedna)
nie została przetłumaczona przez ten dedykowany translator do reguł. Chodzi
o &lt;a href=&#34;https://morfikov.github.io
/post/unikanie-atakow-ddos-z-synproxy/&#34;&gt;mechanizm SYNPROXY&lt;/a&gt;, który jest zwykle wykorzystywany do ograniczenia skali ataków DDOS z
wykorzystaniem pakietów SYN. Co by nie mówić, to ochrona jaką daje SYNPROXY jest jak najbardziej
pożądana z perspektywy serwerów. Dlaczego zatem, gdy się zajrzy na stronę
&lt;a href=&#34;https://wiki.nftables.org/wiki-nftables/index.php/Supported_features_compared_to_xtables&#34;&gt;wspieranych rzeczy w nftables&lt;/a&gt;, to przy SYNPROXY widnieje bliżej nieokreślone sformułowanie
&lt;code&gt;consider native interface&lt;/code&gt; ? Po rozmowach z deweloperami udało się ustalić, że ten zapis oznacza
brak wsparcia dla SYNPROXY w &lt;code&gt;nftables&lt;/code&gt; . Jeśli zatem ktoś wykorzystuje ten mechanizm mając dodane
stosowne reguły w &lt;code&gt;iptables&lt;/code&gt; , to czy powinien się on obawiać przejścia na &lt;code&gt;nftables&lt;/code&gt; ?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak sklonować duże repozytorium git na niestabilnym łączu sieciowym</title>
      <link>https://morfikov.github.io/post/jak-sklonowac-duze-repozytorium-git-na-niestabilnym-laczu-sieciowym/</link>
      <pubDate>Sat, 16 Feb 2019 05:29:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-sklonowac-duze-repozytorium-git-na-niestabilnym-laczu-sieciowym/</guid>
      <description>&lt;p&gt;Połączenie z internetem, z którego ostatnio przyszło mi korzystać, nie należało zbytnio do tych
najbardziej wydajnych pod względem prędkości przesyłu danych. O ile szybkość transferu można by
jeszcze przemilczeć, to owe łącze nie należało też do tych najstabilniejszych i czasem kontakt
ze światem był zwyczajnie zrywany. Krótko rzecz ujmując, ten net nadawał się chyba jedynie do
przeglądania stron WWW. Pech jednak chciał, że potrzebowałem zassać na takim
połączeniu &lt;a href=&#34;https://salsa.debian.org/kernel-team/linux&#34;&gt;repozytorium git&#39;a z patch&#39;ami Debiana&lt;/a&gt;
nakładanymi na kernel linux&#39;a. To repozytorium nie należy do największych ale też do małych ono
się nie zalicza -- waży około 2 GiB. Oczywiście można by zrobić jedynie płytki klon takiego repo za
sprawą &lt;code&gt;git clone --depth=1&lt;/code&gt; , co skutkowałoby pobraniem plików w wersji z ostatniego commit&#39;a, co
z kolei zredukowałoby w znacznym stopniu wielkość pobieranych danych (parę-paręnaście MiB). Co
jednak zrobić w przypadku, gdy musimy sklonować sporych rozmiarów repozytorium git, a dysponujemy
przy tym dość wolnym połączeniem sieciowym? Czy jest to w ogóle możliwe, bo przecież git nie ma
zaimplementowanej opcji wznawiania przerwanej synchronizacji i każde zakłócenie tego procesu
skutkować będzie tym, że całe repozytorium trzeba będzie pobrać jeszcze raz i to bez względu na to,
czy proces się zawiesi zaraz na początku, czy też pod koniec operacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak włączyć IPv6 Privacy Extensions w Debianie (SLAAC)</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-ipv6-privacy-extensions-w-debianie-slaac/</link>
      <pubDate>Sun, 10 Feb 2019 08:22:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-ipv6-privacy-extensions-w-debianie-slaac/</guid>
      <description>&lt;p&gt;Protokół IPv6 został opracowany już dość dawno temu, a jednak ilość hostów w internecie
komunikujących się za jego pomocą wciąż nie jest zbyt wysoka
i &lt;a href=&#34;https://www.google.com/intl/en/ipv6/statistics.html&#34;&gt;oscyluje w granicach 25%&lt;/a&gt;. Faktem jest, że
migracja z IPv4 na IPv6 może być sporym kosztem dla niektórych podmiotów jeśli chodzi o kwestię
związaną z wymianą sprzętu i ze zmianą konfiguracji sieci, co pewnie zniechęca część ISP do
wdrożenia tego protokołu. Użytkownicy korzystający z sieci z kolei nie wiedzieć czemu też
preferują IPv4 nad IPv6. Jakiś czas temu czytałem nawet artykuł na temat zagrożenia prywatności
jakie może nieść ze sobą protokół IPv6. Chodzi generalnie o to, że obecnie wszyscy przywykliśmy do
rozwiązania jakie oferuje nam NAT, które jest w stanie utrudnić nieco naszą identyfikację i analizę
naszej aktywności w internecie. W przypadku IPv6 adresy IP są dość unikatowe w skali globalnej, a
część odpowiedzialna za identyfikację hosta (ostatnie 64 bity) stanowi identyfikator EUI64, który z
kolei jest generowany na podstawie adresu MAC karty sieciowej. W taki oto sposób interfejs tej
karty będzie miał stały identyfikator EUI64, a hosta będzie można zidentyfikować bez problemu i
bez względu na to u którego ISP podłączymy nasz komputer. Rozwiązaniem tego problemu jest mechanizm
zwany IPv6 Privacy Extensions. Przydałoby się zatem rzucić na niego okiem i jeśli okaże się
użyteczny, to wypadałoby go włączyć w naszym Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ustalić nazwę procesu korzystającego z sieci</title>
      <link>https://morfikov.github.io/post/jak-ustalic-nazwe-procesu-korzystajacego-z-sieci/</link>
      <pubDate>Fri, 08 Feb 2019 20:10:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ustalic-nazwe-procesu-korzystajacego-z-sieci/</guid>
      <description>&lt;p&gt;Konfigurując filtr pakietów &lt;code&gt;iptables&lt;/code&gt;/&lt;code&gt;nftables&lt;/code&gt; na Debianie zwykle nie przykładamy większej wagi
do procesów, które chcą nawiązać połączenia wychodzące z naszego linux&#39;owego hosta. Mamy przecież
&amp;quot;skonfigurowany&amp;quot; firewall w łańcuchach &lt;code&gt;INPUT&lt;/code&gt; i &lt;code&gt;FORWARD&lt;/code&gt; i wszelkie zagrożenia z sieci nie
powinny nas dotyczyć. Problem w tym, że jeśli jakiś złowrogi proces zostanie uruchomiony w naszym
systemie, to jest on w stanie komunikować się ze światem zewnętrznym praktycznie bez żadnych
ograniczeń za sprawą braku jakichkolwiek reguł w łańcuchu &lt;code&gt;OUTPUT&lt;/code&gt; . Można oczywiście temu zaradzić
budując zaporę sieciową na bazie &lt;code&gt;cgroups&lt;/code&gt; , gdzie każda aplikacja będzie miała oznaczone pakiety,
przez co będzie można je rozróżnić i zablokować albo przepuścić przez filter. W tym wpisie jednak
nie będziemy się zajmować konstrukcją tego typu FW, tylko spróbujemy sobie odpowiedzieć na pytanie
jak namierzyć proces, który komunikuje się z siecią (lub też próbuje), posiadając jedynie log
&lt;code&gt;iptables&lt;/code&gt;/&lt;code&gt;nftables&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak uruchomić kilka usług w kontenerze Docker&#39;a</title>
      <link>https://morfikov.github.io/post/jak-uruchomic-kilka-uslug-w-kontenerze-dockera/</link>
      <pubDate>Sat, 02 Feb 2019 07:20:43 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-uruchomic-kilka-uslug-w-kontenerze-dockera/</guid>
      <description>&lt;p&gt;W kontenerach Docker&#39;a nie powinno się uruchamiać więcej usług niż jedna. Czasami jednak zachodzi
potrzeba, by właśnie uruchomić kilka niezależnych od siebie procesów, które będą ze sobą
współpracować w obrębie takiego pojedynczego kontenera. Weźmy sobie na przykład serwer WWW Apache2
i bazę danych MySQL/MariaDB. Każda z tych usług posiada swój dedykowany kontener (nawet oficjalny)
i generalnie skonfigurowanie komunikacji między tymi dwoma kontenerami Docker&#39;a nie jest niczym
trudnym. Jeśli jednak ktoś by się uparł, to może stworzyć sobie taki kontener, który będzie
uruchamiał obie te usługi. Oczywiście w tym przypadku raczej nikt nie będzie łączył tych dwóch
kontenerów w jeden ale są pewne sytuacje, w których będziemy chcieli uruchomić więcej niż jeden
proces wewnątrz kontenera i gdy ten czas nadejdzie, to wypadałoby wiedzieć jak się do tego
przedsięwzięcia zabrać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zalogować błędy podczas zamykania systemu Debian Linux</title>
      <link>https://morfikov.github.io/post/jak-zalogowac-bledy-podczas-zamykania-systemu-debian-linux/</link>
      <pubDate>Sat, 02 Feb 2019 06:12:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zalogowac-bledy-podczas-zamykania-systemu-debian-linux/</guid>
      <description>&lt;p&gt;By wyłączyć komputer, jego system operacyjny musi pierw zatrzymać (lub też ubić siłowo) wszystkie
działające usługi za wyjątkiem tego mającego PID z numerkiem 1. Zwykle proces zamykania się systemu
Debian Linux nie trwa więcej niż parę sekund ale czasami pojawiają się dziwne problemy, które mogą
to zadanie utrudnić lub też całkowicie uniemożliwić. Nawet jeśli system będzie się w stanie
zresetować, to zanim to nastąpi, to na konsoli mogą pojawić się komunikaty mogące pomóc nam w
zdiagnozowaniu dolegliwości, która doskwiera naszej maszynie. Problem w tym, że część tych
wiadomości nie zostanie nigdy zalogowana do pliku, gdzie moglibyśmy ich poszukać. Dzieje się tak
dlatego, że w pewnym określonym momencie zamykania się systemu trzeba wyłączyć usługę logowania, co
zwykle widać w logu jako &lt;code&gt;systemd-journald[]: Journal stopped&lt;/code&gt; . Gdy dziennik zostanie zatrzymany,
żadna wiadomość, która od tego momentu pojawi się na ekranie, nie zostanie już zalogowana do pliku.
Jeśli teraz pojawią nam się ostrzeżenia lub błędy, a po chwili komputer się zresetuje, to możemy
mieć nie lada problem z ustaleniem przyczyny mimo, że system nam ją zgłasza. Przydałoby się zapisać
te komunikaty, tylko jak to zrobić, skoro usługa logowania jest już nieaktywna?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uruchamianie graficznych aplikacji w kontenerach Docker&#39;a</title>
      <link>https://morfikov.github.io/post/uruchamianie-graficznych-aplikacji-w-kontenerach-dockera/</link>
      <pubDate>Sun, 27 Jan 2019 11:32:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uruchamianie-graficznych-aplikacji-w-kontenerach-dockera/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/jak-uruchomic-firefoxa-w-osobnej-przestrzeni-nazw-sieciowych/&#34;&gt;Bawiąc się ostatnio na Debianie przestrzeniami nazw sieciowych&lt;/a&gt;,
wpadł mi do głowy pomysł na nieco bardziej zautomatyzowaną formę separacji procesów użytkownika od
pozostałej części systemu. Co by nie mówić, opisany w podlinkowanym artykule sposób uruchomienia
Firefox&#39;a niezbyt mi przypadł do gustu. Nowy sposób separacji zakłada za to wykorzystanie
kontenerów Docker&#39;a, w których to będzie uruchamiany dowolny proces, np. Firefox, a całym
przedsięwzięciem związanym z procesem konteneryzacji będzie zajmował się już Docker. W ten sposób
uruchomienie dowolnej aplikacji, w tym też tych graficznych (GUI), będzie sprowadzać się do wydania
w terminalu tylko jednego polecenia. Zatem do dzieła.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ręcznie zweryfikować sygnaturę modułu kernela linux</title>
      <link>https://morfikov.github.io/post/jak-recznie-zweryfikowac-sygnature-modulu-kernela-linux/</link>
      <pubDate>Sat, 26 Jan 2019 10:10:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-recznie-zweryfikowac-sygnature-modulu-kernela-linux/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio kernelem linux na dystrybucji Debian i opcjami mającymi poprawić jego
bezpieczeństwo, włączyłem
sobie &lt;a href=&#34;https://morfikov.github.io
/post/automatyczne-podpisywanie-modulow-kernela-przez-dkms/&#34;&gt;mechanizm podpisywania modułów&lt;/a&gt;.
W ten sposób żaden zewnętrzny moduł nie zostanie załadowany przez jądro operacyjne, no chyba, że
taki moduł będzie podpisany przez ten sam klucz co i kernel. Zdziwiłem się odrobinę, gdy moim
oczom pokazał się hash &lt;code&gt;md4&lt;/code&gt; w wyjściu polecenia &lt;code&gt;modinfo&lt;/code&gt; . Jak się okazało później, to niezbyt
dokładne zinterpretowanie wiadomości PKCS#7 przez &lt;code&gt;kmod&lt;/code&gt; było (i nadal jest) wynikiem &lt;a href=&#34;https://bugzilla.redhat.com/show_bug.cgi?id=1320921&#34;&gt;błędu
obecnego w tym pakiecie od już paru lat&lt;/a&gt;. W
efekcie &lt;code&gt;modinfo&lt;/code&gt; nie jest w stanie zweryfikować tej sygnatury, a w moim umyśle zaistniało pytanie:
czy istnieje w ogóle możliwość manualnego sprawdzenia czy ta sygnatura jest w porządku? Kernel co
prawda ten cały zabieg przeprowadza automatycznie ale przydałoby się ręcznie zweryfikować
poprawność sygnatury modułu i przy okazji obadać sobie co tak naprawdę się dzieje podczas tego
procesu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak uruchomić Firefox&#39;a w osobnej przestrzeni nazw sieciowych</title>
      <link>https://morfikov.github.io/post/jak-uruchomic-firefoxa-w-osobnej-przestrzeni-nazw-sieciowych/</link>
      <pubDate>Sun, 20 Jan 2019 21:10:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-uruchomic-firefoxa-w-osobnej-przestrzeni-nazw-sieciowych/</guid>
      <description>&lt;p&gt;Domyślnie każdy proces uruchomiony na linux (w tym przypadku Debian) dziedziczy swoją przestrzeń
nazw sieciowych (network namespaces) od procesu nadrzędnego, standardowo od procesu init (tego z
pid 1). W takim przypadku, wszystkie procesy współdzielą tę samą przestrzeń nazw sieciowych, przez
co mają dostęp do tych samych interfejsów sieciowych, tych samych tras routingu, a reguły
firewall&#39;a czy ustawienia serwerów DNS w jednakowym stopniu dotyczą wszystkich procesów i
zmieniając sieciową konfigurację systemu robimy to globalnie dla wszystkich tych procesów
jednocześnie. Czasami tego typu mechanika działania sieci nie jest zbyt pożądana z punktu
widzenia bezpieczeństwa lub też prywatności użytkownika. Przykładem mogą być przeglądarki
internetowe, np. Firefox, Opera czy Google Chrome/Chromium, które mogą zdradzić nasz lokalny adres
IP (w przypadku stosowania NAT). Jako, że też zostawiamy wszędzie nasz namiar w postaci
zewnętrznego adresu IP, to oba te adresy mogą nas bez większego problemu zidentyfikować w
internecie. Można jednak postarać się, by ten adres lokalny, który zwróci przeglądarka
internetowa, różnił się od tego, który przydziela nam nasz operator ISP.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatyczne podpisywanie modułów kernela przez DKMS</title>
      <link>https://morfikov.github.io/post/automatyczne-podpisywanie-modulow-kernela-przez-dkms/</link>
      <pubDate>Sat, 05 Jan 2019 04:10:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/automatyczne-podpisywanie-modulow-kernela-przez-dkms/</guid>
      <description>&lt;p&gt;Budując kernel linux&#39;a trzeba zastanowić się nad kwestią modułów, które nie są wbudowane
bezpośrednio w samo jądro operacyjne. Nie chodzi tutaj bezpośrednio o funkcjonalność kernela,
którą można zbudować jako moduł w procesie jego kompilacji ale raczej o wszystkie zewnętrzne
moduły, które przez zespół kernela są traktowane jako &lt;code&gt;out-of-tree&lt;/code&gt; . By poprawić nieco
bezpieczeństwo związane z takimi modułami, można wdrożyć podpisy cyfrowe, które takie moduły
muszą okazać podczas próby załadowania ich w systemie. Gdy moduł nie został podpisany, to kernel
go nie załaduje zwracając przy tym błąd &lt;code&gt;modprobe: ERROR: could not insert &#39;module&#39;: Required key not available&lt;/code&gt; . W ten sposób można ochronić się przed częścią ataków, w których moduły pochodzenia
trzeciego mogą zostać załadowane i poczynić nam ogromne spustoszenie w systemie. Problem w tym, że
w dystrybucji Debian wykorzystywany jest mechanizm DKMS (Dynamic Kernel Module Support). Może i
mamy dzięki niemu możliwość instalacji w systemie całej masy dodatkowych modułów ale ich również
nie będzie można załadować, bo nie zostały podpisane kluczem, którego certyfikat został zaszyty
w kernelu. Można jednak zmusić mechanizm DKMS, by wskazane przez nas moduły podpisywał
automatycznie przy ich instalacji i aktualizacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Budowanie kernela linux dla konkretnej maszyny z Debianem</title>
      <link>https://morfikov.github.io/post/budowanie-kernela-linux-dla-konkretnej-maszyny-z-debianem/</link>
      <pubDate>Thu, 27 Dec 2018 22:14:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/budowanie-kernela-linux-dla-konkretnej-maszyny-z-debianem/</guid>
      <description>&lt;p&gt;Każda maszyna działająca pod kontrolą dystrybucji linux ma na swoim pokładzie kernel, czyli jądro
operacyjne, które zarządza praktycznie każdym aspektem pracy takiego komputera. W dystrybucji
Debian, kernel jest dostarczany w pakietach mających nazwy zaczynające się od &lt;code&gt;linux-image-*&lt;/code&gt;.
Te pakiety są budowane przez odpowiednie osoby z zespołu Debiana i udostępniane do łatwej
instalacji użytkownikowi końcowemu. Niemniej jednak, taki kernel ma za zadanie działać na jak
największej ilości komputerów, a przez to posiada całą masę modułów, które na naszej maszynie nigdy
nie będą wykorzystane. Ten fakt nie wpływa w jakimś ogromnym stopniu na pracę maszyny, ale gdy
później zachodzi potrzeba skonfigurowania kernela w nieco inny sposób, np. włączenie jednej czy
dwóch opcji czy też nałożenie patch&#39;a, który nie został zaaplikowany przez dev&#39;ów Debiana, to
trzeba taki kernel na nowo skompilować już samodzielnie, a to zajmie nam bardzo dużo czasu. Zamiast
tego można pokusić się o przygotowanie kernela pod konkretny hardware wyłączając przy tym całą masę
zbędnych rzeczy i ograniczając przy tym czas jaki jest potrzebny na zbudowanie całego jądra
operacyjnego. Czy istnieje jakiś prosty sposób, by taki kernel zbudować sobie samemu mając przy tym
minimalną wiedzę co do opcji kernela, które mogą nas przysporzyć o ból... głowy? Okazuje się, że
tak i w tym artykule prześledzimy sobie cały ten proces.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja serwera XMPP/Jabber pod linux (ejabberd)</title>
      <link>https://morfikov.github.io/post/konfiguracja-serwer-xmpp-jabber-linux-ejabberd/</link>
      <pubDate>Mon, 20 Mar 2017 20:26:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-serwer-xmpp-jabber-linux-ejabberd/</guid>
      <description>&lt;p&gt;Użytkownicy internetu mają całą masę różnych sposobów na komunikację miedzy sobą. Kiedyś wszyscy
korzystali z komunikatorów typu Gadu-Gadu. Ja byłem jedyną osobą, która od samego początku wolała
alternatywne rozwiązania i jechałem na komunikatorze Tlen (ten od O2), a w niedługim czasie
przesiadłem się na Jabber&#39;a i tak z niego korzystam do dziś. W zasadzie GG i Tlen są obecnie już
chyba na wymarciu, bo większość ludzi (jak nie wszyscy) przerzuciła się na Facebook&#39;a czy Twitter&#39;a.
Niemniej jednak, pisanie o sprawach prywatnych w tych serwisach nie jest najlepszym rozwiązaniem.
Jeśli chcemy zadbać o poufność przesyłanych przez internet komunikatów, to trzeba to robić na inne
sposoby. Jednym z nich jest właśnie korzystanie z &lt;a href=&#34;https://xmpp.org/&#34;&gt;protokołu XMPP/Jabber&lt;/a&gt;. To co
odróżnia Jabber&#39;a od innych technologii na rynku, to fakt zdecentralizowania sieci, czyli mamy całą
masę serwerów Jabber&#39;a, na których możemy sobie stworzyć konto. Uwalenie jednego serwera nie wpływa
na działanie pozostałych. Google także wykorzystuje protokół XMPP/Jabber i mając konto na gmail&#39;u,
mamy również stosowny JID w postaci adresu email, który możemy sobie wklepać do jednego z klientów
Jabber&#39;a, np. &lt;a href=&#34;https://xmpp.org/software/clients.html&#34;&gt;PSI czy Gajim&lt;/a&gt;, i jesteśmy już w stanie
rozmawiać z osobami, które mają konta na innych serwerach. Właśnie, inne serwery, a może by tak
sobie postawić własny serwer Jabber&#39;a? Tak się składa, że w repozytorium Debiana znajduje się
&lt;a href=&#34;https://www.ejabberd.im/&#34;&gt;oprogramowanie ejabberd&lt;/a&gt;, które jest nam w stanie umożliwić realizację
tego przedsięwzięcia.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Redshift i dostosowanie temperatury kolorów ekranu</title>
      <link>https://morfikov.github.io/post/redshift-i-dostosowanie-temperatury-kolorow-ekranu/</link>
      <pubDate>Sun, 22 Jan 2017 18:48:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/redshift-i-dostosowanie-temperatury-kolorow-ekranu/</guid>
      <description>&lt;p&gt;Pewnie spotkaliście się już wiele razy z informacją, że ekrany naszych smartfonów, tabletów czy
komputerów szkodzą naszym oczom. Chodzi generalnie o to, że wyświetlacze LCD emitują światło
niebieskie, które w nadmiarze nie wpływa dla nas (i naszego wzroku) korzystnie, a przecie każdy z
nas siedzi godzinami przed komputerem. W zasadzie te negatywne efekty ciągłego spoglądania na
wyświetlacz nasilają się zwłaszcza wieczorami i w nocy. Jeśli pracujemy na laptopie do późna i przy
okazji mamy na tej maszynie zainstalowaną jakąś dystrybucję linux&#39;a, np. Debian, to możemy złagodzić
skutki zmęczenia oczu przez dobór nieco innej temperatury kolorów wyświetlanego obrazu. W tym
zadaniu może nam pomóc oprogramowanie &lt;a href=&#34;http://jonls.dk/redshift/&#34;&gt;redshift&lt;/a&gt; i to jemu będzie
poświęcony poniższy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować połączenie VPN przez SSH</title>
      <link>https://morfikov.github.io/post/jak-skonfigurowac-polaczenie-vpn-przez-ssh/</link>
      <pubDate>Sun, 11 Dec 2016 15:59:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-skonfigurowac-polaczenie-vpn-przez-ssh/</guid>
      <description>&lt;p&gt;Szukając informacji na &lt;a href=&#34;https://morfikov.github.io
/post/jak-ukryc-ruch-openvpn-przy-pomocy-stunnel/&#34;&gt;temat ukrycia ruchu generowanego przez
OpenVPN&lt;/a&gt;, natrafiłem także na
sposób, który &lt;a href=&#34;https://help.ubuntu.com/community/SSH_VPN&#34;&gt;wykorzystuje do tego celu połączenie SSH&lt;/a&gt;.
W efekcie jesteśmy w stanie upodobnić ruch VPN do tego, który zwykle służy do zarządzania zdalnymi
systemami linux. Jako, że temat maskowania połączenia VPN jest kluczowy w walce z cenzurą internetu,
to im więcej sposobów, by taki zabieg przeprowadzić, tym lepiej. Dlatego też postanowiłem odświeżyć
nieco podlinkowany wyżej artykuł i sprawdzić czy jest on jeszcze aktualny. Wprawdzie nie dysponuję
Ubuntu, a jedynie dystrybucją Debian ale raczej nie powinno być problemów z odwzorowaniem
konfiguracji na tym systemie, choć artykuł jest dość leciwy już i pewnie trzeba będzie kilka rzeczy
zaktualizować.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ukryć ruch OpenVPN przy pomocy stunnel</title>
      <link>https://morfikov.github.io/post/jak-ukryc-ruch-openvpn-przy-pomocy-stunnel/</link>
      <pubDate>Sat, 10 Dec 2016 15:18:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ukryc-ruch-openvpn-przy-pomocy-stunnel/</guid>
      <description>&lt;p&gt;Ci z nas, którzy korzystają codziennie z internetu, wiedzą, że większość nawiązywanych połączeń
między dwoma punktami w tej sieci globalnej przechodzi przez szereg węzłów i jest podatnych na
przechwycenie i podsłuchanie. Nawet jeśli ruch z określonymi serwisami jest szyfrowany, to w dalszym
ciągu nie jesteśmy w stanie ukryć pewnych newralgicznych informacji, takich jak docelowy adres IP i
port, na którym nasłuchuje zdalna usługa. Wszystkie połączenia sieciowe zestawiane z naszego
komputera czy routera domowego przechodzą przez infrastrukturę ISP, u którego mamy wykupiony
internet. Tacy ISP są nam w stanie pod naciskiem rządu zablokować połączenia z konkretnymi adresami
wprowadzając na terenie danego kraju cenzurę treści dostępnej w internecie, czego obecnie jesteśmy
świadkami w Europie, no i w Polsce. Można oczywiście posiłkować się rozwiązaniami opartymi o VPN,
np. &lt;a href=&#34;https://morfikov.github.io
/post/jak-skonfigurowac-serwer-vpn-na-debianie-openvpn/&#34;&gt;stawiając serwer OpenVPN w innym
kraju&lt;/a&gt;. Problem jednak w
tym, że ruch OpenVPN różni się od tego, z którym mamy do czynienia w przypadku choćby HTTPS. Jest
zatem możliwość rozpoznania ruchu VPN i zablokowania go stosując &lt;a href=&#34;https://en.wikipedia.org/wiki/Deep_packet_inspection&#34;&gt;głęboką analizę
pakietów&lt;/a&gt; (Deep Packet Inspection, DPI). By
się przed tego typu sytuacją ochronić, trzeba upodobnić ruch generowany przez OpenVPN do zwykłego
ruchu SSL/TLS. Do tego celu służy &lt;a href=&#34;https://www.stunnel.org/index.html&#34;&gt;narzędzie stunnel&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować serwer VPN na Debianie (OpenVPN)</title>
      <link>https://morfikov.github.io/post/jak-skonfigurowac-serwer-vpn-na-debianie-openvpn/</link>
      <pubDate>Tue, 06 Dec 2016 19:22:49 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-skonfigurowac-serwer-vpn-na-debianie-openvpn/</guid>
      <description>&lt;p&gt;Co raz częściej słychać w mediach o próbie cenzurowania internetu i blokowaniu dostępu do kolejnych
serwisów i stron www. Ostatnio znowu podnieśli kwestię blokowania pokemonów bezpośrednio u ISP tak,
by za zgodą ISP (władzy) można przeglądać tego typu serwisy. W sumie mam już tego dość i korzystając
z okazji, że posiadam za granicą niewielkich rozmiarów VPS, który i tak nie jest zbytnio obciążony,
to postanowiłem sobie skonfigurować na nim serwer VPN w oparciu o &lt;a href=&#34;https://openvpn.net/index.php/open-source/documentation/howto.html&#34;&gt;oprogramowanie
OpenVPN&lt;/a&gt;, które jest standardowo
dostępne w każdej dystrybucji linux&#39;a. Proces konfiguracji serwera jak i klienta z zainstalowanym
Debianem zostanie opisany poniżej. Niemniej jednak, inne urządzenia takie jak routery WiFi i
smartfony również wymagają zaimplementowania w nich mechanizmu szyfrującego ruch ale te rozwiązania
zostaną opisane w osobnych wątkach.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przesyłanie dźwięku i plików ze smartfona przez bluetooth</title>
      <link>https://morfikov.github.io/post/przesylanie-dzwieku-plikow-ze-smartfona-bluetooth/</link>
      <pubDate>Sat, 19 Nov 2016 19:40:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przesylanie-dzwieku-plikow-ze-smartfona-bluetooth/</guid>
      <description>&lt;p&gt;Praktycznie każdy telefon czy komputer/laptop jest wyposażony już w adapter bluetooth. Obecnie coraz
rzadziej ten protokół jest wykorzystywany do przesyłania plików jako takich, bo przecie mamy WiFi.
Niemniej jednak, w starszych modelach urządzeń bluetooth może być dla nas jedyną opcją, by przesłać
pliki bezprzewodowo. Nawet jeśli dysponujemy smartfonem z jednym z nowszych Androidów, to i tak są
pewne sytuacje, w których bluetooth może znaleźć ciekawe zastosowanie, np. streaming dźwięku.
Urządzenia bluetooth bardzo często sprawiają problemy pod linux i przydałoby się zebrać trochę
informacji na temat ich konfiguracji, by przesyłanie dźwięku i plików nie stanowiło dla nas
większego wyzwania w sytuacjach podbramkowych, gdzie wszelkie inne alternatywy komunikacji zawodzą.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przerabianie zdjęć i innych plików graficznych z Imagemagick</title>
      <link>https://morfikov.github.io/post/przerabianie-zdjec-innych-plikow-graficznych-imagemagick/</link>
      <pubDate>Sun, 06 Nov 2016 12:40:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przerabianie-zdjec-innych-plikow-graficznych-imagemagick/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.imagemagick.org/script/index.php&#34;&gt;Imagemagick to zestaw tekstowych narzędzi&lt;/a&gt; do
manipulacji obrazami graficznymi. Łapie on takie formaty jak DPX, EXR, GIF, JPEG, JPEG-2000, PDF,
PhotoCD, PNG, Postscript, SVG, oraz TIFF. Przy pomocy Imagemagick można przeprowadzać cała masę
operacji na plikach począwszy od tych podstawowych, kończąc na tych najbardziej zaawansowanych. W
sumie to nie wiem czy jest coś czego by nie dało się zrobić przy pomocy tego magika. Czasami
korzystanie z wiersza poleceń jest też o wile wygodniejsze w przypadku przeróbki całej masy zdjęć,
gdzie graficzne narzędzia typu GIMP raczej średnio się nadają. Postanowiłem zatem zrobić wpis o
Imagemagick (pakiet &lt;code&gt;imagemagick&lt;/code&gt; w dystrybucji Debian) i zawrzeć w nim wszystkie te ciekawsze
polecenia, na które w przyszłości natrafię podczas przerabiania fotek, skrinów czy innych grafik.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ukryć zaszyfrowany kontener LUKS pod linux</title>
      <link>https://morfikov.github.io/post/jak-ukryc-zaszyfrowany-kontener-luks-pod-linux/</link>
      <pubDate>Tue, 25 Oct 2016 19:30:23 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ukryc-zaszyfrowany-kontener-luks-pod-linux/</guid>
      <description>&lt;p&gt;Gdy w grę wchodzi poufność informacji, to przeciętny użytkownik komputera od razu zaczyna rozważać
szyfrowanie danych. Są różne narzędzia, które te kwestię realizują w mniejszym lub większym stopniu.
Kiedyś wszyscy korzystali z &lt;a href=&#34;http://truecrypt.sourceforge.net/&#34;&gt;TrueCrypt&lt;/a&gt; ale po jego dziwnych
przygodach ludzie stopniowo zaczęli od tego oprogramowania odchodzić. W jego miejscu zaczęły
pojawiać się różne forki, np. &lt;a href=&#34;https://veracrypt.codeplex.com/&#34;&gt;VeraCrypt&lt;/a&gt;. Abstrahując od tych ww.
narzędzi, w każdym linux&#39;ie mamy również dostępny &lt;a href=&#34;https://gitlab.com/cryptsetup/cryptsetup/wikis/FrequentlyAskedQuestions&#34;&gt;mechanizm szyfrujący na bazie
LUKS&lt;/a&gt; i jego gołą wersję
wykorzystującą dm-crypt. Przy pomocy każdego z tych narzędzi jesteśmy w stanie zaszyfrować dysk
komputera, pendrive, czy nawet kartę SD, w taki sposób, by nikt inny nie uzyskał dostępu do danych
zgromadzonych na tych nośnikach informacji. Problem w tym, że w dalszym ciągu ktoś może nas
torturować, by wydobyć od nas hasło czy keyfile i uzyskać dostęp do tych zaszyfrowanych danych bez
większego trudu. Dlatego też pojawiło się coś nazwanego &lt;a href=&#34;https://en.wikipedia.org/wiki/Plausible_deniability&#34;&gt;Plausible
Deniability&lt;/a&gt;, gdzie wykorzystywane są tak
naprawdę dwa nośniki z czego jeden robi za przykrywkę, a na drugim mamy zgromadzone poufne pliki. W
ten sposób agresorowi podajemy hasło do trefnego kontenera i wszyscy są zadowoleni. Czy aby na
pewno?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wykryć komputer w sieci przy pomocy nmap</title>
      <link>https://morfikov.github.io/post/jak-wykryc-komputer-w-sieci-przy-pomocy-nmap/</link>
      <pubDate>Mon, 26 Sep 2016 18:29:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wykryc-komputer-w-sieci-przy-pomocy-nmap/</guid>
      <description>&lt;p&gt;Opisywane jakiś czas temu przeze mnie &lt;a href=&#34;https://morfikov.github.io
/post/transmitery-sieciowe-tl-wpa4226t-kit-tp-link/&#34;&gt;ekstendery
powerline&lt;/a&gt;, tak bardzo mi
przypadły do gustu, że korzystam z nich praktycznie bez przerwy. Po skonfigurowaniu &lt;a href=&#34;https://morfikov.github.io
/post/jak-skonfigurowac-roaming-wifi-wpa_supplicant-linux/&#34;&gt;roamingu sieci
WiFi w linux&#39;ie&lt;/a&gt;, mój
laptop w nieodczuwalny dla mnie w sposób rekonfiguruje połączenie w obrębie sieci domowej. Sygnał
jest na prawdę bardzo dobrej jakości w każdym zakątku domu, przez co w ogóle zapomniałem o istnieniu
tych transmiterów sieciowych. Chciałem przenieść jeden z ekstenderów z kanału 1 (domyślny), na kanał
6, który jest najmniej zatłoczony. Problem w tym, że zapomniałem jakim adresem IP dysponuje AP tego
urządzenia. Przestrzeń adresowa tej sieci to 192.168.1.0/24, czyli adresów jest 254 (192.168.1.0,
192.168.0.255 zarezerwowane dla broadcast). Nie uśmiechało mi się wpisywanie każdego z tych adresów
w przeglądarce, by ten panel admina odszukać metodą na chybił trafił. Na szczęście są o wiele
szybsze metody szukania maszyn w sieci, np. zapytania o adres IP w protokole ARP. A przy pomocy
&lt;a href=&#34;https://nmap.org/&#34;&gt;skanera nmap&lt;/a&gt; możemy w parę sekund ustalić adres IP wszystkich aktualnie
podłączonych komputerów do sieci.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Smartfon z Androidem pod linux&#39;em (MTP/PTP)</title>
      <link>https://morfikov.github.io/post/smartfon-android-linux-mtp-ptp/</link>
      <pubDate>Thu, 22 Sep 2016 21:54:23 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/smartfon-android-linux-mtp-ptp/</guid>
      <description>&lt;p&gt;Wpadł mi w łapki &lt;a href=&#34;http://www.neffos.pl/product/details/C5&#34;&gt;smartfon Neffos C5&lt;/a&gt; od TP-LINK, który ma
na pokładzie Androida. Chciałem nim zrobić parę fotek, tylko pojawił się problem uzyskania dostępu
do zasobów tego telefonu. Samo urządzenie pod linux&#39;em identyfikowane jest jako &lt;code&gt;idVendor=2357&lt;/code&gt; oraz
&lt;code&gt;idProduct=0314&lt;/code&gt; ale po jego podłączeniu do portu USB komputera nie pojawiły się żadne nowe dyski,
które można by przejrzeć w celu zgania ich zawartości. Problem tkwił w konfiguracji mojego Debiana,
w którym to brakowało obsługi protokołu MTP. Po chwili rozgryzłem tę zagadkę instalując w systemie
pakiet &lt;code&gt;jmtpfs&lt;/code&gt; , co umożliwiło interakcję z systemem plików telefonu i zgranie zrobionych zdjęć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mostek eth0 &#43; wlan0 z bridge-utils i wpa_supplicant</title>
      <link>https://morfikov.github.io/post/mostek-eth0-wlan0-bridge-utils-wpa_supplicant/</link>
      <pubDate>Sun, 18 Sep 2016 13:01:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mostek-eth0-wlan0-bridge-utils-wpa_supplicant/</guid>
      <description>&lt;p&gt;Posiadając w komputerze kilka interfejsów sieciowych, prędzej czy później dostrzeżemy wady jakie
niesie ze sobą konfiguracja wszystkich posiadanych kart sieciowych. Skonfigurowanie szeregu
interfejsów przewodowych nie stanowi raczej większego wyzwania. Można je spiąć w jeden za pomocą
bonding&#39;u czy też konfigurując wirtualny interfejs mostka (bridge). A co w przypadku bezprzewodowych
interfejsów? Tu również możemy &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-interfejsow-bond-bonding/&#34;&gt;skonfigurować interfejs
bond0&lt;/a&gt; lub też podpiąć interfejs
&lt;code&gt;wlan0&lt;/code&gt; pod mostek. Jako, że bonding już opisywałem, to w tym artykule zajmiemy się mostkowaniem
interfejsu przewodowego i bezprzewodowego, które zwykle dostępne są w naszych laptopach. Ten proces
zostanie opisany w oparciu o dystrybucję linux&#39;a Debian i skontrastujemy go sobie z w/w bonding&#39;iem.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cannot move /etc/resolv.conf.dhclient-new to /etc/resolv.conf: Operation not permitted</title>
      <link>https://morfikov.github.io/post/cannot-move-etcresolv-conf-dhclient-new-to-etcresolv-conf-operation-not-permitted/</link>
      <pubDate>Sat, 10 Sep 2016 20:54:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/cannot-move-etcresolv-conf-dhclient-new-to-etcresolv-conf-operation-not-permitted/</guid>
      <description>&lt;p&gt;Użytkownicy linux&#39;a przykładają nieco większą wagę do konfiguracji swojego systemu. Te nieco
bardziej świadome jednostki zdają sobie sprawę, że różnego rodzaju automaty są w stanie przepisywać
konfigurację systemową bez naszej wiedzy. Weźmy sobie resolver DNS. To bardzo krytyczna usługa, nie
tylko z punktu widzenia bezpieczeństwa ale też i prywatności. Zakładając, że chcemy korzystać z
pewnych określonych serwerów DNS lub też mamy &lt;a href=&#34;https://morfikov.github.io
/post/dnscrypt-proxy-czyli-szyfrowanie-zapytan-dns/&#34;&gt;skonfigurowaną usługę
dnscrypt-proxy&lt;/a&gt;, trzeba zadbać
o to, by adresy w pliku &lt;code&gt;/etc/resolv.conf&lt;/code&gt; nie zostały z jakiegoś powodu przepisane. Użytkownicy
zwykle nadają temu plikowi atrybut odporności ( &lt;code&gt;chattr +i&lt;/code&gt; ) . Niemniej jednak, przy pobieraniu
konfiguracji sieciowej za sprawą protokołu DHCP, w logu można zaobserwować komunikat: &lt;code&gt;mv: cannot move &#39;/etc/resolv.conf.dhclient-new&#39; to &#39;/etc/resolv.conf&#39;: Operation not permitted&lt;/code&gt; . Niby w niczym
on nie przeszkadza ale możemy tak skonfigurować demona &lt;code&gt;dhclient&lt;/code&gt; , by tę wiadomość wyeliminować.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować roaming WiFi z wpa_supplicant w linux&#39;ie</title>
      <link>https://morfikov.github.io/post/jak-skonfigurowac-roaming-wifi-wpa_supplicant-linux/</link>
      <pubDate>Sat, 10 Sep 2016 12:13:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-skonfigurowac-roaming-wifi-wpa_supplicant-linux/</guid>
      <description>&lt;p&gt;Bezprzewodowe sieci WiFi są wszędzie. Wystarczy tylko przejść się kawałek po okolicy i przeskanować
eter, a sami zobaczymy, że wynik takiego skanowania zidentyfikuje nam całą masę domowych nadajników.
Oczywiście do większości z nich raczej nigdy nie będziemy mieć dostępu ale są wśród nich takie AP,
do których zwykliśmy się logować. Niekoniecznie te AP muszą należeć do naszej własnej domowej sieci
WiFi. Mogą to być, np. firmowe hotspoty. Nawet jeśli ograniczymy się tylko do naszego domu, to gdy
ten jest nieco większy, to prawdopodobnie jeden bezprzewodowy router nie wystarczy, by pokryć
zasięgiem całą dostępną przestrzeń użytkową. Będziemy musieli dokupić drugi router, czy jakiś
wzmacniacz sygnału. Być może też zdecydujemy się na &lt;a href=&#34;https://morfikov.github.io
/post/transmitery-sieciowe-tl-wpa4226t-kit-tp-link/&#34;&gt;transmitery sieciowe
(powerline)&lt;/a&gt;. Jest cała masa
urządzeń, które mogą nam pomóc rozwiązać problem słabego zasięgu. To co zwykle łączy te urządzenia,
to fakt, że wszystkie z nich zawierają dodatkowy AP, który trzeba skonfigurować. Pojawia się zatem
problem przełączania między tymi punktami dostępowymi. Można sobie z tym poradzić konfigurując
roaming. W takiej sytuacji przełączanie między sieciami będzie następowało automatycznie, szybko i
bez naszego udziału. W linux&#39;ach roaming można włączyć przy pomocy narzędzia &lt;code&gt;wpa_supplicant&lt;/code&gt; i w
tym artykule zobaczymy jak tego dokonać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Debian: Profilowanie sieci z guessnet, ifplugd i wpasupplicant</title>
      <link>https://morfikov.github.io/post/debian-profilowanie-sieci-guessnet-ifplugd-wpasupplicant/</link>
      <pubDate>Mon, 05 Sep 2016 13:01:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/debian-profilowanie-sieci-guessnet-ifplugd-wpasupplicant/</guid>
      <description>&lt;p&gt;Kilka dni temu na &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=28903&#34;&gt;forum dug.net.pl&lt;/a&gt; pojawił się
ciekawy wątek dotyczący problemu skonfigurowania profilowanych sieci. Chodzi o to, że praktycznie
każdy z nas jest po części w jakiś sposób mobilny i zabiera laptopa ze sobą w dziwne miejsca. Sieci
w tych lokalizacjach mogą cechować się różnym poziomem bezpieczeństwa. Dlatego też zamiast korzystać
z jednej konfiguracji sieci na linux&#39;ie, można stworzyć szereg profili i w oparciu o nie dostosować
sobie połączenie sieciowe. W tym artykule spróbujemy zaimplementować takie rozwiązanie na Debianie
wyposażonym w menadżer okien Openbox. W skrócie stworzymy automat, który będzie nam działał w
oparciu o pakiety guessnet, &lt;a href=&#34;http://0pointer.de/lennart/projects/ifplugd/&#34;&gt;ifplugd&lt;/a&gt; oraz
&lt;a href=&#34;https://w1.fi/wpa_supplicant/&#34;&gt;wpasupplicant&lt;/a&gt;. Cała konfiguracja zaś sprowadzać się będzie jedynie
do edycji plików &lt;code&gt;/etc/network/interfaces&lt;/code&gt; oraz &lt;code&gt;/etc/wpa_supplicant/wpa_supplicant.conf&lt;/code&gt; .&lt;/p&gt;
&lt;p&gt;Niniejszy artykuł został nieco przerobiony po fazach eksperymentów. Przede wszystkim, zrezygnowałem
z zaprzęgania &lt;code&gt;guessnet&lt;/code&gt; do rozpoznawania sieci WiFi i aplikowania roamingu. Zamiast tego zostały
wykorzystane natywne rozwiązania roamingowe oferowane przez &lt;code&gt;wpa_supplicant&lt;/code&gt; . Zaowocowało to
uproszczeniem całej konfiguracji, co przełożyło się na wyeliminowanie pewnych błędów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Metryki tras interfejsów eth0 i wlan0 w laptopie (metric)</title>
      <link>https://morfikov.github.io/post/metryki-tras-interfejsow-eth0-wlan0-laptop-metric/</link>
      <pubDate>Fri, 02 Sep 2016 17:50:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/metryki-tras-interfejsow-eth0-wlan0-laptop-metric/</guid>
      <description>&lt;p&gt;W obecnych czasach posiadanie komputera, który dysponuje kilkoma interfejsami sieciowymi nie jest
niczym niezwykłym. Praktycznie każdy laptop posiada już na pokładzie co najmniej jedną kartę WiFi i
minimum jeden port ethernet. W efekcie czego jesteśmy w stanie podłączyć się do sieci zarówno
przewodowo jak i bezprzewodowo. Problem jednak pojawia się w momencie, gdy chcemy wykorzystywać oba
te interfejsy, z tym, że dysponujemy jedynie niezbyt zaawansowanym menadżerem okien Openbox. Takie
środowiska zwykle nie mają na pokładzie automatów pokroju Network Manager, przez co bardziej
zaawansowana konfiguracja sieci może być dość skomplikowana. Do tej pory wykorzystywałem &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-interfejsow-bond-bonding/&#34;&gt;interfejs
bond0&lt;/a&gt;, by mieć możliwość łatwego
przełączania się miedzy sieciami. Istnieje inny sposób konfiguracji interfejsów &lt;code&gt;eth0&lt;/code&gt; i &lt;code&gt;wlan0&lt;/code&gt; w
pliku &lt;code&gt;/etc/network/interfaces&lt;/code&gt; tak, by działały one nam równolegle i nie powodowały problemów z
połączeniem, a wszystko za sprawą opcji &lt;code&gt;metric&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dynamiczna konfiguracja sieci w oparciu o ifplugd</title>
      <link>https://morfikov.github.io/post/dynamiczna-konfiguracja-sieci-ifplugd/</link>
      <pubDate>Thu, 01 Sep 2016 12:24:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dynamiczna-konfiguracja-sieci-ifplugd/</guid>
      <description>&lt;p&gt;Sporo użytkowników różnego rodzaju linux&#39;ów, zwłaszcza dystrybucji Debian, niezbyt chwali sobie
automaty konfigurujące połączenie sieciowe typu &lt;a href=&#34;https://wiki.gnome.org/Projects/NetworkManager&#34;&gt;Network
Manager&lt;/a&gt;. W sumie nigdy się jemu bliżej nie
przyglądałem ale na necie nie cieszy się on najlepszą opinią. Niemniej jednak, Network Manager
potrafi automatyzować pewne aspekty pracy w sieci. Weźmy przykład korzystania z dwóch różnych pod
względem parametrów sieci przewodowych. Jak się zachowa nasz OS w chwili przełączania się między
tymi sieciami w przypadku, gdy nie będziemy mieli zainstalowanego jakiegoś automatu dynamicznie
konfigurującego połączenie? W przypadku jednej sieci, połączenie będzie nam działać, w przypadku
drugiej zaś napotkamy problemy. W lekkich środowiskach opartych o menadżery okien, np. Openbox, nie
musimy instalować Network Manager&#39;a, by ogarnąć tę kwestię konfiguracyjną. Możemy posiłkować się
demonem &lt;code&gt;ifplugd&lt;/code&gt; i to tym narzędziu będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Blokowanie zapytań DNS z dnscrypt-proxy na linux&#39;ie</title>
      <link>https://morfikov.github.io/post/blokowanie-zapytan-dns-dnscrypt-proxy-linux/</link>
      <pubDate>Thu, 25 Aug 2016 20:04:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/blokowanie-zapytan-dns-dnscrypt-proxy-linux/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://dnscrypt.org/&#34;&gt;Narzędzie dnscrypt-proxy&lt;/a&gt; począwszy od
&lt;a href=&#34;https://github.com/jedisct1/dnscrypt-proxy/releases&#34;&gt;wersji 1.7.0&lt;/a&gt; ma domyślnie włączoną obsługę
wtyczek. W standardzie nie ma ich dużo, bo jedynie trzy ale mogą one się okazać dla pewnych osób
bardzo użyteczne. Dzięki tym plugin&#39;om możemy, np. zablokować rozwiązywanie nazw w protokole IPv6 na
wypadek, gdyby ten protokół nie był wspierany w naszej sieci domowej czy też u naszego ISP. Możemy
także zdefiniować sobie adresy/domeny, które powinny zostać zablokowane i w efekcie użytkownicy nie
będą w stanie odwiedzić tych miejsc w internecie. Jest także wtyczka, która może nam pomóc zalogować
zapytania DNS. Jak widać, całkiem przyzwoite są te dodatki. W tym wpisie przyjrzymy się nieco bliżej
konfiguracji poszczególnych wtyczek dla &lt;code&gt;dnscrypt-proxy&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Request body exceeds maximum size (131072) for SSL buffer</title>
      <link>https://morfikov.github.io/post/request-body-exceeds-maximum-size-131072-for-ssl-buffer/</link>
      <pubDate>Wed, 24 Aug 2016 22:52:29 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/request-body-exceeds-maximum-size-131072-for-ssl-buffer/</guid>
      <description>&lt;p&gt;Dziś chciałem zaktualizować jeden z moich bardziej obszerniejszych wpisów na tym blogu ale
oczywiście nie mogło odbyć się bez problemów. Gdy już wszystkie poprawki zostały naniesione i cały
artykuł trafił do formularza WordPress&#39;a, przeglądarka zwróciła mi błąd &lt;code&gt;Request Entity Too Large&lt;/code&gt; .
Z początku nie wiedziałem o co chodzi ale, że ten aktualizowany artykuł był naprawdę długi, to
domyśliłem się, że chodzi o ilość bajtów, które chciałem przesłać w zapytaniu. Przeglądając logi
serwera Apache2, znalazłem tam jeszcze dodatkowo komunikaty &lt;code&gt;[ssl:error] request body exceeds maximum size (131072) for SSL buffer&lt;/code&gt; oraz &lt;code&gt;[ssl:error] could not buffer message body to allow SSL renegotiation to proceed&lt;/code&gt; . Może ta cała sytuacja brzmi groźnie ale wybrnięcie z niej jest wręcz
banalne. Wystarczy dostosować wartość dyrektywy &lt;code&gt;SSLRenegBufferSize&lt;/code&gt; w konfiguracji serwera Apache2.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chroot Apache2 vs dyrektywa open_basedir w PHP</title>
      <link>https://morfikov.github.io/post/chroot-apache2-vs-dyrektywa-open_basedir-w-php/</link>
      <pubDate>Mon, 22 Aug 2016 22:03:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/chroot-apache2-vs-dyrektywa-open_basedir-w-php/</guid>
      <description>&lt;p&gt;Kilka dni temu wpadł mi w oko artykuł na temat wykonania &lt;a href=&#34;https://nfsec.pl/root/5874&#34;&gt;chroot serwera
Apache2&lt;/a&gt;. Problem z tamtym tekstem jest taki, że nie uwzględnia on
serwera bazy danych MySQL. W efekcie, taki chroot&#39;owany Apache2 będzie miał problemy z połączeniem
się do bazy, a nasz serwis bez niej raczej nie będzie działał prawidłowo. Przydałoby się zatem
dopracować nieco ten artykuł i wypracować takie rozwiązanie, które nie popsuje przy okazji naszego
serwisu www. Dlatego też w tym wpisie wykonamy sobie chroot zarówno serwera Apache2 z obsługą PHP i
bazy danych MySQL za sprawą modułu &lt;code&gt;unixd&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zrobić screenshot całej strony www w Firefox</title>
      <link>https://morfikov.github.io/post/jak-zrobic-screenshot-strony-www-firefox/</link>
      <pubDate>Mon, 22 Aug 2016 08:38:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zrobic-screenshot-strony-www-firefox/</guid>
      <description>&lt;p&gt;Każdy z nas potrafi raczej zrobić prostego &amp;quot;skrina&amp;quot; tego co wyświetla się w danej chwili na ekranie
naszego komputera. Nie jest to jakaś zaawansowana wiedza i wystarczy przycisnąć przycisk PrintScreen
na klawiaturze i zrzut ekranu powinien zostać przechwycony przez system i zwykle gdzieś zapisany.
Niemniej jednak, strony www w przeglądarce internetowej bardzo rzadko są nam pokazywane w całej
swojej okazałości. Zwykle mamy po prawej stronie pasek przewijania (scrollbar), za pomocą którego
możemy przewinąć stronę w górę lub w dół. Pojawia się zatem pytanie: jak w takiej sytuacji zrobić
screenshot całej strony www? Można, co prawda, przewinąć stronę kilka razy, zrobić zrzut każdego
kawałka i scalić obraz w jakimś programie graficznym ale raczej za dużo z tym zachodu. Można także
zaprzęgnąć jakiś plugin do przeglądarki, np. Firefox ma na wyposażeniu &lt;a href=&#34;https://addons.mozilla.org/en-us/firefox/addon/screenshot-capture-annotate/&#34;&gt;Awesome
Screenshot&lt;/a&gt;. Istnieje
jednak prostsza alternatywa i do tego natywnie zaimplementowana w Firefox&#39;ie. Mowa o &lt;a href=&#34;https://developer.mozilla.org/en/docs/Tools/GCLI&#34;&gt;wierszu
poleceń Firefox&#39;a&lt;/a&gt;. W tym krótkim wpisie
zobaczymy jak przy pomocy tego narzędzia w bardzo prosty sposób zrobić fotkę całej witryny www.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Transmiter sieciowy i jego panel admina pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/transmiter-sieciowy-panel-admina-linux/</link>
      <pubDate>Sat, 20 Aug 2016 21:54:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/transmiter-sieciowy-panel-admina-linux/</guid>
      <description>&lt;p&gt;Bawię się ostatnio trochę transmiterem sieciowym (powerline ekstender). Konkretnie jest to zestaw
&lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WPA4226T-KIT.html&#34;&gt;TL-WPA4226T KIT (AV500)&lt;/a&gt; od
TP-LINK. Same urządzenia działają przyzwoicie i realizują powierzane im funkcje w sposób bardzo
zadowalający ale był jeden problem, który mi nie dawał spokoju. Do tych ekstenderów jest dołączona
płytka. Na płytce są aplikacje, które umożliwiają konfigurację tych transmiterów sieciowych. Te
programiki nie mają wersji dla linux&#39;a. Nasunęło mi się zatem pytanie: to jak mam niby te
transmitery skonfigurować pod tym systemem operacyjny? Niby one działają OOTB ale w przypadku
bezprzewodowego routera WiFi z alternatywnym firmware OpenWRT/LEDE na pokładzie występuje kolizja
adresów IP. Zarówno ekstendery jak i router roszczą sobie prawo do adresu 192.168.1.1 . Panel admina
takich transmiterów umożliwia zmianę tego adresu, tylko nie mamy jak się do niego dobrać z poziomu
linux&#39;a. W tym artykule postaramy się rozwiązać problem kolizji adresów IP i skonfigurujemy nasz
transmiter tak, by miał inny adres.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sterowniki dla karty WiFi Archer T1U (mt7610u_sta)</title>
      <link>https://morfikov.github.io/post/sterowniki-karta-wifi-archer-t1u-mt7610u_sta/</link>
      <pubDate>Thu, 18 Aug 2016 14:35:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sterowniki-karta-wifi-archer-t1u-mt7610u_sta/</guid>
      <description>&lt;p&gt;Dziś postanowiłem się wziąć za ostatnią kartę WiFi, którą podesłał mi TP-LINK. Jest to nano adapter
Archer T1U V1 na &lt;a href=&#34;https://wikidevi.com/wiki/TP-LINK_TL-WDN5200&#34;&gt;czipie MediaTek MT7610U&lt;/a&gt;
identyfikowany w systemie jako &lt;code&gt;idVendor=2357&lt;/code&gt; , &lt;code&gt;idProduct=0105&lt;/code&gt; . Na opakowaniu pisało, że ta
karta działa na linux&#39;ach ale oczywiście w przypadku mojego Debiana, ten adapter nie został w ogóle
wykryty. Winą są zbyt stare sterowniki, które nie zostały zaktualizowane przez MediaTek od 2013
roku. TP-Link może i ma u siebie na stronie &lt;a href=&#34;http://www.tp-link.com/en/download/Archer-T1U.html#Driver&#34;&gt;nieco nowszą wersję
sterowników&lt;/a&gt;, bo z 2015 roku ale nie
udało mi się za ich sprawą zbudować poprawnie modułu &lt;code&gt;mt7610u_sta&lt;/code&gt; na kernelu 4.6 . Na szczęście
mamy jedną alternatywę, która pomoże nam jako tako wybrnąć z tej sytuacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zresetować hasło root do bazy danych MySQL</title>
      <link>https://morfikov.github.io/post/reset-hasla-bazy-danych-mysql/</link>
      <pubDate>Tue, 16 Aug 2016 18:36:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/reset-hasla-bazy-danych-mysql/</guid>
      <description>&lt;p&gt;Dziś podczas przenoszenia jednej z baz danych przytrafiła mi się bardzo dziwna sytuacja. Niby
wszystkie kroki zostały przeprowadzone poprawnie i nic bazie nie dolega ale jest jeden problem.
Okazuje się, że po wszystkim nie sposób do tej bazy uzyskać dostęp. Tak to się już czasem zdarza, że
człowiek ustawi hasło administratora bazy i po chwili je zapomni. Generalnie rzecz biorąc, to
komputery za mnie mają pamiętać hasła do różnych aplikacji, w tym też i do baz danych. Ja tylko
ograniczam się zawsze do kilku fraz, które odblokowują keyring. Niemniej jednak, jakimś dziwnym
trafem, w tym keyring&#39;u zabrakło hasła do tej nieszczęsnej bazy danych. Jak zatem odzyskać to
zagubione hasło do bazy MySQL? Odpowiedź jest nawet bardzo prosta, o ile się posiada dostęp do
użytkownika root na serwerze i na szczęście takowy posiadałem, więc w sumie nikt nic nie zauważył.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sterowniki do karty TP-LINK TL-WN823N (8192eu)</title>
      <link>https://morfikov.github.io/post/sterowniki-tp-link-tl-wn823n-8192eu/</link>
      <pubDate>Fri, 12 Aug 2016 20:50:39 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sterowniki-tp-link-tl-wn823n-8192eu/</guid>
      <description>&lt;p&gt;Systemy operacyjne nie są w stanie wejść w interakcję ze sprzętem, do którego nie posiadają
sterowników. Linux już od dość dawna żyje sobie wśród nas i coraz bardziej pcha się na desktopy.
Niemniej jednak producenci tych wszystkich urządzeń niechętnie wypuszczają sterowniki dla
alternatywnych systemów. Ostatnio próbowałem uruchomić &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WN823N.html&#34;&gt;adapter TL-WN823N
V2&lt;/a&gt; od firmy TP-LINK. Na opakowaniu
widnieje napis sugerujący, że ta karta działa pod linux&#39;em. Rzeczywistość jednak okazała się
zupełnie inna. Mianowicie, mój Debian w ogóle nie rozpoznał tej karty. Jedyne informacje jakie mi
zwrócił to nazwę producenta czipu, którym okazał się być &lt;code&gt;Realtek&lt;/code&gt; , oraz &lt;code&gt;idVendor=2357&lt;/code&gt; i
&lt;code&gt;idProduct=0109&lt;/code&gt; . &lt;a href=&#34;http://www.tp-link.com/en/download/TL-WN823N.html#Driver&#34;&gt;Sterowników dostępnych na stronie
TP-LINK&#39;a&lt;/a&gt; nie szło zbudować na obecnym
kernelu 4.6 . Trzeba było zatem poszukać innej alternatywy. Na szczęście udało się znaleźć moduł
8192eu (rtl8192eu), który się skompilował i zainstalował bez problemu. Karta TL-WN823N V2 została
wykryta i działa. W tym wpisie zostanie pokazany proces kompilacji tego modułu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Debian: Bezpieczne pobieranie aktualizacji (apt-transport-https)</title>
      <link>https://morfikov.github.io/post/debian-bezpieczne-pobieranie-aktualizacji-apt-transport-https/</link>
      <pubDate>Tue, 09 Aug 2016 16:04:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/debian-bezpieczne-pobieranie-aktualizacji-apt-transport-https/</guid>
      <description>&lt;p&gt;Posiadanie aktualnego systemu za sprawą regularnych aktualizacji może znacząco przyczynić się do
poprawy bezpieczeństwa naszego linux&#39;a. Niemniej jednak, niezabezpieczony proces aktualizacji może
zdradzić pewne informacje, które mogą się okazać przydatne dla potencjalnego atakującego. Dlatego
też menadżer pakietów &lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;aptitude&lt;/code&gt; w Debianie wyposażony jest w dodatkowe transporty
umożliwiające komunikację z serwerem repozytorium w oparciu o różne protokoły. Standardowy
protokół, którym posługują się maszyny mające na pokładzie dystrybucję Debian, to HTTP
(ewentualnie FTP). Oba z nich ślą wszelkie informacje w postaci czystego tekstu, który nadaje się do
analizy przez człowieka. Możemy jednak skorzystać z protokołu SSL/TLS i zaszyfrować proces
pobierania aktualizacji za sprawą pakietu &lt;code&gt;apt-transport-https&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wybrać optymalny mirror repozytorium Debiana</title>
      <link>https://morfikov.github.io/post/jak-wybrac-optymalny-mirror-repozytorium-debiana/</link>
      <pubDate>Sun, 07 Aug 2016 15:15:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wybrac-optymalny-mirror-repozytorium-debiana/</guid>
      <description>&lt;p&gt;Debian to dość stara i rozbudowana dystrybucja linux&#39;a, którą można spotkać praktycznie w każdym
zakątku naszego globu. Dziesiątki tysięcy pakietów dostępne w oficjalnych repozytoriach tylko
czekają aż je pobierzemy i zainstalujemy w swoim systemie. Problem zaczyna się jednak w momencie,
gdy wielu użytkowników w tym samym czasie zaczyna pobierać pakiety i to z tego samego serwera. Wtedy
aktualizacja Debiana może trwać dłużej niż zazwyczaj. By zaadresować ten problem, developerzy tej
dystrybucji stawiają serwery lustrzane (mirror) w różnych częściach świata i rozładowują w ten
sposób ruch, który by powędrował do głównego serwera. Spora część krajów ma kilka własnych
mirror&#39;ów ale ich jakość może czasami zostawić wiele do życzenia. Co w przypadku, gdy taki mirror,
z którego my korzystamy, ulegnie awarii? Trzeba będzie poddać edycji plik &lt;code&gt;/etc/apt/sources.list&lt;/code&gt; i
zmienić adres repozytorium przez dostosowanie w nim części odpowiedzialnej za lokalizację, np.
&lt;code&gt;ftp.pl&lt;/code&gt; czy &lt;code&gt;ftp.us&lt;/code&gt; . Istnieje jednak sposób, który dostosuje lokalizację serwera lustrzanego
automatycznie, a my już nie będziemy musieli sobie głowy zawracać edycją wspomnianego wyżej pliku.&lt;/p&gt;
&lt;p&gt;Projekt, o którym traktuje poniższy wpis, nie jest już rozwijany przez Debiana. Więcej info
&lt;a href=&#34;https://wiki.debian.org/DebianGeoMirror&#34;&gt;tutaj&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Debian: Anonimowe pobieranie aktualizacji (apt-transport-tor)</title>
      <link>https://morfikov.github.io/post/debian-anonimowe-pobieranie-aktualizacji-apt-transport-tor/</link>
      <pubDate>Sun, 07 Aug 2016 13:06:03 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/debian-anonimowe-pobieranie-aktualizacji-apt-transport-tor/</guid>
      <description>&lt;p&gt;Dystrybucja linux&#39;a Debian oferuje możliwość pobierania pakietów &lt;code&gt;.deb&lt;/code&gt; za pomocą sieci TOR. W ten
sposób jesteśmy w stanie ukryć nieco informacji na temat zainstalowanego w naszym systemie
oprogramowania. Jakby nie patrzeć, aplikacje mają pełno dziur i nie wszystkie z tych programików są
łatane natychmiast po opublikowaniu podatności. Z chwilą dokonywania aktualizacji systemu,
potencjalny atakujący może dowiedzieć się zatem z jakich programów korzystamy, wliczając w to ich
wersje. Znając te dane, można ocenić czy system posiada jakieś błędy. By zaimplementować w
menadżerze pakietów &lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;aptitude&lt;/code&gt; możliwość korzystania z &lt;a href=&#34;https://www.torproject.org/&#34;&gt;sieci
TOR&lt;/a&gt;, musimy posiadać w systemie skonfigurowanego klienta TOR oraz
zainstalować pakiet &lt;code&gt;apt-transport-tor&lt;/code&gt; . W tym artykule postaramy się skonfigurować ten cały
mechanizm TOR&#39;owych aktualizacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Apache2: Konfiguracja OCSP Stapling</title>
      <link>https://morfikov.github.io/post/apache2-konfiguracja-ocsp-stapling/</link>
      <pubDate>Sat, 06 Aug 2016 19:16:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/apache2-konfiguracja-ocsp-stapling/</guid>
      <description>&lt;p&gt;Serwery udostępniające nam różnego rodzaju strony www na protokole SSL/TLS posiadają certyfikaty,
które są ważne przez pewien okres czasu. Z reguły jest to rok albo, jak w przypadku
&lt;a href=&#34;https://morfikov.github.io
/post/certyfikat-letsencrypt-dla-bloga-certbot/&#34;&gt;letsencrypt&lt;/a&gt;, są to 3 miesiące.
Taki certyfikat może zostać unieważniony z różnych przyczyn ale informacja o tym fakcie musi trafić
do wszystkich klientów odwiedzających taki serwis www. Do tego celu mogą posłużyć dwa mechanizmy.
Pierwszym z nich są listy &lt;a href=&#34;https://pl.wikipedia.org/wiki/Lista_uniewa%C5%BCnionych_certyfikat%C3%B3w&#34;&gt;Certificate Revocation
Lists&lt;/a&gt; (CRL). Drugim zaś
jest &lt;a href=&#34;https://pl.wikipedia.org/wiki/Online_Certificate_Status_Protocol&#34;&gt;Online Certificate Status
Protocol&lt;/a&gt; (OCSP). W tym wpisie
postaramy się zaimplementować to drugie rozwiązanie na serwerze Apache2.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Apache2: Moduł evasive, ipset i iptables (anty DOS/DDOS)</title>
      <link>https://morfikov.github.io/post/apache2-modul-evasive-ipset-iptables/</link>
      <pubDate>Sat, 06 Aug 2016 09:13:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/apache2-modul-evasive-ipset-iptables/</guid>
      <description>&lt;p&gt;Apache2 ma kilka ciekawych modułów, które mogą uchronić nasz serwer www przed atakami DOS i DDOS.
Jednym z nich jest moduł &lt;code&gt;evasive&lt;/code&gt; . Nie jest on jednak oficjalnym modułem i brak o nim
jakiejkolwiek wzmianki w oficjalnej dokumentacji na stronie Apache2. Niemniej jednak, jest to bardzo
prosty moduł składający się dosłownie z kilku dyrektyw, które są w stanie zablokować zapytania o
zasoby serwera w przypadku, gdy zostanie przekroczony pewien ustalony przez nas limit. Dodatkowo,
ten moduł może współgrać z filtrem &lt;code&gt;iptables&lt;/code&gt; oraz &lt;code&gt;ipset&lt;/code&gt; , dając nam możliwość wygodnego
blokowania uporczywych klientów na poziomie pakietów sieciowych.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problemy z dyrektywą SSLOpenSSLConfCmd w Apache2</title>
      <link>https://morfikov.github.io/post/problemy-z-dyrektywa-sslopensslconfcmd-w-apache2/</link>
      <pubDate>Fri, 05 Aug 2016 15:52:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problemy-z-dyrektywa-sslopensslconfcmd-w-apache2/</guid>
      <description>&lt;p&gt;W stabilnej dystrybucji linux&#39;a debian niewiele rzeczy ulega zmianie w przeciągu roku czy dwóch lat.
Dlatego też ta gałąź jest wykorzystywana głównie w przypadku serwerów, min. na tym VPS. Na co dzień
jednak korzystam z debiana SID, czyli gałęzi niestabilnej, która jest nieco bardziej aktualna i
przystosowana do otaczającej nas tej wirtualnej rzeczywistości. Chodzi generalnie o nowsze
oprogramowanie implementujące całą masę ficzerów, których starsze wersje nie posiadają. W tym
przypadku problem dotyczy serwera Apache2, który ostatnimi czasy wypracował szereg mechanizmów
obronnych adresujących ataki na protokół SSL/TLS. Jedną z podatności jest słaba liczba pierwsza
wykorzystywana w &lt;a href=&#34;https://pl.wikipedia.org/wiki/Protok%C3%B3%C5%82_Diffiego-Hellmana&#34;&gt;protokole
Diffie-Hellman&#39;a&lt;/a&gt;. Ten problem
można stosunkowo łatwo poprawić w nowszej wersji Apache2 wykorzystując dyrektywę &lt;code&gt;SSLOpenSSLConfCmd&lt;/code&gt;
. W starszych wersjach ona niestety nie działa. Niemniej jednak, w dalszym ciągu możemy użyć
własnych parametrów dla protokołu Diffie-Hellman&#39;a, z tym, że trzeba to zrobić nieco inaczej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Apache2: Jak odchudzić nieco plik access.log</title>
      <link>https://morfikov.github.io/post/apache2-jak-odchudzic-nieco-plik-access-log/</link>
      <pubDate>Thu, 04 Aug 2016 11:10:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/apache2-jak-odchudzic-nieco-plik-access-log/</guid>
      <description>&lt;p&gt;Mając serwer www oparty o oprogramowanie Apache2, w pewnym momencie zacznie nas nieco przytłaczać
kwestia logowania do pliku &lt;code&gt;/var/log/apache2/access.log&lt;/code&gt; wszystkiego co się nawinie. Jak nazwa pliku
sugeruje, znajdują się w nim komunikaty, które serwer generuje ilekroć tylko ktoś odwiedzi nasz
serwis. Każdy zasób przesłany do klienta, np. style CSS czy obrazki, zostanie zalogowany w powyższym
pliku. Generalnie rzecz ujmując, nie musimy logować wszystkich tych informacji, chyba, że ich
faktycznie potrzebujemy. Trzeba jednak wziąć pod uwagę fakt, że w przypadku obciążonych serwerów,
ilość operacji I/O dysku może być znaczna. Dodatkowo, miejsce na dysku za sprawą takiego obszernego
logu może bardzo szybko się wyczerpać. W tym artykule postaramy się nieco ograniczyć apetyt serwera
Apache2 na logi i oduczymy go logować większość zbędnych komunikatów za sprawą dyrektywy
&lt;code&gt;SetEnvIf&lt;/code&gt;/&lt;code&gt;SetEnvIFNoCase&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>packet_write_wait: Connection to IP port 22: Broken pipe</title>
      <link>https://morfikov.github.io/post/packet_write_wait-connection-to-ip-port-22-broken-pipe/</link>
      <pubDate>Wed, 03 Aug 2016 13:41:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/packet_write_wait-connection-to-ip-port-22-broken-pipe/</guid>
      <description>&lt;p&gt;Operowanie na VPS nie jest jakoś specjalnie trudne, zwłaszcza w przypadku, gdy mamy dostęp root i
możemy logować się na serwer z wykorzystaniem protokołu SSH. Dalej to już zwykła linux&#39;owa
mechanika, która może być nieco inna, w zależności od tego, jaki dokładnie system operacyjny na tym
VPS stoi. Czasami jednak, w pewnym momencie podczas połączenia możemy zostać rozłączeni z
niewiadomych nam przyczyn. Niemniej jednak, zawsze, gdy ten problem występuje, w terminalu można
zobaczyć komunikat: &lt;code&gt;packet_write_wait: Connection to 1.2.3.4 port 22: Broken pipe&lt;/code&gt; . Przydałoby się
zatem coś na ten stan rzeczy poradzić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cache-Control, Last-Modified, ETag i Expires w Apache2</title>
      <link>https://morfikov.github.io/post/cache-control-last-modified-etag-i-expires-w-apache2/</link>
      <pubDate>Mon, 01 Aug 2016 18:50:48 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/cache-control-last-modified-etag-i-expires-w-apache2/</guid>
      <description>&lt;p&gt;Każda przeglądarka internetowa potrafi buforować dane w swoim cache w celach optymalizacji
przeglądanych stron www. Dzięki temu, szereg elementów odwiedzonych już witryn nie musi być
ponownie pobieranych z serwera. Zyskuje na tym nie tylko serwer ale również i sam klient, któremu
strona ładuje się parokrotnie szybciej. Pod ten mechanizm podpadają nie tylko pliki graficzne ale
również style CSS, skrypty JS, a nawet pliki &lt;code&gt;.html&lt;/code&gt; . Generalnie rzecz ujmując, wszystko co serwer
www jest w stanie przesłać przeglądarce. Problemem może jednak się okazać zbyt krótki/długi okres
ważności cache. Jeśli ten czas jest za krótki, to elementy strony będą niepotrzebnie utylizować
łącze, nie tylko nasze ale również i serwera www. Z kolei, jeśli okres ważności będzie za długi,
to będziemy odwiedzać nieaktualną stronę. Optymalnym rozwiązaniem byłaby taka konfiguracja serwera
www, gdzie dla konkretnych elementów strony sami moglibyśmy ustalić czas ważności cache. Apache2
daje nam taką możliwość przez ustawienie nagłówków HTTP &lt;code&gt;Cache-Control&lt;/code&gt; , &lt;code&gt;Expires&lt;/code&gt; , &lt;code&gt;ETag&lt;/code&gt; oraz
&lt;code&gt;Last-Modified&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>&#34;Internal dummy connection&#34; w logu Apache2 (mpm_prefork)</title>
      <link>https://morfikov.github.io/post/internal-dummy-connection-apache2-mpm_prefork/</link>
      <pubDate>Sat, 30 Jul 2016 20:00:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/internal-dummy-connection-apache2-mpm_prefork/</guid>
      <description>&lt;p&gt;Od czasu do czasu przeglądam sobie logi Apache2 w poszukiwaniu pewnych nieprawidłowości. Na dobrą
sprawę, to nie ma tutaj zbytnio dużo roboty, przynajmniej póki co. Niemniej jednak, w pliku
&lt;code&gt;/var/log/apache2/access.log&lt;/code&gt; co jakiś czas pojawiają się komunikaty zawierające &amp;quot;internal dummy
connection&amp;quot;. Za co one odpowiadają i czy można je w zupełności zignorować bez stwarzania zagrożenia
bezpieczeństwa dla serwera www?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zdalny backup przy pomocy rsync, ssh i sudo</title>
      <link>https://morfikov.github.io/post/zdalny-backup-przy-pomocy-rsync-ssh-sudo/</link>
      <pubDate>Thu, 28 Jul 2016 23:15:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zdalny-backup-przy-pomocy-rsync-ssh-sudo/</guid>
      <description>&lt;p&gt;Mój VPS, jako, że jest dość tani, nie zawiera całej masy wynalazków. Jedną z tych bardziej
użytecznych rzeczy jest backup danych na dysku VPS&#39;a. OVH liczy sobie trochę grosza za usługę
snapshot&#39;ów. Dlatego też byłem zmuszony poszukać innego rozwiązania, które sprawiłoby, że kopia
wszystkich ważnych plików byłaby zawsze poza granicami tego VPS. Najlepiej, gdyby te pliki były
umieszczany na moim własnym komputerze, czy jakiejś stacji roboczej, która ma robić za taki
backup&#39;owy serwer. Problem w tym, że ciężko jest zsynchronizować sobie poprawnie katalogi na
odległość, choć jest to możliwe przy pomocy &lt;code&gt;ssh&lt;/code&gt; , &lt;code&gt;rsync&lt;/code&gt; oraz &lt;code&gt;sudo&lt;/code&gt; . Z tym, że mamy tutaj
szereg problemów związanych z uprawnieniami do plików. No i oczywiście trzeba także uwzględnić inny
port SSH. Trochę było z tym zamieszania ale ostatecznie udało się to zadanie rozwiązać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Certyfikat Let&#39;s Encrypt dla bloga WordPress (certbot)</title>
      <link>https://morfikov.github.io/post/certyfikat-letsencrypt-dla-bloga-certbot/</link>
      <pubDate>Sat, 23 Jul 2016 12:00:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/certyfikat-letsencrypt-dla-bloga-certbot/</guid>
      <description>&lt;p&gt;Jeszcze nie tak dawno temu, rzadko który serwis internetowy wykorzystywał certyfikaty SSL/TLS do
zabezpieczenia komunikacji między serwerem, a łączącymi się do niego klientami. W dalszym ciągu
jednak notuje się strony bez &amp;quot;zielonej kłódki&amp;quot; ale na szczęście jest ich coraz mniej w naszym
otoczeniu. Liczbę tych stron można by z powodzeniem ograniczyć jeszcze bardziej, gdyby takie
certyfikaty były za free, łatwe do zaimplementowania i dostępne praktycznie dla każdego od tak. No i
na dobrą sprawę są, tylko ludzie jeszcze nie zdają sobie z tego sprawy. Istnieje bowiem &lt;a href=&#34;https://letsencrypt.org/&#34;&gt;projekt
Let&#39;s Encrypt&lt;/a&gt;, który umożliwia stosunkowo bardzo proste wdrożenie
certyfikatu na serwerze www opartym, np. o oprogramowanie Apache2. W tym wpisie zobaczymy jak ta
cała procedura implementacji certyfikatu SSL/TLS przebiega.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zablokować hotlink&#39;i w Apache2</title>
      <link>https://morfikov.github.io/post/zablokowac-hotlink-apache2/</link>
      <pubDate>Wed, 20 Jul 2016 18:55:21 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zablokowac-hotlink-apache2/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Hotlink&#34;&gt;Hotlink lub hotlinking&lt;/a&gt; to proceder wykorzystywania zasobów
(plików) jednej strony www przez inny serwis internetowy. Chodzi generalnie o to, że materiały,
które pojawiają się w obcych serwisach, fizycznie w dalszym ciągu są hostowane, np. na naszym
serwerze. W taki sposób osoba, która linkuje do naszych plików &lt;code&gt;.jpg&lt;/code&gt; , &lt;code&gt;.png&lt;/code&gt; , &lt;code&gt;.mp3&lt;/code&gt; czy nawet
&lt;code&gt;.css&lt;/code&gt; i tworzy swój serwis w oparciu o nie, nie ponosi przy tym praktycznie żadnego obciążenia ze
swojej strony. Cały ten ciężar jest spychany na nasz serwer, co zjada nam transfer i zapychając
łącze. W tym krótkim wpisie postaramy się zablokować możliwość hotlink&#39;owania przez inne serwisy
www w Apache2.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HTTP Strict Transport Security (HSTS) w Apache2</title>
      <link>https://morfikov.github.io/post/http-strict-transport-security-hsts-apache2/</link>
      <pubDate>Tue, 19 Jul 2016 19:08:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/http-strict-transport-security-hsts-apache2/</guid>
      <description>&lt;p&gt;Ostatnio na niebezpieczniku czytałem &lt;a href=&#34;https://niebezpiecznik.pl/post/podroze-kosztuja/&#34;&gt;taki oto
post&lt;/a&gt;. Historia jak historia, nieco długa ale
mniej więcej w połowie pojawiła się informacja na temat nagłówków HSTS (&lt;a href=&#34;https://en.wikipedia.org/wiki/HTTP_Strict_Transport_Security&#34;&gt;HTTP Strict Transport
Security&lt;/a&gt;), który jest przesyłany w
zapytaniach HTTP/HTTPS. Postanowiłem nieco się zainteresować tym tematem i zbadać czym są te
nagłówki HSTS i w jaki sposób są one w stanie poprawić bezpieczeństwo protokołów SSL/TLS
wykorzystywanych podczas szyfrowania zawartości stron internetowych.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Baza danych pozwoleń w Firefox&#39;ie (permissions.sqlite)</title>
      <link>https://morfikov.github.io/post/baza-danych-pozwolen-firefox-permissions-sqlite/</link>
      <pubDate>Sun, 17 Jul 2016 21:43:14 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/baza-danych-pozwolen-firefox-permissions-sqlite/</guid>
      <description>&lt;p&gt;Praktycznie każda przeglądarka, w tym też i Firefox, oferuje możliwość nadania określonym domenom
praw dostępu do zasobów systemowych. Chodzi generalnie o wykorzystywanie wtyczek, np. flash, które
są aktywowane na danej stronie internetowej jeśli ta ich potrzebuje. Po części też sprawa dotyczy
korzystania z urządzeń takich jak wbudowane w laptop kamera i mikrofon oraz szeregu dodatkowych
rzeczy, np. ciasteczka, pop-up&#39;y i inne takie. Obecnie Firefox standardowo blokuje dostęp do
pluginów, a gdy zachodzi potrzeba skorzystania z któregoś z nich, to zostaje nam zaprezentowane
okienko, w którym możemy zdecydować co zrobić. Gdy często odwiedzamy daną witrynę, to naturalnie
prosimy naszą przeglądarkę, by ta zapisała ustawienia dla tej strony. Firefox robi to przez dodanie
wyjątku w pliku &lt;code&gt;permissions.sqlite&lt;/code&gt; . W sporej części przypadków będziemy mogli cofnąć pozwolenia w
dość prosty sposób. Niemniej jednak, nie we wszystkich z nich da się to tak łatwo zrobić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nf_conntrack: automatic helper assignment is deprecated</title>
      <link>https://morfikov.github.io/post/nf_conntrack-automatic-helper-assignment-deprecated/</link>
      <pubDate>Sat, 16 Jul 2016 18:59:19 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/nf_conntrack-automatic-helper-assignment-deprecated/</guid>
      <description>&lt;p&gt;Jeśli ktoś uważnie śledzi logi systemowe, to od czasu do czasu można w nich znaleźć komunikat,
którzy brzmi mniej więcej tak: &lt;code&gt;nf_conntrack: automatic helper assignment is deprecated and it will be removed soon. Use the iptables CT target to attach helpers instead&lt;/code&gt; . Ta wiadomość odnosi się do
jednego z modułów linux&#39;owego filtra pakietów &lt;code&gt;iptables&lt;/code&gt; . Moduł, o którym mowa to &lt;code&gt;nf_conntrack&lt;/code&gt; ,
który odpowiada za śledzenie połączeń nawiązywanych przez system. Sam komunikat zaś dotyczy
mechanizmów pomocniczych, których sposób aktywacji jest już nieco przestarzały i zostanie wkrótce
usunięty. Co to oznacza dla przeciętnego użytkownika linux&#39;a i czym są w istocie te mechanizmy
pomocnicze, które znajdują zastosowane na zaporze sieciowej?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zweryfikować status poleceń w pipe</title>
      <link>https://morfikov.github.io/post/zweryfikowac-status-polecen-pipe/</link>
      <pubDate>Sun, 10 Jul 2016 19:14:31 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zweryfikowac-status-polecen-pipe/</guid>
      <description>&lt;p&gt;Ja zbytnio się nie nadaję na programistę ale czasem jakieś trzeciorzędne skrypty nawet potrafię
napisać. Problem ze skryptami jest taki, że mogą one nie do końca działać jak należy. Zwykle w
takich przypadkach, skrypt zwraca jakiś kod wyjścia. Z reguły też jest on inny od 0, który z kolei
oznacza, że skrypt został wykonany prawidłowo. Załóżmy teraz, że wywołujemy szereg poleceń. Każde z
nich przekierowuje swoje wyjście na wejście innego polecenia przy pomocy znaku &lt;code&gt;|&lt;/code&gt; (pipe) . Jak w
takim przypadku ustalić czy wszystkie z tych poleceń w łańcuchu wykonały się poprawnie? W tym wpisie
postaramy się odpowiedzieć na to pytanie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja kluczy GPG na github&#39;ie</title>
      <link>https://morfikov.github.io/post/implementacja-kluczy-gpg-githubie/</link>
      <pubDate>Sun, 03 Jul 2016 15:30:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-kluczy-gpg-githubie/</guid>
      <description>&lt;p&gt;Github to serwis, w którym użytkownicy mogą pracować wspólnie nad różnymi projektami utrzymywanymi w
systemie kontroli wersji GIT. Konto w w/w serwisie może być łakomym kąskiem dla przestępców,
zwłaszcza gdy uczestniczymy w dość rozbudowanych projektach i przyczyniamy się do ich tworzenia w
dużym stopniu. Z tego powodu github implementuje rozwiązania, które mają na celu poprawić
bezpieczeństwo naszej pracy. Mamy już uwierzytelnianie dwuetapowe, &lt;a href=&#34;https://morfikov.github.io
/post/github-z-obsluga-kluczy-ssh/&#34;&gt;obsługę kluczy
SSH&lt;/a&gt; ale nadal brakowało odpornego systemu,
który by uwierzytelnił osoby współdziałające z nami. Chodzi o to, że wszelkie zmiany w repozytorium
GIT muszą być przez kogoś poczynione. Każdy commit ma zatem swojego właściciela ale my nigdy nie
mamy pewności co do tego, kto tak naprawdę tej zmiany dokonał. Dlatego też &lt;a href=&#34;https://github.com/blog/2144-gpg-signature-verification&#34;&gt;github umożliwił
ostatnio podpisywanie tagów i commit&#39;ów przy pomocy kluczy
GPG&lt;/a&gt;. To właśnie temu tematowi będzie
poświęcony niniejszy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Unexpected Inconsistency: Inode has corrupt extent header</title>
      <link>https://morfikov.github.io/post/unexpected-inconsistency-inode-corrupt-extent-header/</link>
      <pubDate>Fri, 01 Jul 2016 14:27:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/unexpected-inconsistency-inode-corrupt-extent-header/</guid>
      <description>&lt;p&gt;Dzisiaj system plików jednej z partycji mojego głównego dysku uległ awarii z niewiadomych przyczyn.
Dałbym sobie nawet głowę uciąć, że wszystkie partycje zostały poprawnie odmontowane podczas
wyłączania maszyny. Niemniej jednak, z jakiegoś powodu podczas startu systemu, ten wyrzuca szereg
komunikatów dotyczących głównego systemu plików, tj. &lt;code&gt;/&lt;/code&gt; . Sam komunikat brzmi mniej więcej tak:
&lt;code&gt;UNEXPECTED INCONSISTENCY; RUN fsck MANUALLY&lt;/code&gt; . Oznacza to, że błędy w systemie plików nie są łatwe
do naprawy i wymagana jest nasza ingerencja w ten proces. Przy sprawdzaniu systemu plików w
poszukiwaniu błędów przy pomocy &lt;code&gt;fsck.ext4&lt;/code&gt; można było dostrzec min. taką wiadomość: &lt;code&gt;Inode 556975 has corrupt extent header&lt;/code&gt; . Co ona tak naprawdę oznacza i czy damy radę wybrnąć z tej sytuacji bez
szwanku?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Narzędzia nice, renice, ionice, taskset i trickle</title>
      <link>https://morfikov.github.io/post/nice-renice-ionice-taskset-trickle/</link>
      <pubDate>Thu, 16 Jun 2016 21:35:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/nice-renice-ionice-taskset-trickle/</guid>
      <description>&lt;p&gt;W każdym systemie operacyjnym cała masa procesów rywalizuje ze sobą o zasoby, w skład których
wchodzą min. pamięć operacyjna RAM, procesor i operacje I/O dysku twardego. Czasami zdarza się tak,
że niektóre aplikacje są w stanie zdusić inne programy, bo mają zbyt duże wymagania co do zasobów
systemowych. W takich przypadkach administrator systemu powinien zatroszczyć się o przydział zasobów
konkretnym procesom. W linux&#39;ie do tego typu prac przeznaczony jest &lt;a href=&#34;https://morfikov.github.io
/post/ograniczanie-zasobow-procesom-przez-cgroups/&#34;&gt;mechanizm
cgroups&lt;/a&gt; obecny w kernelu.
Niemniej jednak, jeśli cgroups przerasta nasze umiejętności albo też z jakiegoś powodu nie możemy z
niego korzystać, to istnieje inne rozwiązanie, które może nam pomóc ograniczyć zasoby przydzielane
procesom przez nasz system. Chodzi generalnie o narzędzia &lt;code&gt;nice&lt;/code&gt;/&lt;code&gt;renice&lt;/code&gt; (procesor) , &lt;code&gt;ionice&lt;/code&gt;
(dysku twardy) , &lt;code&gt;taskset&lt;/code&gt; (przypisanie procesu do konkretnego procesora) oraz &lt;code&gt;trickle&lt;/code&gt; (sieć). W
tym wpisie zobaczymy jak przy pomocy tych powyższych narzędzi limitować procesy systemowe.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Skrypt dhclient&#39;a (dhclient script)</title>
      <link>https://morfikov.github.io/post/skrypt-dhclienta-dhclient-script/</link>
      <pubDate>Tue, 14 Jun 2016 16:26:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/skrypt-dhclienta-dhclient-script/</guid>
      <description>&lt;p&gt;Jak wiele osób zapewne wie, szereg dystrybucji linux&#39;a wykorzystuje &lt;code&gt;dhclient&lt;/code&gt; w celu pobrania
sieciowej konfiguracji hosta za sprawą protokółu DHCP. W zasadzie cała konfiguracja tego narzędzia
sprowadza się do określenia szeregu opcji w pliku &lt;code&gt;/etc/dhcp/dhclient.conf&lt;/code&gt; . W debianie nawet nie
musimy dotykać tego pliku, by wszystko działało nam jak trzeba. Niemniej jednak, czasem konfiguracja
interfejsów sieciowych może wymagać od nas dodatkowych zabiegów. W celu ułatwienia życia adminom
dodano obsługę skryptów shell&#39;owych
(&lt;a href=&#34;http://manpages.ubuntu.com/manpages/xenial/en/man8/dhclient-script.8.html&#34;&gt;dhclient-script&lt;/a&gt;). Taki
skrypt jesteśmy w stanie wywołać w zależności od zaistniałych zdarzeń protokołu DHCP. W tym wpisie
zostanie pokazane w jaki sposób te skrypty możemy utworzyć i wykorzystać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja interfejsów sieciowych w dhclient</title>
      <link>https://morfikov.github.io/post/konfiguracja-interfejsow-sieciowych-w-dhclient/</link>
      <pubDate>Thu, 09 Jun 2016 18:05:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-interfejsow-sieciowych-w-dhclient/</guid>
      <description>&lt;p&gt;Konfiguracja maszyn w sieci za sprawą protokołu DHCP znacznie ułatwia życie administratorom. Cały
ten proces jest nie tylko szybszy ale też eliminuje szereg błędów, które mogą pojawić się za sprawą
czynnika ludzkiego. W przypadku, gdy nasza maszyna dysponuje kilkoma interfejsami sieciowymi, to
każdy z nich możemy skonfigurować nieco inaczej. Oczywiście, nie chodzi o samą konfigurację
adresacji ale o szereg parametrów, które klient przesyła do serwera DHCP. To dzięki nim host min.
wie jak ustawić adresację na interfejsie i pod jaki adres słać zapytania DNS. Każdy interfejs może w
ten sposób posiadać własne opcje, które klient DHCP będzie przesyłał do serwera. W tym artykule
postaramy się konfigurować niezależnie dwa interfejsy sieciowe przy pomocy &lt;code&gt;dhclient&lt;/code&gt; , czyli
domyślnego klienta DHCP w linux&#39;ie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak odszukać pliki utworzone godzinę temu (find)</title>
      <link>https://morfikov.github.io/post/jak-odszukac-pliki-utworzone-godzine-temu-find/</link>
      <pubDate>Thu, 09 Jun 2016 12:44:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-odszukac-pliki-utworzone-godzine-temu-find/</guid>
      <description>&lt;p&gt;W linux&#39;ie wszystko może być reprezentowane za pomocą pliku. Te pliki są tworzone, zmieniane i
usuwane praktycznie non stop podczas pracy systemu operacyjnego. Zwykle też nie zwracamy uwagi na
metadane opisujące pliki w systemie plików, bo przecie bardziej interesuje nas ich zawartość.
Niemniej jednak, w pewnych sytuacjach te metadane mogą się okazać bardzo użyteczne. Weźmy sobie
przykład partycji &lt;code&gt;/home/&lt;/code&gt; . Prawie zawsze po odpaleniu aplikacji są tworzone na niej nowe pliki lub
zmieniane te już istniejące. Jako, że nie zawsze wiemy na jakich plikach operuje dany program, to
moglibyśmy przeszukać pliki w katalogu domowym użytkownika i poddać analizie ich czas modyfikacji.
Taką operacje możemy przeprowadzić przy pomocy polecenia &lt;code&gt;find&lt;/code&gt; i w tym wpisie zobaczymy jak tego
dokonać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uruchamianie zadań cron co 15 minut lub 6 godzin</title>
      <link>https://morfikov.github.io/post/zadania-cron-co-15-minut-lub-6-godzin/</link>
      <pubDate>Tue, 07 Jun 2016 18:56:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zadania-cron-co-15-minut-lub-6-godzin/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Cron&#34;&gt;cron&lt;/a&gt; to takie linux&#39;owe narzędzie, które cyklicznie, co pewien
ustalony interwał czasu, wykonuje jakieś zaplanowane zadania. Minimalna wartość tego interwału to
jedna minuta. Niemniej jednak, bardzo wielu użytkowników linux&#39;a zastanawia się w jaki sposób
wywołać określone zadanie, np. co 5, 10, 15, 30 minut, czy nawet co 2, 6 albo 12 godzin. Dlatego
właśnie powstał ten wpis, by nieco przybliżyć mechanikę samego cron&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Data i czas utworzenia pliku w linux&#39;ie (crtime)</title>
      <link>https://morfikov.github.io/post/data-czas-utworzenia-pliku-w-linuxie-crtime/</link>
      <pubDate>Tue, 07 Jun 2016 17:07:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/data-czas-utworzenia-pliku-w-linuxie-crtime/</guid>
      <description>&lt;p&gt;Systemy plików, które wykorzystujemy na partycjach swoich dysków, zawierają metadane opisujące
pliki. Domyślnym systemem plików w większości linux&#39;ów (do nich zalicza się też debian) jest EXT4.
Gdy listujemy pliki przy pomocy narzędzia &lt;code&gt;ls&lt;/code&gt; , jesteśmy w stanie uzyskać szereg informacji
opisujących konkretny plik. Mamy tam min. czas ostatniej modyfikacji i-węzła (i-node), czyli tzw.
&lt;code&gt;ctime&lt;/code&gt; . Narzędzia takie jak &lt;code&gt;stat&lt;/code&gt; są w stanie podać również inne czasy, tj. &lt;code&gt;atime&lt;/code&gt; (ostatni czas
dostępu do pliku) oraz &lt;code&gt;mtime&lt;/code&gt; (ostatni czas modyfikacji pliku). Jednak żaden z tych powyższych nie
przekłada się na czas utworzenia pliku. Co prawda, po stworzeniu pliku, wszystkie te czasy są ze
sobą zsynchronizowane ale po przeprowadzeniu szeregu różnych operacji na tym pliku, problematyczne
może być ustalenie pierwotnej daty jego utworzenia. Celem tego artykułu jest pokazanie, jak przy
pomocy &lt;code&gt;debugfs&lt;/code&gt; uzyskać czas utworzenia dowolnie wskazanego pliku w systemie plików EXT4.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>FZF (fuzzy finder) dla tmux&#39;a</title>
      <link>https://morfikov.github.io/post/fzf-fuzzy-finder-dla-tmuxa/</link>
      <pubDate>Mon, 06 Jun 2016 10:47:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/fzf-fuzzy-finder-dla-tmuxa/</guid>
      <description>&lt;p&gt;Jakiś czas temu pisałem o &lt;a href=&#34;https://morfikov.github.io
/post/implementacja-multipleksera-tmux/&#34;&gt;implementacji tmux&#39;a na
debianie&lt;/a&gt;. Dla tych, którzy nie za bardzo
wiedzą &lt;a href=&#34;https://tmux.github.io/&#34;&gt;czym tmux jest&lt;/a&gt;, to wyjaśniam, że jest to narzędzie, które min.
potrafi dzielić okno terminala na kilka mniejszych okienek. W ten sposób możemy korzystać ze swojego
ulubionego terminala i cieszyć się funkcjonalnością znaną choćby z terminatora. Ta umiejętność
dzielenia okien w tmux idealnie współgra z &lt;a href=&#34;https://github.com/junegunn/fzf&#34;&gt;FZF (fuzzy finder)&lt;/a&gt;.
Jest to narzędzie, które pomaga min. przeszukiwać historię poleceń shell&#39;a. BASH czy ZSH są, jakby
nie patrzeć, dość ograniczone pod tym względem. Może i ZSH nieco lepiej radzi sobie z odnajdywaniem
poleceń w historii od BASH ale i tak jego umiejętności pozostają daleko w tyle za FZF. Dlatego też w
tym artykule spróbujemy sobie zainstalować ten cały &amp;quot;fuzzy finder&amp;quot;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wyczyścić tablicę conntrack&#39;a w debianie</title>
      <link>https://morfikov.github.io/post/jak-wyczyscic-tablice-conntrack-w-debianie/</link>
      <pubDate>Sun, 05 Jun 2016 12:34:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wyczyscic-tablice-conntrack-w-debianie/</guid>
      <description>&lt;p&gt;Sporo użytkowników lunux&#39;a, zwłaszcza dystrybucji debian, korzysta z własnych skryptów firewall&#39;a
aplikujących reguły &lt;code&gt;iptables&lt;/code&gt; . Tego typu rozwiązanie ma jednak swoje wady i zalety. Niewątpliwie
do zalet można zaliczyć brak dodatkowego oprogramowania obsługującego zaporę sieciową. Jeśli chodzi
zaś o wady, to niestety cały skrypt trzeba sobie dobrze przemyśleć przed zaaplikowaniem. Ludzie
często zapominają tutaj o śledzeniu połączeń przez kernel. To właśnie na podstawie wpisów w
&lt;code&gt;/proc/net/ip_conntrack&lt;/code&gt; lub &lt;code&gt;/proc/net/nf_conntrack&lt;/code&gt; system wie, które pakiety należy na zaporze
przepuścić, a które zablokować. Jeśli teraz dodajemy reguły do filtra &lt;code&gt;iptables&lt;/code&gt; , to nowa polityka
zapory nie będzie odnosić się do tych nawiązanych już połączeń, które są określone w tablicy
conntrack&#39;a. By się upewnić, że tego typu scenariusz nigdy nas nie spotka, musimy tę tablicę
opróżnić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja trybu AP kart WiFi na debianie</title>
      <link>https://morfikov.github.io/post/konfiguracja-trybu-ap-kart-wifi-na-debianie/</link>
      <pubDate>Sat, 04 Jun 2016 15:26:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-trybu-ap-kart-wifi-na-debianie/</guid>
      <description>&lt;p&gt;Jakiś czas temu dokonałem zakupu adaptera WiFi &lt;a href=&#34;https://morfikov.github.io
/post/recenzja-karta-wifi-tp-link-tl-wn722n/&#34;&gt;TP-Link
TL-WN722n&lt;/a&gt;, a to z tego względu, że
potrzebowałem zewnętrznej karty sieciowej do mojego laptopa. Chodziło generalnie o to, że ten
wbudowany w niego broadcom nie był w stanie robić kilku użytecznych rzeczy, min. testów
penetracyjnych mojej bezprzewodowej sieci domowej. Jak się później okazało, ten zakupiony adapter
posiada też dodatkowy ficzer, którym jest tryb AP (Access Point). Wprawdzie ta karta nie może się
równać z routerami WiFi, bo te zwykle mają więcej anten, z których każda jest lepszej jakości ale
jesteśmy w stanie połączyć ze sobą bezprzewodowo kilka stacji roboczych. Trzeba jednak wziąć po
uwagę, że zasięg jak i transfer będą w dużej mierze ograniczone. W tym wpisie postaramy się
przerobić zwykłą maszynę, na której jest zainstalowany debian, na punkt dostępowy sieci WiFi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sparse files (rozrzedzone pliki)</title>
      <link>https://morfikov.github.io/post/sparse-files-rozrzedzone-pliki/</link>
      <pubDate>Thu, 02 Jun 2016 16:42:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sparse-files-rozrzedzone-pliki/</guid>
      <description>&lt;p&gt;Każdy system plików opiera się na blokach danych. Standardowo taki blok w systemie plików EXT4 ma 4
KiB (8 x 512 bajtów). Za każdym razem, gdy tworzymy jakiś plik na dysku, alokowana jest pewna część
bloków, na których ten plik ma zostać zapisany. Te większe pliki rezerwują więcej bloków, choć nie
zawsze są to bloki ciągłe. W taki sposób, plik o rozmiarze 10 GiB okupowałby dokładnie tyle miejsca
na dysku ile sam waży. Niemniej jednak są pewne pliki, które może i ważą te 10 GiB ale system plików
postrzega je tak jakby miały 100 MiB czy 200 MiB, w zależności od tego ile &amp;quot;faktycznie&amp;quot; taki plik
zajmuje miejsca. Jak to możliwe? Pliki, o których mowa, to tzw. &amp;quot;rozrzedzone pliki&amp;quot; (&lt;a href=&#34;https://en.wikipedia.org/wiki/Sparse_file&#34;&gt;Sparse
files&lt;/a&gt;). Taki plik składa się z szeregu bloków pustych
(mających same zera), których nie trzeba zapisywać na dysk. Zamiast tego, można jedynie zapisać
metadane w strykturze systemu plików, które będą opisywać te puste bloki. Poniższy artykuł ma na
celu pokazać do czego takie pliki sparse mogą nam się przydać i jak z nich korzystać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ukryć user-agent w nagłówku email</title>
      <link>https://morfikov.github.io/post/jak-ukryc-user-agent-w-naglowku-email/</link>
      <pubDate>Sun, 29 May 2016 12:05:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ukryc-user-agent-w-naglowku-email/</guid>
      <description>&lt;p&gt;Na każdym kroku można natknąć się na przecieki informacyjne, które zagrażają naszej prywatności.
Widzieliśmy to choćby i na przykładzie &lt;a href=&#34;https://morfikov.github.io
/post/jak-ukryc-prywatny-adres-ip-w-naglowku-email/&#34;&gt;prywatnego adresu IP widocznego w nagłówku w wiadomości
email&lt;/a&gt;. Przeglądając ten
podlinkowany wpis mogliśmy z grubsza zobaczyć jak wygląda taki nagłówek wiadomości. Bardziej uważni
czytelnicy zwrócili uwagę na jego zawartość. Poza polem zawierającym adres IP, można było też
zobaczyć pole odpowiadające za &lt;a href=&#34;https://pl.wikipedia.org/wiki/User_agent&#34;&gt;user-agent&lt;/a&gt;. Ciąg zawarty
w tym polu zdradza informacje na temat wykorzystywanego klienta pocztowego oraz systemu
operacyjnego. Ten komunikat możemy jednak ukryć i w tym wpisie zostanie to pokazane na przykładzie
&lt;a href=&#34;https://www.mozilla.org/pl/thunderbird/&#34;&gt;Thunderbird&#39;a&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ukryć prywatny adres IP w nagłówku email</title>
      <link>https://morfikov.github.io/post/jak-ukryc-prywatny-adres-ip-w-naglowku-email/</link>
      <pubDate>Sat, 28 May 2016 18:29:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ukryc-prywatny-adres-ip-w-naglowku-email/</guid>
      <description>&lt;p&gt;Korzystając z różnego rodzaju klientów email udostępniamy serwerom mailowym nieco więcej informacji
niż gdybyśmy to robili z panelu webowego serwera pocztowego. Chodzi generalnie o adres IP hosta,
który przesłał wiadomość na serwer. Tradycyjnie w nagłówku email&#39;a znajdzie się nasz adres
zewnętrzny, ten przypisany przez ISP. Niemniej jednak, w części przypadków będzie załączony również
adres IP z przestrzeni prywatnej, np. 10.0.0.0/8 lub 192.168.0.0/16 . O ile nie damy rady zataić
publicznego IP naszego ISP, to jesteśmy w stanie ukryć ten prywatny adres i tym samym nieco poprawić
naszą prywatność. W tym wpisie zostanie pokazane, to jak ten adres prywatny ukryć w nagłówku
wiadomości email w kliencie &lt;a href=&#34;https://www.mozilla.org/pl/thunderbird/&#34;&gt;Thunderbird&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ukryć hostname w protokole DHCP</title>
      <link>https://morfikov.github.io/post/jak-ukryc-hostname-w-protokole-dhcp/</link>
      <pubDate>Tue, 24 May 2016 20:07:14 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ukryc-hostname-w-protokole-dhcp/</guid>
      <description>&lt;p&gt;Darmowe hotspoty sieci WiFi są dostępne w każdym mieście. Dzięki nim możemy uzyskać połączenie z
internetem praktycznie za free. Niemniej jednak, takie połączenie nie jest do końca bezpieczne i
może zagrażać naszej prywatności. Wiele osób stara się temu przeciwdziałać &lt;a href=&#34;https://morfikov.github.io
/post/jak-przypisac-losowy-adres-mac-interfejsu/&#34;&gt;generując losowy adres
MAC&lt;/a&gt;. No i to jest jakieś
wyjście, o ile ten adres jest generowany z głową. Niemniej jednak, w takich sieciach WiFi, host ma
przydzielaną adresację za pomocą &lt;a href=&#34;https://pl.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol&#34;&gt;protokołu
DHCP&lt;/a&gt;. Ci, którzy wiedza, jak
odbywa się konfiguracja za pomocą tego protokołu, wiedzą też, że nasz komputer przesyła pewne dane
do serwera DHCP. Jakie dane? To zwykle zależy od konfiguracji klienta DHCP. Na linux&#39;ach domyślnym
klientem DHCP jest &lt;code&gt;dhclinet&lt;/code&gt; i on standardowo przesyła nazwę hosta (hostname) w zapytaniu o
adresację. Co nam zatem po losowym adresie MAC, gdy można nas zidentyfikować po nazwie hosta? W tym
artykule postaramy się ukryć lub też losowo wygenerować hostname danej maszyny w sieci.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja DDNS dla OpenDNS</title>
      <link>https://morfikov.github.io/post/konfiguracja-ddns-dla-opendns/</link>
      <pubDate>Mon, 23 May 2016 20:09:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-ddns-dla-opendns/</guid>
      <description>&lt;p&gt;Ludzkość w dalszym ciągu siedzi na przestarzałym już od prawie 20 lat protokole IPv4. Nie widać, też
by w najbliższym czasie coś miało się w tej kwestii zmienić. Można, co prawda, wykupić sobie stały
adres IP ale to kosztuje, no i płacimy za coś co powinniśmy mieć w standardzie, gdyby ludzie w końcu
zaczęli korzystać z IPv6. Niemniej jednak, by te wszystkie nasze maszyny podłączyć jakoś do sieci,
potrzebne nam są prywatne adresy IP + NAT lub też dynamicznie zmieniające się adresy publiczne.
Bywają też przypadki, że mamy przydzielane dynamicznie adresy z puli prywatnej, np. w wyniku dbania
o prywatność w sieciach WiFi przez &lt;a href=&#34;https://morfikov.github.io
/post/jak-przypisac-losowy-adres-mac-interfejsu/&#34;&gt;generowanie sobie przy każdym połączeniu losowego adresu
MAC&lt;/a&gt;. Zwykle w takiej sytuacji
zmienia nam się adres zewnętrzny (publiczny), który wskazuje na jeden z adresów naszego ISP. Taki
zmieniający się adres powoduje problemy przy konfiguracji poszczególnych usług sieciowych, np. gdy w
grę wchodzi konfiguracja filtra DNS, który jest zapewniany przez OpenDNS. By tego typu niedogodności
rozwiązać, możemy posłużyć się &lt;a href=&#34;https://pl.wikipedia.org/wiki/DDNS&#34;&gt;DDNS (dynamic DNS)&lt;/a&gt;. Za każdym
razem, gdy adres IP ulega zmianie, klient DDNS informuje o tym fakcie skonfigurowane usługi. W tym
artykule przyjrzymy się nieco bliżej temu mechanizmowi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Równoważenie ruchu łącz kilku ISP (load balancing)</title>
      <link>https://morfikov.github.io/post/rownowazenie-ruchu-lacz-kilku-isp-load-balancing/</link>
      <pubDate>Sun, 22 May 2016 13:40:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/rownowazenie-ruchu-lacz-kilku-isp-load-balancing/</guid>
      <description>&lt;p&gt;Podłączenie pojedynczego komputera do sieci raczej nie stanowi żadnego problemu dla przeciętnego
użytkownika linux&#39;a. Wystarczy jedynie skonfigurować kilka parametrów i możemy oglądać swoje
ulubione serwisy www. Co jednak w przypadku, gdy mamy do dyspozycji kilka łącz internetowych? Jedną
z opcji jest używanie łącza tego ISP, które jest lepsze gabarytowo, a pozostałe łącza trzymać na
wypadek awarii tego pierwszego. Nie jest to zbytnio satysfakcjonujące rozwiązanie, zwłaszcza w
przypadku, gdy tym providerom płacimy za świadczone nam usługi. W taki sposób płacimy, np. za dwa
łącza, a korzystamy z jednego w danej chwili. W linux&#39;ie obsługa wielu łącz różnych ISP jest dość
skomplikowana. By taki mechanizm zaimplementować sobie, trzeba stworzyć kilka tablic routingu.
Następnie ruch sieciowy musi zostać oznaczony w &lt;code&gt;iptables&lt;/code&gt; i przekierowany do tych tablic przez
kernel. Przy odrobienie wysiłku jesteśmy jednak w stanie zaprojektować sobie load balancer, który
będzie równoważył obciążenie łącza między kilku ISP. Dodatkowo, jeśli jedno z łączy nam nawali, to
automatycznie zostaniemy przełączeni na drugie łącze (failover). W tym artykule postaramy się
zaprojektować taki właśnie mechanizm.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Target MARK w iptables (sumowanie oznaczeń)</title>
      <link>https://morfikov.github.io/post/target-mark-w-iptables/</link>
      <pubDate>Wed, 18 May 2016 15:17:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/target-mark-w-iptables/</guid>
      <description>&lt;p&gt;Pakiety i połączenia można oznaczać w &lt;code&gt;iptables&lt;/code&gt; za pomocą target &lt;code&gt;MARK&lt;/code&gt; oraz &lt;code&gt;CONNMARK&lt;/code&gt; . Ta
właściwość tego filtra jest znana chyba większość użytkowników linux&#39;a. Z reguły nie interesujemy
się zbytnio szczegółami oznaczania pakietów/połączeń, bo zwykle jest ono przeprowadzane prawidłowo.
Niemniej jednak, są przypadki, w których markery nie będą ustawiane poprawnie. Chodzi o sytuacje,
gdzie mamy do czynienia z kilkoma mechanizmami oznaczającymi pakiety. Dla przykładu weźmy sobie
kształtowanie ruchu za pomocą narzędzia &lt;code&gt;tc&lt;/code&gt; oraz failover czy load balancing łącza w oparciu o
różne tablice routingu. W obu tych mechanizmach zwykle używa się markowania pakietów w &lt;code&gt;iptables&lt;/code&gt;
. Co się jednak dzieje z takim pakietem, gdy przechodzi przez reguły zarówno pierwszego jak i
drugiego mechanizmu? To właśnie spróbujemy ustalić w tym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>CUPS, czyli konfiguracja drukarki pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/cups-konfiguracja-drukarki-pod-linuxem/</link>
      <pubDate>Wed, 11 May 2016 21:45:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/cups-konfiguracja-drukarki-pod-linuxem/</guid>
      <description>&lt;p&gt;Ja jestem tym szczęśliwcem, który posiada takie fajne urządzenie zwane drukarką. Bardzo umila ono
życie pod warunkiem, że działa jak należy, a z tym różnie bywa, zwłaszcza pod linux&#39;em. W debianie
do obsługi drukarek używa się &lt;a href=&#34;https://en.wikipedia.org/wiki/CUPS&#34;&gt;CUPS (Common Unix Printing
System)&lt;/a&gt; i można powiedzieć, że radzi on sobie z tym zadaniem
całkiem nieźle, przynajmniej w przypadku mojej drukarki. Drukarka, o której mowa, to dość stary
model, konkretnie jest to EPSON Stylus Color 760. Potrzebne są jej odpowiednie sterowniki, które są
dostępne w repozytorium debiana. Jedyne czego potrzeba do szczęścia, to skonfigurowanie demona
&lt;code&gt;cupsd&lt;/code&gt; , który będzie zarządzał tą drukarką. W tym artykule postaramy się skonfigurować to powyższe
urządzenie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Debugowanie reguł iptables via target TRACE</title>
      <link>https://morfikov.github.io/post/debugowanie-regul-iptables-target-trace/</link>
      <pubDate>Wed, 11 May 2016 13:20:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/debugowanie-regul-iptables-target-trace/</guid>
      <description>&lt;p&gt;Linux&#39;owy firewall w postaci &lt;code&gt;iptables&lt;/code&gt; może czasami mieć zdefiniowanych sporo reguł. W takim
gąszczu jest czasem ciężko się odnaleźć. Bywa zwykle tak, że dodając kolejną regułę chcemy
przyblokować szereg pakietów, a mimo to przechodzą one przez zaporę jak gdyby nigdy nic. W takim
przypadku zaczyna się mozolne przeszukiwanie reguł w &lt;code&gt;iptables&lt;/code&gt; i próba ustalenia, którą z nich
zaakceptowała interesujący nas pakiet. Nie musimy jednak głowić się aż tak, by w miarę szybko dociec
jak te reguły przez filtr przechodzą i jak są przetwarzane. Możemy skorzystać z mechanizmu śledzenia
reguł, który jest wbudowany bezpośrednio w &lt;code&gt;iptables&lt;/code&gt; . Mowa oczywiście o target &lt;code&gt;TRACE&lt;/code&gt; . W tym
artykule zobaczymy jak przy pomocy &lt;code&gt;TRACE&lt;/code&gt; ustalić, przez które reguły i łańcuchy przechodzi pakiet.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SMStools i smsd, czyli automat do wysyłania SMS</title>
      <link>https://morfikov.github.io/post/smstools-smsd-automat-wysylania-sms/</link>
      <pubDate>Fri, 06 May 2016 20:33:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/smstools-smsd-automat-wysylania-sms/</guid>
      <description>&lt;p&gt;Pod linux&#39;em jest całe mnóstwo oprogramowania, które może realizować zadanie odbierania i wysyłania
wiadomości SMS. Są również narzędzia, dzięki którym cały proces związany z przetwarzaniem SMS&#39;ów
można zautomatyzować. Jakiś czas temu opisywałem tego typu funkcjonalność na przykładzie
&lt;a href=&#34;https://morfikov.github.io
/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/&#34;&gt;gammu-smsd&lt;/a&gt;. Nadal uważam, że
jest to przyzwoite narzędzie ale jakby nie patrzeć wymaga ono wielu zależności. Właśnie przez nie
&lt;code&gt;gammu-smsd&lt;/code&gt; nie nadaje się do zastosowań, gdzie ma się do dyspozycji niewiele miejsca. Niemniej
jednak, w przypadku OpenWRT mamy tam możliwość zainstalowania pakietu &lt;code&gt;smstool3&lt;/code&gt; , w którym jest
dostępny demon &lt;code&gt;smsd&lt;/code&gt; . Tak się też składa, że debian również ma swoich repozytoriach to narzędzie
posiada, z tym, że w pakiecie &lt;a href=&#34;http://smstools3.kekekasvi.com/index.php?p=blacklist&#34;&gt;smstools&lt;/a&gt;. W
tym wpisie skonfigurujemy sobie działającą bramkę SMS, która będzie automatycznie odbierać
wiadomości SMS i podejmować stosowne działanie w zależności od numeru czy treści otrzymanego
komunikatu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przypisać losowy adres MAC do interfejsu</title>
      <link>https://morfikov.github.io/post/jak-przypisac-losowy-adres-mac-interfejsu/</link>
      <pubDate>Fri, 29 Apr 2016 16:42:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przypisac-losowy-adres-mac-interfejsu/</guid>
      <description>&lt;p&gt;Interfejsy kart sieciowych, które są instalowane w komputerach, posiadają adres MAC (&lt;a href=&#34;https://en.wikipedia.org/wiki/MAC_address&#34;&gt;Media Access
Control&lt;/a&gt;). Jest to unikalny identyfikator, który wyróżnia
nasz komputer spośród tłumu. Na podstawie tego adresu można nie tylko określić markę sprzętu, którą
się posługujemy ale także można sklasyfikować cały nasz ruch sieciowy. W ten sposób bardzo prosto
możemy zostać zidentyfikowani wymieniając dane przez darmowe hotspoty sieci bezprzewodowych WiFi.
Niemniej jednak, jesteśmy się w stanie obronić przed tego typu inwigilacją zmieniając adres MAC
naszego komputera. Nie jest to zbytnio trudne ale trzeba uważać, by znowu nie przesadzić w drugą
stronę i czasem nie zostać zidentyfikowanym przez naszą &amp;quot;odmienność&amp;quot;. W tym wpisie postaramy się
wypracować taki mechanizm, który zmieni nam adres MAC przy każdym podłączeniu do sieci i przy
zachowaniu zdroworozsądkowych zasad.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przeciek DNS (DNS leak) w VPN (resolvconf)</title>
      <link>https://morfikov.github.io/post/przeciek-dns-dns-leak-w-vpn-resolvconf/</link>
      <pubDate>Mon, 25 Apr 2016 14:37:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przeciek-dns-dns-leak-w-vpn-resolvconf/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://dnsleaktest.com/what-is-a-dns-leak.html&#34;&gt;Przeciek DNS (dns leak)&lt;/a&gt; to nic innego jak wyciek
poufnej informacji, za sprawą nieprawidłowej konfiguracji resolver&#39;a DNS. Może niekoniecznie jest
winne tutaj samo oprogramowanie, które realizuje zapytania DNS, czy też serwer domen jakiejś
organizacji. Chodzi głównie o tematykę &lt;a href=&#34;https://pl.wikipedia.org/wiki/Virtual_Private_Network&#34;&gt;VPN&lt;/a&gt;,
gdzie cały ruch sieciowy powinien być wrzucany do tunelu SSL/TLS i szyfrowany. W pewnych sytuacjach,
zapytania DNS mogą zostać wysyłane pod zewnętrzny resolver, często w formie niezaszyfrowanej i do
tego poza połączeniem VPN. Ten ruch można podsłuchać, przechwycić i poddać analizie. Celem tego
artykułu jest tak skonfigurowanie linux&#39;a (w tym przypadku dystrybucja Debian), by te przecieki
wyeliminować. Jest to możliwe za sprawą narzędzia &lt;code&gt;resolvconf&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Obsługa kodów USSD w modemach LTE</title>
      <link>https://morfikov.github.io/post/obsluga-kodow-ussd-w-modemach-lte/</link>
      <pubDate>Wed, 20 Apr 2016 15:31:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/obsluga-kodow-ussd-w-modemach-lte/</guid>
      <description>&lt;p&gt;Każdy, kto ma lub miał prepaid&#39;a, prędzej czy później musiał nauczyć się obsługi &lt;a href=&#34;https://pl.wikipedia.org/wiki/Unstructured_Supplementary_Service_Data&#34;&gt;kodów
USSD&lt;/a&gt;. To za ich pomocą
jesteśmy w stanie sprawdzić stan konta czy też aktywować poszczególne usługi. Co się jednak stanie,
gdy taki prepaid zostanie umieszczony w modemie LTE? Teoretycznie modem powinien nam zapewnić
połączenie LTE ale to jest nieco inna technologia niż GSM czy UMTS, a to za ich pomocą mogą być
przesyłane zarówno kody USSD i SMS. Niby modemy LTE potrafią operować również na UMTS i GSM ale pod
linux&#39;em przesyłanie kodów USSD może być nieco problematyczne. Jedynym oprogramowaniem będącym w
stanie operować na tych kodach był &lt;code&gt;modem-manager-gui&lt;/code&gt; . Problem w tym, że zajmuje on praktycznie
cały modem dla siebie, co w pewnych sytuacjach może nie być pożądane. Zatem jakie alternatywy nam
pozostają? W jaki sposób operować na tych kodach USSD pod linux&#39;em?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tworzenie repozytorium git na github&#39;ie</title>
      <link>https://morfikov.github.io/post/tworzenie-repozytorium-git-na-githubie/</link>
      <pubDate>Tue, 19 Apr 2016 17:08:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/tworzenie-repozytorium-git-na-githubie/</guid>
      <description>&lt;p&gt;Po eksperymentah z repozytorium git na github&#39;ie postanowiłem zrobić drobną ściągawkę na temat
obsługi tego mechanizmu z poziomu linii poleceń. Oczywiście, tutaj będą przedstawione jedynie
podstawy, tj. jak zacząć tworzyć takie repozytorium. Bardziej zaawansowane rzeczy, np.
&lt;a href=&#34;https://morfikov.github.io
/post/github-z-obsluga-kluczy-ssh/&#34;&gt;implementacja kluczy SSH na github&#39;ie&lt;/a&gt;, czy
też &lt;a href=&#34;https://morfikov.github.io
/post/implementacja-kluczy-gpg-repozytorium-git/&#34;&gt;podpisywanie swojej pracy przy pomocy kluczy
GPG&lt;/a&gt; zostały opisane w osobnych
wpisach, bo lekko wykraczają poza tematykę tego artykułu. Oczywiście te dwie rzeczy nie są wymagane
do pracy z git&#39;em ale trzeba rozważyć ich wdrożenie jeśli faktycznie zamierzamy zacząć korzystać z
tego VCS&#39;a. W każdym razie, tutaj zajmę się podstawowymi operacjami, które człowiek zwykle
przeprowadza, gdy przychodzi mu korzystać z git&#39;a. Zdaję sobie sprawę, że są różne nakładki
graficzne na narzędzie &lt;code&gt;git&lt;/code&gt; ale, jak się okaże po przeczytaniu tego wpisu, operowanie na tekstowym
&lt;code&gt;git&lt;/code&gt; nie jest takie straszne, choć sama dokumentacja może przerazić, bo jest tego dość sporo i
raczej wszystkiego od razu nie ogarniemy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wvdial i PPP, czyli modem LTE w trybie RAS</title>
      <link>https://morfikov.github.io/post/wvdial-ppp-czyli-modem-lte-w-trybie-ras/</link>
      <pubDate>Thu, 14 Apr 2016 19:01:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wvdial-ppp-czyli-modem-lte-w-trybie-ras/</guid>
      <description>&lt;p&gt;Jak wielu użytkowników linux&#39;a zapewne wie, modem GSM/UMTS/LTE może pracować w kilku trybach.
Najpopularniejszym z nich jest tryb RAS wykorzystujący interfejsy udostępniane przez to urządzenie
w katalogu &lt;code&gt;/dev/&lt;/code&gt; , zwykle &lt;code&gt;ttyUSB0&lt;/code&gt; , &lt;code&gt;ttyUSB1&lt;/code&gt; , etc. By taki modem mógł nawiązać połączenie z
siecią, potrzebny jest demon &lt;a href=&#34;https://pl.wikipedia.org/wiki/Point_to_Point_Protocol&#34;&gt;PPP&lt;/a&gt;. O trybie
RAS wspominałem już parokrotnie, min. we wpisach dotyczących &lt;a href=&#34;https://morfikov.github.io
/post/darmowy-internet-lte-od-rbmplay/&#34;&gt;konfiguracji połączenia LTE w
RBM/Play&lt;/a&gt; jak i przy omawianiu &lt;a href=&#34;https://morfikov.github.io
/post/aero2-w-polaczeniu-z-dnsmasq-dnscrypt-proxy/&#34;&gt;problemów
z resolver&#39;em DNS w przypadku
Aero2&lt;/a&gt;. Generalnie ten tryb
różni się trochę od &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-modemu-lte-w-trybie-ndis-ncm/&#34;&gt;trybu
NDIS(NCM)&lt;/a&gt; głównie tym, że tutaj
nie uzyskamy większych prędkości niż 20-30 mbit/s. Niemniej jednak, jeśli nie mamy dobrej jakości
połączenia LTE, lub nasz modem z jakiegoś powodu pod linux&#39;em nie potrafi pracować w trybie NDIS,
to możemy skonfigurować połączenie w trybie RAS wykorzystując do tego celu &lt;code&gt;wvdial&lt;/code&gt; oraz demona PPP.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wysyłanie i odbieranie SMS w wammu</title>
      <link>https://morfikov.github.io/post/wysylanie-odbieranie-sms-w-wammu/</link>
      <pubDate>Mon, 11 Apr 2016 20:19:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wysylanie-odbieranie-sms-w-wammu/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://wammu.eu/&#34;&gt;Wammu&lt;/a&gt; to aplikacja, przy pomocy której jesteśmy w stanie zarządzać swoim
telefonem komórkowym. Można ją także wykorzystać do zarządzania modemami USB, tymi samymi, które są
w stanie nam dostarczyć połączenie LTE. Przy pomocy &lt;code&gt;wammu&lt;/code&gt; nie damy rady jednak nawiązać połączenia
internetowego ale jest kilka rzeczy, do których ten soft może nam się przydać. Karta SIM obecna w
takim modemie może mieć zapisane kontakty, które możemy edytować, usuwać i ewentualnie dodawać nowe.
Ważniejszym ficzerem, który oferuje &lt;code&gt;wammu&lt;/code&gt; , jest możliwość wysyłania i odbierania wiadomości SMS.
Wcześniej opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/&#34;&gt;wysyłanie i odbieranie SMS za pomocą
gammu-smsd&lt;/a&gt;, niemniej jednak, w
przypadku &lt;code&gt;wammu&lt;/code&gt; nie będziemy uruchamiać żadnej usługi systemowej. Same wiadomości SMS odbiera i
wysyła się na podobnej zasadzie co w telefonie komórkowym. Przyjrzymy się zatem bliżej temu
kawałkowi oprogramowania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gammu-smsd, czyli wysyłanie i odbieranie SMS</title>
      <link>https://morfikov.github.io/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/</link>
      <pubDate>Sat, 09 Apr 2016 18:53:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/</guid>
      <description>&lt;p&gt;Eksperymentując ostatnio z modemem Huawei E3372s-153 w wersji NON-HiLink, pomyślałem, że przydałoby
się zaprojektować jakiś prosty system do odbioru i wysyłania SMS. Nie chodzi tutaj o zaprzęgnięcie
do pracy oprogramowania takiego jak &lt;a href=&#34;https://linuxonly.ru/cms/page.php?7&#34;&gt;modem-manager-gui&lt;/a&gt; czy też
&lt;a href=&#34;https://wammu.eu/wammu/&#34;&gt;wammu&lt;/a&gt; ale bardziej o przekazywanie tych wiadomości SMS, które trafiają na
modem, na inny numer telefonu komórkowego. Czyli stworzenie takiego telefonicznego proxy, które te
SMS będzie przekazywał dalej. Tego typu funkcjonalność można zaimplementować praktycznie w każdym
linux&#39;ie, tylko wymagane jest posiadanie odpowiednich narzędzi. W tym przypadku rozchodzi się o
&lt;code&gt;gammu-smsd&lt;/code&gt; i to o nim będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana nazwy interfejsu modemu ttyUSB0</title>
      <link>https://morfikov.github.io/post/zmiana-nazwy-interfejsu-modemu-ttyusb0/</link>
      <pubDate>Sat, 09 Apr 2016 18:50:19 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-nazwy-interfejsu-modemu-ttyusb0/</guid>
      <description>&lt;p&gt;Spora część osób posiada różnego rodzaju urządzenia do komunikacji GSM/UMTS/LTE. Mogą to być
smartfony, czy też modemy USB. Zwykle po podpięciu takiego urządzenia do portu USB, system wykrywa
je i oddaje nam do dyspozycji kilka interfejsów w katalogu &lt;code&gt;/dev/&lt;/code&gt; . W przypadku modemu Huawei
E3372s-153 w wersji NON-HiLink, standardowo są dwa interfejsy: &lt;code&gt;ttyUSB0&lt;/code&gt; oraz &lt;code&gt;ttyUSB1&lt;/code&gt; . Gdy
podłączamy tylko jedno urządzenie, to nie mamy problemy z tymi nazwami. Co się jednak stanie w
przypadku, gdzie tych urządzeń będzie więcej i podepniemy je w losowej kolejności? Nawet jeśli
będziemy wiedzieć które interfejsy są od jakich urządzeń, to i tak trzeba będzie przepisywać pliki
konfiguracyjne różnych aplikacji pod kątem dostosowania tych nazw. Możemy jednak stworzyć unikalne
nazwy interfejsów w oparciu o &lt;a href=&#34;https://en.wikipedia.org/wiki/Udev&#34;&gt;reguły udev&#39;a&lt;/a&gt; i tym zajmiemy się
w niniejszym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Modem LTE HUAWEI E3372 bez usb-modeswitch</title>
      <link>https://morfikov.github.io/post/modem-lte-huawei-e3372-bez-usb-modeswitch/</link>
      <pubDate>Wed, 06 Apr 2016 18:51:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modem-lte-huawei-e3372-bez-usb-modeswitch/</guid>
      <description>&lt;p&gt;Ten artykuł, podobnie jak kilka poprzednich, powstał w oparciu o moje badania przeprowadzane nad
modemem LTE HUAWEI E3372s-153 w wersji NON-HiLink. Niby rozwiązań dotyczących konfiguracji modemów
pod linux&#39;em jest pełno w sieci ale zasadniczą różnicą niżej opisanego sposobu jest kompletne
pozbycie się pakietu &lt;code&gt;usb-modeswitch&lt;/code&gt; . Dla przypomnienia, ten pakiet odpowiada za przełączanie
trybu modemu. Zwykle są dostępne dwa tryby. Pierwszy z nich jest w stanie dostarczyć sterowniki (pod
windows), po instalacji których modem przechodzi w drugi tryb, już ten właściwy. Na linux&#39;ach to
przełączanie jest realizowane via &lt;code&gt;usb-modeswitch&lt;/code&gt; . I tu się nasuwa pytanie, czy ten modem
faktycznie trzeba przełączać? A może istnieje sposób, który by automatycznie ustawił modem na taki
tryb, który linux&#39;y lubią najbardziej? Okazało się, że istnieje i w tym wpisie zostanie on
przestawiony.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja modemu LTE w trybie NDIS (NCM)</title>
      <link>https://morfikov.github.io/post/konfiguracja-modemu-lte-w-trybie-ndis-ncm/</link>
      <pubDate>Tue, 05 Apr 2016 15:45:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-modemu-lte-w-trybie-ndis-ncm/</guid>
      <description>&lt;p&gt;Sporo modemów LTE potrafi pracować w kilku trybach. Weźmy na przykład modem Huawei E3372s-153 w
wersji NON-HiLink. Standardowo obsługuje on tryb RAS (&lt;a href=&#34;https://en.wikipedia.org/wiki/Remote_Access_Service&#34;&gt;Remote Access
Services&lt;/a&gt;) jak i NDIS (&lt;a href=&#34;https://en.wikipedia.org/wiki/Network_Driver_Interface_Specification&#34;&gt;Network Driver
Interface Specification&lt;/a&gt;).
Domyślnie też włączony jest NDIS ale, by móc z tego trybu korzystać na debianie, musimy nieco
inaczej skonfigurować sobie połączenie sieciowe. Gdy w grę wchodzą modemy LTE, to użytkownicy zwykli
korzystać z narzędzia &lt;code&gt;wvdial&lt;/code&gt; , który zaprzęga do pracy demona PPP i w ten sposób modem zaczyna
pracować w trybie RAS, a nie NDIS. W tym wpisie skonfigurujemy sobie połączenie sieciowe na debianie
w taki sposób, by wykorzystywało ono potencjał trybu NDIS.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Darmowy internet LTE od RBM (Play)</title>
      <link>https://morfikov.github.io/post/darmowy-internet-lte-od-rbmplay/</link>
      <pubDate>Sun, 03 Apr 2016 14:57:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/darmowy-internet-lte-od-rbmplay/</guid>
      <description>&lt;p&gt;We wpisie dotyczącym &lt;a href=&#34;https://morfikov.github.io
/post/aero2-w-polaczeniu-z-dnsmasq-dnscrypt-proxy/&#34;&gt;konfiguracji serwerów DNS na potrzeby
Aero2&lt;/a&gt; wspomniałem, że ten
operator daje możliwość korzystania z internetu LTE praktycznie za darmo. Trzeba tam, co prawda,
złożyć wniosek i zapłacić jakieś grosze za przysłanie karty SIM ale opłat jako takich za
połączenie internetowe nie ma żadnych. Uporczywy może być jedynie kod CAPTCHA, który trzeba
wpisywać co 60 minut. Szukając na necie informacji na temat darmowego internetu LTE &lt;a href=&#34;http://jdtech.pl/2015/09/darmowy-internet-lte-w-redbullmobile-porady-2015.html&#34;&gt;doszukałem się
tego oto wpisu&lt;/a&gt;.
Jest tam przedstawiony sposób na włączenie bezpłatnej usługi internetu LTE u operatora RBM (Play). Z
początku wydawało mi się to niezbyt wiarygodne, by tego typu oferta była w ogóle dostępna ale
okazało się jednak, że nie ma tutaj żadnego haczyka i ten internet LTE faktycznie można włączyć i
korzystać z niego za free. W tym wpisie postaramy się skonfigurować Debiana właśnie na potrzeby tej
usługi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aero2 w połączeniu z dnsmasq i dnscrypt-proxy</title>
      <link>https://morfikov.github.io/post/aero2-w-polaczeniu-z-dnsmasq-dnscrypt-proxy/</link>
      <pubDate>Sat, 02 Apr 2016 18:47:47 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aero2-w-polaczeniu-z-dnsmasq-dnscrypt-proxy/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aero2.pl/&#34;&gt;Aero2&lt;/a&gt; już od dość dawna oferuje darmowy dostęp do internetu w technologi LTE
ale jakoś wcześniej nie byłem tym tematem zainteresowany. Parę dni temu złożyłem jednak wniosek o
kartę SIM, tak by posiadać zapasowe łącze na wypadek, gdyby mój obecny ISP z jakiegoś powodu padł.
Aero2 oferuje wersję komercyjną jak i tę za free i każda z nich ma swoje wady i zalety. Jako, że to
łącze ma robić jedynie za zapas, to korzystam z wersji FREE, a jest ono dość poważne ograniczenie,
tj. występuje tutaj &lt;a href=&#34;https://pl.wikipedia.org/wiki/CAPTCHA&#34;&gt;kod CAPTCHA&lt;/a&gt;, który trzeba wpisywać tak
co godzinę, po czym należy resetować modem. Ten kod może zostać zaserwowany jedynie w przypadku
korzystania z DNS Aero2 i pozornie odpada możliwość używania własnego systemu DNS opartego o
&lt;a href=&#34;http://www.thekelleys.org.uk/dnsmasq/doc.html&#34;&gt;dnsmasq&lt;/a&gt; i &lt;a href=&#34;https://dnscrypt.org/&#34;&gt;dnscrypt-proxy&lt;/a&gt;.
Po kilku dniach eksperymentów udało mi się wypracować przyzwoitą konfigurację, która potrafi obejść
to ograniczenie, poprawiając tym samym prywatność i bezpieczeństwo w internecie korzystając z
darmowego LTE za sprawą Aero2. W tym wpisie postaramy się zaimplementować ten mechanizm na debianie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rkhunter jako ochrona przed rootkit&#39;ami</title>
      <link>https://morfikov.github.io/post/rkhunter-jako-ochrona-przed-rootkitami/</link>
      <pubDate>Tue, 08 Mar 2016 15:42:59 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/rkhunter-jako-ochrona-przed-rootkitami/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Rootkit&#34;&gt;Rootkit&lt;/a&gt; to takie ustrojstwo, które jest w stanie przebywać
niepostrzeżenie w naszym systemie przez bardzo długi czas. Dzieje się tak ze względu na uśpioną
czujność administratora. Teoretycznie wszystko jest w należytym porządku, nie widać żadnych
złowrogich procesów, a szereg narzędzi, które mają przeciwdziałać rootkit&#39;om, nie zwraca żadnych
ostrzeżeń o ewentualnych próbach naruszenia bezpieczeństwa systemu operacyjnego. Taki rootkit jest w
stanie całkowicie przejąc kontrolę nad linux&#39;em i np. może decydować o tym jakie procesy zostaną nam
pokazane, a jakie ukryte. W świetle takiego zagrożenia, linux&#39;y wypracowały sobie pewne mechanizmy
obronne. W tym wpisie przebadamy sobie jeden z projektów, tj.
&lt;a href=&#34;http://rkhunter.sourceforge.net/&#34;&gt;rkhunter&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Systemowy klient TOR w TorBrowser</title>
      <link>https://morfikov.github.io/post/systemowy-klient-tor-w-torbrowser/</link>
      <pubDate>Wed, 02 Mar 2016 15:14:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/systemowy-klient-tor-w-torbrowser/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.torproject.org/projects/torbrowser.html.en&#34;&gt;TorBrowser&lt;/a&gt; to projekt, który ma na celu
zabezpieczenie użytkownika przed przeciekiem informacji. Jest to połączenie klienta sieci TOR oraz
przeglądarki Firefox (plus kilka dodatków). Ten mechanizm jest tak skonfigurowany, by możliwie jak w
największym stopniu dbał o naszą prywatność podczas przeglądania stron internetowych. Kilka lat
wstecz, użytkownicy Firefox&#39;a mogli się zaopatrzyć w addon TorButton. Niemniej jednak, obecnie &lt;a href=&#34;https://www.torproject.org/docs/torbutton/index.html.en&#34;&gt;ten
dodatek nie jest już rozwijany&lt;/a&gt;,
przynajmniej nie jako osobny projekt. Cały ten TorButton został zintegrowany z TorBrowser i nie ma
obecnie sposobu na to, by przeznaczyć jeden profil Firefox&#39;a pod bezpieczne przeglądanie internetu.
Jeśli chcemy mieć taką możliwość, to musimy korzystać z TorBrowser. Nie stanowi to oczywiście
problemu ale jako, że ma on w sobie wbudowanego klienta TOR&#39;a, to uruchamia też pewne procesy, które
mogą okazać się zbędne, zwłaszcza, gdy na swoim linux&#39;ie mamy już systemową instancję TOR&#39;a. W takim
przypadku, przydałoby się wyłączyć tego klienta TOR w TorBrowser, a ruch z przeglądarki przekierować
do systemowego TOR&#39;a i przez ten proces postaramy się przebrnąć w tym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zdiagnozować kernel OOPS</title>
      <link>https://morfikov.github.io/post/jak-zdiagnozowac-kernel-oops/</link>
      <pubDate>Mon, 22 Feb 2016 18:41:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zdiagnozowac-kernel-oops/</guid>
      <description>&lt;p&gt;Kernel linux&#39;a, jak każdy inny program, podczas swojego działania może napotkać nieprzewidzianą
przez programistów sytuację. W przypadku zwykłych aplikacji, pewne błędy krytyczne mogą doprowadzić
do &amp;quot;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Naruszenie_ochrony_pami%C4%99ci&#34;&gt;naruszenia ochrony pamięci&lt;/a&gt;&amp;quot;, co
szerzej jest znane jako segfault. W przypadku wystąpienia tego błędu, proces zwykle jest
unicestwiany. Co jednak w przypadku kernela? Odpowiedź jest prosta: &lt;a href=&#34;https://pl.wikipedia.org/wiki/Kernel_panic&#34;&gt;kernel
panic&lt;/a&gt;, czyli panika kernela, która pozostawia system w
stanie braku jakichkolwiek oznak życia. Są jednak pewne błędy, z którymi kernel jest w stanie sobie
poradzić i odzyskać sprawność w mniejszym lub większym stopniu. Te błędy są nazywane &lt;a href=&#34;http://slacksite.com/slackware/oops.html&#34;&gt;kernel
OOPS&lt;/a&gt;. W tym wpisie postaramy się przeanalizować
przykładowy OOPS i zobaczymy czy uda nam się ustalić przyczynę zaistniałego problemu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja protokołu SSL/TLS w vsftpd</title>
      <link>https://morfikov.github.io/post/implementacja-protokolu-ssltls-w-vsftpd/</link>
      <pubDate>Sat, 13 Feb 2016 22:30:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-protokolu-ssltls-w-vsftpd/</guid>
      <description>&lt;p&gt;Kwestię &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-vsftpd-w-debianie/&#34;&gt;konfiguracji serwera FTP na debianie w oparciu o
vsftpd&lt;/a&gt; już przerabialiśmy. Została nam
jeszcze do omówienia implementacja protokołu SSL/TLS. FTP nie jest bezpiecznym protokołem i wszelkie
dane logowania są przesyłane przez sieć otwartym tekstem. W przypadku, gdy stawiamy lokalny serwer
FTP w zaufanej sieci lub też będziemy korzystać jedynie z dostępu anonimowego, to raczej nie
potrzebujemy szyfrować danych. Trzeba pamiętać, że każde szyfrowanie dość mocno obciąża procesor,
który może stanowić wąskie gardło przy przesyle danych. W tym wpisie założenie jest takie, że
bezpieczeństwo danych, które będziemy przesyłać za pomocą protokołu FTP, jest rzeczą najważniejszą i
dlatego wdrożyć szyfrowanie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja vsftpd w Debianie</title>
      <link>https://morfikov.github.io/post/konfiguracja-vsftpd-w-debianie/</link>
      <pubDate>Fri, 12 Feb 2016 02:39:29 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-vsftpd-w-debianie/</guid>
      <description>&lt;p&gt;Serwery FTP umożliwiają przesyłanie plików przez sieć za pomocą protokołu TCP. Raczej wszyscy
mieliśmy z nimi już do czynienia. Może niekoniecznie zarządzaliśmy takimi serwerami ale na pewno
zdarzyło nam się pobierać pliki za ich pomocą. W tym wpisie jednak postaramy się skonfigurować taki
serwer FTP w oparciu o oprogramowanie &lt;a href=&#34;https://security.appspot.com/vsftpd.html&#34;&gt;vsftpd&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aktualizacja Firefox&#39;a i Thunderbird&#39;a w debianie</title>
      <link>https://morfikov.github.io/post/aktualizacja-firefoxa-thunderbirda-w-debianie/</link>
      <pubDate>Tue, 09 Feb 2016 03:04:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aktualizacja-firefoxa-thunderbirda-w-debianie/</guid>
      <description>&lt;p&gt;W 2006 roku, Mozilla przyczepiła się do debiana o to, że ten &lt;a href=&#34;https://en.wikipedia.org/wiki/Mozilla_Corporation_software_rebranded_by_the_Debian_project&#34;&gt;wykorzystuje ich znaki
towarowe&lt;/a&gt;.
Chodziło głównie o to, że debian wprowadzał swoje poprawki, które nie były zatwierdzone przez zespół
Mozilli. W efekcie czego, debian pozmieniał nazwy szeregu produktów Mozilli i tak zamiast normalnego
Firefox&#39;a mamy Iceweasel, podobnie z Thunderbird&#39;em i Icedove. Obecnie nie ma możliwości wgrania
aplikacji Mozilli wykorzystując repozytorium debiana. Trzeba się trochę wysilić i paczki pobierać
ręcznie z serwerów Mozilli. Takie rozwiązanie nie jest zbytnio praktyczne, bo przecie w linux&#39;ie
aplikacji nie aktualizuje się za pomocą ich interfejsów graficznych. Jeśli tak by było, to
musielibyśmy uruchamiać przeglądarkę z uprawnieniami root w trybie graficznym, czego raczej nikt
rozsądny nie próbowałby robić. Można, co prawda, napisać skrypt i całą operację aktualizacji nieco
zautomatyzować. Problem w tym, że zarówno Firefox jak i Thunderbird ważą tak około 50 MiB każdy i
taka aktualizacja polegająca na pobraniu całej aplikacji i zainstalowaniu jej na nowo zjadłaby
trochę transferu. Istnieje jednak rozwiązanie, które zakłada wykorzystanie &lt;a href=&#34;https://wiki.mozilla.org/Software_Update:Manually_Installing_a_MAR_file&#34;&gt;plików
MAR&lt;/a&gt;. Ważą one zaledwie
kilka MiB, bo zawierają jedynie aktualizację danej aplikacji. W tym wpisie spróbujemy się przyjrzeć
procesowi aktualizacji z wykorzystaniem tych właśnie plików.&lt;/p&gt;
&lt;p&gt;Zgodnie z &lt;a href=&#34;https://glandium.org/blog/?p=3622&#34;&gt;informacją na tym blogu&lt;/a&gt;, Firefox wraca do debiana i
zastępuje tym samym Iceweasel. Od tego momentu można już instalować pakiet &lt;code&gt;firefox&lt;/code&gt; i cieszyć się
normalnym produktem Mozilli. Niniejszy artykuł w dalszym ciągu znajduje zastosowanie ale nie można
mieszać opisanego niżej sposobu aktualizacji Firefox&#39;a z tym dostarczanym w ramach menadżera
pakietów &lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;aptitude&lt;/code&gt; . Zatem albo instalujemy Firefox&#39;a bezpośrednio z repozytorium debiana,
albo ściągamy pakiet z serwerów Mozilli.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Backup dysku przez sieć przy pomocy dd i netcat</title>
      <link>https://morfikov.github.io/post/backup-dysku-przez-siec-przy-pomocy-dd-netcat/</link>
      <pubDate>Mon, 08 Feb 2016 00:45:07 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/backup-dysku-przez-siec-przy-pomocy-dd-netcat/</guid>
      <description>&lt;p&gt;Dyski talerzowe mają to do siebie, że zawierają elementy mechaniczne, np. ramię głowicy czy też sam
napęd dysku. Te ruchome elementy się zużywają podczas eksploatacji dysku i trzeba mieć na uwadze, że
prędzej czy później taki dysk ulegnie awarii. Statystycznie rzecz biorąc, około 5% dysków rocznie
zdycha. Oczywiście to tylko statystyka i w sporej części przypadków dyski twarde ulegają awarii
znacznie wcześniej. Niekoniecznie musimy mieć tutaj do czynienia z &lt;a href=&#34;https://pl.wikipedia.org/wiki/Planowane_starzenie&#34;&gt;planowanym postarzaniem
sprzętu&lt;/a&gt; i zwyczajnie możemy trafić na trefny
model, którego wada fabryczna wyjdzie po 2-3 miesiącach użytkowania. Poza tym, producenci dysków
implementują w nich te energooszczędne rozwiązania, które znacznie skracają żywotność nośników.
Można o tym przekonać się analizując &lt;a href=&#34;https://morfikov.github.io
/post/parkowanie-glowicy-w-dyskach-wstern-digital/&#34;&gt;193 parametr SMART (Load/Unload Cycle) odpowiadający za
parkowanie głowicy&lt;/a&gt; w dyskach
firmy Western Digital. Także na dobrą sprawę nie możemy być pewni kiedy nam ten dysk zwyczajnie
odmówi posłuszeństwa. Dlatego też powinniśmy się zabezpieczyć na taką ewentualność robiąc kopię
bezpieczeństwa (backup) danych zawartych na dysku. W tym wpisie postaramy się zrobić kompletny obraz
dysku laptopa przy pomocy narzędzi &lt;code&gt;dd&lt;/code&gt; i &lt;code&gt;nc&lt;/code&gt; (netcat). Nie będziemy przy tym rozkręcać urządzenia
czy też podłączać do portu USB zewnętrznego nośnika. Dane prześlemy zwyczajnie przez sieć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mechanizm inhibitor lock w systemd</title>
      <link>https://morfikov.github.io/post/mechanizm-inhibitor-lock-w-systemd/</link>
      <pubDate>Thu, 04 Feb 2016 23:36:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mechanizm-inhibitor-lock-w-systemd/</guid>
      <description>&lt;p&gt;Hibernacja w przypadku komputerów, zwłaszcza laptopów, to bardzo użyteczny wynalazek. Na linux&#39;ach
wymaga ona czasem lekkiej konfiguracji ale generalnie można powiedzieć, że działa OOTB. Po migracji
szeregu dystrybucji na systemd, proces hibernacji zdaje się przebiegać nieco inaczej niż to miało
miejsce w przeszłości. Bardzo często możemy się spotkać z sytuacjami, gdzie przy próbie
zahibernowania czy wyłączenia systemu, ten zwyczajnie ignoruje nasze żądanie i pracuje dalej jak
gdyby nigdy nic. W tym przypadku nie mamy do czynienia z bug&#39;iem ale ficzerem. Okazuje się bowiem,
że systemd dysponuje mechanizmem zwanym &lt;a href=&#34;https://www.freedesktop.org/wiki/Software/systemd/inhibit/&#34;&gt;inhibitor
lock&lt;/a&gt;, który ma na celu powstrzymanie
systemu od dokonania hibernacji, uśpienia lub wyłączenia w pewnych określonych sytuacjach. W tym
wpisie przyjrzymy się nieco bliżej temu mechanizmowi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja protokołu IPv6 za pomocą tunelu 6to4</title>
      <link>https://morfikov.github.io/post/implementacja-protokolu-ipv6-za-pomoca-tunelu-6to4/</link>
      <pubDate>Thu, 04 Feb 2016 16:57:37 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-protokolu-ipv6-za-pomoca-tunelu-6to4/</guid>
      <description>&lt;p&gt;Ogromna cześć lokalnych ISP zdaje się nie nadążać za ciągle zmieniającą się rzeczywistością. Problem
dotyczy implementacji protokołu IPv6, który jest już z nami od bardzo wielu lat. W przypadku mojego
obecnego ISP raczej nie mam co liczyć na to, by w bliżej nieokreślonej przyszłości dodał on obsługę
tego protokołu. Istnieje jednak mechanizm zwany &lt;a href=&#34;https://pl.wikipedia.org/wiki/6to4&#34;&gt;tunelowaniem pakietów protokołu IPv6 wewnątrz
pakietów protokołu IPv4&lt;/a&gt; (w skrócie 6to4), którym warto się
zainteresować. W ogromnym skrócie, część puli adresowej IPv6 jest zarezerwowana i zmapowana na
adresy protokołu IPv4. Dzięki takiemu podejściu, każdy kto posiada stały zewnętrzny adres IPv4 ma
również adres w puli IPv6. Mając zatem zarezerwowany adres, możemy pokusić się o utworzenie tunelu
6to4, co aktywuje w naszej infrastrukturze ten nowszy protokół obchodząc jednocześnie ograniczenia
ISP. Trzeba jednak mieć na względzie, że nie jest to natywne wsparcie dla protokołu IPv6 i jest
niemal pewne, że wystąpią mniejsze lub większe problemy z wydajnością.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak dodać nowy dysk do LVM</title>
      <link>https://morfikov.github.io/post/jak-dodac-nowy-dysk-lvm/</link>
      <pubDate>Tue, 02 Feb 2016 16:21:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-dodac-nowy-dysk-lvm/</guid>
      <description>&lt;p&gt;Rozmiary obecnych dysków twardych zwykliśmy już liczyć w TiB. Jest to dość sporo ale ciągle zdarzają
się sytuacje, gdzie zaczyna nam brakować miejsca na pliki. W takich przypadkach myślimy raczej o
zmianie rozmiaru istniejących już partycji czy też dokupieniu nowego dysku. Pierwsza z powyższych
opcji nie zawsze może wchodzić w grę, no chyba, że zaimplementowaliśmy sobie
&lt;a href=&#34;https://pl.wikipedia.org/wiki/LVM&#34;&gt;LVM&lt;/a&gt;. Jeśli tak, to możemy bez większego problemu &lt;a href=&#34;https://morfikov.github.io
/post/zmiana-rozmiaru-lvm/&#34;&gt;zmieniać
rozmiar każdego z tych voluminów LVM&lt;/a&gt;. Niemniej jednak,
nawet jeśli już dostosujemy sobie te wirtualne dyski, to miejsce wciąż może nam się skończyć i
raczej można przyjąć za pewne, że tak się stanie w bliżej nieokreślonej przyszłości. Gdy to nastąpi,
czeka nas druga opcja wymieniona wyżej, tj. zaopatrzenie się w dodatkowy nośnik danych. Przy pomocy
LVM jesteśmy w stanie ten nowy dysk dodać do istniejącej grupy voluminów i zwiększyć tym wirtualnym
partycjom rozmiar bez potrzeby przerywania pracy systemu, czy też wykonywania dodatkowych czynności
związanych z formatowaniem i instalowaniem systemu na nowo. W tym wpisie postaramy się przebrnąć
przez ten proces.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Streaming obrazu za sprawą ffmpeg i netcat</title>
      <link>https://morfikov.github.io/post/streaming-obrazu-za-sprawa-ffmpeg-netcat/</link>
      <pubDate>Sat, 30 Jan 2016 20:37:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/streaming-obrazu-za-sprawa-ffmpeg-netcat/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=28188&#34;&gt;Na forum DUG&#39;a pojawił się ciekawy post&lt;/a&gt;, w którym
autor wątku chciał wykonać coś co określił jako &amp;quot;display mirroring&amp;quot;. Poszukałem trochę informacji na
temat tego zagadnienia i okazało się, że to nic innego jak tylko wyświetlenie tej samej zawartości,
np. na dwóch monitorach. Nie jest to nic zaawansowanego, bo przecie Xserver jest w stanie tego typu
zadanie zrealizować. Niemniej jednak, oba monitory muszą być podłączone do tego samego komputera. W
tym przypadku mamy dwie maszyny i dwa osobne monitory. Celem jest przesłanie obrazu z jednej maszyny
na drugą za pomocą sieci. W tym podlinkowanym wątku została poruszona kwestia przechwycenia obrazu
przy pomocy &lt;code&gt;ffmpeg&lt;/code&gt; i przesłania go przez sieć za pomocą &lt;code&gt;nc&lt;/code&gt; (netcat). Tak bardzo zainteresowało
mnie to rozwiązanie, że postanowiłem zobaczyć jak wygląda ono w praktyce.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana identyfikatora UUID</title>
      <link>https://morfikov.github.io/post/zmiana-identyfikatora-uuid/</link>
      <pubDate>Sat, 30 Jan 2016 16:52:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-identyfikatora-uuid/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=28210&#34;&gt;Na forum DUG&#39;a po raz kolejny pojawił się post&lt;/a&gt;
dotyczący unikalnych identyfikatorów, które są nadawane partycjom dysków twardych. Nie wiem jak
sprawa ma się w przypadku windowsów ale linux na podstawie tych numerów
&lt;a href=&#34;https://en.wikipedia.org/wiki/Universally_unique_identifier&#34;&gt;UUID&lt;/a&gt;
(&lt;a href=&#34;https://pl.wikipedia.org/wiki/Globally_Unique_Identifier&#34;&gt;GUID&lt;/a&gt;) jest w stanie identyfikować
konkretne urządzenia. Czasem się zdarza tak, że dwa dyski czy partycje mają taki sam identyfikator,
co prowadzi zwykle do problemów. Kolizja numerów identyfikacyjnych może być wynikiem pozostałości po
procesie produkcyjnym ale może także powstać za sprawą klonowania nośnika za pomocą narzędzia &lt;code&gt;dd&lt;/code&gt; .
Tak czy inaczej, przydałoby się wiedzieć jak ustalić, poprawnie wygenerować czy też zmienić UUID
wszędzie tam, gdzie jest on wykorzystywany i o tym będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja multipleksera tmux</title>
      <link>https://morfikov.github.io/post/implementacja-multipleksera-tmux/</link>
      <pubDate>Sat, 30 Jan 2016 03:30:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-multipleksera-tmux/</guid>
      <description>&lt;p&gt;Wszystko zaczęło się od pewnego posta na &lt;a href=&#34;https://forum.dug.net.pl/&#34;&gt;forum DUGa&lt;/a&gt;, w którym to jeden
użytkownik polecał innemu, aby ten zainteresował się programem o nazwie &lt;code&gt;tmux&lt;/code&gt; . Nie wiem czy tamta
osoba to zrobiła ale ja postanowiłem się przyjrzeć temu wynalazkowi zwanemu &lt;a href=&#34;https://en.wikipedia.org/wiki/Terminal_multiplexer&#34;&gt;terminal
multiplekser&lt;/a&gt;. Po niezbyt wnikliwym przejrzeniu
&lt;a href=&#34;https://tmux.github.io/&#34;&gt;strony projektu&lt;/a&gt; rzuciło mi się w oczy dzielenie okna jednego terminala na
szereg mniejszych. Ten ficzer znany był mi min. z &lt;a href=&#34;https://gnometerminator.blogspot.fr/p/introduction.html&#34;&gt;terminala
terminator&lt;/a&gt;. Zasadniczą różnicą tych dwóch
aplikacji jest to, że &lt;code&gt;tmux&lt;/code&gt; może być uruchomiony również pod TTY, efektywnie dzieląc obszar jednej
konsoli. Nie to bym ciągle siedział w trybie tekstowym ale skoro &lt;code&gt;tmux&lt;/code&gt; potrafi to samo co
&lt;code&gt;terminator&lt;/code&gt; oraz działa zarówno w trybie graficznym jak i tekstowym przy zaznaczeniu, że zjada
także mniej pamięci RAM, to czemu nie zaimplementować sobie jego obsługi? W trakcie użytkowania
tmux&#39;a okazało, że potrafi on sporo więcej i dlatego właśnie powstał ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wyłączyć systemowy &#34;beep&#34;</title>
      <link>https://morfikov.github.io/post/jak-wylaczyc-glosnik-sprzetowy-w-komputerze/</link>
      <pubDate>Mon, 25 Jan 2016 21:56:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wylaczyc-glosnik-sprzetowy-w-komputerze/</guid>
      <description>&lt;p&gt;Zgodnie z tym co można wyczytać na &lt;a href=&#34;https://wiki.archlinux.org/index.php/Disable_PC_speaker_beep&#34;&gt;wiki
Archlinux&#39;a&lt;/a&gt;, mamy kilka źródeł
generowania dźwięków, które trafiają do wbudowanego głośnika naszego komputera (case speaker). Te
dźwięki określane mianem &amp;quot;beep&amp;quot; mogą powstać za sprawą BIOS&#39;u płyty głównej, systemu operacyjnego,
środowiska graficznego lub też różnych programów użytkowych. Najbardziej uporczywe są dźwięki
generowane przez BIOS. Na dobrą sprawę, jeśli w BIOS&#39;ie nie ma żadnych opcji dotyczących
konfiguracji tego głośnika, to raczej niewiele jesteśmy w stanie zrobić w tej kwestii. Możemy zawsze
ten głośnik odłączyć fizycznie. Choć nie jest to zalecane, bo na podstawie wydawanych przez niego
dźwięków, jesteśmy w stanie określić czy z naszym komputerem jest wszystko w porządku. Niemniej
jednak, w tych pozostałych trzech w/w punkach mamy większe pole manewru, gdzie możemy dostosować
sobie szereg parametrów i o tym właśnie będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Odpowiedni DPI (PPI) dla monitora</title>
      <link>https://morfikov.github.io/post/odpowiedni-dpi-dla-monitora-pod-xserverem/</link>
      <pubDate>Sun, 24 Jan 2016 22:22:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/odpowiedni-dpi-dla-monitora-pod-xserverem/</guid>
      <description>&lt;p&gt;Monitory posiadają różne wymiary fizyczne i co za tym idzie mają też inne rozdzielczości. Te
informacje nie są jakoś zbytnio tajne i każdy klient przed zakupem konkretnego modelu monitora jest
w stanie się zapoznać z tymi parametrami. To co zwykle sprzedawcy starają się ukryć przed nami, to
współczynnik &lt;a href=&#34;https://pl.wikipedia.org/wiki/Ppi&#34;&gt;PPI (pixels per inch)&lt;/a&gt;. Zwykle też można spotkać
się z terminem &lt;a href=&#34;https://pl.wikipedia.org/wiki/Dpi&#34;&gt;DPI (dots per inch)&lt;/a&gt;. Nie są one równoznaczne,
bo w monitorach LCD jeden piksel składa się z trzech podpikseli. Sprzedawcy wykorzystują ten fakt i
chwalą się, że dany model monitora ma 300 DPI. W skrajnych przypadkach można nawet usłyszeć i 300
PPI. Osoby, które nie rozróżniają tych dwóch pojęć mogą bardzo łatwo zostać oszukane podczas zakupu.
Problem potęguje fakt, że gdy monitor jest sporych rozmiarów i patrzymy na niego z większej
odległości, to nawet nie dostrzeżemy, że nas oszukano. Na wszelki wypadek lepiej założyć, że
sprzedawca ma co innego na myśli niż my i podaną wartość podzielić przez 3, a następnie
skontrastować tak otrzymaną liczbę z PPI większości monitorów (100). Niemniej jednak, dobrze jest
przed zakupem monitora sprawdzić jaki współczynnik PPI ma dany model i nie sugerować się tym co
sprzedawca napisał w ofercie. Dlatego też w tym wpisie postaramy się ustalić faktyczną wartość PPI
dla naszego obecnego lub przyszłego monitora.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja terminala urxvt</title>
      <link>https://morfikov.github.io/post/konfiguracja-terminala-urxvt/</link>
      <pubDate>Sat, 23 Jan 2016 19:13:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-terminala-urxvt/</guid>
      <description>&lt;p&gt;Na rynku oprogramowania linux&#39;owego mamy całą gamę różnego rodzaju pseudo terminali, które na dobrą
sprawę robią za konsolę w środowiskach graficznych. Jako, że takie środowiska rozrosły się dość
mocno ostatnimi czasy, to instalacja niektórych terminali może pociągać za sobą wiele zależności. To
z kolei przyczynia się do wgrania zbędnego oprogramowania. Inną kwestią są zasoby systemowe, bo
niektóre z terminali potrafią zjeść naprawdę sporo pamięci operacyjnej. Są oczywiście lżejsze
alternatywy i w tym wpisie omówimy sobie konfigurację terminala urxvt.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ukrywanie informacji w plikach (steganografia)</title>
      <link>https://morfikov.github.io/post/ukrywanie-informacji-w-plikach-steganografia/</link>
      <pubDate>Thu, 21 Jan 2016 21:49:23 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ukrywanie-informacji-w-plikach-steganografia/</guid>
      <description>&lt;p&gt;Jak możemy wyczytać na wikipedii, &lt;a href=&#34;https://pl.wikipedia.org/wiki/Steganografia&#34;&gt;steganografia&lt;/a&gt; to
nauka, która ma na celu ukrycie faktu prowadzenia komunikacji. Odróżnia ją to nieco od kryptografii,
gdzie wiadomość jest wprawdzie nieczytelna ale wiadome jest, że dokonywana jest wymiana informacji
między dwoma punktami. W przypadku steganografii możemy ukryć pewną informację, np. w pliku
graficznym maskując tym samym cały proces przekazywania danych. W taki sposób osoba, która nie ma
pojęcia o fakcie ukrycia informacji, zobaczymy jedynie zwykły obrazek. Poniższy wpis ma na celu
sprawdzenie jak skuteczna jest ta metoda i czy nadaje się do zastosowania dla przeciętnego zjadacza
chleba.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Metadane plików graficznych (EXIF)</title>
      <link>https://morfikov.github.io/post/metadane-plikow-graficznych-exif/</link>
      <pubDate>Thu, 21 Jan 2016 16:58:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/metadane-plikow-graficznych-exif/</guid>
      <description>&lt;p&gt;Każdy plik posiada szereg opisujących go atrybutów. Możemy się o tym przekonać wykorzystując
narzędzia &lt;code&gt;ls&lt;/code&gt; lub &lt;code&gt;stat&lt;/code&gt; . W ich przypadku zostaną nam zwrócone takie informacje jak rozmiar
pliku, data modyfikacji czy też prawa dostępu. To właśnie są metadane opisujące pliki w obszarze
systemu plików i są one wymagane, by system operacyjny działał prawidłowo. To jednak nie jedyne
metadane, z którymi spotykamy się na co dzień. Najlepszym przykładem są zdjęcia czy filmy robione
smartfonami czy też aparatami lub kamerami cyfrowymi. Każdy plik stworzony za pomocą tych urządzeń
zawiera w sobie bardzo rozbudowane informacje, które nie zawsze chcielibyśmy udostępniać. W tym
wpisie skupimy się głównie na &lt;a href=&#34;https://pl.wikipedia.org/wiki/Exchangeable_Image_File_Format&#34;&gt;danych
EXIF&lt;/a&gt; zawartych w plikach graficznych,
które postaramy się wydobyć, zmienić i usunąć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Quake II pod linux&#39;em bez Wine</title>
      <link>https://morfikov.github.io/post/quake-ii-pod-linuxem-bez-wine/</link>
      <pubDate>Tue, 19 Jan 2016 16:59:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/quake-ii-pod-linuxem-bez-wine/</guid>
      <description>&lt;p&gt;Linux nie nadaje się za bardzo na konsolę do gier i do tego stwierdzenia raczej nikogo nie trzeba
przekonywać. Wszyscy znamy projekt WineHQ, który umożliwia odpalanie szeregu aplikacji z windowsa, w
tym też i gier, ale zwykle też trzeba się nieco napracować, by daną grę uruchomić pod Wine. Nawet
jeśli się nam to uda, to i tak zawsze będziemy mieć problemy czy to z wydajnością, czy też jakimiś
mniej lub bardziej dającymi się we znaki błędami. Bardzo rzadko zdarza mi się grać w cokolwiek ale
jest kilka kultowych gierek z lat &#39;90, które można odpalić na linux&#39;ie bez zaciągania do tego Wine.
Jedyne czego nam potrzeba to posiadać nośnik z plikami do danej gry. W tym wpisie postaramy się
odpalić Quake II na 64 bitowym debianie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Emulacja rolek myszy (scroll)</title>
      <link>https://morfikov.github.io/post/emulacja-rolek-myszy-scroll/</link>
      <pubDate>Sun, 17 Jan 2016 17:14:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/emulacja-rolek-myszy-scroll/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?pid=295709&#34;&gt;Na forum DUG&lt;/a&gt; pojawił się ciekawy temat
dotyczący emulacji rolek myszy (scroll) w urządzeniach, które ich nie posiadają. W tym przypadku
chodziło o bliżej nieokreślony model &lt;a href=&#34;https://pl.wikipedia.org/wiki/Trackball&#34;&gt;trackball&#39;a&lt;/a&gt;.
Niemniej jednak, są też myszy, które może i rolki mają, ale użytkownikom tych urządzeń zwyczajnie
nie chce się wysilać, by tymi kółkami kręcić non stop. Jako, że ja się zaliczam do tej grupy osób,
pomyślałem, by zaimplementować sobie ficzer, który sprawi, że moja bardzo wypasiona mysz będzie
miała pod prawym przyciskiem również emulację scroll&#39;a. Oczywiście dalej będzie można klikać prawym
przyciskiem, by uzyskać dostęp do menu kontekstowego i pod tym względem nic się nie zmieni. W tym
wpisie sprawdzimy jak taka emulacja rolek wygląda w praktyce.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Nagłówek kontenera LUKS trzymany na pendrive</title>
      <link>https://morfikov.github.io/post/naglowek-kontenera-luks-trzymany-na-pendrive/</link>
      <pubDate>Fri, 15 Jan 2016 20:28:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/naglowek-kontenera-luks-trzymany-na-pendrive/</guid>
      <description>&lt;p&gt;Jeśli kiedyś rozważaliśmy &lt;a href=&#34;https://morfikov.github.io
/post/keyfile-trzymany-w-glebokim-ukryciu/&#34;&gt;umieszczenie pliku klucza (keyfile) do zaszyfrowanego kontenera LUKS na
pendrive&lt;/a&gt;, to ciekawszą alternatywą
może okazać się umieszczenie całego nagłówka takiego kontenera na zewnętrznym nośniku. Ma to tę
przewagę nad keyfile, że wszystkie informacje zapewniające dostęp do kontenera, wliczając w to klucz
główny, są oddzielone od zaszyfrowanych danych. W ten sposób nawet jeśli kontener wpadnie w
niepowołane ręce, to nie ma żadnego sposobu na to, by ten ktoś te dane odzyskał, no bo przecie nie
ma klucza szyfrującego. Przechwycenie hasła również nic to nie zmieni, no chyba, że ten ktoś
zdobędzie również pendrive z nagłówkiem kontenera. Z ludzkiego punktu widzenia, to na takim dysku
będą znajdować się jedynie losowymi dane i do tego w formie kompletnie nieczytelnej dla człowieka
(brak systemu plików). Niemniej jednak, jest kilka rzeczy, o których warto pamiętać, gdy w grę
wchodzi nagłówek LUKS i to o nich porozmawiamy sobie w tym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klucz główny kontenera LUKS i jego odzyskanie</title>
      <link>https://morfikov.github.io/post/odzyskanie-klucza-glownego-w-kontenerze-luks/</link>
      <pubDate>Fri, 15 Jan 2016 16:25:39 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/odzyskanie-klucza-glownego-w-kontenerze-luks/</guid>
      <description>&lt;p&gt;Kontenery LUKS to takie wynalazki, za których pomocą jesteśmy w stanie zaszyfrować całe dyski
twarde, a właściwie to znajdujące się na nich dane. Taki kontener składa się głównie z nagłówka,
który jest umieszczany na początku partycji. By być w stanie dokonać szyfrowania i deszyfrowania
informacji w locie, system musi posiadać klucz główny (master key). Ten klucz jest przechowywany w
nagłówku i by go wydobyć, musimy wprowadzić jedno z haseł do kontenera. Później klucz wędruje do
pamięci, a hasło jest z niej usuwane. W ten sposób system ma dostęp do klucza głównego przez cały
czas począwszy od chwili otwarcia kontenera, aż do momentu jego zamknięcia. &lt;a href=&#34;https://gitlab.com/cryptsetup/cryptsetup/wikis/FrequentlyAskedQuestions&#34;&gt;Ten klucz jesteśmy w
stanie bez większego problemu
wydobyć&lt;/a&gt;, co może być
bardzo przydatne na wypadek zapomnienia hasła, czy też uszkodzenia samego nagłówka. W tym wpisie
postaramy się odzyskać klucz główny zaszyfrowanego kontenera LUKS.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Backup systemu przy pomocy LVM snapshot</title>
      <link>https://morfikov.github.io/post/backup-przy-pomocy-lvm-snapshot/</link>
      <pubDate>Fri, 15 Jan 2016 14:09:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/backup-przy-pomocy-lvm-snapshot/</guid>
      <description>&lt;p&gt;W dzisiejszych czasach systemy operacyjne są bardziej odporne na błędy niż to miało miejsce kilka
czy kilkanaście lat temu. Bardzo ciężko jest się zatem odnaleźć w sytuacji, gdzie nasz linux odmawia
współpracy i nie chce się w ogóle uruchomić. Niemniej jednak, jeśli chodzi o samą kwestię
naprawiania szkód po ewentualnej awarii systemu, to, jakby nie patrzeć, zajmuje ona nasz cenny czas.
Oczywiście takie błędy sprawiają, że mamy szansę nieco zgłębić strukturę używanego systemu
operacyjnego ale też pojawiają się w najmniej oczekiwanym momencie. W takiej sytuacji nie ma mowy
byśmy siedzieli paręnaście minut i zastanawiali się nad tym dlaczego coś nie działa jak należy.
Jest kilka mechanizmów bezpieczeństwa, które mogą nam nieco czasu zaoszczędzić. W tym wpisie omówimy
sobie zagadnienia związane z &lt;a href=&#34;http://www.tldp.org/HOWTO/html_single/LVM-HOWTO/#snapshotintro&#34;&gt;LVM
snapshot&lt;/a&gt;, czyli migawką systemu,
którą możemy wykonać praktycznie natychmiast i w razie problemów przywrócić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Domyślne aplikacje w oparciu o typy plików (MIME)</title>
      <link>https://morfikov.github.io/post/domyslne-aplikacje-w-oparciu-o-typy-plikow-mime/</link>
      <pubDate>Tue, 12 Jan 2016 20:18:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/domyslne-aplikacje-w-oparciu-o-typy-plikow-mime/</guid>
      <description>&lt;p&gt;Pełne środowiska graficzne zwykle oferują odpowiednie narzędzia, które mogą posłużyć skonfigurowaniu
domyślnych aplikacji. Jesteśmy zatem w stanie bardzo prosto przypisać szereg &lt;a href=&#34;https://pl.wikipedia.org/wiki/Typ_MIME&#34;&gt;typów
MIME&lt;/a&gt; do odpowiednich programów. Wobec takiego stanu rzeczy,
przy próbie uruchomienia jakiegoś pliku, ten zostanie odpalony przez konkretną aplikację. Niemniej
jednak, jeśli chodzi o środowiska graficzne oparte o menadżery okien, np. Openbox, to na dobrą
sprawę mamy bardzo małe pole manewru. Niezależnie czy korzystamy z GNOME, KDE, XFCE, MATE czy też
Openbox&#39;a, wszystkie z nich wykorzystują dokładnie ten sam mechanizm wiązania aplikacji z typami
plików. Możemy zatem ominąć te wszystkie graficzne nakładki i ręcznie skonfigurować sobie typy MIME,
tak by działały niezależnie od wykorzystywanego środowiska graficznego. W tym wpisie spróbujemy
przyjrzeć się nieco bliżej konfiguracji tego całego mechanizmu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja serwera dźwięku PulseAudio</title>
      <link>https://morfikov.github.io/post/konfiguracja-serwera-dzwieku-pulseaudio/</link>
      <pubDate>Mon, 11 Jan 2016 21:49:37 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-serwera-dzwieku-pulseaudio/</guid>
      <description>&lt;p&gt;Wielu użytkowników linux&#39;a nie przepada zbytnio za PulseAudio, bo ten z jakiegoś powodu sprawia u
nich same kłopoty. U mnie ten serwer dźwięku działa przyzwoicie i zwykle nie ma z nim żadnych
problemów. Obecnie ten projekt jest już na tyle dojrzały, że te większe środowiska graficzne
zwyczajnie polegają na nim w zależnościach. Jeśli jednak &lt;a href=&#34;https://morfikov.github.io
/post/instalacja-debiana-z-wykorzystaniem-debootstrap/&#34;&gt;instalowaliśmy debiana za pomocą narzędzia
debootstrap&lt;/a&gt; i
&lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-xservera-na-debianie-xorg/&#34;&gt;konfigurowaliśmy osobno graficzną sesję
Xserver&#39;a&lt;/a&gt;, &lt;a href=&#34;https://morfikov.github.io
/post/menadzer-logowania-lightdm/&#34;&gt;menadżer logowania
LightDM&lt;/a&gt; czy też &lt;a href=&#34;https://morfikov.github.io
/post/menadzer-okien-openbox/&#34;&gt;menadżer okien
Openbox&lt;/a&gt;, to raczej zależy nam na minimalnym
środowisku, które może się zwyczajnie obejść bez PulseAudio. Niemniej jednak, PulseAudio ma kilka
ciekawych bajerów, których ALSA nie posiada. By się nie rozpisywać zbytnio, mogę wspomnieć choćby o
możliwości&lt;a href=&#34;https://morfikov.github.io
/post/pulseaudio-i-przesylanie-dzwieku-przez-siec/&#34;&gt;przesyłania dźwięku przez
sieć&lt;/a&gt;, czy też o takim
ficzerze jak &lt;a href=&#34;https://morfikov.github.io
/post/normalizacja-glosnosci-w-pulseaudio/&#34;&gt;normalizacja głośności&lt;/a&gt;.
Są to głównie zabawki dla nieco bardziej zaawansowanych użytkowników i gdy ich nie potrzebujemy, to
serwer dźwięku nam się raczej do niczego nie przyda. Warto jednak się zaznajomić z tym nieco
bardziej zaawansowanym kawałkiem oprogramowania i w tym wpisie postaramy się nieco omówić instalację
i konfigurację tego serwera dźwięku.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Menadżer okien Openbox</title>
      <link>https://morfikov.github.io/post/menadzer-okien-openbox/</link>
      <pubDate>Sun, 10 Jan 2016 21:31:47 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/menadzer-okien-openbox/</guid>
      <description>&lt;p&gt;Spora większość środowisk graficznych rozrosła się obecnie nieco i ich instalacja na maszynach
wyposażonych w niewiele pamięci RAM może nie wchodzić w grę. Nie jesteśmy też skazani na życie w
konsoli, ani na kupno nowego sprzętu. Możemy nieco odchudzić instalację pozbywając się zbędnych
usług, których tak naprawdę nie potrzebujemy. Poza tym, praktycznie każde z graficznych narzędzi,
przy pomocy których chcemy konfigurować linux&#39;a, ma tekstowe zamienniki, lub też o wiele lżejsze
alternatywy. Jednak w przypadku, gdy korzystamy z takich rozbudowanych środowisk jak GNOME, to nie
koniecznie da się usunąć szereg tych zasobożernych komponentów. Pozostaje nam zwykle jedna opcja,
którą jest usunięcie całego środowiska graficznego i zainstalowanie potrzebnych nam komponentów
osobno. Jako, że mamy już opisany&lt;a href=&#34;https://morfikov.github.io
/post/instalacja-debiana-z-wykorzystaniem-debootstrap/&#34;&gt;proces instalacji debiana przy pomocy
debootstrap&lt;/a&gt;, &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-xservera-na-debianie-xorg/&#34;&gt;instalację i
konfigurację Xserver&#39;a&lt;/a&gt;, jak i
również &lt;a href=&#34;https://morfikov.github.io
/post/menadzer-logowania-lightdm/&#34;&gt;menadżera okien LightDM&lt;/a&gt;, to przyszedł
czas na omówienie niezbędnego w sesji graficznej &lt;a href=&#34;https://pl.wikipedia.org/wiki/Mened%C5%BCer_okien&#34;&gt;menadżera
okien&lt;/a&gt;. W tym wpisie skupimy się głównie na
instalacji i konfiguracji Openbox&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Menadżer logowania LightDM</title>
      <link>https://morfikov.github.io/post/menadzer-logowania-lightdm/</link>
      <pubDate>Fri, 08 Jan 2016 20:12:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/menadzer-logowania-lightdm/</guid>
      <description>&lt;p&gt;Istnieje kilka sposobów na to, by uruchomić sesję graficzną Xserver&#39;a. W przypadku, gdy nie
wykorzystujemy zaawansowanych środowisk graficznych, zwykle korzystamy z polecenia &lt;code&gt;startx&lt;/code&gt;
wydawanego zaraz po zalogowaniu się na konsolę TTY. Niemniej jednak, nawet w tych najprostszych
środowiskach graficznych możemy pokusić się o instalację lekkiego menadżera okien, tak by nie
musieć konfigurować samodzielnie szeregu opcji sesji. Menadżery logowania (display managers) mają
na celu zrobienie dokładnie tego samego co pliki &lt;code&gt;~/.xinitrc&lt;/code&gt; i &lt;code&gt;~/.xserverrc&lt;/code&gt; , z tym, że w nieco
bardziej przyjaznej dla użytkownika formie. W tym wpisie przyjrzymy się nieco dokładniej
&lt;a href=&#34;https://www.freedesktop.org/wiki/Software/LightDM/&#34;&gt;menadżerowi LightDM&lt;/a&gt;. Zostanie także omówiony
sposób blokowania aktywnej sesji Xserver&#39;a bez potrzeby jej zamykania przy pomocy narzędzia
&lt;a href=&#34;https://github.com/the-cavalry/light-locker&#34;&gt;light-locker&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja Xserver&#39;a na debianie (Xorg)</title>
      <link>https://morfikov.github.io/post/konfiguracja-xservera-na-debianie-xorg/</link>
      <pubDate>Fri, 08 Jan 2016 17:53:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-xservera-na-debianie-xorg/</guid>
      <description>&lt;p&gt;Dzięki takiemu wynalazkowi jak Xserver (Xorg) mamy możliwość odpalania aplikacji graficznych. Bez
niego wszystko musielibyśmy robić w czarnej konsoli, przez co funkcjonalność naszej maszyny w dość
znacznym stopniu ucierpiałaby. Oczywiście tryb graficzny ma też swoje wady. Niemniej jednak, Xserver
leży póki co u podstaw każdego środowiska graficznego i jeśli chcemy mieć możliwość odpalania, np.
Firefox&#39;a, czy oglądania filmów w VLC, to nie ma innego wyjścia jak skonfigurować sobie Xserver. W
tym wpisie się zajmiemy tym zagadnieniem, przy czym, chcę uprzedzić, że nie będziemy korzystać z
żadnych automatów, które można znaleźć w tych wszystkich zaawansowanych środowiskach graficznych. A
to z tego względu, że ustawienia tych środowisk zwykle nadpisują ustawienia samego Xserver&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mysz i jej konfiguracja na linux&#39;ie</title>
      <link>https://morfikov.github.io/post/mysz-i-jej-konfiguracja-na-linuxie/</link>
      <pubDate>Fri, 08 Jan 2016 15:09:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mysz-i-jej-konfiguracja-na-linuxie/</guid>
      <description>&lt;p&gt;Mysz, zaraz obok klawiatury, to jedno z tych narzędzi, z których korzystamy praktycznie bez przerwy
ilekroć tylko siadamy przed komputerem. Z reguły działa ona prawidłowo, nawet pod linux&#39;em, z tym,
że dla jednych użytkowników standardowe ustawienia nie są zbyt zadowalające. Nawet jeśli wszystkie
przyciski zostaną rozpoznane poprawnie, to zawsze pozostaje, np. kwestia dostosowania szybkości
przemieszczania się kursora po ekranie. Oczywiście, istnieje także szereg innych aspektów, które
możemy sobie dostosować i tym właśnie się zajmiemy w niniejszym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja jasności ekranu w laptopie (backlight)</title>
      <link>https://morfikov.github.io/post/konfiguracja-jasnosci-ekranu-w-laptopie-backlight/</link>
      <pubDate>Tue, 05 Jan 2016 21:52:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-jasnosci-ekranu-w-laptopie-backlight/</guid>
      <description>&lt;p&gt;Linux nigdy nie był popularnym systemem operacyjnym na stacjach klienckich. Może i cieszy się sporym
wzięciem wśród środowisk serwerowych ale jego niezbyt prosta obsługa nie przemawia do przeciętnego
użytkownika komputera. Wraz z rozwojem technologi, zmienił się też rodzaj urządzeń na jakich
obecnie pracujemy. W dzisiejszych czasach liczy się przede wszystkim mobilność i praktycznie każdy z
nas miał już prawdopodobnie do czynienia z laptopami. Producenci tych urządzeń lubią nam wciskać
windowsa z dopiskiem, że ten laptop bez niego nie będzie w ogóle nam działał. Już od dość dawna
szereg laptopów jest w stanie pracować pod linux&#39;em ale, jakby nie patrzeć, sporo rzeczy w nich nie
działa OOTB i trzeba poświęcić trochę czasu, by tę maszynę doprowadzić do porządku. W tym wpisie
zajmiemy się zagadnieniem podświetlania matrycy (backlight), tak by system był w stanie bez problemu
zapisać ustawienia jasności ekranu przy wyłączaniu komputera oraz, by potrafił je także wczytać
podczas fazy rozruchu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Monitor i jego konfiguracja pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/monitor-i-jego-konfiguracja-pod-linuxem/</link>
      <pubDate>Mon, 04 Jan 2016 18:02:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/monitor-i-jego-konfiguracja-pod-linuxem/</guid>
      <description>&lt;p&gt;Obecnie w linux&#39;ach spora cześć sprzętu jest rozpoznawana prawidłowo, a my nie musimy poświęcać
czasu na dodatkową konfigurację. Domyślne ustawienia sprawdzają się praktycznie za każdym razem, gdy
w grę nie wchodzi nic bardziej zaawansowanego. W tym wpisie rzucimy okiem na konfigurację Xserver&#39;a,
która dotyczyć będzie wyświetlanego obrazu na monitorze. Pośrednio też będziemy musieli
skonfigurować sobie kartę graficzną, bo to ona jest odpowiedzialna w dużej mierze za to, co jest
odbierane przez nasz monitor.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja touchpad&#39;a w laptopie pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/konfiguracja-touchpada-w-laptopie-pod-linuxem/</link>
      <pubDate>Sun, 03 Jan 2016 20:48:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-touchpada-w-laptopie-pod-linuxem/</guid>
      <description>&lt;p&gt;Laptopy zwykle mają niewielkie rozmiary i są możliwie okrojone, tak by zapewnić jak największą
mobilność. Oczywiście nikt tych maszyn nie pozbawił klawiatury, bo to czyniłoby je mało użytecznymi.
Możemy oczywiście spotkać całą masę modeli, które nie mają wydzielonej klawiatury numerycznej, czy
też brak określonych przycisków. Niemniej jednak, nie jest to aż taka niedogodność jak brak myszy. W
laptopach zamiast myszki mamy zaimplementowany &lt;a href=&#34;https://pl.wikipedia.org/wiki/Touchpad&#34;&gt;touchpad&lt;/a&gt;.
Korzystanie z niego wymaga znacznej wprawy ale i tak wątpię, że ktoś byłby w stanie używać go do gry
w CS&#39;a. Tak czy inaczej, każde urządzenie w linux&#39;ie idzie w mniejszym czy większym stopniu sobie
skonfigurować. Taki laptopowy touchpad nie jest żadnym wyjątkiem i w tym wpisie postaramy się go
nieco ogarnąć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Temperatura dysku twardego (hddtemp)</title>
      <link>https://morfikov.github.io/post/temperatura-dysku-twardego-hddtemp/</link>
      <pubDate>Sun, 03 Jan 2016 16:24:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/temperatura-dysku-twardego-hddtemp/</guid>
      <description>&lt;p&gt;Obecnie dyski twarde nie są potrzebne do prawidłowego działania komputera. Mając sporo pamięci
operacyjnej oraz &lt;a href=&#34;https://pl.wikipedia.org/wiki/Live_CD&#34;&gt;system live&lt;/a&gt;, możemy bez problemu korzystać
z takiego sprzętu. Niemniej jednak, systemy live są nieco ograniczone. Najdotkliwszą ich wadą jest
brak zapisywania wprowadzanych zmian. W pewnych przypadkach ta cecha może być bardzo pożądana ale
jeśli chodzi o przeciętnego użytkownika, to chciałby on raczej mieć możliwość zapisu swojej pracy.
Dlatego też zewnętrzny magazyn danych w postaci dysku twardego nie prędko wyjdzie z użytku. Te
urządzenia, jak i większość tych, które podłączamy do naszego komputera, wydzielają ciepło.
Temperatura jest wrogiem numer 1 w przypadku maszyn i musi stale być monitorowana, tak by czasem nie
doszło do przegrzania sprzętu. &lt;a href=&#34;https://pl.wikipedia.org/wiki/Dysk_twardy&#34;&gt;Dyski HDD&lt;/a&gt; mają ten
problem, że im wyższa jest temperatura, tym obszar magnetyczny się bardziej rozszerza, a to powoduje
błędy odczytu i zapisu. Podobnie jest ze zbyt niską temperaturą, gdzie ścieżki i sektory ulegają
skurczeniu. Taki dysk musi pracować w odpowiednich warunkach termalnych. W tym wpisie postaramy się
ustalić aktualną temperaturę dysku oraz spróbujemy ją monitorować, tak by wiedzieć czy czynnik
temperaturowy nie zagraża czasem dyskom podpiętym do naszego PC.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować bonding w Debian linux (eth0&#43;wlan0)</title>
      <link>https://morfikov.github.io/post/konfiguracja-interfejsow-bond-bonding/</link>
      <pubDate>Sat, 02 Jan 2016 15:07:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-interfejsow-bond-bonding/</guid>
      <description>&lt;p&gt;W artykule poświęconym &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-polaczenia-wifi-pod-debianem/&#34;&gt;konfiguracji sieci WiFi na Debianie z wykorzystaniem narzędzia
wpa_supplicant&lt;/a&gt; wspomniałem parę słów na temat &lt;a href=&#34;https://www.kernel.org/pub/linux/kernel/people/marcelo/linux-2.4/Documentation/networking/bonding.txt&#34;&gt;interfejsu bond&lt;/a&gt;. Bonding na linux
wykorzystywany jest w zasadzie do spięcia kilku interfejsów sieciowych, w tym przewodowych
( &lt;code&gt;eth0&lt;/code&gt; ) i bezprzewodowych ( &lt;code&gt;wlan0&lt;/code&gt; ) w jeden (zwykle &lt;code&gt;bond0&lt;/code&gt; ). Takie rozwiązanie sprawia, że
w przypadku awarii któregoś z podpiętych interfejsów, my nie tracimy połączenia z siecią i nie
musimy nic nigdzie przełączać, by to połączenie przywrócić. To rozwiązanie jest o tyle użyteczne,
że w przypadku, gdy podepniemy przewód do gniazda RJ-45 w naszym laptopie, to komunikacja będzie
odbywać się po kablu. Natomiast jeśli przewód zostanie odłączony, to system automatycznie przejdzie
na komunikację bezprzewodową. W tym wpisie spróbujemy zaprojektować sobie właśnie tego typu
mechanizm zarówno za sprawą pakietu &lt;code&gt;ifupdown&lt;/code&gt; , gdzie konfiguracja interfejsów sieciowych jest
zarządzana przez plik &lt;code&gt;/etc/network/interfaces&lt;/code&gt; , jak i przy pomocy natywnego rozwiązania jakie
oferuje systemd/networkd.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instalacja debiana z wykorzystaniem debootstrap</title>
      <link>https://morfikov.github.io/post/instalacja-debiana-z-wykorzystaniem-debootstrap/</link>
      <pubDate>Sat, 02 Jan 2016 03:52:49 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/instalacja-debiana-z-wykorzystaniem-debootstrap/</guid>
      <description>&lt;p&gt;Instalowanie debiana z wykorzystaniem &lt;code&gt;debootstrap&lt;/code&gt; trochę się różni od instalacji z wykorzystaniem
instalatora. Chodzi generalnie o to, że wszystkie kroki instalacyjne trzeba przeprowadzać ręcznie.
Poza tym, cała konfiguracja będzie wymagać manualnego dostosowania. Plus tego rozwiązania jest
oczywisty, albowiem mamy całkowitą władzę nad tym co się w systemie znajdzie oraz jak będzie on
skonfigurowany. By mieć możliwość przeprowadzenia tego typu instalacji potrzebny będzie nam
działający system. Może to być płytka lub pendrive live z &lt;a href=&#34;https://www.debian.org/CD/live/index.pl.html&#34;&gt;Debianem&lt;/a&gt; czy &lt;a href=&#34;https://www.ubuntu.com/download/desktop/try-ubuntu-before-you-install&#34;&gt;Ubuntu&lt;/a&gt;. Można też
wykorzystać już zainstalowany system operacyjny. Ważne jest tylko to, aby była możliwość
zainstalowania w takim systemie pakietu &lt;code&gt;debootstrap&lt;/code&gt; , no i oczywiście wymagany jest dostęp do
internetu. W przeciwieństwie do instalatora debiana, mamy dostęp do graficznego środowiska, a w nim
do przeglądarki i w przypadku utknięcia gdzieś po drodze podczas instalacji, możemy sobie wygooglać
napotkane problemy nie przerywając przy tym prac instalacyjnych.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instalacja i konfiguracja bootloader&#39;a extlinux</title>
      <link>https://morfikov.github.io/post/instalacja-i-konfiguracja-bootloadera-extlinux/</link>
      <pubDate>Sat, 02 Jan 2016 01:47:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/instalacja-i-konfiguracja-bootloadera-extlinux/</guid>
      <description>&lt;p&gt;W debianie mamy do dyspozycji kilka
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Program_rozruchowy&#34;&gt;bootloader&#39;ów&lt;/a&gt;. Z tych częściej używanych to
będą syslinux, extlinux oraz grub2. Jeśli potrzebujemy automatyzacji oraz szeregu zaawansowanych
ficzerów, to dobrym wyjściem jest grub2. Jeśli natomiast korzystamy ze standardowej konfiguracji,
którą można by określić mianem BIOS-MBR i do tego chcemy mieć pełną kontrolę na bootloader&#39;em, to
najlepiej wybrać extlinux&#39;a lub syslinux&#39;a. Syslinux jest wykorzystywany głównie w przypadku
partycji FAT, która znajduje zastosowanie w różnego rodzaju systemach live. Natomiast jeśli w grę
wchodzi system plików EXT4, który jest domyślny na sporej części linux&#39;ów, to pozostaje nam do
wyboru jedynie extlinux. W tym wpisie postaramy się przebrnąć przez proces instalacji i konfiguracji
tego bootloader&#39;a. Nie będziemy przy tym korzystać z żadnych automatów i wszystko postaramy się
dostosować ręcznie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Odszyfrowanie kontenerów LUKS w systemd</title>
      <link>https://morfikov.github.io/post/odszyfrowanie-kontenerow-luks-w-systemd/</link>
      <pubDate>Fri, 01 Jan 2016 17:18:03 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/odszyfrowanie-kontenerow-luks-w-systemd/</guid>
      <description>&lt;p&gt;Osoby, które wykorzystują pełne szyfrowanie dysku, wiedzą, że nie zawsze da radę tak skonfigurować
swój system, by upchnąć go na jednej partycji. Nawet jeśli korzystamy z LVM wewnątrz kontenera LUKS,
to i tak zwykle możemy posiadać inne zaszyfrowane partycje, które są odrębną całością i montowane
osobno przy starcie systemu. W takim przypadku zwykle jesteśmy zmuszeni do podawania hasła do
każdego z tych dysków z osobna, co zajmuje czas. Ten problem opisałem po części przy okazji
&lt;a href=&#34;https://morfikov.github.io
/post/dropbox-i-kontener-luks/&#34;&gt;implementacji kontenera LUKS na potrzeby
Dropbox&#39;a&lt;/a&gt;, jak i we wpisie poświęconym &lt;a href=&#34;https://morfikov.github.io
/post/przejscie-z-truecrypt-na-luks/&#34;&gt;przejściu
z kontenerów TrueCrypt&#39;a na te linux&#39;owe, które są wspierane natywnie przez sam
kernel&lt;/a&gt;. Niemniej jednak, tamto rozwiązanie
było oparte głównie o starszy init (sysvinit), co wymagało dodatkowej konfiguracji, tak by system
otworzył się po podaniu tylko jednego hasła. W tym wpisie postaramy się wdrożyć mechanizm, który
jest oferowany przez systemd.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kopia struktury dysku twardego</title>
      <link>https://morfikov.github.io/post/kopia-struktury-dysku-twardego/</link>
      <pubDate>Fri, 18 Dec 2015 17:01:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kopia-struktury-dysku-twardego/</guid>
      <description>&lt;p&gt;Wszyscy wiedzą, że zabawa z dyskiem zwykle kończy się tragicznie dla zawartych na nim danych. W tym
wpisie spróbujemy się przyjrzeć sytuacjom, które nie jednego użytkownika linux&#39;a potrafią przyprawić
o zawał serca. Chodzi generalnie o uszkodzenie struktury dysku, oczywiście tylko tej programowej. Na
błędy fizyczne nie możemy zbytnio nic poradzić. Natomiast jeśli chodzi o sferę logiczną, to mamy
tutaj dość duże pole do popisu i jesteśmy w stanie się zabezpieczyć przed wieloma krytycznymi
sytuacjami. Postaramy się tutaj omówić to jak wykonać kopię dysku. Taka kopia będzie miała tylko
kilka (ew. kilkanaście) MiB, w skład której wchodzić będzie superblok systemu plików, nagłówki
zaszyfrowanych partycji LUKS, struktura LVM i tablica partycji. Uszkodzenie każdego z tych
powyższych uniemożliwia nam dostęp do danych zgromadzonych na dysku.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru dysków w strukturze LVM</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-lvm/</link>
      <pubDate>Thu, 17 Dec 2015 20:15:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-lvm/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/LVM&#34;&gt;Logical Volume Manager (LVM)&lt;/a&gt;, czyli menadżer voluminów
logicznych w systemach linux, to mechanizm, który jest w stanie podzielić jedną partycję fizyczną na
szereg dysków logicznych. Każdy z tych dysków może być programowo dostosowany bez potrzeby edycji
czy zmiany tablicy partycji fizycznego dysku. Dzięki LVM jesteśmy w stanie obejść kilka ograniczeń
płynących z wykorzystywania tablicy partycji MS-DOS. Głównie chodzi tutaj o 4 partycje podstawowe,
które mieszczą się w &lt;a href=&#34;https://pl.wikipedia.org/wiki/Master_Boot_Record&#34;&gt;MBR&lt;/a&gt;. Jeśli zdecydowaliśmy
się na wykorzystywanie LVM, to w pewnym momencie może okazać się, że niektóre voluminy mają zbyt
duże lub też zbyt małe rozmiary. Trzeba będzie je zatem dostosować i w tym wpisie postaramy się ten
proces zasymulować.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru kontenera LUKS</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-zaszyfrowanego-kontenera-luks/</link>
      <pubDate>Thu, 17 Dec 2015 18:38:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-zaszyfrowanego-kontenera-luks/</guid>
      <description>&lt;p&gt;Ci z nas, którzy zabezpieczają swoje systemy przy pomocy technik kryptograficznych wiedzą, że taki
system trzeba traktować nieco inaczej niż ten, który nie jest w żaden sposób zaszyfrowany. Gdy mamy
na swoim dysku kilka &lt;a href=&#34;https://pl.wikipedia.org/wiki/Linux_Unified_Key_Setup&#34;&gt;kontenerów LUKS&lt;/a&gt; (czy
też TrueCrypt), problematyczna może się okazać zmiana rozmiaru tego typu partycji. Praktycznie żadne
narzędzia graficzne, ewentualnie inne automaty, nie są w stanie nas przez ten proces bezstresowo
przeprowadzić. Musimy zatem skorzystać z niskopoziomowych aplikacji, takich jak &lt;code&gt;fdisk&lt;/code&gt; czy
&lt;code&gt;cryptsetup&lt;/code&gt; , by ten rozmiar sobie dostosować. Problem w tym, że nieumiejętne operowanie na tych
narzędziach może skończyć się tragicznie dla zgromadzonych na dysku danych. W tym wpisie postaram
się opisać cały proces zmiany rozmiaru zaszyfrowanego kontenera LUKS wliczając w to również
dostosowanie partycji i jej systemu plików.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru partycji FAT32 pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-partycji-fat32/</link>
      <pubDate>Thu, 17 Dec 2015 16:05:23 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-partycji-fat32/</guid>
      <description>&lt;p&gt;Partycje mające system plików FAT32 są głównie wykorzystywane w przypadku pendrive i innych pamięci
flash, gdzie nie mamy do czynienia ze sporą ilością danych czy też dużymi plikami. Czasem się zdarza
tak, że układ partycji, który chcieliśmy zrobić, nie wyszedł nam tak jak powinien i musimy tego
pendrive jeszcze raz przeformatować. Pół biedy, gdy na nim nie ma żadnych danych lub mamy możliwość
zgrania ich na osobny dysk. Natomiast w przypadku, gdy nie możemy z jakiegoś powodu skorzystać z w/w
opcji, to musimy liczyć się z utratą danych. Oczywiście, możemy także spróbować zmienić rozmiar
takiej partycji i nic nie powinno się stać znajdującym się na niej danym. W tym wpisie postaramy się
przejść przez proces zmiany rozmiaru partycji mającej system plików FAT32 i zobaczymy czy nasz linux
poradzi sobie z tym zdaniem bez większego problemu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru partycji EXT4</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-partycji-ext4/</link>
      <pubDate>Wed, 16 Dec 2015 19:06:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-partycji-ext4/</guid>
      <description>&lt;p&gt;Jeśli jeszcze nie dokonaliśmy &lt;a href=&#34;https://morfikov.github.io
/post/migracja-systemu-plikow-ext2-i-ext3-na-ext4/&#34;&gt;migracji systemu plików z EXT2/3 na
EXT4&lt;/a&gt;, to powinniśmy rozważyć
tę kwestię z przyczyn czysto praktycznych. W tym wpisie nie będziemy sobie głowy zawracać migracją
między poszczególnymi wersjami systemu plików z rodziny EXT, a raczej skupimy się na tym jak zmienić
rozmiar partycji, której systemem plików jest właśnie EXT4. Bawienie się rozmiarem partycji w tym
przypadku niczym zbytnio się nie różni w stosunku do omawianego wcześniej &lt;a href=&#34;https://morfikov.github.io
/post/zmiana-rozmiaru-partycji-ntfs-pod-linuxem/&#34;&gt;systemu plików
NTFS&lt;/a&gt;. Będziemy wykorzystywać
tylko nieco inne narzędzia.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru partycji NTFS pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-partycji-ntfs-pod-linuxem/</link>
      <pubDate>Wed, 16 Dec 2015 18:03:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-partycji-ntfs-pod-linuxem/</guid>
      <description>&lt;p&gt;Zmiana rozmiaru partycji, nie tylko tej zawierającej system plików NTFS, nie sprawia w dzisiejszych
czasach praktycznie żadnych problemów. Mamy przecie do dyspozycji takie narzędzia jak
&lt;a href=&#34;http://gparted.org/&#34;&gt;gparted&lt;/a&gt;, które w dużej mierze automatyzują cały proces tworzenia i usuwania
partycji, czy też zmiany ich rozmiaru. W tym wpisie przyjrzymy się temu procesowi z bliska, z tym,
że nie będziemy korzystać z żadnych graficznych nakładek. Wszystkie kroki postaramy się
zreprodukować ręcznie z poziomu konsoli przy pomocy takich narzędzi jak &lt;code&gt;fdisk&lt;/code&gt; czy &lt;code&gt;ntfsresize&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja interfejsów IFB w linux&#39;ie</title>
      <link>https://morfikov.github.io/post/konfiguracja-interfejsow-ifb-w-linuxie/</link>
      <pubDate>Wed, 16 Dec 2015 14:46:50 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-interfejsow-ifb-w-linuxie/</guid>
      <description>&lt;p&gt;Ten wpis również będzie poświęcony tematyce
&lt;a href=&#34;http://linux-ip.net/articles/Traffic-Control-HOWTO/index.html&#34;&gt;kontroli&lt;/a&gt; i
&lt;a href=&#34;https://lukasz.bromirski.net/docs/translations/lartc-pl.html&#34;&gt;kształtowania&lt;/a&gt; ruchu sieciowego w
linux&#39;ie, z tym, że ograniczymy się tutaj do konfiguracji interfejsów IFB. Działają one na podobnej
zasadzie co &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-interfejsow-imq-w-linuxie/&#34;&gt;interfejsy IMQ&lt;/a&gt;.
Niewątpliwą zaletą interfejsów IFB jest fakt, że są one natywnie wspierane przez kernel linux&#39;a,
przez co ich obsługa jest dziecinnie prosta. Wadą jest z kolei to, że nie do końca damy radę
kształtować ruch przychodzący do naszej maszyny. Tak czy inaczej, postaramy się skonfigurować te
interfejsy i zobaczymy co z nich idzie wycisnąć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kształtowanie ruchu sieciowego (Traffic Control)</title>
      <link>https://morfikov.github.io/post/ksztaltowanie-ruchu-sieciowego-traffic-control/</link>
      <pubDate>Tue, 15 Dec 2015 20:40:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ksztaltowanie-ruchu-sieciowego-traffic-control/</guid>
      <description>&lt;p&gt;Każdy z nas chciałby, aby jego sieć działała możliwie szybko i bezproblemowo. W przypadku, gdy łącze
nie jest zbytnio obciążone, a my jesteśmy jedynym użytkownikiem internetu, to nie doświadczymy
raczej żadnych problemów z połączeniem. Rzecz w tym, że im więcej użytkowników ma nasza sieć, tym
większe prawdopodobieństwo, że zostanie ona przeciążona, tj. będziemy chcieli przesyłać więcej
danych niż sieć jest w stanie obsłużyć. W ten sposób zaczną pojawiać się kolejki pakietów na
interfejsach, których obsługa zajmuje trochę czasu. Rosą zatem opóźnienia, które są bardzo
odczuwalne w momencie, gdy ktoś lubi sobie pograć w różnego rodzaju gry online. Innym problemem może
być sieć P2P, gdzie pojedynczy host z naszej sieci może nawiązywać dziesiątki czy nawet setki
połączeń i tym samym zapychać łącze nie dając szansy innym użytkownikom na komfortowe korzystanie
z internetu. W obu przypadkach może nam pomóc &lt;a href=&#34;http://lartc.org/lartc.html&#34;&gt;kształtowanie ruchu
sieciowego&lt;/a&gt; (Traffic Control), która jest w stanie nadać pakietom
odpowiedni priorytet, tak by część z nich nie musiała czekać zbyt długo w kolejce. W tym wpisie
przyjrzymy się bliżej temu mechanizmowi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja interfejsów IMQ w linux&#39;ie</title>
      <link>https://morfikov.github.io/post/konfiguracja-interfejsow-imq-w-linuxie/</link>
      <pubDate>Tue, 15 Dec 2015 14:38:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-interfejsow-imq-w-linuxie/</guid>
      <description>&lt;p&gt;W linux&#39;ie, kształtowanie przychodzącego ruchu sieciowego stwarza dość poważne problemy. Na dobrą
sprawę, obecnie w kernelu nie ma żadnego mechanizmu, który byłby w stanie to zadanie realizować.
Istnieją, co prawda, &lt;a href=&#34;https://wiki.linuxfoundation.org/networking/ifb&#34;&gt;interfejsy IFB&lt;/a&gt; ale za ich
pomocą jesteśmy w stanie z powodzeniem kształtować jedynie ruch wychodzący. W przypadku pakietów
napływających, możemy jedynie ograniczyć im przepustowość. W tym powyższym linku jest wzmianka, że
te interfejsy IFB są następcą &lt;a href=&#34;https://github.com/imq/linuximq/wiki/WhatIs&#34;&gt;interfejsów IMQ&lt;/a&gt;.
Niemniej jednak, ten drugi projekt zdaje się działać, choć nie jest obecnie wspierany przez kernel
linux&#39;a. W tym wpisie postaramy się skonfigurować działające interfejsy IMQ, tak, by za ich pomocą
skutecznie kształtować ruch przychodzący.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ograniczanie zasobów procesom przez cgroups</title>
      <link>https://morfikov.github.io/post/ograniczanie-zasobow-procesom-przez-cgroups/</link>
      <pubDate>Tue, 08 Dec 2015 21:21:53 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ograniczanie-zasobow-procesom-przez-cgroups/</guid>
      <description>&lt;p&gt;Nasze komputery obecnie mają dość pokaźne zasoby obliczeniowe. Jeszcze nie tak dawno temu
wyposażenie maszyny w 32 GiB pamięci RAM, czy też 8 rdzeni było czystą abstrakcją. Wydawałoby się,
że te powyższe parametry zaspokoją każdego. Niemniej jednak, nie ważne jak szybki i rozbudowany
będzie nasz PC, to nam zawsze będzie mało. Mamy dwa rdzenie, to chcemy cztery. Mamy cztery, to
chcemy osiem, itd. Poza tym, szereg aplikacji realizuje co raz więcej zadań i staje się bardziej
wymagająca z każdym mijającym rokiem. Jeśli nie przeprowadzamy modernizacji sprzętu, to może się
okazać, że w niedługim czasie zabraknie nam pamięci albo pewne operacje będą wykonywane bardzo
wolno. W sporej części przypadków nie obędzie się bez wymiany podzespołów ale nawet w przypadku, gdy
mamy spory zapas zasobów systemowych, to poszczególne procesy rywalizują o nie ze sobą. Często bywa
tak, że chcielibyśmy, aby konkretny proces wykonał się szybciej, a to pociąga za sobą, np. zmianę
priorytetów w dostępie do rdzeni procesora. W linux&#39;ie jest mechanizm zwany
&lt;a href=&#34;https://en.wikipedia.org/wiki/Cgroups&#34;&gt;cgroups&lt;/a&gt;, który potrafi ograniczyć zasoby całym aplikacjom
bez względu na to ile ona by miała procesów. W tym wpisie postaramy się przebrnąć przez proces
konfiguracji tego mechanizmu i spróbujemy wyprofilować sobie nasz system.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Poradnik maintainer&#39;a, czyli jak zrobić pakiet deb</title>
      <link>https://morfikov.github.io/post/poradnik-maintainera-czyli-jak-zrobic-pakiet-deb/</link>
      <pubDate>Mon, 07 Dec 2015 20:26:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/poradnik-maintainera-czyli-jak-zrobic-pakiet-deb/</guid>
      <description>&lt;p&gt;Debian posiada bardzo rozbudowany system robienia pakietów. Generalnie rzecz biorąc, to wszystkie z
nich musiały przejść przez ten proces zanim trafiły do głównego repozytorium dystrybucji. Dzięki
takiemu stanu rzeczy, nie musimy ręcznie powielać pracy szeregu innych osób i odpada nam
własnoręczna kompilacja pakietów, a wszyscy wiemy, że zajmuje ona cenny czas i zasoby. Paczki
&lt;code&gt;.deb&lt;/code&gt; są tworzone ze źródeł i instalowane przy pomocy menadżera pakietów &lt;code&gt;aptitude&lt;/code&gt;/&lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;dpkg&lt;/code&gt; .
Nic jednak nie stoi na przeszkodzie by daną aplikację skompilować sobie ręcznie i zainstalować ją
przy pomocy &lt;code&gt;make install&lt;/code&gt; . Problem w tym, że w taki sposób robi się śmietnik w naszym systemie i
śledzenie wszystkich zainstalowanych w ten sposób pakietów w pewnym momencie stanie się wręcz
niemożliwe. Dlatego też przydałby nam się mechanizm, który ułatwiłby nam nieco to zadanie. Debian
udostępnia szereg narzędzi, które są w stanie w pełni zautomatyzować cały ten proces budowy
pakietów. Ten poradnik zaś ma na celu zebranie wszystkich istotniejszych informacji związanych z
obsługą narzędzi takich jak &lt;code&gt;dh_make&lt;/code&gt; , &lt;code&gt;dpkg-buildpackage&lt;/code&gt; , &lt;code&gt;pbuilder&lt;/code&gt; , &lt;code&gt;quilt&lt;/code&gt; czy &lt;code&gt;lintian&lt;/code&gt; ,
tak by tworzyć pakiety w prosty sposób i przy tym równając do najwyższych standardów debiana.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wymusić sprawdzenie systemu plików w systemd</title>
      <link>https://morfikov.github.io/post/jak-wymusic-sprawdzenie-systemu-plikow-w-systemd/</link>
      <pubDate>Fri, 04 Dec 2015 20:11:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wymusic-sprawdzenie-systemu-plikow-w-systemd/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem jak w systemach linux&#39;owych przeprowadzić &lt;a href=&#34;https://morfikov.github.io
/post/sprawdzanie-bledow-systemu-plikow-ext4/&#34;&gt;sprawdzenie systemu plików pod
kątem ewentualnych błędów&lt;/a&gt;. Był tam
poświęcony kawałek na temat ręcznego wymuszenia takiego skanowania. Ten sposób, który został opisany
w tamtym wpisie działa wyśmienicie w przypadku sysvinit. Natomiast przy systemd mogą pojawić się
pewne problemy, w efekcie czego nie będziemy w stanie wymusić skanowania pewnych partycji.
Generalnie to rozchodzi się o tę główną, na której znajduje się system plików &lt;code&gt;/&lt;/code&gt; . Postanowiłem się
przyjrzeć nieco temu mechanizmowi i sprawdzić czy faktycznie nic nie da się zrobić i czy musimy
czekać pełną ilość cykli startu systemu, by ten system plików został przez niego przeskanowany
automatycznie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zwiększyć prędkość zapisu w urządzeniach USB</title>
      <link>https://morfikov.github.io/post/jak-zwiekszyc-predkosc-zapisu-w-urzadzeniach-usb/</link>
      <pubDate>Wed, 02 Dec 2015 17:06:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zwiekszyc-predkosc-zapisu-w-urzadzeniach-usb/</guid>
      <description>&lt;p&gt;Przeglądając sobie &lt;a href=&#34;http://www.linux-usb.org/FAQ.html&#34;&gt;FAQ dotyczący urządzeń USB&lt;/a&gt; natknąłem się na
punkt, który opisywał parametr &lt;code&gt;max_sectors&lt;/code&gt; . Niby nic wielkiego, w linux&#39;ie jest przecie pełno
przeróżnych opcji, przy pomocy których jesteśmy w stanie zmienić szereg aspektów pracy naszego
systemu operacyjnego. Rzecz w tym, że parametr &lt;code&gt;max_sectors&lt;/code&gt; potrafi nawet dość znacznie poprawić
wydajność urządzeń USB, w tym tych wszystkich pendrive&#39;ach, w których prędkość zapisu pozostawia
wiele do życzenia. W tym wpisie postaramy się nieco dostosować ten parametr, tak by przyśpieszyć
transfer kopiowanych plików.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Profil AppArmor&#39;a i jego dokładna budowa</title>
      <link>https://morfikov.github.io/post/profil-apparmora-i-jego-dokladna-budowa/</link>
      <pubDate>Tue, 01 Dec 2015 17:57:39 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/profil-apparmora-i-jego-dokladna-budowa/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/apparmor-profilowanie-aplikacji/&#34;&gt;Budowanie samych profili dla AppArmor&#39;a&lt;/a&gt;
nie jest jakoś szczególnie trudne, zwłaszcza, gdy do tego celu wykorzystujemy narzędzia dostępne w
pakiecie &lt;code&gt;apparmor-utils&lt;/code&gt; . Dobrze jest jednak prześledzić sobie
&lt;a href=&#34;http://manpages.ubuntu.com/manpages/xenial/en/man5/apparmor.d.5.html&#34;&gt;manual&lt;/a&gt;
&lt;a href=&#34;http://manpages.ubuntu.com/manpages/xenial/en/man7/apparmor.7.html&#34;&gt;AppArmor&#39;a&lt;/a&gt; oraz to, co twórcy
piszą na swojej stronie w &lt;a href=&#34;http://wiki.apparmor.net/index.php/Documentation&#34;&gt;oficjalnej
dokumentacji&lt;/a&gt; projektu. Poniższy wpis powstał w
celu zrozumienia składni profili AppArmor&#39;a, tak by jeszcze bardziej uprościć proces ich budowania.&lt;/p&gt;
&lt;p&gt;Opis składni znajdujący się poniżej został zaczerpnięty z
&lt;a href=&#34;http://wiki.apparmor.net/index.php/QuickProfileLanguage&#34;&gt;wiki&lt;/a&gt;
&lt;a href=&#34;http://wiki.apparmor.net/index.php/AppArmor_Core_Policy_Reference&#34;&gt;AppArmor&#39;a&lt;/a&gt;. Część z poniższych
informacji może nie mieć zastosowania w przypadku starszych wersji samego AppArmor&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak odzyskać usunięte z dysku pliki</title>
      <link>https://morfikov.github.io/post/jak-odzyskac-usuniete-z-dysku-pliki/</link>
      <pubDate>Mon, 30 Nov 2015 19:03:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-odzyskac-usuniete-z-dysku-pliki/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/usuwanie-plikow-przy-pomocy-shred/&#34;&gt;Całkowite usuwanie plików (shred)&lt;/a&gt; jak i
&lt;a href=&#34;https://morfikov.github.io
/post/programowe-sprzetowe-zerowanie-dysku/&#34;&gt;zerowanie całych nośników&lt;/a&gt; ma na celu
nieodwracalne zniszczenie danych. W tych podlinkowanych artykułach próbowaliśmy zatrzeć ślady po
skasowanych plikach. W tym wpisie zaś prześledzimy sobie co tak naprawdę się dzieje po utworzeniu i
skasowaniu pliku, a także spróbujemy odzyskać te z nich, które już nie istnieją w naszym systemie.
Ten artykuł będzie dotyczył jedynie systemu plików z rodziny &lt;code&gt;ext&lt;/code&gt; , głównie &lt;code&gt;ext4&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kodowanie nazw plików i jego zmiana</title>
      <link>https://morfikov.github.io/post/kodowanie-nazw-plikow-i-jego-zmiana/</link>
      <pubDate>Fri, 27 Nov 2015 15:15:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kodowanie-nazw-plikow-i-jego-zmiana/</guid>
      <description>&lt;p&gt;Chciałem dziś wypakować sobie kilka plików, które były zebrane w paczkę &lt;code&gt;.zip&lt;/code&gt; . Problem w tym, że
ta osoba, co te pliki pakowała, najwyraźniej robiła to na widnowsie no i nie użyła standardowego
kodowania, które jest wykorzystywane na każdym innym systemie, tj. UTF-8. Wobec tego, wszystkie
pliki mają w swoich nazwach znaczek &lt;code&gt;�&lt;/code&gt; w miejscu polskich liter. Jako, że tych plików jest dość
dużo, to odpada ręczna edycja nazw i trzeba pomyśleć nad jakimś innym rozwiązaniem. Zmiana
kodowania nazw plików, to nie jest to samo co &lt;a href=&#34;https://morfikov.github.io
/post/zmiana-kodowania-znakow-w-plikach-na-utf-8/&#34;&gt;zmiana kodowania zawartości tych
plików&lt;/a&gt;. Na szczęście w
linux&#39;ie mamy do dyspozycji narzędzie &lt;code&gt;convmv&lt;/code&gt; , które jest w stanie, jak sama nazwa mówi, przepisać
nazwy plików ustawiając przy tym odpowiednie kodowanie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana hasła konta administratora root</title>
      <link>https://morfikov.github.io/post/zmiana-hasla-konta-administratora-root/</link>
      <pubDate>Wed, 25 Nov 2015 13:55:44 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-hasla-konta-administratora-root/</guid>
      <description>&lt;p&gt;W pewnych skrajnych przypadkach może się nam zdarzyć tak, że zapomnimy hasła do konta administratora
systemu. Jak wiadomo bez użytkownika root w naszych linux&#39;ach nie da się zbytnio nic zrobić. Na
pewno nie da się przeprowadzić żądnych prac administracyjnych. Zwykle w takim przypadku moglibyśmy
przeinstalować system i ustawić nowe hasło ale to wydaje się lekką przesadą. Poza tym, co w
przypadku gdy nie możemy zwyczajnie zainstalować na nowo systemu lub nie mamy akurat pod ręką płytki
czy pendrive live? Czy w linux&#39;ie jest w ogóle możliwość odzyskania hasła użytkownika root bez
rozkręcania komputera biorąc pod uwagę te wszystkie mechanizmy bezpieczeństwa, które czynią ten
system tak bezpiecznym? Oczywiście zmiana hasła do konta administratora jest możliwa i nawet nie
trzeba się przy tym zbytnio wysilać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Programowe i sprzętowe zerowanie dysku</title>
      <link>https://morfikov.github.io/post/programowe-sprzetowe-zerowanie-dysku/</link>
      <pubDate>Tue, 24 Nov 2015 17:54:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/programowe-sprzetowe-zerowanie-dysku/</guid>
      <description>&lt;p&gt;Zerowanie dysku twardego ma na celu usunięcie wszystkich znajdujących się na nim danych. Generalnie
chodzi o zapisanie całej powierzchni danego nośnika samymi zerami. Ten proces różni się znacząco of
formatowania dysku, czyli utworzenia nowego systemu plików, gdzie praktycznie wszystkie dane można
bez większego problemu odzyskać. Zerowanie dysku (czy też pendrive) może w pewnych przypadkach
&lt;a href=&#34;https://morfikov.github.io
/post/uszkodzony-sektor-na-dysku-i-jego-realokoacja/&#34;&gt;naprawić logiczne błędy
sektorów&lt;/a&gt; na dysku. Niemniej
jednak, nie usuniemy za jego pomocą fizycznych bad&#39;ów. Generalnie rzecz biorąc, mamy do wyboru dwie
techniki zerowania. Jedna jest dokonywana na poziomie programowym, np. przy pomocy &lt;code&gt;dd&lt;/code&gt; , druga zaś
na poziomie sprzętowym, np. w &lt;code&gt;hdparm&lt;/code&gt; . W tym wpisie postaramy się wyzerować przykładowy dysk.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Całkowite usuwanie plików przy pomocy shred</title>
      <link>https://morfikov.github.io/post/usuwanie-plikow-przy-pomocy-shred/</link>
      <pubDate>Tue, 24 Nov 2015 15:11:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/usuwanie-plikow-przy-pomocy-shred/</guid>
      <description>&lt;p&gt;W przypadku, gdy musimy pozbyć się jakiegoś pliku, który znajduje się na dysku, to nie jest zalecane
korzystanie z narzędzia &lt;code&gt;rm&lt;/code&gt; . Usuwa ono jedynie odnośnik do pliku, który go identyfikuje w
strukturze systemu plików, tzw. &lt;a href=&#34;https://pl.wikipedia.org/wiki/I-w%C4%99ze%C5%82&#34;&gt;i-węzeł&lt;/a&gt; (i-node).
To co uzyskujemy za pomocą takich narzędzi jak &lt;code&gt;rm&lt;/code&gt; , to jedynie oznaczenie pewnych bloków (tych od
pliku) jako wolne, w których system operacyjny będzie w stanie dokonać zapisu danych późniejszym
czasie. Podczas tej operacji nie są usuwane żadne informacje z dysku, a mając na uwadze ten fakt,
możemy bez problemu tak &amp;quot;usunięty&amp;quot; plik odzyskać. By mieć pewność, że plik zostanie trwale
zniszczony, trzeba go ponownie napisać, np. przy pomocy
&lt;a href=&#34;http://manpages.ubuntu.com/manpages/wily/en/man1/shred.1.html&#34;&gt;shred&lt;/a&gt;, który standardowo jest
dostępny w każdej dystrybucji linux&#39;a i to jemu będzie poświęcony ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Integralność plików passwd, group, shadow, gshadow</title>
      <link>https://morfikov.github.io/post/integralnosc-plikow-passwd-group-shadow-gshadow/</link>
      <pubDate>Tue, 24 Nov 2015 12:30:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/integralnosc-plikow-passwd-group-shadow-gshadow/</guid>
      <description>&lt;p&gt;W pliku &lt;code&gt;/etc/passwd&lt;/code&gt; jest przechowywana baza danych kont użytkowników w systemie linux. Z kolei w
&lt;code&gt;/etc/group&lt;/code&gt; mamy wypisane wszystkie grupy oraz powiązanych z nimi użytkowników. Generalnie rzecz
biorąc, to te dwa pliki odpowiadają za konfigurację kont. Problem jednak zaczyna się w momencie gdy
w grę wchodzą hasła, zarówno do kont jak i do grup. Gdyby były one trzymane w tych plikach, nie
byłyby one w żaden sposób szyfrowane. Dlatego też powstał inny mechanizm, który ma na celu
przeniesienie zahashowanych haseł do plików &lt;code&gt;/etc/shadow&lt;/code&gt; i &lt;code&gt;/etc/gshadow&lt;/code&gt; . W debianie
użytkownikami i grupami możemy zarządzać przy pomocy odpowiednich narzędzi, które automatycznie
dostosują wszystkie powyższe pliki. Nic jednak nie stoi na przeszkodzie aby edytować każdy z nich
ręcznie. Problemy mogą się pojawić w momencie, gdy te pliki będą zawierać różne wpisy, np. w pliku
&lt;code&gt;passwd&lt;/code&gt; będzie określony użytkownik, który jednocześnie nie będzie istniał w pliku &lt;code&gt;shadow&lt;/code&gt; ,
podobnie z grupami. W tym wpisie postaramy się sprawdzić te pliki i upewnimy się czy aby na pewno
jest z nimi wszystko w porządku.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przewidywalne nazwy interfejsów sieciowych</title>
      <link>https://morfikov.github.io/post/przewidywalne-nazwy-interfejsow-sieciowych/</link>
      <pubDate>Sun, 22 Nov 2015 21:44:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przewidywalne-nazwy-interfejsow-sieciowych/</guid>
      <description>&lt;p&gt;Podczas jednej z aktualizacji systemu został mi zwrócony pewien komunikat. Oświadczał on bowiem, że
od jakiegoś czasu nazewnictwo interfejsów sieciowych w systemie uległo zmianie, oraz, że w wersji 10
debiana, ten obecny system nazw nie będzie już wspierany. Rozchodzi się o coś co nazywa się
&lt;a href=&#34;https://www.freedesktop.org/wiki/Software/systemd/PredictableNetworkInterfaceNames/&#34;&gt;Predictable Network Interface
Names&lt;/a&gt;, czyli
przewidywalne nazwy interfejsów sieciowych. Jako, że aktualne wydanie stabilnego debiana ma numerek
8 i w niedalekiej przyszłości zostanie wydana 9, to przydałoby się już zacząć migrować na ten nowy
system nazw. W tym wpisie dokonamy takiej migracji i zobaczymy jakie zmiany musimy poczynić, by nie
doświadczyć problemów związanych z tą migracją nazw.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czy zmiana nazwy użytkownika root ma sens?</title>
      <link>https://morfikov.github.io/post/czy-zmiana-nazwy-uzytkownika-root-ma-sens/</link>
      <pubDate>Sat, 21 Nov 2015 19:52:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czy-zmiana-nazwy-uzytkownika-root-ma-sens/</guid>
      <description>&lt;p&gt;Wielu ludzi potrafi się rozpisywać na temat bezpieczeństwa systemu linux jednocześnie nie zauważając
jednego bardzo poważnego problemu. Wszyscy wiemy, że linux&#39;y są bezpieczne min. przez fakt
rozgraniczenia konta administratora od konta zwykłego użytkownika i nadaniu im różnych praw dostępu
do poszczególnych części systemu operacyjnego. O ile konta użytkowników mają różne nazwy, o tyle
administrator w praktycznie każdym linux&#39;ie kryje się pod nazwą &lt;code&gt;root&lt;/code&gt; . Znając nazwę konta, można
próbować złamać hasło. To trochę dziwne, że nie można sobie arbitralnie ustalić nazwy dla tego konta
tak by uniknąć wszelkich ataków, które związane są z logowaniem się na określonego użytkownika w
systemie. W tym wpisie postaramy się prześledzić całą procedurę zmiany nazwy konta &lt;code&gt;root&lt;/code&gt; na jakąś
dowolną i zobaczymy czy wpłynie to w jakimś stopniu na pracę naszego systemu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wypakować każde archiwum</title>
      <link>https://morfikov.github.io/post/jak-wypakowac-kazde-archiwum/</link>
      <pubDate>Fri, 20 Nov 2015 15:15:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wypakowac-kazde-archiwum/</guid>
      <description>&lt;p&gt;Archiwum &lt;code&gt;.tar.gz&lt;/code&gt; czy też każde inne, np. &lt;code&gt;.zip&lt;/code&gt; lub &lt;code&gt;.rar&lt;/code&gt; , jest bardzo użyteczne przy
przesyłaniu przez sieć plików między wieloma maszynami. Nie dość, że zaoszczędzają nam sporo
transferu, to jeszcze do tego operujemy na jednym pliku. Problem z tymi wszystkimi rodzajami
archiwów jest taki, że do każdego z nich mamy inne narzędzia. Zwykle też każde z tych narzędzi ma
inne opcje, które taką paczkę potrafią wypakować. Przydałby się zatem sposób, który ogarnąłby
wypakowanie różnych archiwów i sprowadzałby się do wydania w terminalu tylko jednego polecenia, bez
potrzeby pamiętania nazw narzędzi i ich opcji. W tym wpisie postaramy się coś takiego
zaimplementować na swoich linux&#39;ach.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja cache DNS w Firefox&#39;ie</title>
      <link>https://morfikov.github.io/post/konfiguracja-cache-dns-w-firefoxie/</link>
      <pubDate>Fri, 20 Nov 2015 14:01:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-cache-dns-w-firefoxie/</guid>
      <description>&lt;p&gt;We wpisie poświęconym &lt;a href=&#34;https://morfikov.github.io
/post/cache-dns-buforowania-zapytan/&#34;&gt;systemowemu cache DNS w
linux&#39;ie&lt;/a&gt; mieliśmy okazję zobaczyć jak
wzrasta wydajność po zaimplementowaniu tego mechanizmu. W skrócie, to ponad drugie tyle zapytań było
rozwiązywanych lokalnie bez potrzeby odwoływania się do zdalnego serwera DNS, co zajmuje sporo czasu
(20-40ms). Przeglądarki internetowe, np. Firefox, mają swoje wynalazki, które potrafią wyeliminować
opóźnienia związane z surfowaniem po stronach www. Do nich zalicza się również cache DNS, z tym, że
w tym przypadku zaimplementowany jest on na poziomie przeglądarki, a nie globalnie w systemie.
Dzięki temu rozwiązaniu, nawet bez &lt;code&gt;dnsmasq&lt;/code&gt; , Firefox jest nam w stanie zaoszczędzić sporo czasu
przy przeglądaniu internetu. Zajrzyjmy zatem Firefox&#39;owi pod maskę i sprawdźmy, które parametry
dotyczące cache DNS wymagają dostosowania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Nagrywanie strumienia audio radia internetowego</title>
      <link>https://morfikov.github.io/post/nagrywanie-strumienia-audio-radia-internetowego/</link>
      <pubDate>Thu, 19 Nov 2015 17:49:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/nagrywanie-strumienia-audio-radia-internetowego/</guid>
      <description>&lt;p&gt;Człowiek raczej nigdy nie przywyknie do absolutnej ciszy. Dlatego nawet jeśli pracujemy nad czymś
ważnym, to chcemy mieć w tle jakiś dźwięk, który zagłuszy ciszę. Zwykle jest to nasza ulubiona
muzyka odtwarzana na jednym z player&#39;ów audio, który mamy zainstalowany w swoim linux&#39;ie. Muzyka
może nam się szybko znudzić, zwłaszcza gdy w kółko odsłuchujemy te same kawałki. Te bardziej
wymagające osobniki preferują informacje zamiast muzyki, a to wiąże się w dużej mierze z wszelkiej
maści podcastami czy też radiami internetowymi. W sporej części przypadków, musimy być obecni przy
kompie podczas nadawania audycji. Może nie koniecznie jest to wymagane przy podcastach, bo pliki
&lt;code&gt;.mp3&lt;/code&gt; możemy sobie ściągnąć w późniejszym czasie ale sporo stacji radiowych nie dostarczy
słuchaczom audycji w trybie offline. Poza tym, w przypadku podcastów, mamy także część audycji,
która jest nienagrywana i nie jest uwzględniona w pliku &lt;code&gt;.mp3&lt;/code&gt; . Tak czy inaczej, przydałoby się
mieć możliwość nagrania strumienia audio, który jest przesyłany przez sieć. Czy istnieje jakiś
prosty sposób, który nam to umożliwi?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Statystyki transferu danych w sieci (vnstat)</title>
      <link>https://morfikov.github.io/post/statystyki-transferu-danych-w-sieci-vnstat/</link>
      <pubDate>Thu, 19 Nov 2015 16:16:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/statystyki-transferu-danych-w-sieci-vnstat/</guid>
      <description>&lt;p&gt;W prehistorycznych czasach, internet był bardzo limitowany. Nie chodzi tutaj o prędkość, która
obecnie sięga 100+ mbit/s, a o transfer danych. Świat poszedł już trochę do przodu od tamtego czasu
i chyba żaden ISP, który obecnie dostarcza internet stacjonarny, nie narzuca swoim klientom ile
danych mogą pobrać i/lub wysłać w konkretnym miesiącu. Problem pojawia się w przypadku internetu
mobilnego, który w niedługim czasie prawdopodobnie zapanuje nad światem. Mowa oczywiście o
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Long_Term_Evolution&#34;&gt;LTE&lt;/a&gt;, czyli szerokopasmowym internecie
bezprzewodowym. Chodzi generalnie o to, że spora cześć providerów (jak nie wszyscy) limitują
transfer danych w tej usłudze. Jest to około 100GB na miesiąc. Może to wydawać się dużo ale trzeba
mieć na względzie, że dotyczy to zarówno download&#39;u jak i upload&#39;u. No i oczywiście, dziś wszystko
mamy w HD i rzadko kto korzysta z internetu sam. Nawet przeciętna strona www waży już kilka MiB.
Przydałoby się zatem wiedzieć ile danych transmitujemy przez sieć każdego dnia, tak by czasem nie
doświadczyć problemów związanych z przekroczeniem transferu. W tym wpisie postaramy się pozyskać te
informacje i wygenerujemy sobie przyzwoite statystyki transferu przy pomocy narzędzia &lt;code&gt;vnstat&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Montowanie obrazów ISO (urządzenia loop)</title>
      <link>https://morfikov.github.io/post/montowanie-obrazow-iso-urzadzenia-loop/</link>
      <pubDate>Thu, 19 Nov 2015 14:17:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/montowanie-obrazow-iso-urzadzenia-loop/</guid>
      <description>&lt;p&gt;Użytkownicy Debiana (i innych dystrybucji linux&#39;a) mają czasem poważne problemy z zamontowaniem
&lt;a href=&#34;https://pl.wikipedia.org/wiki/ISO_%28obraz%29&#34;&gt;obrazu ISO&lt;/a&gt; pozyskanego czy to z internetu, czy też
od swoich znajomych. Na windowsach zwykliśmy korzystać z takich rozwiązań jak Daemon Tools, Alcohol
120%, czy też &lt;a href=&#34;http://wincdemu.sysprogs.org/&#34;&gt;WinCDEmu&lt;/a&gt;. Na linux&#39;ach z narzędzi, które mają GUI,
można chyba wyróżnić &lt;a href=&#34;https://launchpad.net/furiusisomount&#34;&gt;furiusisomount&lt;/a&gt; oraz
&lt;a href=&#34;http://sourceforge.net/projects/acetoneiso/&#34;&gt;acetoneiso&lt;/a&gt; ale nie będziemy się nimi zajmować w tym
wpisie. Na dobrą sprawę, to nie potrzebujemy żadnego zewnętrznego oprogramowania, by sprawnie i
szybko zamontować dowolny obraz ISO w swoim systemie. W tym wpisie zostanie przedstawiony sposób
montownia tychże obrazów, który zakłada wykorzystanie urządzeń &lt;code&gt;loop&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cache DNS, czyli włączenie buforowania zapytań</title>
      <link>https://morfikov.github.io/post/cache-dns-buforowania-zapytan/</link>
      <pubDate>Mon, 16 Nov 2015 20:13:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/cache-dns-buforowania-zapytan/</guid>
      <description>&lt;p&gt;Większość z nas wie, że standardowe instalacje systemu linux nie buforują żadnych zapytań do
serwerów DNS. Dzieje się tak dlatego, że te systemy domyślnie nie mają zainstalowanego żadnego
oprogramowania, które by im to umożliwiało. Niesie to ze sobą zwiększenie opóźnień transakcji
krótkoterminowych, np. tych w protokole http czy https. Za każdym razem gdy odwiedzamy jakiś serwis
www, musimy wykonać szereg zapytań DNS, by rozwiązać nazwy domen na adresy IP. W przypadku gdybyśmy
mieli cache DNS, to te nazwy nie musiałyby być za każdym każdym razem rozwiązywane na nowo,
przynajmniej nie przez odpytywanie zdalnego serwera DNS, do którego RTT wynosi jakieś 20-40ms.
Przydałoby się zatem nieco poprawić wydajność stron www i w tym wpisie postaramy się zaimplementować
prosty cache DNS z wykorzystaniem &lt;a href=&#34;http://www.thekelleys.org.uk/dnsmasq/doc.html&#34;&gt;narzędzia
dnsmasq&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uprawnienia do plików systemowych w linux&#39;ie</title>
      <link>https://morfikov.github.io/post/uprawnienia-do-plikow-systemowych-w-linuxie/</link>
      <pubDate>Mon, 16 Nov 2015 12:34:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uprawnienia-do-plikow-systemowych-w-linuxie/</guid>
      <description>&lt;p&gt;Każdy z nas popełnia błędy. Niektóre z nich są błahe i w sporej części łatwe do poprawienia. Zwykle
też nie niosą one ze sobą większych konsekwencji. Natomiast błędy, które popełniamy podczas pracy w
systemie operacyjnym wykonując różne prace administracyjne mogą nas czasem słono kosztować. W
linux&#39;ach ogromną rolę odgrywają prawa do plików. O ile root ma dostęp do wszystkich plików, to w
przypadku zwykłych użytkowników (czy tez usług systemowych) już tak nie jest. Przypadkowa zmiana
tych uprawnień może zaowocować problemami związanymi z bezpieczeństwem takiego systemu, a w
niektórych przypadkach może nawet uniemożliwić jego start. Na necie kilka razy obił mi się o oczy
temat, gdzie ludzie przez przypadek (lub też &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=27876&#34;&gt;całkiem
świadomie&lt;/a&gt;) zmienili masowo uprawnienia w takich
katalogach jak &lt;code&gt;/usr/&lt;/code&gt; czy &lt;code&gt;/etc/&lt;/code&gt; . Powiem nawet więcej, mi się raz taka sytuacja kiedyś
przytrafiła. Co w takim przypadku można zrobić? Czy jedyną opcją, jaka nam pozostaje, to ponowna
instalacja sytemu? Na szczęście nie, bo uprawnienia do plików możemy sobie zwyczajnie spisać i
odtworzyć je w późniejszym czasie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana kodowania znaków w plikach na UTF-8</title>
      <link>https://morfikov.github.io/post/zmiana-kodowania-znakow-w-plikach-na-utf-8/</link>
      <pubDate>Fri, 13 Nov 2015 16:18:56 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-kodowania-znakow-w-plikach-na-utf-8/</guid>
      <description>&lt;p&gt;Pliki tekstowe w linux&#39;ie są zakodowane w &lt;a href=&#34;https://www.cl.cam.ac.uk/~mgk25/unicode.html&#34;&gt;formacie
UTF-8&lt;/a&gt;. Ta cyfra &lt;code&gt;8&lt;/code&gt; może być jednak myląca, bo ilość
bajtów potrzebnych do zakodowania pojedynczego znaku może się różnić i wynosi od 1 do 4. Tak czy
inaczej, środowiska linux&#39;owe już dawno zaimplementowały obsługę tego systemu kodowania i uczyniły
go sobie domyślnym. Są jednak takie systemy operacyjne, które nie wykorzystują domyślnie UTF-8 do
kodowania tekstu. Wobec czego, gdy spróbujemy otworzyć w edytorze taki plik, to w pewnych miejscach
będziemy mieli krzaczki, zwykle tam gdzie są polskie znaki. To zjawisko jest bardzo
charakterystyczne dla napisów w filmach. Niemniej jednak, zarówno edytory tekstu jak i player&#39;y
video są w stanie dokonać automatycznego doboru systemu kodowania i zwrócić nam czytelny plik. Nie
zawsze jednak tak robią. Zamiast bawić się w tego typu automatyczne wynalazki, dużo lepszym
rozwiązaniem jest zmiana kodowania plików, tak by przekonwertować je do formatu UTF-8 i w tym
wpisie postaramy się to zrobić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kiedy uruchomiony proces wymaga restartu</title>
      <link>https://morfikov.github.io/post/kiedy-uruchomiony-proces-wymaga-restartu/</link>
      <pubDate>Fri, 13 Nov 2015 14:22:21 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kiedy-uruchomiony-proces-wymaga-restartu/</guid>
      <description>&lt;p&gt;Linux słynie z tego, że nie są wymagane w nim częste restarty całego systemu operacyjnego. Nie ma
przy tym znaczenia czy aktualizujemy jakieś oprogramowanie, czy też wgrywamy nową wersję kernela.
Jeśli by to przenieść na środowisko windowsa, to tam system jest w stanie się automatycznie
zresetować kilka razy tylko podczas samego procesu aktualizacji. Można zatem kwestionować zasadność
twierdzenia, że linux nie wymaga restartu. Może nie koniecznie jesteśmy zmuszeni do dokonania
restartu w danej chwili, tak jak to ma miejsce w przypadku windowsa, ale czy aby na pewno po
instalacji jakichś pakietów w systemie, każdy proces powinien w dalszym ciągu działać bez restartu?
Na to pytanie postaramy się odpowiedzieć w tym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dzielenie i łączenie pliku mp3</title>
      <link>https://morfikov.github.io/post/dzielenie-i-laczenie-pliku-mp3/</link>
      <pubDate>Fri, 13 Nov 2015 13:03:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dzielenie-i-laczenie-pliku-mp3/</guid>
      <description>&lt;p&gt;Każdy z nas odsłuchuje czasem pliki &lt;code&gt;.mp3&lt;/code&gt; . Niekoniecznie musi to być muzyka, np. mogą być to
audycje radiowe, czy też inne materiały audio. W przypadku dłuższych nagrań problematyczne może być
odnalezienie w nich tego kawałka, który akurat chcielibyśmy ponownie odsłuchać. Podobnie sprawa ma
się w przypadku, gdy dany materiał chcemy komuś przesłać. Jeśli ślemy całe nagranie, to musimy dodać
informację od którego momentu zaczyna się coś dziać w tym utworze. Nie prościej wyciąć ten
interesujący nas kawałek i zapisać go w osobnym pliku?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migracja systemu plików ext2 i ext3 na ext4</title>
      <link>https://morfikov.github.io/post/migracja-systemu-plikow-ext2-i-ext3-na-ext4/</link>
      <pubDate>Thu, 12 Nov 2015 14:16:49 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/migracja-systemu-plikow-ext2-i-ext3-na-ext4/</guid>
      <description>&lt;p&gt;Dyski twarde są w stanie pomieścić setki gigabajtów danych. Ilość informacji, które jesteśmy w
stanie przechować na pojedynczym nośniku, rośnie w zastraszającym tempie. Rozwój technologii nie
jest jedynym polem gdzie prowadzone są prace nad nowymi rozwiązaniami poprawiającymi szereg aspektów
pracy tych urządzeń. Innym polem jest sfera programowa, która w przypadków dysków twardych w dużej
mierze dotyczy systemu plików. Albowiem każda powierzchnia, na której mają być przechowywane dane,
potrzebuje odpowiedniej struktury, którą również można usprawnić. Wobec czego, ten domyślny system
plików w linux&#39;ie, tj. &lt;code&gt;ext&lt;/code&gt; , przeszedł szereg modyfikacji i pojawiły się wersje &lt;code&gt;ext2&lt;/code&gt; , &lt;code&gt;ext3&lt;/code&gt; i
&lt;code&gt;ext4&lt;/code&gt; . Jeśli jakaś partycja dysku twardego zawiera starszą wersję systemu plików, powinniśmy
dokonać migracji na jego nowszy odpowiednik. W przypadku migracji z &lt;code&gt;ntfs&lt;/code&gt; na &lt;code&gt;ext4&lt;/code&gt; (czy też
odwrotnie), nieunikniona jest utrata danych. Czy w przypadku migracji z systemu plików &lt;code&gt;ext2&lt;/code&gt; i
&lt;code&gt;ext3&lt;/code&gt; na &lt;code&gt;ext4&lt;/code&gt; również musimy zgrywać wszystkie dane na osobny nośnik by przeformatować
odpowiednio taki dysk czy partycję? Okazuje się że nie musimy i możemy dokonać takiej migracji bez
obaw o utratę danych i w tym wpisie postaramy się ten zabieg przeprowadzić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wyłączyć monitor z linii poleceń</title>
      <link>https://morfikov.github.io/post/jak-wylaczyc-monitor-z-linii-polecen/</link>
      <pubDate>Wed, 11 Nov 2015 22:30:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wylaczyc-monitor-z-linii-polecen/</guid>
      <description>&lt;p&gt;Pewnego niezbyt pamiętnego dnia byłem zmuszony skorzystać z windowsa. Po chwili pracy na nim,
musiałem odejść od komputera na dłuższą chwilę. Chciałem zatem wyłączyć monitor bez jednoczesnego
wyłączania całego komputera, czy przełączania go w stan uśpienia. Problem na jaki się natknąłem był
taki, że kompletnie nie miałem pojęcia jak tego dokonać i ostatecznie zakończyło się to
przyciśnięciem fizycznego przycisku na obudowie monitora. Gdybym tego nie zrobił, monitor by się
wyłączył sam ale dopiero po pewnym czasie, który został określony w opcjach zarządzania energią. Nie
miałem za bardzo czasu i chęci szukać rozwiązania tego problemu ale z tego co widziałem na necie, to
ludzie rozpisywali jakieś tutorale na ten temat, co wydało mi się co najmniej dziwne. Czy w
windowsie nie nie ma żadnej opcji by wyłączyć w prosty sposób monitor? Najwyraźniej nie ma,
przynajmniej ja jej nie znalazłem. Czy my na linux&#39;ie też mamy takie problemy? W tym wpisie
postaramy się odpowiedzieć na pytanie czy jest jakiś prosty sposób by na linux&#39;ie wyłączyć monitor z
wiersza poleceń, tak by efekt był praktycznie natychmiastowy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Osadzanie urxvt na pulpicie przy pomocy openbox&#39;a</title>
      <link>https://morfikov.github.io/post/osadzanie-urxvt-na-pulpicie-przy-pomocy-openboxa/</link>
      <pubDate>Mon, 09 Nov 2015 21:27:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/osadzanie-urxvt-na-pulpicie-przy-pomocy-openboxa/</guid>
      <description>&lt;p&gt;Wszyscy wiemy, że ogromna rzesza ludzi nie patrzy w logi systemowe. Nawet jeśli części z nas zdarza
się to raz na jakiś czas, to zwykle nie wtedy, gdy coś złego się dzieje z naszym systemem. W
przypadku jakichkolwiek problemów, mamy spore prawdopodobieństwo, że szereg zdarzeń może zostać
zalogowanych w dzienniku systemowym. Dlaczego zatem nie osadzić jakiegoś terminala na pulpicie, w
którym będą zbierane logi w czasie rzeczywistym? W takim przypadku co kilka (czy kilkanaście) minut
będziemy w stanie podejrzeć wszystkie komunikaty jakie zostały zalogowane przez system. W tym wpisie
postaramy się osadzić na pulpicie terminal urxvt i posłużymy się w tym celu menadżerem okien openbox
.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kolorowanie wyjścia terminala</title>
      <link>https://morfikov.github.io/post/kolorowanie-wyjscia-terminala/</link>
      <pubDate>Mon, 09 Nov 2015 14:57:01 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kolorowanie-wyjscia-terminala/</guid>
      <description>&lt;p&gt;Każdy terminal jest w stanie wyświetlić tekst w kilku kolorach. Zwykle mamy ich do dyspozycji 8
lub 16. Niektóre terminale potrafią rozróżniać nawet 256 kolorów. Niemniej jednak, kolor całego
tekstu jaki jest wyświetlany w terminalu jest zwykle jednolity i nie ma w nim praktycznie żadnych
urozmaiceń. W taki sposób mamy czarny tekst i białe tło. Jako, że te terminale są w stanie
wyświetlić więcej kolorów, to dla większej czytelności przydałoby się skonfigurować kolorowanie
wyjścia takich narzędzi jak &lt;code&gt;ls&lt;/code&gt; , &lt;code&gt;grep&lt;/code&gt; czy &lt;code&gt;man&lt;/code&gt; . Jesteśmy w stanie pokolorować także szereg
innych rzeczy i o tym będzie ten poniższy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uzupełnianie poleceń w bash (bash completion)</title>
      <link>https://morfikov.github.io/post/uzupelnianie-polecen-w-bash/</link>
      <pubDate>Sat, 07 Nov 2015 16:56:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uzupelnianie-polecen-w-bash/</guid>
      <description>&lt;p&gt;Bash nie nadaje się dla nieco bardziej zaawansowanych użytkowników linux&#39;a. Najbardziej odczuwalnym
elementem bash&#39;a jest brak uzupełniania poleceń za pomocą klawisza Tab . Nie mówimy tutaj o
przeszukiwaniu zmiennej &lt;code&gt;$PATH&lt;/code&gt; pod kątem dopasowań pliku wykonywalnego do tego co wpisujemy
aktualnie w terminalu. Nie chodzi też o uzupełnianiu ścieżek podawanych do &lt;code&gt;cd&lt;/code&gt; ale o opcje, które
jakiś program może przyjąć jako argument. Zwykle musimy się uczyć ich na pamięć lub zaglądać do
help&#39;a czy manuala. Możliwe jest jednak skorzystanie z dodatku zwanego &lt;a href=&#34;https://en.wikipedia.org/wiki/Command-line_completion&#34;&gt;bash
completion&lt;/a&gt;, który w sporej części przypadków
potrafi dostarczyć dość zaawansowane uzupełnianie poleceń, którymi się posługujemy na co dzień. Ten
wpis ma na celu pokazanie jak włączyć ten cały mechanizm i uprościć sobie nieco życie podczas pracy
w terminalu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Plik .bashrc, czyli konfiguracja bash&#39;a</title>
      <link>https://morfikov.github.io/post/plik-bashrc-czyli-konfiguracja-basha/</link>
      <pubDate>Sat, 07 Nov 2015 15:23:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/plik-bashrc-czyli-konfiguracja-basha/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/plik-bash_history-czyli-historia-polecen-basha/&#34;&gt;konfigurację historii bash&#39;a w pliku
.bash_history&lt;/a&gt; ale
możliwości konfiguracyjne bash&#39;a nie ograniczają się jedynie do zmiany kilku parametrów czy
zmiennych dotyczących historii wpisywanych w terminalu poleceń. Ten wpis ma na celu zebranie tych
bardziej użytecznych funkcjonalności bash&#39;a, które często są wykorzystywane przez użytkowników
linux&#39;a i dopisywane w pliku &lt;code&gt;.bashrc&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czyszczenie konsoli TTY w systemd</title>
      <link>https://morfikov.github.io/post/czyszczenie-konsoli-tty-w-systemd/</link>
      <pubDate>Sat, 07 Nov 2015 11:48:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czyszczenie-konsoli-tty-w-systemd/</guid>
      <description>&lt;p&gt;Podczas uruchamiania się systemu, na ekranie zwykle widzimy szereg komunikatów. Informują nas one o
tym jakie usługi są aktywowane oraz czy wystąpiły jakieś błędy. Po tym jak faza boot dobiegnie
końca, wszystkie te informacje dalej są wyświetlane na konsoli TTY i możemy je podejrzeć po
przyciśnięciu klawiszy Ctrl-Alt-F1 . W pewnych sytuacjach może to stwarzać zagrożenie
bezpieczeństwa, bo są tam zawarte informacje o tym jakie usługi zostały uruchomione. Przydałoby się
zatem wyczyścić tę konsolę TTY po załadowaniu się systemu i o tym będzie poniższy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Skrót Ctrl-Alt-Del w systemd</title>
      <link>https://morfikov.github.io/post/skrot-ctrl-alt-del-w-systemd/</link>
      <pubDate>Sat, 07 Nov 2015 10:12:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/skrot-ctrl-alt-del-w-systemd/</guid>
      <description>&lt;p&gt;Po przesiadce z sysvinit na systemd okazało się, że system inaczej się zachowuje po przyciśnięciu
kombinacji klawiszy Ctrl-Alt-Del . Niby za wiele nie zmieniałem w konfiguracji systemu ale w żaden
sposób przy pomocy plików konfiguracyjnych nie szło zmienić zachowania tego powyższego skrótu.
Okazuje się bowiem, że w systemd, akcję pod ten skrót przypisuje się w nieco innym miejscu niż to
było robione w sysvinit. W tym wpisie postaramy się zmienić domyślne zachowanie tego skrótu, tak by
po jego przyciśnięciu wyłączyć komputer.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Plik .bash_history, czyli historia poleceń bash&#39;a</title>
      <link>https://morfikov.github.io/post/plik-bash_history-czyli-historia-polecen-basha/</link>
      <pubDate>Fri, 06 Nov 2015 01:08:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/plik-bash_history-czyli-historia-polecen-basha/</guid>
      <description>&lt;p&gt;Operowanie na linux&#39;ie wiąże się w dużej mierze z wpisywaniem poleceń do terminala. Każdy kto
spędził trochę czasu w tym systemie, wie, że do komfortowej pracy potrzebny jest przyzwoicie
skonfigurowany shell. Domyślnym shell&#39;em w debianie, jak i wielu innych linux&#39;ach, jest bash. Każdy
z nas na początku wpisywał wszystkie polecenia ręcznie i nawet nie wiedział, że istnieje coś takiego
jak uzupełnianie pewnych fraz, czy też nazw, przy pomocy klawisza Tab . Z czasem nasz stopień
poznania jakiejś dystrybucji linux&#39;a osiąga pewien dość zaawansowany poziom i wpisywanie za każdym
razem tych samych poleceń jedynie spowalnia naszą pracę. Dlatego właśnie bash, podobnie jak i inne
shell&#39;e, mają swoje pliki konfiguracyjne, w których to możemy &lt;a href=&#34;https://www.gnu.org/software/bash/manual/bash.html#Shell-Variables&#34;&gt;dostosować naprawdę sporo
rzeczy&lt;/a&gt;. W tym wpisie skupimy
się na historii poleceń, która trafia do pliku &lt;code&gt;.bash_history&lt;/code&gt; w katalogu domowym każdego
użytkownika w systemie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fwknop z obsługą kuczy GPG</title>
      <link>https://morfikov.github.io/post/fwknop-z-obsluga-kuczy-gpg/</link>
      <pubDate>Thu, 05 Nov 2015 20:52:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/fwknop-z-obsluga-kuczy-gpg/</guid>
      <description>&lt;p&gt;Ostatnio opisywałem jak zaimplementować na swoim serwerze &lt;a href=&#34;https://morfikov.github.io
/post/port-knocking-i-single-packet-authorization/&#34;&gt;mechanizm port
knocking&#39;u&lt;/a&gt; , który oparty był
o &lt;a href=&#34;http://www.cipherdyne.org/fwknop/docs/fwknop-tutorial.html&#34;&gt;Single Packet Authorization&lt;/a&gt;. Tamten
wpis dotyczył głównie wykorzystania szyfrów symetrycznych ale istnieje też możliwość skorzystania z
kluczy GPG. W ten sposób uwierzytelnianie oraz szyfrowanie pakietów odbywałoby się przy ich pomocy.
W tym wpisie postaramy się tak skonfigurować narzędzie &lt;code&gt;fwknop&lt;/code&gt; , tak by było ono w stanie
przepuszczać jedynie tych klientów, którzy posługują się kluczami GPG.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Moduł xt_recent i limitowanie połączeń w iptables</title>
      <link>https://morfikov.github.io/post/modul-xt_recent-i-limitowanie-polaczen-w-iptables/</link>
      <pubDate>Thu, 05 Nov 2015 17:17:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-xt_recent-i-limitowanie-polaczen-w-iptables/</guid>
      <description>&lt;p&gt;Kluczową rolę w filtrze iptables pełnią stany połączeń. Zwykle mamy do czynienia z trzema z nich:
NEW, RELATED i ESTABLISHED. Wszystko co nie pasuje do tych stanów, jest traktowane jako INVALID i
tak dla przykładu trafiają tam pakiety mające niemożliwe kombinacje flag, przynajmniej jeśli chodzi
o punkt widzenia poprawnej komunikacji sieciowej (ustawione flagi &lt;code&gt;SYN&lt;/code&gt; i &lt;code&gt;FIN&lt;/code&gt; jednocześnie).
Jednak istnieje szereg pakietów, które mogą potencjalnie zagrażać bezpieczeństwu maszyny i nie są
one uwzględnione w stanie INVALID. Takie pakiety są używane do skanowania portów w celu wykrycia
usług znajdujących się na serwerze. Krótko mówiąc, stan INVALID nie złapie skanów &lt;code&gt;UDP&lt;/code&gt;, &lt;code&gt;ACK&lt;/code&gt; oraz
&lt;code&gt;SYN&lt;/code&gt; . Czy jesteśmy faktycznie bezbronni i nic nie możemy zrobić? Na szczęście iptables ma do
dyspozycji &lt;a href=&#34;http://ipset.netfilter.org/iptables-extensions.man.html&#34;&gt;moduł xt_recent&lt;/a&gt;, który jest w
stanie zablokować wszystkie te powyżej wymienione formy ataków.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Port knocking na przykładzie knockd i iptables</title>
      <link>https://morfikov.github.io/post/port-knocking-na-przykladzie-knockd-i-iptables/</link>
      <pubDate>Thu, 05 Nov 2015 00:26:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/port-knocking-na-przykladzie-knockd-i-iptables/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Port_knocking&#34;&gt;Port knocking&lt;/a&gt; zezwala na zdalny dostęp do usług,
które są chronione za pomocą zapory sieciowej. Generalnie rzecz biorąc, iptables ma blokować
jakikolwiek ruch na porcie, na którym nasłuchuje jakaś demon. Oczywiście tym sposobem żaden klient
nie mógłby nawiązać połączenia z serwerem i tutaj właśnie znajduje zastosowanie &lt;code&gt;knockd&lt;/code&gt; , który
jest w stanie dodawać dynamicznie odpowiednie reguły do filtra iptables. Nawiązywanie połączenia
trwa z reguły bardzo szybko. Po tym jak klient uzyskał dostęp do serwera, te dodane wcześniej reguły
są usuwane blokując tym samym wszelkie nowe próby połączenia ale nie odcinając jednocześnie
ustanowionych już połączeń. Ten wpis ma jedynie na celu zaprezentowanie narzędzia &lt;code&gt;knockd&lt;/code&gt; .
Niemniej jednak, jest ono już przestarzałe i powinno się od niego odchodzić na rzecz &lt;a href=&#34;https://morfikov.github.io
/post/port-knocking-i-single-packet-authorization/&#34;&gt;Single Packet
Authorization, czyli alternatywnego port
knocking&#39;u&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pliki hosts.allow i hosts.deny</title>
      <link>https://morfikov.github.io/post/pliki-hosts-allow-i-hosts-deny/</link>
      <pubDate>Wed, 04 Nov 2015 22:36:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pliki-hosts-allow-i-hosts-deny/</guid>
      <description>&lt;p&gt;Obecnie najpopularniejszym rozwiązaniem pod kątem ograniczania dostępu do usług systemowych jest
zapora sieciowa. Reguły iptables są w tym przypadku wręcz niezastąpione. Jednak poleganie na samych
regułach iptables nie jest zbyt dobrym pomysłem. A to z tego względu, że jeśli &lt;a href=&#34;https://morfikov.github.io
/post/firewall-na-linuxowe-maszyny-klienckie/&#34;&gt;skrypt
firewall&#39;a&lt;/a&gt; z jakiegoś powodu nie
zostanie wywołany przy starcie systemu, to nasza maszyna pozostaje praktycznie bezbronna i będzie
akceptować wszelkie próby połączeń do wszystkich nasłuchujących w takim systemie usług. Na szczęście
nie jest znowu aż tak źle jak mogłoby się wydawać. Albowiem linux posiada dwa pliki
&lt;code&gt;/etc/hosts.allow&lt;/code&gt; i &lt;code&gt;/etc/hosts.deny&lt;/code&gt; , które są w stanie zarządzać dostępem do usług systemowych.
Poniższy wpis będzie poświęcony właśnie tym dwóm plikom.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Port knocking i Single Packet Authorization</title>
      <link>https://morfikov.github.io/post/port-knocking-i-single-packet-authorization/</link>
      <pubDate>Wed, 04 Nov 2015 21:36:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/port-knocking-i-single-packet-authorization/</guid>
      <description>&lt;p&gt;Poniższy wpis ma na celu zaprezentować jak w prosty sposób dozbroić nieco serwer, tak by znajdujące
się na nim usługi były należycie chronione. Zostanie to pokazane na przykładzie SSH, bo chyba każdy
serwer posiada zdalny dostęp przez shell&#39;a i za bardzo nie godzi się by zostawić tę usługę otwartą
na zewnętrzny świat wirtualny bez jakiegokolwiek nadzoru. Postaramy się tutaj wdrożyć &lt;a href=&#34;https://pl.wikipedia.org/wiki/Port_knocking&#34;&gt;port
knocking&lt;/a&gt;, z tym, że nie będziemy wykorzystywać do tego
celu narzędzia &lt;code&gt;knockd&lt;/code&gt; . Skorzystamy za to z
&lt;a href=&#34;http://www.cipherdyne.org/fwknop/docs/fwknop-tutorial.html&#34;&gt;fwknop&lt;/a&gt; , który eliminuje szereg wad
występujących w leciwym już &lt;code&gt;knockd&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migawka (snapshot) repozytorium debiana</title>
      <link>https://morfikov.github.io/post/migawka-snapshot-repozytorium-debiana/</link>
      <pubDate>Wed, 04 Nov 2015 18:23:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/migawka-snapshot-repozytorium-debiana/</guid>
      <description>&lt;p&gt;Aktualizacje systemu niosą ze sobą nowsze wersje pakietów. Czasami mają one błędy, które wychodzą na
jaw po jakimś czasie korzystania z danej aplikacji. W takiej sytuacji zwykle zachodzi potrzeba
cofnięcia wersji kilku pakietów. Jest jednak wielce prawdopodobne, że akurat tej wersji pakietu,
której potrzebujemy, nie znajdziemy z repozytorium debiana. Pobieranie pojedynczych pakietów z
internetu przez klikanie w pierwszy lepszy link, który zostanie nam zwrócony przez wyszukiwarkę, nie
jest dobrym pomysłem. Na szczęście w przypadku debiana nie musimy się aż tak narażać. A to z tego
względu, że &lt;a href=&#34;http://snapshot.debian.org/archive/debian/&#34;&gt;debian robi migawki (shapshots) swoich
repozytoriów&lt;/a&gt; 4 razy dziennie (co 6 godzin). W ten
sposób mamy dostęp do różnych stanów repozytoriów, w tym też tych, które zawierają pakiety
aktualnie niedostępne w repozytoriach. W tym wpisie postaramy się pobrać i zainstalować
nieistniejące pakiety z takich snapshot&#39;ów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ostatnio używane pliki (recently-used.xbel)</title>
      <link>https://morfikov.github.io/post/ostatnio-uzywane-pliki-recently-used-xbel/</link>
      <pubDate>Mon, 02 Nov 2015 23:54:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ostatnio-uzywane-pliki-recently-used-xbel/</guid>
      <description>&lt;p&gt;Wielu ludzi nie lubi gdy maszyny monitorują każdy ich krok. W tym przypadku chodzi o pliki, które
otwieramy czy zmieniamy podczas codziennej pracy na komputerze. Nasz system domyślnie tworzy listę i
skrupulatnie dodaje do niej nowe pozycje. Ta lista jest przechowywana w pliku &lt;code&gt;recently-used.xbel&lt;/code&gt; ,
który znajduje się w katalogu &lt;code&gt;~/.local/share/&lt;/code&gt; . Gdy popatrzymy na tę funkcjonalność trochę pod
inny kątem, możemy zauważyć, że w pewnych sytuacjach zagraża ona naszej prywatności. Skasowanie tego
pliku nie rozwiązuje problemu, bo jest on tworzony na nowo, a nadawanie atrybutu odporności (
&lt;code&gt;chattr +i&lt;/code&gt; ) nie jest żadnym rozwiązaniem. Na szczęście jest sposób na to by ten mechanizm
dezaktywować i o tym będzie poniższy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zrzut ekranu konsoli TTY (fbcat)</title>
      <link>https://morfikov.github.io/post/zrzut-ekranu-konsoli-tty-fbcat/</link>
      <pubDate>Mon, 02 Nov 2015 21:14:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zrzut-ekranu-konsoli-tty-fbcat/</guid>
      <description>&lt;p&gt;W przypadku, gdy dzieją się dziwne rzeczy z naszym linux&#39;em i ten zaczyna sypać niezrozumiałymi dla
nas błędami, to zawsze możemy takie zachowanie uwiecznić na zrzucie ekranu. Co jednak w przypadku,
gdy nawali nam środowisko graficzne i nie będziemy mieli jak zrobić zrzutu? Przecie takie aplikacje
jak &lt;code&gt;scrot&lt;/code&gt; czy też &lt;code&gt;shutter&lt;/code&gt; działają w oparciu o Xserver i bez niego nie zrobią fotki naszego
desktop&#39;a. Zwykle gdy zmuszeni jesteśmy ratować nasz system, robimy to w konsoli TTY. No chyba, że
sprawa jest poważniejsza, wtedy sięgamy po &lt;a href=&#34;https://morfikov.github.io
/post/wlasny-system-live-i-tworzenie-go-od-podstaw/&#34;&gt;system
live&lt;/a&gt; . Logi systemowe czy też
aplikacji mogą okazać się pomocne ale przecie &amp;quot;fotka jest warta więcej niż tysiąc słów&amp;quot;. Jak zatem
zrobić zrzut ekranu mając do dyspozycji jedynie tekstową konsolę TTY? Czy jest to w ogóle możliwe?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja multiarch w dystrybucji Debian</title>
      <link>https://morfikov.github.io/post/konfiguracja-multiarch-na-debianie/</link>
      <pubDate>Mon, 02 Nov 2015 20:20:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-multiarch-na-debianie/</guid>
      <description>&lt;p&gt;Posiadając nowszej klasy procesor, jesteśmy w stanie korzystać z 64 bitowego systemu operacyjnego. W
przypadku windowsów uruchamianie aplikacji 32 czy 64 bitowych nie stanowi większego problemu. W na
debianie sprawa wygląda nieco inaczej. Gdy mamy wgranego 64 bitowego debiana, aplikacje 32 bitowe
nie będą chciały się nam odpalić. Wszystkiemu winne są biblioteki 32 bitowe, które są wykorzystywane
przez dany program, a bez nich on zwyczajnie nie może działać. Jednym z rozwiązań tego problemu może
być &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-kontenerow-lxc/&#34;&gt;kontener LXC&lt;/a&gt;, gdzie jesteśmy w stanie
zainstalować 32 bitowy system wewnątrz środowiska 64 bitowego i to z tego systemu możemy uruchamiać
32 bitowe aplikacje. Skonfigurowanie takiego kontenera może być nieco skomplikowane, dlatego też
dużo lepszym rozwiązaniem jest przerobienie naszego 64 bitowego systemu na
&lt;a href=&#34;https://wiki.debian.org/Multiarch&#34;&gt;muliarch&lt;/a&gt;, czyli taki, który jest w stanie obsługiwać wiele
architektur (multiarch).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Manualna weryfikacja pakietu deb w debianie</title>
      <link>https://morfikov.github.io/post/manualna-weryfikacja-pakietu-deb-w-debianie/</link>
      <pubDate>Mon, 02 Nov 2015 00:16:03 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/manualna-weryfikacja-pakietu-deb-w-debianie/</guid>
      <description>&lt;p&gt;W dobie całego tego świata informatycznego zwykliśmy polegać na osobach, których nigdy w życiu na
oczy nie wiedzieliśmy, nie wspominając o jakimkolwiek kontakcie fizycznym. Zaufanie to obecnie chyba
najbardziej krytyczna luka bezpieczeństwa jeśli chodzi o oprogramowanie, z którego korzystamy na co
dzień. My, którzy używamy debiana w swojej pracy, polegamy na mechanizmach jakie oferuje nam &lt;code&gt;apt&lt;/code&gt;
czy &lt;code&gt;aptitude&lt;/code&gt; przy &lt;a href=&#34;https://wiki.debian.org/SecureApt&#34;&gt;weryfikacji pakietów przed ich instalacją&lt;/a&gt; w
systemie. Co się jednak by stało gdyby w tych menadżerach pojawił się błąd, który by uniemożliwiał
poprawną weryfikację pakietów? Skąd wiemy czy te mechanizmy zabezpieczające w ogóle działają? Może
one nam dają jedynie fałszywe poczucie bezpieczeństwa, a tak naprawdę przez niczym nas nie chronią?
W tym wpisie postaramy się odpowiedzieć na te powyższe pytania i sprawdzimy czy manualna weryfikacja
pakietu jest w ogóle możliwa&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klucze do repozytoriów debiana (trusted.gpg)</title>
      <link>https://morfikov.github.io/post/klucze-do-repozytoriow-debiana-trusted-gpg/</link>
      <pubDate>Sun, 01 Nov 2015 19:14:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/klucze-do-repozytoriow-debiana-trusted-gpg/</guid>
      <description>&lt;p&gt;Obecnie systemy operacyjne stają się nieco bardziej stabilne i czasy, w których reinstalacja
takiego systemu, czy też nawet format dysku, odchodzą powoli w niebyt. &lt;a href=&#34;https://morfikov.github.io
/post/dokladna-data-instalacji-systemu-linux/&#34;&gt;Data instalacji mojego
linux&#39;a&lt;/a&gt; wskazuje na prawie 2 lata wstecz. Jakby nie patrzeć jest to szmat czasu, w czasie
którego przez mojego Debiana przetoczyła się ogromna ilość oprogramowania. Nie zawsze były to
pakiety, które pochodziły z głównych repozytoriów tej dystrybucji. Niemniej jednak, każde
repozytorium z pakietami jest podpisane i by móc z nich bezpiecznie korzystać, trzeba pozyskać
&lt;a href=&#34;https://pl.wikipedia.org/wiki/GNU_Privacy_Guard&#34;&gt;klucz GPG&lt;/a&gt; i dokonać jego weryfikacji. Prędzej czy później przyjdzie czas, gdy takie klucze GPG
przestaną być ważne lub też zmianie ulegną źródła pakietów. W ten sposób baza danych kluczy
zawierać będzie szereg zbędnych pozycji. Może wielu ludziom nie przeszkadza ten fakt ale raz na
jakiś czas przydałoby się oczyścić keyring ze śmieci, które są już nam do niczego niepotrzebne.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Szyfrowanie dźwięku przesyłanego przez sieć</title>
      <link>https://morfikov.github.io/post/szyfrowanie-dzwieku-przesylanego-przez-siec/</link>
      <pubDate>Sun, 01 Nov 2015 00:31:48 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/szyfrowanie-dzwieku-przesylanego-przez-siec/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.freedesktop.org/wiki/Software/PulseAudio/&#34;&gt;PulseAudio to serwer dźwięku&lt;/a&gt;, który jest w
stanie otrzymywać zapytania ze zdalnych lokalizacji. Wobec czego, możemy realizować &lt;a href=&#34;https://morfikov.github.io
/post/pulseaudio-i-przesylanie-dzwieku-przez-siec/&#34;&gt;przesyłanie
dźwięku przez sieć&lt;/a&gt; i usłyszeć
go tam, gdzie go sobie życzymy. Problem w tym, że taki dźwięk jest przesyłany przez sieć w formie
niezaszyfrowanej. Dlatego też jesteśmy narażeni na podsłuchanie wszystkiego co mówimy do mikrofonu
lub też tego co pojawia się w naszych głośnikach. Możemy jednak zabezpieczyć komunikację między
klientem i serwerem dźwięku wykorzystując do tego połączenie SSH. W ten sposób cały sygnał
dźwiękowy, jaki jest generowany przez danego hosta w sieci, zostanie wrzucony w szyfrowany kanał
TLS i nikt nie będzie w stanie go zinterpretować. Ten wpis ma na celu przedstawienie sposobu na
zaszyfrowanie dźwięku, bez którego większość z nas nie wyobraża sobie pacy przy komputerze.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PulseAudio i przesyłanie dźwięku przez sieć</title>
      <link>https://morfikov.github.io/post/pulseaudio-i-przesylanie-dzwieku-przez-siec/</link>
      <pubDate>Sat, 31 Oct 2015 22:53:43 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pulseaudio-i-przesylanie-dzwieku-przez-siec/</guid>
      <description>&lt;p&gt;Bardzo wielu ludzi nie uświadamia sobie faktu, że w przypadku komputerów praktycznie wszystkie dane,
z którymi mamy styczność, są zapisane za pomocą dwóch znaków, tj. 0 i 1. Mając to na względzie, nie
ma chyba informacji, której by nie można było przesłać przez sieć. Serwer dźwięku, jak sama nazwa
wskazuje, jest w stanie odbierać dane zawierają informacje dźwiękowe. Dlatego też jeśli jakiś
komputer nie posiada karty muzycznej lub/i nie jest fizycznie podłączony do głośników, to nie
stanowi to większego problemu by był on w stanie odtwarzać dźwięk, przynajmniej w tym sensie jakim
my to rozumiemy. W tym wpisie sþróbujemy zrealizować przesyłanie dźwięku przez sieć wykorzystując do
tego &lt;a href=&#34;https://www.freedesktop.org/wiki/Software/PulseAudio/&#34;&gt;PulseAudio&lt;/a&gt; i zobaczymy czy sprawi nam
to jakieś problemy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Szyfrowanie ruchu do Xserver&#39;a przy pomocy SSH</title>
      <link>https://morfikov.github.io/post/szyfrowanie-ruchu-do-xservera-przy-pomocy-ssh/</link>
      <pubDate>Sat, 31 Oct 2015 16:47:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/szyfrowanie-ruchu-do-xservera-przy-pomocy-ssh/</guid>
      <description>&lt;p&gt;W przypadku zaufanych sieci lokalnych, czy też &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-kontenerow-lxc/&#34;&gt;kontenerów
LXC&lt;/a&gt;, nie musimy zbytnio się troszczyć o
bezpieczeństwo przesyłanych danych. Nikt nam przecież nie założy tutaj podsłuchu. Dlatego też we
wpisie poświęconym konfiguracji Wine nie szyfrowaliśmy praktycznie żadnego ruchu sieciowego. Gdyby
jednak zaszła potrzeba przesłania pakietów do zdalnego Xserver&#39;a przez internet, to takie
rozwiązanie naraziłoby nas na przechwycenie wszystkich danych. By zabezpieczyć się przed tego typu
scenariuszem możemy zaszyfrować ruch do Xserver&#39;a &lt;a href=&#34;https://help.ubuntu.com/community/SSH/OpenSSH/PortForwarding&#34;&gt;forward&#39;ując wszystkie zapytania przy pomocy
szyfrowanego tunelu TLS&lt;/a&gt;. Możemy to
zrobić przy pomocy SSH i w tym wpisie postaramy się skonfigurować ten mechanizm.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Xauth i xhost na straży bezpieczeństwa Xserver&#39;a</title>
      <link>https://morfikov.github.io/post/xauth-i-xhost-na-strazy-bezpieczenstwa-xservera/</link>
      <pubDate>Fri, 30 Oct 2015 23:45:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/xauth-i-xhost-na-strazy-bezpieczenstwa-xservera/</guid>
      <description>&lt;p&gt;Na debianie Xserver domyślnie ma wyłączoną możliwość nasłuchiwania połączeń zdalnych. Chodzi
oczywiście o kwestie bezpieczeństwa, bo przecie nie od dziś wiadomo, że akurat to oprogramowanie
jest dziurawe jak sito i nikt rozsądny nie chciałby instalować go na swoim serwerze. Należałoby
jednak rozgraniczyć wykorzystywanie podatności jakiegoś oprogramowania od możliwości wejścia z nim w
interakcję. Jakby nie patrzeć, sam Xserver posiada co najmniej trzy mechanizmy ochrony, a do tego
dochodzą jeszcze reguły &lt;code&gt;iptables&lt;/code&gt; , czy też pliki &lt;code&gt;/etc/hosts.allow&lt;/code&gt; i &lt;code&gt;/etc/hosts.deny&lt;/code&gt; .
Prawdopodobnie jest ich jeszcze kilka ale te najczęściej wykorzystywane mechanizmy gdy pojawia się
słowo Xserver, to &lt;code&gt;-nolisten tcp&lt;/code&gt; (domyślnie aktywowany), &lt;code&gt;xhost&lt;/code&gt; oraz &lt;code&gt;xauth&lt;/code&gt; . Pierwszy z nich
wyklucza się z pozostałymi i to tym dwóm ostatnim przyjrzymy bliżej w tym wpisie.&lt;/p&gt;
&lt;p&gt;Mechanizmy &lt;code&gt;xhost&lt;/code&gt; oraz &lt;code&gt;xauth&lt;/code&gt; w żaden sposób nie zabezpieczają informacji przesyłanych do
Xserver&#39;a. Wobec czego, całą komunikację można bez problemu podsłuchać. Stwarza to zagrożenie
przechwycenia nie tylko obrazu wyświetlanego na monitorze ale także danych dotyczących myszy i
przyciskanych klawiszy na klawiaturze.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wine w kontenerze LXC</title>
      <link>https://morfikov.github.io/post/wine-w-kontenerze-lxc/</link>
      <pubDate>Fri, 30 Oct 2015 17:13:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wine-w-kontenerze-lxc/</guid>
      <description>&lt;p&gt;Każdy kto zmienił architekturę systemu z i386 na amd64 raczej nie dostrzegł większej różnicy w
operowaniu na którejś z nich. Czasem jedynie pakiety w nazwie mają 64 zamiast 32. Jest natomiast
jedna rzecz, która drażni chyba każdego. Mowa tutaj o &lt;a href=&#34;https://www.winehq.org/&#34;&gt;projekcie Wine&lt;/a&gt;.
Wine nie umie obsługiwać natywnie serwera dźwięku PulseAudio. Do tego dochodzi jeszcze problem,
który związany jest z tymi wszystkimi pakietami 32 bitowymi, które trzeba zainstalować. I w ten
sposób nasz system staje się bardziej multiarch niż amd64. W tym wpisie postaramy się przy pomocy
kontenera LXC odizolować Wine od całej reszty systemu operacyjnego, tak by nie musieć wgrywać do
niego całej masy zbędnych bibliotek.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja kontenerów LXC</title>
      <link>https://morfikov.github.io/post/konfiguracja-kontenerow-lxc/</link>
      <pubDate>Thu, 29 Oct 2015 23:27:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-kontenerow-lxc/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://wiki.debian.org/LXC&#34;&gt;Kontenery LXC&lt;/a&gt; mają za zadanie odizolować poszczególne usługi od
pozostałej części systemu. LXC jest podobny nieco do maszyn wirtualnych, np. tych tworzonych przez
VirtualBox. Niemniej jednak, oba mechanizmy różnią się trochę. Zasadnicza różnica między nimi polega
na tym, że LXC wykorzystuje &lt;a href=&#34;https://morfikov.github.io
/post/przygotowanie-srodowiska-chroot-do-pracy/&#34;&gt;środowisko
chroot&lt;/a&gt; , w którym współdzielone
jest jądro operacyjne. Nie trzeba także z góry określać zasobów pod działanie takiego kontenera, tak
jak to ma w przypadku maszyn wirtualnych. Rzućmy zatem okiem jak wygląda konfiguracja takich
kontenerów na linux&#39;ie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Więcej niż jeden profil w Firefox&#39;ie</title>
      <link>https://morfikov.github.io/post/wiecej-niz-jeden-profil-w-firefoxie/</link>
      <pubDate>Thu, 29 Oct 2015 16:50:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wiecej-niz-jeden-profil-w-firefoxie/</guid>
      <description>&lt;p&gt;Ogromna większość ludzi korzysta z jednego profilu swojej przeglądarki internetowej. Niesie to ze
sobą spore zagrożenie bezpieczeństwa jak i może godzić w naszą prywatność. Jeśli dzielimy z kimś
komputer, to raczej wszyscy domownicy posiadają osobne konta w systemie, a co z tym się wiąże, inny
profil przeglądarki. I na tym zwykle podział się kończy ale przecie to nie wszystko. Profil, jak
sama nazwa wskazuje, jest w stanie dostosować opcje przeglądarki, np. pod kątem pewnych aktywności.
W tym wpisie postaramy się utworzyć kilka profili w Firefox&#39;ie i sprawdzimy korzystanie z nich
będzie odczuwalne w jakiś sposób dla przeciętnego użytkownika internetu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aktywacja i konfiguracja klawisza SysRq</title>
      <link>https://morfikov.github.io/post/aktywacja-i-konfiguracja-klawisza-sysrq/</link>
      <pubDate>Thu, 29 Oct 2015 01:57:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aktywacja-i-konfiguracja-klawisza-sysrq/</guid>
      <description>&lt;p&gt;SysRq (System Request) to klawisz na klawiaturze, po którego przyciśnięciu można wysłać
niskopoziomowe zapytana bezpośrednio do kernela linux&#39;a. Te komendy działają nawet w przypadku
pozornego braku kontaktu z systemem operacyjnym, tj. zacięcia dźwięku, nieruchomy kursor myszy, a
nawet w przypadku braku możliwości wpisywania znaków z klawiatury. Zwykle po opisanych wyżej
symptomach, człowiek jest skłonny przycisnąć przycisk reset na obudowie swojego komputera, no bo jak
inaczej odwiesić taki system? Problem z twardym resetem (za pomocą przycisku) jest taki, że
praktycznie zawsze po nim występuje uszkodzenie struktury systemu plików na dysku, a czasami
uszkodzeniu ulega cała partycja. To niesie ze sobą ryzyko utraty danych. Dlatego też powinniśmy
zaprzestać resetowania komputerów przy pomocy przycisków i zacząć korzystać z klawisza SysRq .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatyczny restart maszyny po kernel panic</title>
      <link>https://morfikov.github.io/post/automatyczny-restart-maszyny-po-kernel-panic/</link>
      <pubDate>Wed, 28 Oct 2015 23:56:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/automatyczny-restart-maszyny-po-kernel-panic/</guid>
      <description>&lt;p&gt;Gdy nasz linux napotka z jakiegoś powodu błąd wewnątrz swojej struktury, to istnieją sytuacje, w
których obsługa tego błędu czasem nie jest możliwa. Wobec czego, zostaje wyrzucony komunikat
systemowy oznajmiający nam, że &lt;a href=&#34;https://pl.wikipedia.org/wiki/Kernel_panic&#34;&gt;kernel spanikował (kernel
panic)&lt;/a&gt;, bo nie wie co w takim przypadku zrobić. Gdy
tego typu sytuacja się nam przytrafia, nie ma innego wyjścia jak tylko uruchomić system ponownie. Co
jednak w przypadku gdy pracujemy zdalnie i nie jesteśmy w stanie zresetować takiej maszyny
fizycznie? Na szczęście kernel ma kilka opcji, które mogą zainicjować automatyczny restart w
przypadku wystąpienia kernel panic.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja wtyczki flash na linux&#39;ie (mms.cfg)</title>
      <link>https://morfikov.github.io/post/konfiguracja-wtyczki-flash-na-linuxie-mms-cfg/</link>
      <pubDate>Wed, 28 Oct 2015 21:21:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-wtyczki-flash-na-linuxie-mms-cfg/</guid>
      <description>&lt;p&gt;W obecnych czasach powoli się odchodzi od stosowania technologi flash w przeglądarkach. Na dobra
sprawę, po tym jak google w youtube przesiadł się na html5, to korzystanie z flash player&#39;a nie ma
już większego sensu. Są jednak serwisy, które nie nadążają za zmieniającą się rzeczywistością i w
ich przypadku przejście z flash&#39;a na html5 może jeszcze zająć kilka lat. Zatem nawet jeśli nie
korzystamy z flash&#39;a na co dzień, to i tak większość z nas będzie chciała go mieć w systemie, tak na
wszelki wypadek, by nie być pozbawionym możliwości oglądania materiałów video na tych drugorzędnych
serwisach. Jako, że wtyczka flash jest bardzo dziurawa, przydałoby się ją nieco skonfigurować i w
tym wpisie zostanie przedstawionych szereg opcji, które można umieścić w pliku &lt;code&gt;mms.cfg&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Usuwanie wpisów z about:config w Firefox&#39;ie</title>
      <link>https://morfikov.github.io/post/usuwanie-wpisow-z-aboutconfig-w-firefoxie/</link>
      <pubDate>Tue, 27 Oct 2015 20:58:39 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/usuwanie-wpisow-z-aboutconfig-w-firefoxie/</guid>
      <description>&lt;p&gt;Po wpisaniu w pasku adresu Firefox&#39;a &lt;a href=&#34;http://kb.mozillazine.org/About:config&#34;&gt;about:config&lt;/a&gt; ,
zostanie nam zwrócona dość długa lista parametrów konfiguracyjnych, które możemy sobie dostosować
wedle uznania. Większość z nich ma spory wpływ na zachowanie samej przeglądarki ale są też i opcje,
które zostały dodane za sprawą różnych dodatków. Chodzi o to, że za każdym razem gdy instalujemy
nowy addon, to ten zwykle ma opcje konfiguracyjne i to właśnie one są widoczne w &lt;code&gt;about:config&lt;/code&gt; . W
przypadku gdy już nie korzystamy z tego dodatku i wyrzuciliśmy go kompletnie z Firefox&#39;a, wpisy w
konfiguracji dalej widnieją. Przydałoby się zatem nieco przeczyścić naszą przeglądarkę i usunąć te
wszystkie śmieci.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pliki .torrent i magnet linki w Firefox&#39;ie</title>
      <link>https://morfikov.github.io/post/pliki-torrent-i-magnet-linki-w-firefoxie/</link>
      <pubDate>Tue, 27 Oct 2015 20:02:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pliki-torrent-i-magnet-linki-w-firefoxie/</guid>
      <description>&lt;p&gt;Przeglądarki mają to do siebie, że każda z nich korzysta z własnych ustawień dotyczących &lt;a href=&#34;https://pl.wikipedia.org/wiki/Typ_MIME&#34;&gt;typów MIME
(mime type)&lt;/a&gt;. Do tego dochodzi jeszcze fakt, że często te
ustawienia są inne od tych, które mamy w systemie. Może to nie jest jakiś wielki problem, bo w
opcjach Firefox&#39;a możemy bez trudu szereg rzeczy poprzestawiać. Natomiast jest jeden problem,
którego w prosty sposób się obejść nie da i trzeba się trochę na nim pochylić. Chodzi o dodawanie
nowych typów MIME, które nie są pokazane na liście obsługiwanych typów w Preferences -&amp;gt;
Applications. Wiąże się z tym tak skonfigurowanie przeglądarki, by automatycznie otworzyła ona jakiś
program ilekroć dany typ pliku będzie pobierany.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mechanizm SYN cookies w protokole TCP</title>
      <link>https://morfikov.github.io/post/mechanizm-syn-cookies-w-protokole-tcp/</link>
      <pubDate>Sat, 24 Oct 2015 20:22:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mechanizm-syn-cookies-w-protokole-tcp/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/SYN_flood&#34;&gt;Atak SYN flood&lt;/a&gt; to rodzaj ataku DoS, którego celem jest
wyczerpanie zasobów serwera uniemożliwiając mu tym samym poprawne realizowanie danej usługi, do
której został oddelegowany. Jest to dość popularne zjawisko i w przypadku, gdy mamy postawioną
jakąś maszynę na publicznym adresie IP, przydałoby się nieco zainteresować tym problem, który może
wystąpić w najmniej oczekiwanym momencie. W tym wpisie rzucimy okiem na mechanizm SYN cookies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Unikanie ataków DDoS z SYNproxy</title>
      <link>https://morfikov.github.io/post/unikanie-atakow-ddos-z-synproxy/</link>
      <pubDate>Sat, 24 Oct 2015 17:39:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/unikanie-atakow-ddos-z-synproxy/</guid>
      <description>&lt;p&gt;Internet nie jest zbyt przyjaznym miejscem i jest wielce prawdopodobne, że prędzej czy później ktoś
zaatakuje jedną z naszych maszyn, która świadczy w nim jakieś usługi. Są różne typy ataków, w tym
przypadku chodzi o ataki DDoS z wykorzystaniem pakietów wchodzących w proces potrójnego witania
(three way handshake) przy nawiązywaniu połączenia w protokole TCP, tj. pakiety &lt;code&gt;SYN&lt;/code&gt; , &lt;code&gt;SYN-ACK&lt;/code&gt; i
&lt;code&gt;ACK&lt;/code&gt; . Istnieje szereg mechanizmów, które adresują problem SYN flooding&#39;u ale żaden z nich nie jest
doskonały. Jakiś czas temu, do kernela linux&#39;owego trafił patch implementujący &lt;a href=&#34;https://lwn.net/Articles/563151/&#34;&gt;mechanizm
SYNproxy&lt;/a&gt; i w tym wpisie obadamy go sobie nieco dokładniej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Moduł kernela i wartości jego parametrów</title>
      <link>https://morfikov.github.io/post/modul-kernela-i-wartosci-jego-parametrow/</link>
      <pubDate>Fri, 23 Oct 2015 19:35:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-kernela-i-wartosci-jego-parametrow/</guid>
      <description>&lt;p&gt;Raczej na pewno spotkaliśmy się już z modułami kernela w linux&#39;ie. Generalnie rzecz biorąc, taki
moduł może być ładowany dynamicznie i w sporej części przypadków niezależnie, choć z zwykle jest
pociągany przy zdarzeniach udev&#39;a. Czasem jednak, dany moduł nie działa jak należy i może to być
wynikiem, np. problemów w samym module, lub też jego niewłaściwej konfiguracji, która konfliktuje z
podzespołami naszego komputera. Ten wpis będzie dotyczył tego jak ustalić parametry modułów i ich
domyślne wartości, tak by móc je sobie zmienić w późniejszym czasie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pobieranie pakietów przy pomocy cron-apt</title>
      <link>https://morfikov.github.io/post/pobieranie-pakietow-przy-pomocy-cron-apt/</link>
      <pubDate>Fri, 23 Oct 2015 14:42:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pobieranie-pakietow-przy-pomocy-cron-apt/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem konfigurację dla menadżera pakietów &lt;code&gt;apt&lt;/code&gt; i &lt;code&gt;aptitude&lt;/code&gt; &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-apt-i-aptitude-w-pliku-apt-conf/&#34;&gt;w pliku
apt.conf&lt;/a&gt; . Ten wpis również
tyczy się konfiguracji wspomnianych menadżerów, z tym, że zostanie tutaj opisana pewna
funkcjonalność, która może nam zaoszczędzić trochę czasu przy aktualizacji systemu. Chodzi o to,
że pakiety praktycznie zawsze muszą być pobrane na dysk przed ich instalacją. Gdy nie dysponujemy
dobrym pod względem przepustowości łączem, proces pobierania pakietów jest zwykle dłuższy niż sama
ich instalacja. Przydałoby się zatem zaprogramować pobieranie plików w tle, tak by nie musieć ich
pobierać tuż przez przed procesem instalacyjnym.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Reinstalacja kernela i bootloader&#39;a</title>
      <link>https://morfikov.github.io/post/reinstalacja-kernela-bootloadera/</link>
      <pubDate>Thu, 22 Oct 2015 18:41:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/reinstalacja-kernela-bootloadera/</guid>
      <description>&lt;p&gt;Wykorzystywanie pełnego szyfrowania dysku twardego ma jedną zasadniczą wadę. O ile nasze dane są
należycie zabezpieczone, o tyle trzeba zwracać uwagę na to komu zezwalamy na dostęp do naszego
komputera. Nie chodzi tutaj o to, kto będzie używał samego systemu operacyjnego, choć to też jest
ważne, ale przede wszystkim chodzi o te osoby, które mają dostęp fizyczny do naszej maszyny. Czasem
możemy nabrać podejrzenia, że ktoś mógł nam jakąś pluskwę podłożyć. Wykrycie takiego robala, np. w
postaci sprzętowego keylogger&#39;a, nie powinno sprawić problemów. Z kolei już manipulacja boot
sektorem dysku twardego, lub też zmiany w initramfs, który znajduje się na niezaszyfrowanej partycji
&lt;code&gt;/boot/&lt;/code&gt; mogą przejść niezauważone. Jak zatem odratować system, co do którego mamy jakieś
zastrzeżenia?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Montowanie katalogu /tmp/ jako tmpfs</title>
      <link>https://morfikov.github.io/post/montowanie-katalogu-tmp-jako-tmpfs/</link>
      <pubDate>Wed, 21 Oct 2015 22:19:14 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/montowanie-katalogu-tmp-jako-tmpfs/</guid>
      <description>&lt;p&gt;Linux jest w stanie operować na wielu systemach plików, np. ext4, ntfs, fat. Większość z nich odnosi
się do dysków twardych, czy też innych urządzeń przechowujących spore ilości danych. Problem z tego
typu systemami plików jest taki, że operacje na plikach w ich obrębie, jak i same pliki, zostawiają
ślady. Dlatego też jeśli musimy tymczasowo skopiować plik zawierający tajne dane, lub też taki plik
poddać obróbce, nie powinniśmy go umieszczać bezpośrednio na dysku. No chyba, że wykorzystujemy
pełne szyfrowanie. Inną opcją (i o wiele prostszą w implementacji) jest przeznaczenie części
pamięci operacyjnej RAM pod &lt;a href=&#34;https://wiki.archlinux.org/index.php/Tmpfs&#34;&gt;system plików tmpfs&lt;/a&gt; i o
tym będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dropbox i kontener LUKS</title>
      <link>https://morfikov.github.io/post/dropbox-i-kontener-luks/</link>
      <pubDate>Wed, 21 Oct 2015 20:34:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dropbox-i-kontener-luks/</guid>
      <description>&lt;p&gt;Ogarnęliśmy już szyfrowanie plików na dropbox&#39;ie przy pomocy
&lt;a href=&#34;https://morfikov.github.io
/post/implementacja-encfs-na-dropboxie/&#34;&gt;encfs&lt;/a&gt; oraz &lt;a href=&#34;https://morfikov.github.io
/post/kontener-truecrypt-trzymany-na-dropboxie/&#34;&gt;kontenerów
TrueCrypt&lt;/a&gt;. Każda z w/w operacji
drastycznie poprawiła prywatność naszych plików, które przechowujemy w chmurze. Poniższy wpis będzie
w podobnym klimacie, tj. spróbujemy umieścić na dropbox&#39;ie &lt;a href=&#34;https://pl.wikipedia.org/wiki/Linux_Unified_Key_Setup&#34;&gt;kontener
LUKS&lt;/a&gt;, co niesie ze sobą sporo udogodnień i
czyni korzystanie z zaszyfrowanego dropbox&#39;a praktycznie transparentnym.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kontener TrueCrypt trzymany na dropbox&#39;ie</title>
      <link>https://morfikov.github.io/post/kontener-truecrypt-trzymany-na-dropboxie/</link>
      <pubDate>Tue, 20 Oct 2015 18:27:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kontener-truecrypt-trzymany-na-dropboxie/</guid>
      <description>&lt;p&gt;Żyjemy w czasach, w których mobilność jest tak samo ważna albo może i ważniejsza (dla niektórych
ludzi na pewno) jak i bezpieczeństwo i poufność danych. Użyteczność zwykle nie idzie w patrze z
bezpieczeństwem, bo im prostszy jest dla nas dostęp do danych, tym bardziej zagraża ich
bezpieczeństwu. W tym przypadku chcielibyśmy mieć możliwość dostępu do plików, np. naszego domowego
PC, z dowolnego miejsca na ziemi. Czy można w prosty i w miarę bezpieczny sposób coś takiego
osiągnąć? &lt;a href=&#34;https://morfikov.github.io
/post/implementacja-encfs-na-dropboxie/&#34;&gt;Jakiś czas temu opisywałem implementację encfs na
dropbox&#39;ie&lt;/a&gt;, w tym artykule zostanie zaś
opisane sprzęgnięcie dropbox&#39;a z kontenerem TrueCrypt.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przejście z Truecrypt na LUKS</title>
      <link>https://morfikov.github.io/post/przejscie-z-truecrypt-na-luks/</link>
      <pubDate>Tue, 20 Oct 2015 09:58:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przejscie-z-truecrypt-na-luks/</guid>
      <description>&lt;p&gt;Jakiś czas temu, można było usłyszeć, że TrueCrypt nie dba wcale o bezpieczeństwo danych
zaszyfrowanych za jego pomocą. &lt;a href=&#34;http://istruecryptauditedyet.com/&#34;&gt;Audyt bezpieczeństwa&lt;/a&gt; jednak nie
wykazał większych podatności w tym oprogramowaniu. &lt;a href=&#34;https://madiba.encs.concordia.ca/~x_decarn/truecrypt-binaries-analysis/&#34;&gt;Analiza
binarek&lt;/a&gt; dostępnych na
stronie TrueCrypt&#39;a pod kątem &lt;a href=&#34;https://wiki.debian.org/ReproducibleBuilds&#34;&gt;Reproducible Builds&lt;/a&gt;
również nie wykazała większych odchyłów w stosunku do binarek generowanych prosto z kodu
źródłowego. Problematyczne może być jednak to, że tak naprawdę nie wiadomo kto stoi za tym całym
projektem, przynajmniej gdy był jeszcze rozwijany. Cała sytuacja zamknięcia TrueCrypt&#39;a z sieci była
też co najmniej dziwna. W obliczu takich niewiadomych, powinniśmy rozważyć przejście na natywne
rozwiązania linux&#39;owe, które są jawnie rozwijane, wiadomo kto za nimi stoi i, co najważniejsze, mają
wsparcie w samym kernelu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja encfs na dropbox&#39;ie</title>
      <link>https://morfikov.github.io/post/implementacja-encfs-na-dropboxie/</link>
      <pubDate>Mon, 19 Oct 2015 23:11:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-encfs-na-dropboxie/</guid>
      <description>&lt;p&gt;Jako, że ostatnio &lt;a href=&#34;https://morfikov.github.io
/post/szyfrowanie-katalogu-home-przy-pomocy-encfs/&#34;&gt;zaszyfrowaliśmy katalog domowy przy pomocy
encfs&lt;/a&gt; , to nie sposób sobie
nie zadać pytania czy tego typu mechanizm może działać w oparciu o serwisy online takie jak, np.
&lt;a href=&#34;https://www.dropbox.com/&#34;&gt;dropbox&lt;/a&gt;. Chodzi o to, że dropbox umożliwia synchronizację plików w
czasie rzeczywistym, co może być problematyczne, gdy w grę wchodzi szyfrowanie danych. Wszelkie inne
rozwiązania na bazie &lt;a href=&#34;https://pl.wikipedia.org/wiki/Linux_Unified_Key_Setup&#34;&gt;LUKS&lt;/a&gt; są mało
praktyczne w tym przypadku. Natomiast synchronizowanie pojedynczych plików zaszyfrowanych przy
pomocy &lt;code&gt;encfs&lt;/code&gt; zapowiada się obiecująco.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zaszyfrowana przestrzeń wymiany SWAP</title>
      <link>https://morfikov.github.io/post/zaszyfrowana-przestrzen-wymiany-swap/</link>
      <pubDate>Mon, 19 Oct 2015 22:32:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zaszyfrowana-przestrzen-wymiany-swap/</guid>
      <description>&lt;p&gt;Opisując mechanizm szyfrowania katalogu domowego przy pomocy &lt;a href=&#34;https://morfikov.github.io
/post/szyfrowanie-katalogu-home-przy-pomocy-encfs/&#34;&gt;narzędzia
encfs&lt;/a&gt; , wspomniałem o
problemie jaki powstaje przy jednoczesnym braku szyfrowania przestrzeni wymiany SWAP. Oczywiście,
jeśli posiadamy w systemie dużą ilość pamięci RAM, to raczej nie potrzebna nam jest przestrzeń
wymiany. Podobnie sprawa ma się w przypadku, gdy nie korzystamy z hibernacji. Natomiast, jeśli jedna
z naszych partycji jest sformatowana jako SWAP i aktywnie z niej korzystamy, to niepełne szyfrowanie
dysku, jakie zapewnia &lt;code&gt;encfs&lt;/code&gt; może doprowadzić do skompromitowania zaszyfrowanych danych.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Szyfrowanie katalogu /home/ przy pomocy encfs</title>
      <link>https://morfikov.github.io/post/szyfrowanie-katalogu-home-przy-pomocy-encfs/</link>
      <pubDate>Mon, 19 Oct 2015 21:54:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/szyfrowanie-katalogu-home-przy-pomocy-encfs/</guid>
      <description>&lt;p&gt;Wielu ludzi uważa, że szyfrowanie całego dysku jest zbędne i pozbawione większego sensu, no bo
przecie &amp;quot;system nie zawiera żadnych wrażliwych danych, które by wymagały szyfrowania&amp;quot;. Nie będę się
tutaj spierał co do tego punktu widzenia, bo raczej wszyscy znają moje zdanie na temat &amp;quot;danych
wymagających szyfrowania&amp;quot; i skupię się tu raczej na tym jak troszeczkę podratować niepełne
szyfrowanie, które ludzie, nie wiedząc czemu, są bardziej skłonni stosować, niż cały ten full disk
encryption.&lt;/p&gt;
&lt;p&gt;Narzędzie &lt;code&gt;encfs&lt;/code&gt; nie przeszło pomyślnie &lt;a href=&#34;https://defuse.ca/audits/encfs.htm&#34;&gt;audytu bezpieczeństwa&lt;/a&gt;
, a to z takiego powodu, że projekt nie był rozwijany przez szereg lat. &lt;a href=&#34;https://github.com/vgough/encfs&#34;&gt;Obecnie jest on w rekach
społeczności&lt;/a&gt; i to od niej będzie zależeć czy te wykryte błędy
zostaną poprawione.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zabezpieczenie konta root przy pomocy pam-usb</title>
      <link>https://morfikov.github.io/post/zabezpieczenie-konta-root-przy-pomocy-pam-usb/</link>
      <pubDate>Mon, 19 Oct 2015 21:01:03 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zabezpieczenie-konta-root-przy-pomocy-pam-usb/</guid>
      <description>&lt;p&gt;Jakiś czas temu natknąłem się na moduł &lt;code&gt;pam-usb&lt;/code&gt; , który to w dość ciekawy sposób zabezpiecza dostęp
do konta użytkownika root. &lt;a href=&#34;https://wiki.debian.org/pamusb&#34;&gt;Cały mechanizm opiera się o pendrive&lt;/a&gt;,
którego to unikalne cechy są brane pod uwagę przy uwierzytelnianiu podczas logowania się na konto
super użytkownika, czyli min. gdy wydajemy polecenie &lt;code&gt;su&lt;/code&gt; albo &lt;code&gt;sudo&lt;/code&gt; . Jest to o tyle ciekawa
rzecz, że konto użytkownika root możne stać się niewrażliwe na próby złamania hasła w przypadku
połączenia sieciowego. Jak by nie patrzeć, atakujący, który łączy się zdalnie, nie jest w stanie
podłączyć do naszego komputera żadnego fizycznego urządzenia, w wyniku czego nigdy nie uzyska
dostępu do konta administratora.&lt;/p&gt;
&lt;p&gt;Pakiet &lt;code&gt;libpam-usb&lt;/code&gt; wyleciał z debiana jakiś czas temu. &lt;a href=&#34;https://tracker.debian.org/news/686153&#34;&gt;Powodem
były&lt;/a&gt; zależności, które wskazywały na przestarzały już
pakiet &lt;code&gt;udisks&lt;/code&gt; . Poza tym, nikt nie zajmował się tym pakietem. Obecnie jest on dostępny jedynie w
starszych wydaniach debiana.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konwersja napisów w kontenerze MP4</title>
      <link>https://morfikov.github.io/post/konwersja-napisow-w-kontenerze-mp4/</link>
      <pubDate>Mon, 19 Oct 2015 19:31:49 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konwersja-napisow-w-kontenerze-mp4/</guid>
      <description>&lt;p&gt;Podczas ogarniania kolekcji filmów i przerabiania jej w taki sposób by został nam tylko jeden plik,
tj. &lt;a href=&#34;https://morfikov.github.io
/post/kontener-multimedialny-mkv/&#34;&gt;kontener MKV&lt;/a&gt;, możemy czasem napotkać
problemy, które mogą nam uniemożliwić to zadanie. Może się zdarzyć tak, że będziemy mieli do
czynienia z innymi kontenerami niż MKV, np. MP4. Ten wpis będzie poświęcony właśnie tego rodzaju
kontenerom.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kontener multimedialny MKV</title>
      <link>https://morfikov.github.io/post/kontener-multimedialny-mkv/</link>
      <pubDate>Mon, 19 Oct 2015 19:29:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kontener-multimedialny-mkv/</guid>
      <description>&lt;p&gt;Wiele osób posiada pliki video i ci co uczą się angielskiego, czy innych języków, niezbyt przepadają
za słuchaniem polskiego lektora na filmach, bo zagłusza on przecie całą oryginalną ścieżkę audio.
Poza tym, jakość tłumaczenia jest na żenująco niskim poziomie. Z samego słuchu człowiek ciężko się
uczy, zwłaszcza jak zaczyna naukę nowego języka, dlatego też można sobie dociągnąć polskie napisy.
Co jednak w przypadku, gdy chcemy mieć kilka ścieżek audio czy napisów w jednym filmie? Posiadanie
wielu plików wprowadza trochę zamętu. Poniżej zostanie opisany sposób na ogarnięcie kolekcji
filmowej, tak by został nam się tylko jeden plik w przypadku każdego ulubionego przez nas filmu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja apt i aptitude w pliku apt.conf</title>
      <link>https://morfikov.github.io/post/konfiguracja-apt-i-aptitude-w-pliku-apt-conf/</link>
      <pubDate>Sun, 18 Oct 2015 20:04:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-apt-i-aptitude-w-pliku-apt-conf/</guid>
      <description>&lt;p&gt;Praktycznie każdy z nas korzysta z menadżera pakietów &lt;code&gt;apt&lt;/code&gt; lub też jego nakładki &lt;code&gt;aptitude&lt;/code&gt; .
Operowanie na debianie bez tych narzędzi raczej by nam nieco utrudniło życie. Sporo osób ogranicza
się jedynie do podstawowych poleceń, typu &lt;code&gt;update&lt;/code&gt; , &lt;code&gt;upgrade&lt;/code&gt; czy &lt;code&gt;dist-upgrade&lt;/code&gt; , pomijając przy
tym całą konfigurację w/w narzędzi. W tym wpisie zostanie zaprezentowanych szereg opcji, które można
zdefiniować na stałe w pliku konfiguracyjnym &lt;code&gt;/etc/apt/apt.conf&lt;/code&gt; , tak by nie trzeba było ich ciągle
wpisywać w terminalu ilekroć tylko korzystamy któregoś menadżera pakietów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Usuwanie środowiska graficznego</title>
      <link>https://morfikov.github.io/post/usuwanie-srodowiska-graficznego/</link>
      <pubDate>Sun, 18 Oct 2015 17:52:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/usuwanie-srodowiska-graficznego/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=27813&#34;&gt;Na forum DUG&#39;a&lt;/a&gt; znów został poruszony ciekawy
wątek, tym razem odnośnie usunięcia całego środowiska graficznego z systemu. Pozornie niby nic
nadzwyczajnego, przecie każdy z nas potrafi odinstalować szereg pakietów via &lt;code&gt;apt&lt;/code&gt; czy &lt;code&gt;aptitude&lt;/code&gt; .
Problematyczne za to mogą się okazać zależne pakiety, które nie zostaną automatycznie usunięte wraz
z konkretnym metapakietem od środowiska graficznego. Jak zatem usunąć te pozostałości?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Oczyszczanie bazy danych dconf</title>
      <link>https://morfikov.github.io/post/oczyszczanie-bazy-danych-dconf/</link>
      <pubDate>Sat, 17 Oct 2015 18:00:43 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/oczyszczanie-bazy-danych-dconf/</guid>
      <description>&lt;p&gt;Jak możemy przeczytać &lt;a href=&#34;https://wiki.gnome.org/action/show/Projects/dconf&#34;&gt;na wiki projektu GNOME&lt;/a&gt; ,
&lt;code&gt;dconf&lt;/code&gt; to swojego rodzaju baza danych, która zawiera informacje o konfiguracji systemu w postaci
klucz-wartość. Jak nie korzystam, co prawda, ze środowisk graficznych ale wykorzystuję w swoim
linux&#39;ie szereg ich elementów, które mogą działać z powodzeniem w okrojonym systemie, np.
&lt;code&gt;gnome-keyring&lt;/code&gt; . Część programów wykorzystuje tę bazę danych do przechowywania swoich ustawień,
które możemy zmieniać via &lt;code&gt;gsettings&lt;/code&gt; , &lt;code&gt;gconf&lt;/code&gt; lub też &lt;code&gt;dconf&lt;/code&gt; . Problem pojawia się po dłuższym
czasie używania systemu, gdzie cześć z ustawień jest już przestarzała, np. w wyniku zaprzestania
użytkowania jakiejś aplikacji. Przydałoby się zatem raz na jakiś czas oczyścić te bazę danych ze
zbędnych wpisów i o tym będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Serwer kluczy GPG i kwestia prywatności</title>
      <link>https://morfikov.github.io/post/serwer-kluczy-gpg-i-kwestia-prywatnosci/</link>
      <pubDate>Fri, 16 Oct 2015 18:59:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/serwer-kluczy-gpg-i-kwestia-prywatnosci/</guid>
      <description>&lt;p&gt;Czytając sobie artykuł na temat &lt;a href=&#34;https://trac.torproject.org/projects/tor/wiki/doc/TorifyHOWTO/GnuPG&#34;&gt;TORyfikacji zapytań do serwerów kluczy
GPG&lt;/a&gt;, pomyślałem, że w sumie
mógłbym zreprodukować przedstawione tam kroki dotyczące implementacji tego rozwiązania na windowsie
i wdrożyć je na linux&#39;ie. Chodzi generalnie o to, by serwer kluczy GPG nie był odpytywany
bezpośrednio przy szukaniu/przesyłaniu kluczy przez sieć, bo to może identyfikować nas, jak i grupę
ludzi, która się z nami komunikuje. Jakby nie patrzeć, klucze GPG składają się z dość newralgicznych
informacji, typu imię, nazwisko czy adres email, a serwer kluczy GPG tych danych w żaden sposób nie
zabezpiecza i są one zwykle przesyłane otwartym tekstem przez sieć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Brak dźwięku przy nieaktywnej sesji logowania</title>
      <link>https://morfikov.github.io/post/brak-dzwieku-przy-nieaktywnej-sesji-logowania/</link>
      <pubDate>Thu, 15 Oct 2015 20:52:50 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/brak-dzwieku-przy-nieaktywnej-sesji-logowania/</guid>
      <description>&lt;p&gt;Jeśli korzystamy z &lt;a href=&#34;https://www.freedesktop.org/wiki/Software/PulseAudio/&#34;&gt;serwera dźwięku
PulseAudio&lt;/a&gt; na swoim linux&#39;ie, prawdopodobnie
zdarzyła nam się już sytuacja, w której chcieliśmy zablokować lub wygasić ekran monitora mając
jednocześnie odpalony jakiś odtwarzacz muzyki. Gdy tylko ekran zostanie zablokowany, możemy
odnotować brak dźwięku, bo ten zwyczajnie natychmiast zamiera. Za to po odblokowaniu ekranu, dźwięk
wraca. Podobnie sprawa ma się przy przejściu z trybu graficznego (Xorg) na jedną z konsol TTY.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja połączenia WiFi pod debianem</title>
      <link>https://morfikov.github.io/post/konfiguracja-polaczenia-wifi-pod-debianem/</link>
      <pubDate>Thu, 15 Oct 2015 19:32:48 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-polaczenia-wifi-pod-debianem/</guid>
      <description>&lt;p&gt;Sieci bezprzewodowe w obecnych czasach to standard i nie ma chyba miejsca na ziemi gdzie nie dałoby
rady ulokować routera WiFi, do którego można by podłączyć szereg urządzeń. Każdy kto próbował
konfigurować sieć bezprzewodową na debianie, wie, że może to być bardzo upierdliwe, zwłaszcza jeśli
mamy dostęp do wielu AP, które posiadają różne konfiguracje. Wynaleziono, co prawda, automaty, które
mają pomagać w ogarnięciu tego całego bezprzewodowego zamieszania, np. &lt;code&gt;network-manager&lt;/code&gt; czy &lt;code&gt;wicd&lt;/code&gt;
ale w przypadku lekkich stacji roboczych, które nie mają wgranego pełnego środowiska graficznego, a
jedynie jakiś menadżer okien, np. Openbox, to instalacja tych powyższych narzędzi może zwyczajnie
nie wchodzić w grę.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmienna TZ w środowisku linux&#39;owym</title>
      <link>https://morfikov.github.io/post/zmienna-tz-w-srodowisku-linuxowym/</link>
      <pubDate>Thu, 15 Oct 2015 17:02:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmienna-tz-w-srodowisku-linuxowym/</guid>
      <description>&lt;p&gt;Ten wpis będzie poświęcony poprawie wydajności naszych systemów linux&#39;owych. Okazuje się bowiem, że
w pewnych aspektach ich pracy &lt;a href=&#34;http://www.brendangregg.com/blog/2014-05-11/strace-wow-much-syscall.html&#34;&gt;nie wszystko działa jak
należy&lt;/a&gt;. Rozchodzi się o
zmienną środowiskową &lt;code&gt;TZ&lt;/code&gt; , w oparciu o którą to zwracane są, np. czasy utworzenia czy modyfikacji
plików na dysku. Ten przypadek jest o tyle dziwny, że każdy z nas ma już na swojej maszynie
skonfigurowany czas systemowy, za który odpowiada pakiet &lt;code&gt;tzdata&lt;/code&gt; . Niby wyraźnie określiliśmy
strefę czasową, w tym przypadku jest to &lt;code&gt;Europe/Warsaw&lt;/code&gt; ale widać system operacyjny posiłkuje się
odwołaniami do pliku &lt;code&gt;/etc/localtime&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Baza danych użytkowników serwera freeradius</title>
      <link>https://morfikov.github.io/post/baza-danych-uzytkownikow-serwera-freeradius/</link>
      <pubDate>Tue, 13 Oct 2015 19:31:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/baza-danych-uzytkownikow-serwera-freeradius/</guid>
      <description>&lt;p&gt;Poprzedni wpis był o sieciach bezprzewodowych, a konkretnie dotyczył on &lt;a href=&#34;https://morfikov.github.io
/post/wpa2-enterprise-serwer-freeradius/&#34;&gt;konfiguracji protokołu WPA
Enterprise w oparciu o serwer
freeradius&lt;/a&gt;. Ten post będzie w podobnym
klimacie, z tym, że skupimy się tutaj na nieco innym podejściu to kwestii użytkowników, którzy mogą
się łączyć do sieci WiFi. Ich konfiguracja nie zostanie praktycznie w żaden sposób ruszona, no może
za wyjątkiem &lt;a href=&#34;http://wiki.freeradius.org/guide/SQL-HOWTO&#34;&gt;przeniesienia jej do bazy danych MySQL&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WPA/WPA2 Enterprise i serwer freeradius</title>
      <link>https://morfikov.github.io/post/wpa2-enterprise-serwer-freeradius/</link>
      <pubDate>Tue, 13 Oct 2015 18:42:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wpa2-enterprise-serwer-freeradius/</guid>
      <description>&lt;p&gt;Poniższy wpis ma na celu stworzenie infrastruktury WiFi w oparciu o oprogramowanie freeradius
zainstalowane na debianowym serwerze. Projekt zakłada wykorzystanie osobnego urządzenia NAS (AP), w
tym przypadku jest to router &lt;a href=&#34;http://wiki.openwrt.org/toh/tp-link/tl-wr1043nd&#34;&gt;TP-Link TL-WR1043N/ND
v2&lt;/a&gt;, na którym jest zainstalowane oprogramowanie
OpenWRT. W oparciu o te dwie maszyny spróbujemy skonfigurować protokół WPA2 Enterprise z obsługą
trzech metod uwierzytelniania, tj. EAP-TLS, EAP-TTLS oraz PEAP (v0) . Będziemy również potrzebować
kilku certyfikatów (w tym CA), bez których to pewne mechanizmy mogą nie działać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Generowanie certyfikatów przy pomocy easy-rsa</title>
      <link>https://morfikov.github.io/post/generowanie-certyfikatow-przy-pomocy-easy-rsa/</link>
      <pubDate>Thu, 08 Oct 2015 14:29:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/generowanie-certyfikatow-przy-pomocy-easy-rsa/</guid>
      <description>&lt;p&gt;Jakiś czas temu przedstawiłem &lt;a href=&#34;https://morfikov.github.io
/post/generowanie-certyfikatow/&#34;&gt;manualny sposób na generowanie
certyfikatów&lt;/a&gt;, które można z powodzeniem
wykorzystać przy ssl, openvpn czy freeradius. Nie było tego znowu aż tak dużo ale jakby nie patrzeć
trochę parametrów trzeba znać, a najlepiej mieć przygotowane odpowiednie linijki, by sam proces
generowania certyfikatów przebiegł dość sprawnie. Jednak wychodzi na to, że nie trzeba się znowu aż
tak wysilać, bo istnieją dedykowane narzędzia, które wygenerują nam wszystkie potrzebne pliki. Mowa
o &lt;code&gt;easy-rsa&lt;/code&gt; i to niego będzie dotyczył ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zaszyfrowane logi w rsyslog i syslog-ng</title>
      <link>https://morfikov.github.io/post/zaszyfrowane-logi-w-rsyslog-i-syslog-ng/</link>
      <pubDate>Thu, 08 Oct 2015 13:53:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zaszyfrowane-logi-w-rsyslog-i-syslog-ng/</guid>
      <description>&lt;p&gt;Jakiś czas temu, na forum DUG&#39;a wyczytałem coś o przesyłaniu logów systemowych przez sieć. W sumie,
to nigdy mi to do głowy nie przyszło ale jeśli by się nad tym głębiej zastanowić, tego typu
mechanizm może okazać się całkiem użyteczny. Na dobrą sprawę nie wiem jak to jest rozwiązane w
debianie opartym o systemd, natomiast jeśli chodzi o inne init&#39;y (openrc i sysvinit), to tego typu
funkcjonalność można zaimplementować wykorzystując narzędzie &lt;code&gt;rsyslog&lt;/code&gt; lub &lt;code&gt;syslog-ng&lt;/code&gt; . W tym
wpisie zostanie opisana konfiguracja debianowego serwera, na którym będzie nasłuchiwał daemon
&lt;code&gt;rsyslog&lt;/code&gt; . Dodatkowo, zostanie przedstawiona konfiguracja dwóch klientów, z których jeden będzie
miał zainstalowanego &lt;code&gt;syslog-ng&lt;/code&gt; , a drugi &lt;code&gt;rsyslog&lt;/code&gt; . Z klientów logi zostaną przesłane do serwera.
Dodatkowo, postaramy się &lt;a href=&#34;http://www.rsyslog.com/doc/v8-stable/tutorials/tls_cert_summary.html&#34;&gt;zaszyfrować ruch przy pomocy kanału
TLS&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aktualizacja systemu i logowanie komunikatów</title>
      <link>https://morfikov.github.io/post/aktualizacja-systemu-logowanie-komunikatow/</link>
      <pubDate>Thu, 08 Oct 2015 12:39:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aktualizacja-systemu-logowanie-komunikatow/</guid>
      <description>&lt;p&gt;Aktualizacja systemu to chyba jedna z bardziej podstawowych czynności, które przeprowadzamy niemalże
codziennie. Tak się złożyło, że chwilę po zakończeniu tego procesu musiałem wyłączyć w pośpiechu
komputer. Nie zdążyłem przy tym przeczytać uważnie informacji, które zwrócił mi terminal. Oczywiście
mógłbym zahibernować maszynę i wrócić do logu instalacji w wolnej chwili ale nie zawsze hibernacja
jest możliwa. Poza tym, na myśl przychodzą mi osoby, które często zakładają wątki na forach o tym,
że aktualizacja uwaliła ich system. Zawsze w takiej sytuacji prosi się danego człowieka o podanie
logu z aktualizacji systemu albo przynajmniej próbuje się wyciągnąć od takiego delikwenta informację
na temat tego co było aktualizowane. W większości przypadków, taki człowiek nie ma o tym kompletnie
pojęcia, a jak już, to podaje bardzo nieprecyzyjne dane. Ten post ma na celu ułatwienie znalezienia
informacji o tym co było przedmiotem aktualizacji, tak by mieć nieco jaśniejszy obraz tego co mogło
nawalić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tworzenie repozytorium przy pomocy reprepro</title>
      <link>https://morfikov.github.io/post/tworzenie-repozytorium-przy-pomocy-reprepro/</link>
      <pubDate>Wed, 07 Oct 2015 17:37:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/tworzenie-repozytorium-przy-pomocy-reprepro/</guid>
      <description>&lt;p&gt;Ten kto tworzył kiedyś paczki &lt;code&gt;.deb&lt;/code&gt; wie, że cały proces może w końcu człowieka nieco przytłoczyć.
Paczka, jak to paczka, budowana jest ze źródeł i konfigurowana przez jej opiekuna. Z reguły ludzie
instalują kompilowane programy via &lt;code&gt;make install&lt;/code&gt; . Niektórzy idą o krok dalej i używają do tego
celu narzędzi typu &lt;code&gt;checkinstall&lt;/code&gt; . I wszystko jest w miarę w porządku, przynajmniej jeśli chodzi o
utrzymywanie jednej paczki. Przeprowadzamy kompilację tylko raz, po czym instalujemy dany pakiet i
zapominamy o nim. Niemniej jednak, tego typu postępowanie może doprowadzić nasz system na skraj
niestabilności. W tym poście nie będziemy zajmować się zbytnio sposobem w jaki powinno się tworzyć
paczki &lt;code&gt;.deb&lt;/code&gt; , a jedynie tym jak je przechowywać. Do tego celu potrzebne jest nam repozytorium,
które zbudujemy w oparciu o oprogramowanie &lt;code&gt;reprepro&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Parametr readahead w dyskach twardych</title>
      <link>https://morfikov.github.io/post/parametr-readahead-w-dyskach-twardych/</link>
      <pubDate>Wed, 07 Oct 2015 15:45:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/parametr-readahead-w-dyskach-twardych/</guid>
      <description>&lt;p&gt;W celu optymalizacji swojej pracy i poprawy wydajności przy transferze danych, dyski twarde często
odczytują więcej sektorów niż było to określone w żądaniu. Chodzi o to, że odczytywany przez nas z
dysku plik jest podzielony na sektory i gdy dysk odczytuje pierwszy sektor tego pliku, to wczytuje
także kilka kolejnych sektorów zlokalizowanych za tym, którego żądanie odczytania zostało właśnie
zrealizowane. Te dodatkowe sektory trafiają do wewnętrznego cache dysku twardego, z którego mogą
zostać odczytane w późniejszym czasie, jeśli zajdzie taka potrzeba. Dostęp do danych w cache jest o
wiele szybszy w porównaniu do repozycjonownia głowicy i odczytywania fizycznych sektorów na dysku. W
efekcie czego mamy zwykle dość znaczny wzrost wydajności przy transferze danych. Ten mechanizm nosi
nazwę &lt;strong&gt;readahead&lt;/strong&gt; i w tym wpisie przyjrzymy mu się nieco bliżej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Parametr multcount w dyskach twardych</title>
      <link>https://morfikov.github.io/post/parametr-multcount-w-dyskach-twardych/</link>
      <pubDate>Tue, 06 Oct 2015 21:57:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/parametr-multcount-w-dyskach-twardych/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://manpages.ubuntu.com/manpages/xenial/pl/man8/hdparm.8.html&#34;&gt;W manualu hdparm&lt;/a&gt; możemy
przeczytać o opcji &lt;code&gt;-m&lt;/code&gt; , która szerzej jest znana jako &lt;strong&gt;multcount&lt;/strong&gt;. Obecnie praktycznie każdy
dysk w większym lub mniejszym stopniu ma zaimplementowaną jej obsługę, tj. wartość tego parametru
różni się i zwykle im większą, tym lepiej dysk powinien się sprawować. Nie wszystkie dyski mają tę
opcję włączoną standardowo. Na przykład te z rodziny WDC, jak czytamy w dokumentacji, są znane z
tego, że działają wolniej po jej ustawieniu. Jako, że mam dysk firmy Western Digital, to
postanowiłem sprawdzić jak, o ile w ogóle, zmieni się wydajność takiego urządzenia po przestawieniu
tego parametru.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Karta dźwiękowa w trybie powersave</title>
      <link>https://morfikov.github.io/post/karta-dzwiekowa-w-trybie-powersave/</link>
      <pubDate>Tue, 06 Oct 2015 10:47:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/karta-dzwiekowa-w-trybie-powersave/</guid>
      <description>&lt;p&gt;Kilka dni temu, &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?pid=291349&#34;&gt;na forum DUG&#39;a&lt;/a&gt;, jeden z
użytkowników miał problem z dźwiękiem. Udało się tę niedogodność wprawdzie poprawić ale został tam
poruszony temat trybu powersave, czyli oszczędzania energii, jaki może posiadać karta dźwiękowa. Na
dobrą sprawę, nigdy mi nawet do głowy nie przyszło, by te karty mogły przełączać sobie stan i zjadać
mniej prądu, tak jak to robią, np. karty WiFi. Oczywiście, postanowiłem zgłębić to zagadnienie i
ustalić na ile przydatna jest ta funkcja i czy da radę bez problemów słuchać muzyki lub oglądać
filmy po jej aktywowaniu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Generowanie certyfikatów</title>
      <link>https://morfikov.github.io/post/generowanie-certyfikatow/</link>
      <pubDate>Sun, 04 Oct 2015 18:11:50 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/generowanie-certyfikatow/</guid>
      <description>&lt;p&gt;Certyfikaty mogą zostać wykorzystane wszędzie tam, gdzie mamy do czynienia z protokołami
szyfrującymi ruch. Zwykle są to serwisy hostujące strony www ale też mogą to być i inne usługi, np.
OpenVPN. Można je także spotkać w sieciach bezprzewodowych gdzie wykorzystywany jest protokół
WPA2-Enterprise. Jeśli operujemy na linux&#39;ie, to prawdopodobnie spotkaliśmy się już z
oprogramowaniem, które wykorzystuje certyfikaty, np. serwer &lt;code&gt;apache2&lt;/code&gt; . Dobrze jest sobie zatem
przyswoić wiedzę na temat generowania certyfikatów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wyłączenie WOL w karcie sieciowej</title>
      <link>https://morfikov.github.io/post/wylaczenie-wol-w-karcie-sieciowej/</link>
      <pubDate>Sun, 04 Oct 2015 16:36:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wylaczenie-wol-w-karcie-sieciowej/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Wake_on_LAN&#34;&gt;WOL&lt;/a&gt; (Wake On LAN) to taki ficzer, który umożliwia
włączenie komputera przez sieć. By tego typu sytuacja miała miejsce, zarówno karta sieciowa oraz
płyta główna komputera musi wspierać WOL. Dodatkowo, BIOS maszyny musi mieć aktywowaną odpowiednią
opcję. Obecnie WOL jest implementowany praktycznie w każdej płycie głównej i karcie sieciowej, także
raczej możemy przyjąć, że nasz komputer może zostać wybudzony za pomocą kabla sieciowego. Stwarza to
oczywiście zagrożenie bezpieczeństwa ale poza tym, w grę wchodzi także większy pobór energii. Jeśli
nie korzystamy z WOL, to jest on dla nas zbędny i należałoby go wyłączyć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Normalizacja głośności w PulseAudio</title>
      <link>https://morfikov.github.io/post/normalizacja-glosnosci-w-pulseaudio/</link>
      <pubDate>Mon, 28 Sep 2015 16:13:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/normalizacja-glosnosci-w-pulseaudio/</guid>
      <description>&lt;p&gt;Każdy z nas spotkał się z sytuacją, gdzie dźwięki odtwarzane na naszych maszynach zmieniają swoje
natężenie w krótkich odstępach czasu, a my przy tym odczuwamy bardzo nieprzyjemne uczucie
dyskomfortu psychicznego. Tego typu efekt jest też bardzo często spotykany przy oglądaniu filmów,
gdzie zwykle muzyka jest sporo głośniejsza od samych dialogów, nie wspominając już o reklamach,
którymi filmy są przerywane. Innym przykładem mogą być mp3, gdzie jedna z nich jest grana zbyt
cicho, natomiast kolejna zbyt głośno. PulseAudio jest w stanie poradzić sobie z tego typu
problemami.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Użytkownik debian-sys-maint w MariaDB</title>
      <link>https://morfikov.github.io/post/uzytkownik-debian-sys-maint-w-mariadb/</link>
      <pubDate>Sun, 27 Sep 2015 15:10:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uzytkownik-debian-sys-maint-w-mariadb/</guid>
      <description>&lt;p&gt;Właśnie robiłem migrację z MySQL ma MariaDB na swoim debianie. Nie obyło się jednak bez problemów,
choć na dobrą sprawę serwer baz danych działał i na pierwszy rzut oka nic złego nie szło
zaobserwować. Dopiero po zajrzeniu w log okazało się, że są jakieś problemy z uprawnieniami, w
efekcie czego nie mogła być przeprowadzona akcja aktualizacji tabel.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Retransmisja i duplikaty pakietów w TCP</title>
      <link>https://morfikov.github.io/post/retransmisja-i-duplikaty-pakietow-w-tcp/</link>
      <pubDate>Wed, 23 Sep 2015 19:31:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/retransmisja-i-duplikaty-pakietow-w-tcp/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Retransmisja&#34;&gt;Retransmisja&lt;/a&gt; pakietu w przypadku sieci opartych na
protokołach TCP/IP nie jest niczym niezwykłym. Oczywiście, pozostaje kwestia samego realizowania
tego przedsięwzięcia ale generalnie rzecz biorąc, systemy linux&#39;owe mają szereg opcji w kernelu,
które możemy sobie dostosować konfigurując tym samym, to w jaki sposób nasz system reaguje na
zjawisko utraty pakietów podczas ich przesyłu między dwoma punktami sieciowymi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zawartość obrazu z modułami kernela (initrd)</title>
      <link>https://morfikov.github.io/post/zawartosc-obrazu-z-modulami-kernela-initrd/</link>
      <pubDate>Sun, 06 Sep 2015 12:45:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zawartosc-obrazu-z-modulami-kernela-initrd/</guid>
      <description>&lt;p&gt;Podczas instalowania jądra operacyjnego w jakiejś dystrybucji linux&#39;a, w katalogu &lt;code&gt;/boot/&lt;/code&gt; jest
tworzonych kilka plików. Mamy tam między innymi
&lt;a href=&#34;https://www.ibm.com/developerworks/linux/library/l-initrd/index.html&#34;&gt;initrd.img&lt;/a&gt; i jest to obraz
posiadający swój własny system plików, który jest ładowany do pamięci RAM w fazie boot (via
bootloader). W tym obrazie znajdują się moduły i narzędzia, przy pomocy których to główny system
plików naszego linux&#39;a może zostać zamontowany. Czasem jednak potrzebujemy zajrzeć wgłąb tego
obrazu, a to nie jest znowu taka prosta sprawa.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aplikowanie zmiennych sysctl przy pomocy udev&#39;a</title>
      <link>https://morfikov.github.io/post/aplikowanie-zmiennych-sysctl-przy-pomocy-udeva/</link>
      <pubDate>Sun, 06 Sep 2015 11:08:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aplikowanie-zmiennych-sysctl-przy-pomocy-udeva/</guid>
      <description>&lt;p&gt;Kernele linux&#39;owe mają dość sporo opcji, które możemy zmienić przy pomocy pliku &lt;code&gt;/etc/sysctl.conf&lt;/code&gt; .
Niby nic nadzwyczajnego ale co w przypadku tych zmiennych, które muszą być ustawione, z tym, że
moduł, który stworzy odpowiednie ścieżki w katalogu &lt;code&gt;/proc/sys/&lt;/code&gt; , nie został załadowany z jakichś
względów przy starcie systemu? Zmienne te nie zostaną ustawione, a w logu pojawi się komunikat
informujący nas o nieodnalezieniu określonego pliku. Okazuje się, że jesteśmy w stanie aplikować
określone ustawienia sysctl w momencie ładowania określonych modułów i temu mechanizmowi się
przyjrzymy bliżej w tym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Moduł ssl w Apache2</title>
      <link>https://morfikov.github.io/post/modul-ssl-w-apache/</link>
      <pubDate>Sat, 05 Sep 2015 18:10:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-ssl-w-apache/</guid>
      <description>&lt;p&gt;Przy okazji uszczelniania serwera Apache2, przypomniał mi się &lt;a href=&#34;https://morfikov.github.io
/post/logjam-czyli-nowa-podatnosc-w-ssltls/&#34;&gt;atak
logjam&lt;/a&gt; , przez który to było niemałe
zamieszanie. Pamiętam, że w tamtym czasie próbowałem zabezpieczyć swój serwer testowy, by był na tę
formę ataku odporny. Niemniej jednak, wersja Apache2, która w tamtym czasie była u mnie
zainstalowana, nie do końca dawała taką możliwość. Dziś podszedłem do tej kwestii jeszcze raz i w
oparciu &lt;a href=&#34;https://weakdh.org/sysadmin.html&#34;&gt;o ten link&lt;/a&gt; udało mi się poprawnie skonfigurować mój
serwer www.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migracja certyfikatów OpenSSL z SHA-1</title>
      <link>https://morfikov.github.io/post/migracja-certyfikatow-openssl-z-sha-1/</link>
      <pubDate>Sat, 05 Sep 2015 17:15:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/migracja-certyfikatow-openssl-z-sha-1/</guid>
      <description>&lt;p&gt;Szukając co by tutaj jeszcze poprawić w moim środowisku testowym, w którym działa między innymi
apache, natrafiłem na komunikat w firefoxie, który oznajmił mi, że certyfikat mojego serwera
korzysta z przestarzałego już algorytmu mieszającego (hash). W tym przypadku jest to SHA-1. &lt;a href=&#34;https://blog.mozilla.org/security/2014/09/23/phasing-out-certificates-with-sha-1-based-signature-algorithms/&#34;&gt;Jak
można przeczytać na blogu
mozilli&lt;/a&gt;,
algorytm SHA-1 wypadł z łask jakiś czas temu i obecnie nie zaleca się jego używania ze względów
bezpieczeństwa. Postanowiłem zatem poprawić tę lukę.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AppArmor i profilowanie aplikacji</title>
      <link>https://morfikov.github.io/post/apparmor-profilowanie-aplikacji/</link>
      <pubDate>Sat, 08 Aug 2015 23:33:59 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/apparmor-profilowanie-aplikacji/</guid>
      <description>&lt;p&gt;Po ostatnich doniesieniach na temat &lt;a href=&#34;https://blog.mozilla.org/security/2015/08/06/firefox-exploit-found-in-the-wild/&#34;&gt;błędu jaki został znaleziony w
Firefox&#39;ie&lt;/a&gt; ,
doszedłem do wniosku, że najwyższy czas nauczyć się obsługi narzędzia &lt;code&gt;AppArmor&lt;/code&gt; . Ma ono pomóc w
kontrolowaniu praw dostępu do zasobów systemu operacyjnego, np. plików, katalogów czy określonych
urządzeń. Jeśli weźmiemy przytoczony wyżej błąd, to przeglądarka bez takiego profilu AppArmor&#39;a była
w stanie przeszukać lokalne pliki i wysłać je gdzieś na net, co powodowałoby udostępnienie poufnych
danych, np. historia poleceń shell&#39;owych, czy klucze prywatne.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fontconfig i konfiguracja czcionek w Debianie</title>
      <link>https://morfikov.github.io/post/fontconfig-i-konfiguracja-czcionek-w-debianie/</link>
      <pubDate>Wed, 05 Aug 2015 17:10:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/fontconfig-i-konfiguracja-czcionek-w-debianie/</guid>
      <description>&lt;p&gt;Od zawsze podobały mi się czcionki windosowskie ale po przejściu na linux&#39;a okazało się, że tutaj
fonty wyglądają zupełnie inaczej i co mogło zdziwić, nie było w standardzie tych moich ulubionych,
tj. Arial, Times New Roman i Courier New. Przez szereg lat miałem obecną w systemie dość dziwną
konfigurację dla fontconfig&#39;a, która działała na takiej zasadzie, że te czcionki aplikacji były w
prządku, natomiast te pobierane z serwisów www (np. w Firefox&#39;ie) dość słabo się renderowały i bez
przeprowadzania kilku zabiegów były one zwyczajnie nieczytelne. Postanowiłem w końcu poczytać trochę
dokumentacji na temat tego jak wygląda konfiguracja czcionek w debianie i po kilku dniach udało mi
się osiągnąć dość zadowalające efekty wizualne.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Polskie znaki pod TTY</title>
      <link>https://morfikov.github.io/post/polskie-znaki-pod-tty/</link>
      <pubDate>Wed, 15 Jul 2015 18:16:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/polskie-znaki-pod-tty/</guid>
      <description>&lt;p&gt;Jeśli w środowisku graficznym mamy ustawiony &lt;a href=&#34;https://morfikov.github.io
/post/jezyk-polski-w-srodowisku-graficznym/&#34;&gt;polski
język&lt;/a&gt;, nie mamy przy tym problemów z
kodowaniem znaków w tekście i nasza klawiatura ma ustawiony odpowiedni &lt;a href=&#34;https://morfikov.github.io
/post/klawiatura-i-jej-konfiguracja-pod-debianem/&#34;&gt;układ
klawiszy&lt;/a&gt; ale jednocześnie
doświadczamy problemów jeśli chodzi o polskie znaki pod TTY, oznacza to prawdopodobnie źle
skonfigurowany wirtualny terminal. Generalnie rzecz biorąc środowisko graficzne i konsola TTY, to
tak jakby dwa różne światy i trzeba je konfigurować w pewnych aspektach osobno.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Język polski w środowisku graficznym</title>
      <link>https://morfikov.github.io/post/jezyk-polski-w-srodowisku-graficznym/</link>
      <pubDate>Wed, 15 Jul 2015 17:29:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jezyk-polski-w-srodowisku-graficznym/</guid>
      <description>&lt;p&gt;Gdy mamy do dyspozycji panel administracyjny jednego ze środowisk graficznych, np. GNOME, zmiana
języka interfejsu aplikacji w systemie nie powinna przysporzyć problemów. Natomiast jeśli chodzi o
wszelkie inne środowiska oparte jedynie o menadżery okien, np. OPENBOX, lub też i te zupełnie nie
mające graficznej sesji, to przestawienie języka jest lekko utrudnione. Przede wszystkim, musimy
rozróżnić dwie kwestie. Jedną z nich jest język interfejsu i wszelkie wiadomości, które wypisuje nam
system, np. na terminalu. A drugą są &lt;a href=&#34;https://morfikov.github.io
/post/klawiatura-i-jej-konfiguracja-pod-debianem/&#34;&gt;polskie
znaki&lt;/a&gt;, które możemy wpisywać
przy pomocy klawiatury. Te dwie rzeczy są ze sobą niepowiązane w żaden sposób, tj. można mieć polski
układ klawiszy i jednocześnie korzystać z angielskiej wersji systemu operacyjnego linux i vice
versa. Choć automaty środowisk graficznych synchronizują te dwa elementy, co wydaje się być raczej
zrozumiałe.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klawiatura i jej konfiguracja pod debianem</title>
      <link>https://morfikov.github.io/post/klawiatura-i-jej-konfiguracja-pod-debianem/</link>
      <pubDate>Wed, 15 Jul 2015 01:21:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/klawiatura-i-jej-konfiguracja-pod-debianem/</guid>
      <description>&lt;p&gt;W środowiskach graficznych, np. GNOME czy KDE, nie musimy zbytnio się zastanawiać nad tym jak
skonfigurować klawiaturę, bo wszystko możemy sobie szybko i w prosty sposób wyklikać z graficznego
panelu administracyjnego systemu. Natomiast jeśli korzystamy jedynie z odchudzonych instalacji
linux&#39;a zawierających jedynie jakiś menadżer okien, np. OPENBOX, to sami musimy zadbać o
skonfigurowanie klawiatury, tak by układ się zgadzał, by były dostępne polskie znaki, no i
oczywiście by system potrafił rozpoznać ewentualne &lt;a href=&#34;https://morfikov.github.io
/post/klawiatura-multimedialna-i-niedzialajace-klawisze/&#34;&gt;klawisze
multimedialne&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kompaktowanie katalogów w systemie plików ext4</title>
      <link>https://morfikov.github.io/post/kompaktowanie-katalogow-w-systemie-plikow-ext4/</link>
      <pubDate>Sat, 11 Jul 2015 13:39:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kompaktowanie-katalogow-w-systemie-plikow-ext4/</guid>
      <description>&lt;p&gt;Jakiś czas temu pewien człowiek &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=27485&#34;&gt;miał dziwaczny
problem&lt;/a&gt;. Jak możemy wyczytać w przytoczonym linku,
system tego użytkownika lekko mówiąc nie zachowywał się tak jak powinien. Objawiało się to przez
dość ekstensywne wykorzystywanie pamięci operacyjnej RAM przy zwykłym listowaniu plików via &lt;code&gt;ls&lt;/code&gt; w
pewnych określonych katalogach. Struktura systemu plików zdaje się być porządku, bo program &lt;code&gt;fsck&lt;/code&gt;
nie zwraca żadnych błędów. Zatem w czym problem?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klawisz Backspace w Firefox&#39;ie</title>
      <link>https://morfikov.github.io/post/klawisz-backspace-w-firefoxie/</link>
      <pubDate>Sat, 11 Jul 2015 10:12:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/klawisz-backspace-w-firefoxie/</guid>
      <description>&lt;p&gt;Przez cały czas korzystania z internetu, robiłem to za pomocą przeglądarki Opera. Nawet po tym jak
przeszedłem na linuxa, to wciąż nie mogłem się z nią rozstać i to pomimo faktu, że nie była ona
przecież opensource, przez co nie była także dostępna w repozytoriach debiana. Gdy deweloperzy z
zespołu Opery przestali rozwijać tę przeglądarkę dla linuxa, musiałem poszukać sobie czegoś innego.
Wybór padł na Firefox&#39;a ale każdy kto używał tych dwóch przeglądarek wie, że różniły się one dość
znacznie parę lat temu i jedną z tych bardziej odczuwalnych różnic była inna obsługa klawisza
Backspace .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Opcja extents w systemach plików ext4</title>
      <link>https://morfikov.github.io/post/opcja-extents-w-systemach-plikow-ext4/</link>
      <pubDate>Fri, 10 Jul 2015 15:20:44 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/opcja-extents-w-systemach-plikow-ext4/</guid>
      <description>&lt;p&gt;Dziś postanowiłem sprawdzić jak wygląda struktura plików mojego dysku. Chodzi oczywiście o ich
fragmentację. Zgodnie z tym co pokazał mi &lt;code&gt;fsck&lt;/code&gt; , pofragmentowanych plików jest 350. Po
zapuszczeniu defragmentacji via &lt;code&gt;e4defrag&lt;/code&gt; ilość tych plików spadła do nieco ponad 100 i jeśli by
się przyjrzeć procesowi defragmentacji, to można było zauważyć linijki mające &lt;code&gt;extents: 100 -&amp;gt; 10&lt;/code&gt;
. Wychodzi na to, że plik dalej jest w kawałkach i nie idzie go zdefragmentować. Jak rozumieć taki
zapis?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Parkowanie głowicy w dyskach Wstern Digital</title>
      <link>https://morfikov.github.io/post/parkowanie-glowicy-w-dyskach-wstern-digital/</link>
      <pubDate>Wed, 08 Jul 2015 20:28:44 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/parkowanie-glowicy-w-dyskach-wstern-digital/</guid>
      <description>&lt;p&gt;Dyski zużywają się z różnych powodów. Jednak najczęstszą przyczyną są nowe wynalazki, które
producent w nich implementuje, bo te niezbyt dobrze działają w określonych warunkach, czy też pod
kontrolą pewnych systemów operacyjnych. Tak właśnie jest w przypadku nowszych dysków firmy Western
Digital (WD). Maja one wprowadzony ficzer parkowania głowicy w przypadku, gdy dysk &lt;a href=&#34;http://wdc.custhelp.com/app/answers/detail/a_id/5357&#34;&gt;jest
nieużywany&lt;/a&gt;. Ma to na celu zmniejszyć pobór
prądu i, co za tym idzie, temperaturę urządzenia. Jako, że parkowanie głowicy w dyskach WD nie
działa poprawnie pod moim linux&#39;em (dystrybucja Debian), to nasuwa się pytanie: jak wyłączyć
parkowanie głowicy by wydłużyć żywotność dysku twardego?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wolny start połączeń w protokole TCP</title>
      <link>https://morfikov.github.io/post/wolny-start-polaczen-w-protokole-tcp/</link>
      <pubDate>Tue, 07 Jul 2015 19:33:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wolny-start-polaczen-w-protokole-tcp/</guid>
      <description>&lt;p&gt;Wolny start jest wynikiem braku zaufania maszyny nadawczej do utworzonego kanału przesyłowego --
połączenia. Nie wie ona czy to łącze jest bowiem w stanie obsłużyć taką porcję danych, którą ma
zamiar przesłać bez czekania na pakiet &lt;code&gt;ACK&lt;/code&gt; . W przypadku bufora odbiorczego, wszystko jest proste,
bo dane dotyczące wielkości okien są zdefiniowane w nagłówku pakietów, do których ma wgląd druga ze
stron. W przypadku gdy nadawca przesyła dane, prędkość z jaką to robi zależy głównie od niego.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bufor połączeń w protokole TCP</title>
      <link>https://morfikov.github.io/post/bufor-polaczen-w-protokole-tcp/</link>
      <pubDate>Wed, 01 Jul 2015 10:20:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/bufor-polaczen-w-protokole-tcp/</guid>
      <description>&lt;p&gt;Wraz ze zwiększaniem zapotrzebowania na szybsze łącza internetowe, ograniczenia wynikające z
protokółu TCP zaczęły powoli dawać się ludziom we znaki. Problemem była bariera prędkości, którą
ciężko było pokonać mając do dyspozycji domyślną formę nagłówka protokołu TCP. Było w nim zwyczajnie
za mało miejsca, co zapoczątkowało jego rozbudowę kosztem ilości danych, które można było przesłać w
pojedynczym segmencie. W tym wpisie skupię się głównie na dwóch opcjach jakie zostały dodane do
nagłówka TCP, tj. dynamiczne skalowanie okien oraz znaczniki czasu, bo te dwa parametry nie mogą
wręcz bez siebie istnieć, zwłaszcza gdy rozmawiamy o łączach pokroju 1 czy 10 gbit/s.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SACK, czyli selektywne potwierdzenia pakietów</title>
      <link>https://morfikov.github.io/post/sack-czyli-selektywne-potwierdzenia-pakietow/</link>
      <pubDate>Wed, 01 Jul 2015 06:04:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sack-czyli-selektywne-potwierdzenia-pakietow/</guid>
      <description>&lt;p&gt;Protokół TCP jest tak zbudowany by zapewnić rzetelny transfer danych między dwoma komunikującymi się
punktami. Z początku jednak, ta cecha tego protokołu powodowała marnowanie dość sporych ilości
zasobów jeśli chodzi o przepustowość łącza. Stało się to widoczne przy większych prędkościach
połączeń, gdzie &lt;a href=&#34;https://morfikov.github.io
/post/bufor-polaczen-w-protokole-tcp/&#34;&gt;skalowany był bufor&lt;/a&gt;
(okno) TCP, co umożliwiło przesyłanie szeregu segmentów bez potrzeby czekania na ich potwierdzenie
przez odbiorcę. To zwiększyło, co prawda, transfer danych ale pojawił się problem z zagubionymi
pakietami.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TSO, czyli odciążenie segmentacji TCP</title>
      <link>https://morfikov.github.io/post/tso-czyli-odciazenie-segmentacji-tcp/</link>
      <pubDate>Tue, 30 Jun 2015 21:15:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/tso-czyli-odciazenie-segmentacji-tcp/</guid>
      <description>&lt;p&gt;Stawiając sobie środowisko testowe pod wireshark&#39;a w celu analizy pakietów sieciowych, zauważyłem,
że coś mi się nie zgadza odnośnie wielkości przesyłanych pakietów między interfejsami kontenerów
LXC. Jakby nie patrzeć, środowisko testowe ma być odwzorowaniem środowiska produkcyjnego i w tym
przypadku wszelkie zasady dotyczące, np. podziału danych na segmenty, muszą być takie same.
Generalnie rzecz biorąc rozmiar pakietu powinien wynosić 1514 bajtów, a był parokrotnie większy.
Okazało się, że jest to za sprawą odciążenia segmentacji w protokole TCP (&lt;a href=&#34;https://lwn.net/Articles/564978/&#34;&gt;TCP Segmentation
Offload&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przeszukiwanie zawartości pakietów (apt-file)</title>
      <link>https://morfikov.github.io/post/przeszukiwanie-zawartosci-pakietow-apt-file/</link>
      <pubDate>Tue, 30 Jun 2015 12:03:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przeszukiwanie-zawartosci-pakietow-apt-file/</guid>
      <description>&lt;p&gt;Podczas procesu kompilacji pakietów często zdarza się tak, że brakuje jakichś zależności, bez
których dany pakietów nie chce się nam zbudować. W większości przypadków, system powinien nam
podpowiedzieć jaki pakiet powinniśmy doinstalować. Nie zawsze jednak będzie to takie oczywiste i
jedyne co nam zostanie zwrócone, to ścieżka danego pliku lub tylko jego nazwa. Nawet jeśli nie
kompilujemy programów, to podczas zwykłego użytkowania komputera możemy potrzebować odnaleźć pakiet,
który zawiera pewien określony plik binarny czy konfiguracyjny. Jak zatem odnaleźć się w gąszczu
plików i katalogów by efektywnie ustalić pakiet, który zawiera interesujące nas pliki?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fragmentacja pakietu i zmiana wartości MTU</title>
      <link>https://morfikov.github.io/post/fragmentacja-pakietu-i-zmiana-wartosci-mtu/</link>
      <pubDate>Mon, 29 Jun 2015 21:35:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/fragmentacja-pakietu-i-zmiana-wartosci-mtu/</guid>
      <description>&lt;p&gt;MTU (Maximum Transmission Unit) to maksymalna długość pakietu jaki może zostać przesłany przez sieć.
Może ona wynosić do 64KiB ale większość punktów sieciowych, takich jak routery, wymusza o wiele
mniejsze rozmiary pakietów. Domyślna wartość MTU dla protokołu Ethernet to 1500 bajtów, oczywiście
bez nagłówka warstwy fizycznej, który ma dodatkowe 14 bajtów. Czasami te standardowe ustawienia mogą
powodować problemy w przypadku pewnych konfiguracji sieci i gdy ich doświadczamy, przydałoby się
zmienić rozmiar MTU przesyłanych pakietów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Znacznik czasu (timestamp) w protokole TCP</title>
      <link>https://morfikov.github.io/post/znacznik-czasu-timestamp-w-protokole-tcp/</link>
      <pubDate>Sun, 28 Jun 2015 17:33:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/znacznik-czasu-timestamp-w-protokole-tcp/</guid>
      <description>&lt;p&gt;O znacznikach czasu (timestamp) wspominałem już raz w ramach omawiania mechanizmu jakim jest &lt;a href=&#34;https://morfikov.github.io
/post/bufor-polaczen-w-protokole-tcp/&#34;&gt;bufor
połączenia&lt;/a&gt;, a konkretnie rozchodziło się o
skalowanie okien TCP. Generalnie rzecz biorąc, przy wyższych prędkościach, rzędu 1 gbit/s, nie ma
innej opcji jak skorzystanie z opcji znaczników czasu, które są niejako rozszerzeniem czegoś co
widnieje pod nazwą &lt;a href=&#34;https://morfikov.github.io
/post/numery-sekwencyjne-w-strumieniu-tcp/&#34;&gt;numery sekwencyjne&lt;/a&gt;
. Z jednej strony może i mamy możliwość implementacji łącz o większej przepustowości ale z drugiej
te znaczniki czasu w pakietach TCP &lt;a href=&#34;https://nfsec.pl/security/2306&#34;&gt;mogą zagrozić bezpieczeństwu&lt;/a&gt;
stacji roboczej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Numery sekwencyjne w strumieniu TCP</title>
      <link>https://morfikov.github.io/post/numery-sekwencyjne-w-strumieniu-tcp/</link>
      <pubDate>Thu, 25 Jun 2015 21:24:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/numery-sekwencyjne-w-strumieniu-tcp/</guid>
      <description>&lt;p&gt;Jeśli zastanawialiście się czym są numery sekwencyjne i potwierdzeń w strumieniach protokołu TCP, to
nie jesteście jedyni, którym to zagadnienie spędza sen z powiek. Dlatego też poniżej postanowiłem
opisać najdokładniej jak umiem proces jaki zachodzi przy przesyłaniu danych z jednego punktu
sieciowego na drugi. Bez zaprzęgnięcia sniffera sieciowego raczej nie da się zrozumieć tego tematu i
poniższy przykład zawiera szereg odwołań do programu wireshark.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Flagi TCP i przełączanie stanów połączeń</title>
      <link>https://morfikov.github.io/post/flagi-tcp-i-przelaczanie-stanow-polaczen/</link>
      <pubDate>Wed, 24 Jun 2015 21:44:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/flagi-tcp-i-przelaczanie-stanow-polaczen/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/firewall-na-linuxowe-maszyny-klienckie/&#34;&gt;jak zaprojektować swój własny
firewall&lt;/a&gt;, wobec czego postanowiłem
nieco bardziej pochylić się nad zagadnieniem stanów połączeń i je dokładniej przeanalizować. Ten
wpis dotyczy głównie protokołu TCP, bo ten UDP jest bezpołączeniowy, więc nie ma tam żadnych stanów.
Dodatkowo opiszę tutaj poszczególne flagi, które mogą zostać ustawione w pakietach zmieniając tym
samym stan połączenia.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czas życia pakietów, czyli zmiana TTL</title>
      <link>https://morfikov.github.io/post/czas-zycia-pakietow-czyli-zmiana-ttl/</link>
      <pubDate>Wed, 24 Jun 2015 17:50:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czas-zycia-pakietow-czyli-zmiana-ttl/</guid>
      <description>&lt;p&gt;Czasem niektórzy ISP z jakiegoś bliżej nieokreślonego powodu blokują dostęp do internetu hostom
zlokalizowanym za routerem czy innym komputerem udostępniającym połączenie sieciowe. ISP zwykle
stara się blokować konkretną wartość pola TTL, która jest ustawiana w każdym przesyłanym przez nasze
maszyny pakiecie. Innym sposobem zablokowania możliwości udostępniania internetu jest ograniczenie
wartości pola TTL do jednego hopa wszystkim pakietom dochodzącym do routera od strony ISP. Jeśli
mamy nieszczęście trafić na takiego providera, to warto wiedzieć, że przy pomocy iptables możemy
ustawić/podbić/zmniejszyć czas życia pakietów, które docierają do routera zarówno od strony LAN jak
i WAN i tym samym bez większego trudu możemy sobie poradzić z tą blokadą.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Udostępnianie połączenia internetowego</title>
      <link>https://morfikov.github.io/post/udostepnianie-polaczenia-internetowego/</link>
      <pubDate>Wed, 24 Jun 2015 13:57:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/udostepnianie-polaczenia-internetowego/</guid>
      <description>&lt;p&gt;Każdy z nas ma router w domu, który potrafi rozdzielić sygnał na szereg komputerów w naszej sieci
lokalnej. Jeśli z jakichś powodów nie chcemy posiadać w domu tego cuda techniki i chcielibyśmy mieć
możliwość udostępniania połączenia internetowego za pośrednictwem innego komputera, to nic nie stoi
nam na przeszkodzie by to zrobić. Taki komputer stacjonarny niczym się nie różni od routera, no może
za wyjątkiem poboru prądu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PeerGuardian w oparciu o ipset i iptables</title>
      <link>https://morfikov.github.io/post/peerguardian-w-oparciu-o-ipset-iptables/</link>
      <pubDate>Tue, 23 Jun 2015 22:50:14 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/peerguardian-w-oparciu-o-ipset-iptables/</guid>
      <description>&lt;p&gt;Wiele klientów torrenta umożliwia ładowanie zewnętrznej listy z zakresami adresów IP i ta lista ma
służyć jako swego rodzaju filtr połączeń chroniący nas przed różnego rodzaju organizacjami, które
mogą zbierać i przetwarzać informacje na temat naszego IP i tego co on porabia w sieci p2p.
Oczywiście, kwestia czy korzystać z takiego typu rozwiązania jest bardzo dyskusyjna i wiele osób
jest zdania, że to tak naprawdę w niczym nie pomoże, a wręcz nawet przyczynia się do
samounicestwienia sieci p2p. Także taki filter może czasem przynieść więcej szkody niż pożytku,
zwłaszcza gdy się go używa lekkomyślnie, czyli na zasadzie, że ten co blokuje więcej adresów musi
być lepszy. Poniżej opiszę wykorzystanie rozszerzenia &lt;code&gt;ipset&lt;/code&gt;, przy pomocy którego zostanie
zablokowany szereg klas adresów. Całość raczej nie skupia się na implementacji filtra, to tylko
przykład do czego &lt;code&gt;ipset&lt;/code&gt; może posłużyć, a że ja nie umiem teoretycznie pisać, to muszę na
przykładach.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Struktura plików urządzeń usb w katalogu /sys/</title>
      <link>https://morfikov.github.io/post/struktura-plikow-urzadzen-usb-w-katalogu-sys/</link>
      <pubDate>Tue, 23 Jun 2015 20:23:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/struktura-plikow-urzadzen-usb-w-katalogu-sys/</guid>
      <description>&lt;p&gt;Jeśli próbowaliśmy odnaleźć odpowiednią ścieżkę do urządzenia usb w linuxowym drzewie katalogów, to
wiemy, że nie jest to łatwe zadanie. Mamy, co prawda, do dyspozycji polecenie &lt;code&gt;lsusb&lt;/code&gt; ale ono nie
daje nam precyzyjnych informacji na temat tego gdzie dokładnie w katalogu &lt;code&gt;/sys/&lt;/code&gt; znajdują się
określone urządzenia. Na necie natrafiłem na &lt;a href=&#34;http://www.linux-usb.org/&#34;&gt;FAQ&lt;/a&gt; dotyczący tego
zagadnienia i postanowiłem napisać kilka zdań o tym jak zinterpretować ciągi typu &lt;code&gt;2-1.1.2:1.1&lt;/code&gt; oraz
jakie to może być urządzenie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Autosuspend i zasilanie portów usb</title>
      <link>https://morfikov.github.io/post/autosuspend-i-zasilanie-portow-usb/</link>
      <pubDate>Tue, 23 Jun 2015 15:34:50 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/autosuspend-i-zasilanie-portow-usb/</guid>
      <description>&lt;p&gt;Kernel w linuxie odcina zasilanie urządzeniom podpiętym do portów usb jeśli sterownik wspiera tego
typu możliwość oraz samo urządzenie nie jest używane przez pewien okres czasu. W taki oto sposób,
jeśli podłączymy, np. zewnętrzną klawiaturę usb do laptopa, możemy zaobserwować, że przy pisaniu
tekstu gubiony jest zwykle pierwszy znak. Może i klawiatura po przyciśnięciu klawisza wyszła ze
stanu bezczynności ale system nie zareagował na tyle szybko by złapać sygnał przycisku. Na necie
ludzie piszą, że jest to problem niekompatybilności urządzeń i tego typu sytuacja nie powinna się
zdarzać. Jeśli jednak natrafiliśmy na klawiaturę czy myszę, która cierpi z powodu automatycznego
zawieszania jej zasilania, możemy wyłączyć ten ficzer zupełnie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sterowniki do karty TP-LINK Archer T4U (8812au)</title>
      <link>https://morfikov.github.io/post/sterowniki-karty-tp-link-archer-t4u-8812au/</link>
      <pubDate>Tue, 23 Jun 2015 11:45:07 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sterowniki-karty-tp-link-archer-t4u-8812au/</guid>
      <description>&lt;p&gt;Póki co, w kernelu linux&#39;a (4.5) nie ma odpowiednich sterowników do &lt;a href=&#34;http://www.tp-link.com.pl/products/details/cat-11_Archer-T4U.html&#34;&gt;adaptera WiFi Archer
T4U&lt;/a&gt; i trzeba je sobie
skompilować ręcznie. Trochę to dziwne, bo przecie kod sterownika jest na licencji GPLv2 i dostępny
już szmat czasu na &lt;a href=&#34;https://github.com/abperiasamy/rtl8812AU_8821AU_linux&#34;&gt;github&#39;ie&lt;/a&gt;. W każdym
razie, jeśli zakupiliśmy w/w kartę i nie jest ona wykrywana po wsadzeniu jej do portu USB, to czeka
nas proces kompilacji modułu &lt;code&gt;8812au&lt;/code&gt; i jego automatyzacja przy pomocy &lt;a href=&#34;https://morfikov.github.io
/post/dkms-czyli-automatycznie-budowane-moduly/&#34;&gt;mechanizmu
DKMS&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tryb oszczędzania energii w kartach wifi</title>
      <link>https://morfikov.github.io/post/tryb-oszczedzania-energii-w-kartach-wifi/</link>
      <pubDate>Tue, 23 Jun 2015 10:25:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/tryb-oszczedzania-energii-w-kartach-wifi/</guid>
      <description>&lt;p&gt;Niektóre karty wifi znane są z tego, że niezbyt chcą one działać pod systemem operacyjnym linux. Nie
jest to wina samego sprzętu, ani tym bardziej linuxa, tylko raczej faktu, że producent nie potrafi
napisać pod ten OS odpowiednich sterowników. Czasem jednak pod względem programowym wszystko wydaje
się być w porządku, tj. sterowniki zostały zainstalowane, są one dobrej jakości i karta działa
praktycznie bez zarzutu. Niemniej jednak, strony www wydają się ładować jakoś tak ociężale, z pewnym
opóźnieniem. Jeśli doświadczyliśmy tego typu zachowania ze strony naszej karty wifi, prawdopodobnie
oznacza to, że ma ona włączony tryb oszczędzania energii (powersave).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Firewall na linux&#39;owe maszyny klienckie</title>
      <link>https://morfikov.github.io/post/firewall-na-linuxowe-maszyny-klienckie/</link>
      <pubDate>Mon, 22 Jun 2015 23:33:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/firewall-na-linuxowe-maszyny-klienckie/</guid>
      <description>&lt;p&gt;Prędzej czy później, każdy z nas będzie musiał zabezpieczyć dostęp do swojego komputera w sieci. Do
tego zadania na stacjach z linux&#39;em jest oddelegowane narzędzie &lt;code&gt;iptables&lt;/code&gt; wraz z szeregiem
dodatków, jak np. &lt;code&gt;ipset&lt;/code&gt; . By zbudować solidny firewall nie potrzeba zbytnio się wysilać. Niemniej
jednak, temat zapory linux&#39;owej jest &lt;a href=&#34;https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html&#34;&gt;bardzo
rozległy&lt;/a&gt; i nie będziemy tutaj
opisywać wszystkich możliwych scenariuszy jej zastosowania. Zamiast tego skupimy się jedynie na
bazowym skrypcie, który można rozbudować bez przeszkód i dostosować go zarówno pod maszyny klienckie
jak i te serwerowe.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ECryptfs jako alternatywa dla encfs</title>
      <link>https://morfikov.github.io/post/ecryptfs-jako-alternatywa-dla-encfs/</link>
      <pubDate>Mon, 22 Jun 2015 18:58:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ecryptfs-jako-alternatywa-dla-encfs/</guid>
      <description>&lt;p&gt;Dnia 2014-10-07 w Debianie była aktualizacja pakietu &lt;code&gt;encfs&lt;/code&gt; , która to zawierała informację na
temat &lt;a href=&#34;https://defuse.ca/audits/encfs.htm&#34;&gt;audytu bezpieczeństwa&lt;/a&gt; jaki się dokonał parę miesięcy wstecz. Wyniki niezbyt dobrze
wypadły, a nawet można powiedzieć, że wręcz katastrofalnie. Generalnie cały test został skwitowany
słowami, że jeśli szyfrujemy pliki przy pomocy tego narzędzia, to jesteśmy relatywnie bezpieczni,
nawet w przypadku jeśli ktoś te pliki przechwyci. Natomiast jeśli zaczniemy zmieniać/dodawać pliki
i ten ktoś ponownie przechwyci nasz zaszyfrowany katalog, wtedy może on bez problemu odszyfrować
całą jego zawartość. Jeśli wykorzystujemy &lt;code&gt;encfs&lt;/code&gt; lokalnie, to być może nam nic nie grozi, nawet w
przypadku raidu NSA na naszą chałupę. Problem w tym, że ogromna rzesza ludzi wykorzystuje &lt;code&gt;encfs&lt;/code&gt;
do zaszyfrowania plików w chmurze, np. na Dropbox&#39;ie czy MEGA, a jak wiadomo, przy każdej
synchronizacji, zmiany w danym katalogu są przesyłane do chmury i wszelkie zabezpieczenie jakie
daje &lt;code&gt;encfs&lt;/code&gt; diabli biorą. Może najwyższy czas zainteresować się &lt;code&gt;ecryptfs&lt;/code&gt;?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Riseup VPN na straży prywatności</title>
      <link>https://morfikov.github.io/post/riseup-vpn-na-strazy-prywatnosci/</link>
      <pubDate>Sun, 21 Jun 2015 17:05:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/riseup-vpn-na-strazy-prywatnosci/</guid>
      <description>&lt;p&gt;W dobie NSA, podsłuchów rządowych i wszelkiego rodzaju pogwałcenia prawa do prywatności, ludzie
wymyślili &lt;a href=&#34;https://pl.wikipedia.org/wiki/Virtual_Private_Network&#34;&gt;VPN&lt;/a&gt;. VPN to nic innego jak tunel
łączący dwie odległe od siebie maszyny, które chcą wymieniać ze sobą dane w sposób uniemożliwiający
osobom trzecim podejrzenie całej tej komunikacji. Zalety korzystania z takiego dobrodziejstwa natury
są oczywiste. Można obejść cenzorów, gdyż cały ruch z naszej maszyny jest przesyłany do serwera w
postaci szyfrowanej, a dopiero z tego serwera sygnał idzie dalej w świat. Jest wiele komercyjnych
usług, które za drobną opłatą mogą zapewnić nam tego tupu usługi ale ja nie będę tutaj się o nich
rozpisywał. Bez problemu można je znaleźć w góglu. My tutaj za to zajmiemy się VPN jaki zapewnia
&lt;a href=&#34;https://riseup.net/&#34;&gt;riseup&lt;/a&gt;. By móc korzystać z ich usług, trzeba założyć na ich stronie konto, a
to z kolei jest przyznawane tym, którzy w jakiś sposób działają na rzecz szeroko pojętej wolności.
Ja wysłałem zgłoszenie i konto zostało mi przyznane. Dlatego też opiszę jak wygląda konfiguracja VPN
na ich przykładzie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Szyfrowanie poczty przy pomocy enigmail</title>
      <link>https://morfikov.github.io/post/szyfrowanie-poczty-przy-pomocy-enigmail/</link>
      <pubDate>Sun, 21 Jun 2015 15:55:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/szyfrowanie-poczty-przy-pomocy-enigmail/</guid>
      <description>&lt;p&gt;Szyfrowanie wiadomości email można uznać za paranoiczne podejście do kwestii wymiany informacji, bo
zwykły człowiek mówi sobie: &amp;quot;ja przecie za pomocą poczty nie wysyłam nic ważnego, nawet swoich
nagich fotek, a nawet jeśli już, to są one od pasa w dół. Poza tym, gmail jest szyfrowany, bo używa
SSL/TLS&amp;quot;. SSL/TLS, co prawda, jest ale ogranicza się do szyfrowania tego co robimy na gmailu. Same
wiadomości natomiast są przesyłane między różnymi serwerami i niekoniecznie są szyfrowane. Poza tym
google kiedyś wspominał, że w przypadku gdy policja będzie żądała dostępu do naszej skrzynki
pocztowej, to nie dość, że on im to umożliwi, to jeszcze wyciągnie wszelkie maile jakie przez tę
skrzynkę zostały przepuszczone -- zarówno te odebrane jak i wysłane.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Błędy bootloadera grub</title>
      <link>https://morfikov.github.io/post/bledy-bootloadera-grub/</link>
      <pubDate>Sun, 21 Jun 2015 00:33:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/bledy-bootloadera-grub/</guid>
      <description>&lt;p&gt;Grub to najpopularniejszy bootloader w systemach linuxowych. Dorobił się tego miejsca na podium
głównie ze względu na swoją pełną automatyzację. Potrafi obsłużyć pokaźną ilości systemów plików,
no i również nie zostaje w tyle w stosunku do aktualnych standardów partycjonowania dysków -- mowa
oczywiście o tablicy partycji GPT. Przeglądając internet w poszukiwaniu odpowiedzi na temat jednego
z błędów jaki grub wyrzucił mi podczas startu systemu, znalazłem &lt;a href=&#34;http://www.uruk.org/orig-grub/errors.html&#34;&gt;ten oto
artykuł&lt;/a&gt;. Zawarte są tam dokładnie wszystkie możliwe
błędy jakie grub potrafi zwrócić wraz z krótkim wyjaśnieniem ich przyczyny. Postanowiłem sobie je
przejrzeć i dorobić do nich polskie tłumaczenie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Udevil i montowanie zasobów bez uprawnień root</title>
      <link>https://morfikov.github.io/post/udevil-i-montowanie-zasobow-bez-uprawnien-root/</link>
      <pubDate>Fri, 19 Jun 2015 20:11:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/udevil-i-montowanie-zasobow-bez-uprawnien-root/</guid>
      <description>&lt;p&gt;Linux jest bezpiecznym środowiskiem operacyjnym ale to nie ze względu na to, że jego kod jest jakoś
mniej podatny na błędy czy coś w tym stylu, tylko przez restrykcyjną politykę dostępu do szeregu
miejsc w systemie. Jednym z nich są wszelkie urządzenia, w skład których wchodzą również i dyski
twarde, pendrive czy napędy cd/dvd. Oczywiście tych urządzeń może być o wile więcej ale my w tym
wpisie omówimy sobie dostęp tylko do tych trzech wymienionych wyżej. Standardowo zwykły użytkownik w
systemie nie ma możliwości przeprowadzenia szeregu czynności pod kątem większości z tych urządzeń i
wliczyć w to można, np. montowanie zasobów. Tego typu operacje może przeprowadzać jedynie
administrator. Ma to na celu ochronę bezpieczeństwa systemu. Jeśli chodzi o nośniki wymienne takie
jak płytki cd/dvd czy pendrive, to na nich może znajdować się podejrzane oprogramowanie i po
zamontowaniu takiego nośnika w systemie, wirusy, trojany czy keyloggery mogą się wgrać do systemu
zagrażając tym samym prywatności wszystkich użytkowników.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Autostart i automatyczne montowanie nośników</title>
      <link>https://morfikov.github.io/post/autostart-i-automatyczne-montowanie-nosnikow/</link>
      <pubDate>Fri, 19 Jun 2015 17:17:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/autostart-i-automatyczne-montowanie-nosnikow/</guid>
      <description>&lt;p&gt;Menadżery plików potrafią automatycznie montować nośniki wymienne w oparciu o pakiet
&lt;a href=&#34;https://www.freedesktop.org/wiki/Software/udisks/&#34;&gt;udisks2&lt;/a&gt;. Potrafią także uruchamiać odpowiednie
aplikacje zlokalizowane na tych urządzeniach. Może to prowadzić do oczywistych zagrożeń i jeśli nasz
system ma być bezpieczny, to musimy wyłączyć obie te opcje. W różnych menadżerach plików, ten proces
przebiega inaczej. Ja korzystam ze &lt;a href=&#34;https://ignorantguru.github.io/spacefm/&#34;&gt;spacefm&lt;/a&gt; i w jego
przypadku mamy dość rozbudowany mechanizm polityki dotyczącej tych dwóch powyższych kwestii.
Niemniej jednak, w przypadku każdego z menadżera plików, proces postępowania powinien przebiegać
mniej więcej w ten sam sposób.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dzielenie pliku i łączenie jego części w całość</title>
      <link>https://morfikov.github.io/post/dzielenie-pliku-i-laczenie-jego-czesci-w-calosc/</link>
      <pubDate>Fri, 19 Jun 2015 13:24:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dzielenie-pliku-i-laczenie-jego-czesci-w-calosc/</guid>
      <description>&lt;p&gt;Obecnie technika podziału jednego pliku na szereg mniejszych nie jest już tak szeroko stosowana jak
parę lat temu gdy internet dopiero zaczynał pojawiać się w naszych domach. Głównym powodem jest
postęp technologii i dziś już mało kto posiada łącza 128Kbit/s, wobec czego przesłanie pliku, który
waży nawet kilka GiB nie jest niczym niezwykłym i nie ma potrzeby go dzielić na części. Niemniej
jednak, z jakichś powodów ludzie chcą mieć taką możliwość i zastanawiają się &lt;a href=&#34;https://unix.stackexchange.com/questions/24630/whats-the-best-way-to-join-files-again-after-splitting-them&#34;&gt;jak podzielić plik na
kilka
części&lt;/a&gt;
na jednej maszynie i połączyć je na innym komputerze.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przestrzeń wymiany SWAP jako plik</title>
      <link>https://morfikov.github.io/post/przestrzen-wymiany-swap-jako-plik/</link>
      <pubDate>Thu, 18 Jun 2015 22:11:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przestrzen-wymiany-swap-jako-plik/</guid>
      <description>&lt;p&gt;Każdy system operacyjny musi być przygotowany na ewentualność wyczerpania się pamięci operacyjnej
RAM. W przypadku gdyby nie był, groziłoby mu powieszenie się. Są różne metody ochrony maszyn z
linuxami na pokładzie przed tego typu sytuacją. Jedne z nich zakładają wykorzystanie wbudowanych w
kernel mechanizmów takich jak choćby &lt;a href=&#34;https://pl.wikipedia.org/wiki/Brak_pami%C4%99ci&#34;&gt;oom-killer&lt;/a&gt;,
który ma za zadanie zabijać te najbardziej żarłoczne procesy. Są również bardziej łagodne sposoby na
uchronienie komputera przed zbyt szybkim wyczerpaniem się pamięci i w tym wpisie omówimy sobie
przestrzeń wymiany SWAP.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DNScrypt-proxy, czyli szyfrowanie zapytań DNS</title>
      <link>https://morfikov.github.io/post/dnscrypt-proxy-czyli-szyfrowanie-zapytan-dns/</link>
      <pubDate>Thu, 18 Jun 2015 20:00:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dnscrypt-proxy-czyli-szyfrowanie-zapytan-dns/</guid>
      <description>&lt;p&gt;Do protokołów SSL/TLS w serwisach www chyba wszyscy już przywykli. Obecnie praktycznie na każdej
stronie, gdzie jest okienko logowania, mamy do czynienia z szyfrowaniem danych przesyłanych w
różnego rodzaju formularzach. Co prawda, klucze nie są zbyt długie (512-2048 bitów) ale zawsze to
lepsze niż nic. O ile dane służące do logowania czy też wszelkie operacje dokonywane w panelach
administracyjnych da radę ukryć bez większego problemu, o tyle zapytania DNS są przesyłane otwartym
tekstem i każdy może je sobie podejrzeć. Pytanie tylko, po co szyfrować ruch DNS? Czy są tam
przesyłane jakieś ważne informacje? Jeśli przyjrzymy się jak działa system DNS, możemy dojść do
wniosku, że szyfrowanie zapytań jest pozbawione sensu, bo z reguły nazwa domeny oznacza konkretny
adres IP. Znając adres IP, możemy ustalić kto na jakie strony wchodzi. Nie do końca jest to prawdą,
poza tym istnieją jeszcze inne czynniki, które sprawiają, że ukrycie zapytań DNS ma jak najbardziej
sens. W tym wpisie zaimplementujemy sobie na naszych linux&#39;ach szyfrowanie zapytań DNS przy
wykorzystaniu &lt;a href=&#34;https://dnscrypt.org/&#34;&gt;narzędzia dnscrypt-proxy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Etykieta systemu plików i jej dostosowanie</title>
      <link>https://morfikov.github.io/post/etykieta-systemu-plikow-i-jej-dostosowanie/</link>
      <pubDate>Thu, 18 Jun 2015 18:32:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/etykieta-systemu-plikow-i-jej-dostosowanie/</guid>
      <description>&lt;p&gt;W poprzednim wpisie dostosowywaliśmy &lt;a href=&#34;https://morfikov.github.io
/post/zarezerwowane-miejsce-w-systemie-plikow-ext4/&#34;&gt;zarezerwowane
miejsce&lt;/a&gt; na określonych
partycjach dla systemowych procesów. Okazuje się także, że zmiana etykiety systemu plików może
przysporzyć wiele problemów początkującym użytkownikom linuxa. Choć jeśli chodzi akurat o nadawanie
czy zmianę etykiet, to tutaj już mamy możliwość przeprowadzenia tej operacji z poziomu narzędzi GUI,
takich jak &lt;code&gt;gparted&lt;/code&gt; , z tym, że niektóre jego komunikaty mogą nieco odstraszać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zarezerwowane miejsce w systemie plików ext4</title>
      <link>https://morfikov.github.io/post/zarezerwowane-miejsce-w-systemie-plikow-ext4/</link>
      <pubDate>Thu, 18 Jun 2015 17:29:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zarezerwowane-miejsce-w-systemie-plikow-ext4/</guid>
      <description>&lt;p&gt;Zwykle nie zwracamy uwagi na to jak formatujemy partycje w systemie linux i akceptujemy domyślne
ustawienia jakie przyjęli sobie deweloperzy danej dystrybucji. Nie ma tutaj znaczenia czy
instalujemy świeży system za pośrednictwem instalatora i przy jego pomocy kroimy dysk, czy też
tworzymy partycje indywidualnie już z poziomu jakiegoś zainstalowanego systemu, bądź też płytki czy
pendrive live. Domyślne ustawienia mają spełniać oczekiwania jak największej liczby odbiorców i nie
zawsze nam one odpowiadają. W przypadku formatowania dysku, problematyczne może być rezerwowanie
miejsca dla procesów użytkownika root.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatyczne wylogowanie użytkownika z konsoli</title>
      <link>https://morfikov.github.io/post/automatyczne-wylogowanie-uzytkownika-z-konsoli/</link>
      <pubDate>Wed, 17 Jun 2015 22:06:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/automatyczne-wylogowanie-uzytkownika-z-konsoli/</guid>
      <description>&lt;p&gt;Każdemu z nas zdarzyło się zostawić włączoną konsolę, na której byliśmy zalogowani jako
administrator systemu root. Być może nie zdajemy sobie sprawy jak często potrafimy popełnić tego
typu gafę. Jedną z metod obrony jest oczywiście wyłączenie konta root w systemie i korzystanie z
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Sudo&#34;&gt;sudo&lt;/a&gt;. Ja jednak wolę inne rozwiązanie, które zakłada
ograniczenie czasu bezczynności, po którym to użytkownik zostanie automatycznie wylogowany.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sprawdzanie błędów systemu plików ext4</title>
      <link>https://morfikov.github.io/post/sprawdzanie-bledow-systemu-plikow-ext4/</link>
      <pubDate>Wed, 17 Jun 2015 20:59:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sprawdzanie-bledow-systemu-plikow-ext4/</guid>
      <description>&lt;p&gt;Systemy plików stosuje się dla różnych nośników danych, takich jak dyski twarde, czy pendrive albo
nawet płyty cd/dvd. Z formalnego punktu widzenia, system plików jest to metoda przechowywania danych
i uzyskiwania do nich dostępu. Bez tego mechanizmu, informacje umieszczone na nośniku przypominały
by jedynie ciąg bitów i nie wiedzielibyśmy gdzie zaczyna się jakiś plik i gdzie się on kończy.
Czasami jednak zdarzają się błędy w systemie plików, które mogą doprowadzić do poważnych awarii
systemu operacyjnego. Dlatego też linux co kilkanaście lub kilkadziesiąt uruchomień sprawdza stan
systemu plików na każdej partycji i naprawia ewentualne błędy. W przypadku gdyby nie były one
naprawiane, mogą pojawić się nowe błędy doprowadzając tym samym do całkowitej zapaści systemu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Reinstalacja bootloadera grub</title>
      <link>https://morfikov.github.io/post/reinstalacja-bootloadera-grub/</link>
      <pubDate>Tue, 16 Jun 2015 21:13:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/reinstalacja-bootloadera-grub/</guid>
      <description>&lt;p&gt;Domyślnym bootloaderem w systemie linux jest &lt;a href=&#34;https://www.gnu.org/software/grub/&#34;&gt;grub&lt;/a&gt; i jako, że
to oprogramowanie jest ładowane do pamięci jako pierwsze, ma ono kluczowe zadanie w procesie startu
systemu operacyjnego. Przy jego pomocy możemy także przekazać szereg parametrów dla modułów kernela,
tym samym odpowiednio go konfigurując. Czasem z pewnych przyczyn, najczęściej gdy inny system
nadpisze MBR, system operacyjny nie chce się podnieść i musimy przeinstalować bootloader,
zakładając, że problem tkwi w nim.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konwersja tablicy partycji GPT na MS-DOS</title>
      <link>https://morfikov.github.io/post/konwersja-tablicy-partycji-gpt-na-ms-dos/</link>
      <pubDate>Tue, 16 Jun 2015 20:16:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konwersja-tablicy-partycji-gpt-na-ms-dos/</guid>
      <description>&lt;p&gt;W poprzednim wpisie poruszyłem temat &lt;a href=&#34;https://morfikov.github.io
/post/konwersja-tablicy-partycji-ms-dos-na-gpt/&#34;&gt;konwersji tablicy partycji MS-DOS (MBR) na
GPT&lt;/a&gt;. Jak można było zauważyć, ten
proces nie był skomplikowany i niemalże automatyczny. Nie towarzyszyło mu także zjawisko utraty
jakichkolwiek danych, jedynie w przypadku posiadania systemu operacyjnego, trzeba było
przeinstalować bootloader. Nasuwa się zatem pytanie, czy również w tak prosty sposób można
przerobić tablicę partycji GPT na MS-DOS? Jest to wykonalne z tym, że trzeba odpowiednio
przygotować sobie do tego celu dysk.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konwersja tablicy partycji MS-DOS na GPT</title>
      <link>https://morfikov.github.io/post/konwersja-tablicy-partycji-ms-dos-na-gpt/</link>
      <pubDate>Tue, 16 Jun 2015 19:26:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konwersja-tablicy-partycji-ms-dos-na-gpt/</guid>
      <description>&lt;p&gt;Od jakiegoś czasu nosiłem się z zamiarem utworzenia na swoim dysku tablicy partycji GPT. Problem w
tym, że tam jest wgranych sporo cennych danych i nie mam gdzie ich przenieść. Jedyne co mi wpadło do
głowy to konwersja tablicy MS-DOS (&lt;a href=&#34;https://superuser.com/questions/700770/mbr-equals-msdos-for-gparted&#34;&gt;zwanej też
MBR&lt;/a&gt;) na GPT. Nie żebym jakoś
tego potrzebował ale tak z ciekawości chciałem zobaczyć czy da się to zrobić w sposób łatwy i
bezproblemowy. Z tego co wyczytałem na necie, to taka konwersja nie powinna sprawić problemów,
zarówno przy przechodzeniu z MS-DOS na GPT jak i odwrotnie, choć w tym drugim przypadku trzeba się
trochę bardziej wysilić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bad sektor w dzienniku systemu plików ext4</title>
      <link>https://morfikov.github.io/post/bad-sektor-w-dzienniku-systemu-plikow-ext4/</link>
      <pubDate>Mon, 15 Jun 2015 22:28:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/bad-sektor-w-dzienniku-systemu-plikow-ext4/</guid>
      <description>&lt;p&gt;Parę dni temu opisywałem jak udało mi się &lt;a href=&#34;https://morfikov.github.io
/post/uszkodzony-sektor-na-dysku-i-jego-realokoacja/&#34;&gt;realokować uszkodzony
sektor&lt;/a&gt; z dysku, który już
przepracował dość długi okres czasu. Nie było to znowu jakoś specjalnie trudne, z tym, że cały
problem dotyczył jakiegoś losowego sektora gdzieś w środku partycji. Jako, że domyślnym systemem
plików na linuxie są te z rodziny &lt;code&gt;ext&lt;/code&gt; (ext2, ext3, ext4) , oraz, że &lt;a href=&#34;https://en.wikipedia.org/wiki/Ext3&#34;&gt;trzecia
wersja&lt;/a&gt; tego systemu plików została wyposażona w dziennik
(journal), to trzeba by się zastanowić, co w przypadku gdy taki uszkodzony sektor trafi się właśnie
w dzienniku tego systemu plików?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Keyfile trzymany w głębokim ukryciu</title>
      <link>https://morfikov.github.io/post/keyfile-trzymany-w-glebokim-ukryciu/</link>
      <pubDate>Mon, 15 Jun 2015 19:53:56 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/keyfile-trzymany-w-glebokim-ukryciu/</guid>
      <description>&lt;p&gt;Pisząc ostatni &lt;a href=&#34;https://morfikov.github.io
/post/udev-czyli-jak-pisac-reguly-dla-urzadzen/&#34;&gt;artykuł na temat
udeva&lt;/a&gt; i montowania przy jego
pomocy zaszyfrowanego kontenera, wpadł mi do głowy ciekawy pomysł na trzymanie pliku klucza
(keyfile) w czymś co się potocznie nazywa &amp;quot;głębokim ukryciem&amp;quot;. Z reguły ludzie nie chcą używać haseł
do odblokowywania swoich systemów czy partycji i zamiast nich wolą stosować keyfile, czyli małe
pliki, zwykle o rozmiarze paru KiB, które, jakby nie patrzeć, są dość unikatowe i odporne na ataki
słownikowe czy inne formy przemocy. Jedyny problem z jakim człowiek musi się zmierzyć, to z
zabezpieczeniem takiego keyfile i tutaj sprawa nie wygląda wcale dobrze. Takie pliki klucze są
trzymane zwykle na tym samym urządzeniu, do których mają zapewniać bezpieczny dostęp, a nawet jeśli
nie na tym samym, to w pobliżu takich urządzeń, dając nam tym samym jedynie fałszywe poczucie
bezpieczeństwa.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uszkodzony sektor na dysku i jego realokoacja</title>
      <link>https://morfikov.github.io/post/uszkodzony-sektor-na-dysku-i-jego-realokoacja/</link>
      <pubDate>Mon, 15 Jun 2015 19:18:01 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uszkodzony-sektor-na-dysku-i-jego-realokoacja/</guid>
      <description>&lt;p&gt;Uszkodzone sektory w przypadku dysków HDD, to jak sama nazwa wskazuje, sektory, które z jakichś
przyczyn nie działają tak jak powinny. Doprowadza to z reguły do niestabilności systemu operacyjnego
objawiającej się jego zawieszaniem w momencie próby odczytu danych z takiego padniętego sektora.
Przyczyny mogą być różne. Zwykle jest to jednak fizyczne uszkodzenie powierzchni nośnika, np w
wyniku wstrząsu, czy też zwyczajne zmęczenie materiału. Jest wielce prawdopodobne, że nie jesteśmy w
stanie nic poradzić w tego typu sytuacji, a ci bardziej zaawansowani użytkownicy zalecają jak
najszybszą wymianę dysku, bo pierwszy bad sektor oznacza, że niedługo będzie ich więcej. Czasem
jednak błędy odczytu mogą być programowe, tj. fizycznie każdy sektor jest w porządku ale z jakiegoś
powodu system nie potrafi odczytać z nich danych. Przy odrobinie szczęścia jesteśmy w stanie
odblokować taki sektor.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problematyczny parametr &#34;Offline Uncorrectable&#34;</title>
      <link>https://morfikov.github.io/post/problematyczny-parametr-offline-uncorrectable/</link>
      <pubDate>Mon, 15 Jun 2015 18:30:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problematyczny-parametr-offline-uncorrectable/</guid>
      <description>&lt;p&gt;Udało mi się znaleźć trochę informacji ma temat parametru S.M.A.R.T &lt;code&gt;198&lt;/code&gt; , tj. &lt;code&gt;Offline Uncorrectable&lt;/code&gt; . Wychodzi na to, że część dysków nie resetuje go, nawet po pomyślnym przejściu testu
&lt;code&gt;offline&lt;/code&gt;. Za to demon &lt;code&gt;smartd&lt;/code&gt; domyślnie ma ustawione informowanie o niezerowej wartości tego
atrybutu w logu systemowym i prawdopodobnie chyba nie da się nic zrobić w tej sprawie ale można
poinstruować &lt;code&gt;smartd&lt;/code&gt; by wyrzucał komunikat tylko w przypadku gdy wartość tego atrybutu zostanie
zwiększona w stosunku do wartości zapisanej przy poprzednim skanowaniu, czyli jeśli teraz mamy
wartość, np. &lt;code&gt;2&lt;/code&gt;, to ostrzeżenie pojawi się gdy będzie tam widniało &lt;code&gt;3&lt;/code&gt; i więcej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Suma kontrolna nagranego obrazu .iso</title>
      <link>https://morfikov.github.io/post/suma-kontrolna-nagranego-obrazu-iso/</link>
      <pubDate>Mon, 15 Jun 2015 15:20:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/suma-kontrolna-nagranego-obrazu-iso/</guid>
      <description>&lt;p&gt;Suma kontrolna daje możliwość sprawdzenia czy dane zawarte w pliku nie zostały zmienione podczas
transferu z jednego medium informacyjnego na inne. Jeśli weźmiemy przykład pakietów sieciowych, to
pliki przesyłane między dwoma punktami są dzielone na mniejsze kawałki. W każdym z nich są zawarte
sumy kontrole danych, które zawierają. Komputer odbierający taki pakiet generuje własną sumę
kontrolą i porównuje ją z tą otrzymaną w pakiecie. W przypadku gdy suma kontrolna się nie zgadza,
mamy do czynienia z błędami przesyłu, tj. pakiet został uszkodzony gdzieś po drodze. W tej sytuacji
maszyna odbierająca dane prosi o ponowne przesłanie uszkodzonego segmentu. Ta sytuacja może się
zdarzyć ale błędy są automatycznie naprawiane. Problem jest taki, że przy pobieraniu plików z
internetu nie zawsze korzystamy z bezpiecznych połączeń, poza tym, zawsze ktoś może uzyskać dostęp
do serwera i podmienić pliki. Czy możemy zatem mieć pewność, że dany plik trafił do nas w formie
takiej jak powinien?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>RAM, cache i dirty pages</title>
      <link>https://morfikov.github.io/post/ram-cache-i-dirty-pages/</link>
      <pubDate>Mon, 15 Jun 2015 15:03:21 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ram-cache-i-dirty-pages/</guid>
      <description>&lt;p&gt;Wiele czasu zajęło mi opanowanie w końcu tych bestii zwanych &lt;a href=&#34;https://www.kernel.org/doc/Documentation/sysctl/vm.txt&#34;&gt;dirty
pages&lt;/a&gt;, które to są trzymane w cache pamięci
RAM i potrafią dać się nieźle we znaki, zwłaszcza gdy ma się mało pamięci operacyjnej i maszynę &lt;a href=&#34;https://lwn.net/Articles/572911/&#34;&gt;64
bitową&lt;/a&gt;. Chodzi o to, że podczas kopiowania plików z/na pendrive,
system zaczyna się strasznie przycinać, bo następuje zrzucanie danych innych procesów z RAM do SWAP
by zrobić miejsce pod te dane, które są aktualnie kopiowane.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja GPG w pliku gpg.conf</title>
      <link>https://morfikov.github.io/post/konfiguracja-gpg-w-pliku-gpg-conf/</link>
      <pubDate>Sun, 14 Jun 2015 23:19:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-gpg-w-pliku-gpg-conf/</guid>
      <description>&lt;p&gt;Narzędzie &lt;code&gt;gpg&lt;/code&gt; posiada swój własny plik konfiguracyjnych, który zwykle jest zlokalizowany w
&lt;code&gt;~/.gnupg/gpg.conf&lt;/code&gt; . Można w nim sprecyzować większość z opcji, które zwykle są podawane w
terminalu przy wywoływaniu polecenia &lt;code&gt;gpg&lt;/code&gt; . Po zdefiniowaniu odpowiednich wpisów w pliku
konfiguracyjnym, nie będziemy musieli już wyraźnie podawać tych parametrów ilekroć będziemy chcieli
skorzystać z &lt;code&gt;gpg&lt;/code&gt; . Przy okazji szukania info o kluczach GPG, natknąłem się na dość ciekawy
&lt;a href=&#34;https://riseup.net/security/message-security/openpgp/best-practices&#34;&gt;artykuł na temat GnuPG&lt;/a&gt;. Jest
tam sporo informacji, które są wielce użyteczne w procesie konfiguracji tego narzędzia poprawiając
tym samym dość znacznie bezpieczeństwo komunikacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>UDEV, czyli jak pisać reguły dla urządzeń</title>
      <link>https://morfikov.github.io/post/udev-czyli-jak-pisac-reguly-dla-urzadzen/</link>
      <pubDate>Sun, 14 Jun 2015 18:13:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/udev-czyli-jak-pisac-reguly-dla-urzadzen/</guid>
      <description>&lt;p&gt;Zapuszczając się w coraz to i głębsze warstwy systemu podczas dążenia do zbadania jak on tak
naprawdę działa, zacząłem się stykać z regułami &lt;a href=&#34;https://wiki.archlinux.org/index.php/Udev&#34;&gt;udeva&lt;/a&gt;
(tymi umieszczanymi w katalogu /etc/udev/rules.d/ ). Jako, że nazbierało mi się już ich kilka,
zaistniała potrzeba przebadania tego co ten katalog tak naprawdę zawiera. Na dobrą sprawę nigdy się
nad tym nie zastanawiałem, jedynie kopiowałem rozwiązania z internetu i wklejałem je do
odpowiedniego pliku i jeśli ono działało, to odznaczałem problem jako rozwiązany. Zwykle takich
reguł się nie potrzebuje, temu praktycznie niewielu ludzi w ogóle się orientuje jak ogarnąć tego
całego udeva. Są przypadki kiedy przepisanie nazw urządzeń czy wykonanie określonych akcji po
podłączeniu jakiegoś sprzętu do komputera jest wielce niezbędne i nie ma innej opcji jak tylko
zrozumieć co udev tak naprawdę robi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Obsługa wielu partycji w module loop</title>
      <link>https://morfikov.github.io/post/obsluga-wielu-partycji-w-module-loop/</link>
      <pubDate>Sun, 14 Jun 2015 16:37:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/obsluga-wielu-partycji-w-module-loop/</guid>
      <description>&lt;p&gt;Wszelkie obrazy &lt;code&gt;.iso&lt;/code&gt; płyt cd/dvd czy nawet pliki &lt;code&gt;.img&lt;/code&gt; zawierające strukturę obrazów live możemy
zamontować lokalnie na komputerze uzyskując tym samym dostęp do ich systemu plików. W większości
przypadków, każdy taki obraz zawiera tylko jedną partycję, czasem lekko przesuniętą względem
początku ale generalnie nie ma większych problemów z zamontowaniem tego typu plików. Najwyżej
trzeba podać jeden dodatkowy parametr, tj. &lt;code&gt;offset&lt;/code&gt; . A co w przypadku obrazów dysków, które zwykle
mają więcej niż jedną partycję? Gdybyśmy spróbowali zamontować taki plik w systemie, to zostanie nam
zwrócony błąd, no bo przecież kernel nie wie za bardzo jak taki plik ma odczytać. Możemy za to
skorzystać z urządzeń &lt;code&gt;loop&lt;/code&gt; , które po odpowiedniej konfiguracji, są w stanie nam takie obrazy z
powodzeniem zamontować na naszym linux&#39;ie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru obrazu .img</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-obrazu-img/</link>
      <pubDate>Sun, 14 Jun 2015 13:05:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-obrazu-img/</guid>
      <description>&lt;p&gt;Struktura pliku &lt;code&gt;.img&lt;/code&gt; czy &lt;code&gt;.iso&lt;/code&gt; niczym nie odbiega od struktury przeciętnego dysku twardego. W obu
przypadkach mamy dokładnie taki sam schemat budowy, tj. mamy obecny
&lt;a href=&#34;https://morfikov.github.io
/post/mbr-ebr-i-tablica-partycji-dysku-twardego/&#34;&gt;MBR&lt;/a&gt; i partycje, z których
pierwsza zwykle jest wyrównana do 1MiB, zostawiając tym samym 2047 sektorów wolnego miejsca z
początku pliku, tuż za MBR, tzw. MBR-GAP. Obraz &lt;code&gt;.img&lt;/code&gt; można poddać edycji, np. utworzyć wewnątrz
niego inne partycje, zmienić rozmiar ich systemu plików, a nawet można manipulować rozmiarem samego
obrazu &lt;code&gt;.img&lt;/code&gt; . Taki plik możemy również zamontować w systemie przy pomocy narzędzia &lt;code&gt;mount&lt;/code&gt; ale też
trzeba odpowiednio podejść do tego zadania, bo przez fakt, że mamy z początku MBR i trochę wolnego
miejsca, to linux zwyczajnie nie potrafi rozpoznać systemu plików, który znajduje się w obrazie
&lt;code&gt;.img&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bezpieczny klucz GPG</title>
      <link>https://morfikov.github.io/post/bezpieczny-klucz-gpg/</link>
      <pubDate>Sun, 14 Jun 2015 11:55:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/bezpieczny-klucz-gpg/</guid>
      <description>&lt;p&gt;W poprzednim wpisie przygotowywaliśmy sobie &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-gpg-w-pliku-gpg-conf/&#34;&gt;plik
gpg.conf&lt;/a&gt;. Opcje w nim ustawione są
niezbędne do wygenerowania dobrego pod względem bezpieczeństwa klucza GPG. Taki klucz GPG nie
powinien być krótszy niż 4096 bitów. Dodatkowo, nie powinno się ustawiać daty ważności dłuższej niż
2 lata, a to z tego powodu, że zawszę tę datę można zmienić i to nawet w przypadku gdy klucz straci
ważność. Chodzi generalnie o ustawienie jakiegoś mechanizmu zabezpieczającego na wypadek gdyby nasz
klucz GPG wpadł w niepowołane ręce i stracilibyśmy nad nim panowanie. Wtedy po jakimś czasie
automatycznie się on unieważni i nie będziemy musieli się martwić czy ktoś może przez przypadek go
używać. Jest również szereg innych rzecz, o które powinniśmy się zatroszczyć i tej tematyce będzie
poświęcony ten wpis, który w dużej mierze powstał w oparciu o te
&lt;a href=&#34;https://www.gnupg.org/gph/en/manual/book1.html&#34;&gt;dwa&lt;/a&gt;
&lt;a href=&#34;https://riseup.net/security/message-security/openpgp/best-practices&#34;&gt;linki&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MBR, EBR i tablica partycji dysku twardego</title>
      <link>https://morfikov.github.io/post/mbr-ebr-i-tablica-partycji-dysku-twardego/</link>
      <pubDate>Fri, 12 Jun 2015 18:44:53 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mbr-ebr-i-tablica-partycji-dysku-twardego/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Master_boot_record&#34;&gt;MBR&lt;/a&gt; to pierwszy sektor dysku twardego, który
może ma jedynie 512 bajtów ale jest to bardzo krytyczny obszar nośnika, po którego uszkodzeniu czy
nadpisaniu tracimy dostęp do wszystkich partycji znajdujących się na dysku. Ci bardziej przezorni
użytkownicy robią sobie backup tego kluczowego punktu, tak by w przypadku problemów mogli go sobie
przywrócić. Nie zawsze jednak potrzebujemy przywracać cały sektor MBR, w większości przypadków
będziemy potrzebować jedynie kodu bootloadera lub samej tablicy partycji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Własny system live i tworzenie go od podstaw</title>
      <link>https://morfikov.github.io/post/wlasny-system-live-i-tworzenie-go-od-podstaw/</link>
      <pubDate>Fri, 12 Jun 2015 15:48:19 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wlasny-system-live-i-tworzenie-go-od-podstaw/</guid>
      <description>&lt;p&gt;Jeśli mamy nieco odbiegające od standardowych oczekiwania dotyczące systemów live, np. wynikają one
z braku obecności pewnych pakietów w obrazie wygenerowanym przez developerów jakiejś konkretnej
dystrybucji, to możemy sobie stworzyć własny obraz live, gdzie mamy możliwość dostosowania całej
konfiguracji takiego systemu wliczając w to również i instalację brakujących pakietów. Obrazy, które
są &lt;a href=&#34;https://www.debian.org/CD/live/&#34;&gt;dostępne na stronie debiana&lt;/a&gt;, zawierają wydanie stabilne i jak
wiadomo, nie jest ono zbyt aktualne pod względem oprogramowania. Natomiast jeśli chodzi o tworzenie
własnych obrazów live, to możemy zdefiniować sobie gałąź, z której mają być pobierane pakiety użyte
w procesie budowania, jak i również dograć te pakiety, które nie są w żaden sposób powiązane z daną
dystrybucją.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przygotowanie środowiska chroot do pracy</title>
      <link>https://morfikov.github.io/post/przygotowanie-srodowiska-chroot-do-pracy/</link>
      <pubDate>Thu, 11 Jun 2015 23:24:07 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przygotowanie-srodowiska-chroot-do-pracy/</guid>
      <description>&lt;p&gt;Linuxy mają tę właściwość, że bardzo ciężko jest stracić do któregoś z nich dostęp, nawet w
przypadku kompletnego zawału systemu. Jeżeli dysponujemy jakimś alternatywnym środowiskiem w postaci
płytki live cd/dvd czy pendrive albo też posiadamy gdzieś zainstalowanego innego linuxa, to istnieje
spore prawdopodobieństwo, że uda się nam reanimować nasz główny system. Wszystko za sprawą narzędzia
jakim jest &lt;a href=&#34;https://pl.wikipedia.org/wiki/Chroot&#34;&gt;chroot&lt;/a&gt; , przy którego to pomocy możemy zmienić
główny katalog systemu plików ( &lt;code&gt;/&lt;/code&gt; ) dla wykonywanych procesów bez potrzeby przechodzenia całej
skomplikowanej procedury uruchamiania systemu operacyjnego. Jeśli tylko uda nam się uzyskać dostęp
do shella, to nie ma takiej możliwości by system nie stanął na nogi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Persistence czyli zachowanie zmian w systemie live</title>
      <link>https://morfikov.github.io/post/persistence-czyli-zachowanie-zmian-w-systemie-live/</link>
      <pubDate>Thu, 11 Jun 2015 19:12:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/persistence-czyli-zachowanie-zmian-w-systemie-live/</guid>
      <description>&lt;p&gt;Systemy live mają jedną ale za to dość dającą się odczuć wadę, mianowicie chodzi o to, że po
wypaleniu takiego obrazu, nie mamy możliwości zachowania zmian. Nawet jeśli doinstalujemy nowy
pakiet czy wyedytujemy jakiś plik, to zmiany wprowadzone przez nas są jedynie tymczasowe, bo
dokonywane w pamięci operacyjnej RAM. W efekcie jeśli uruchomimy taki system ponownie, będziemy
zmuszeni przeprowadzać raz jeszcze wszystkie poprzednie czynności pod kątem jego dostosowania. W
przypadku cd/dvd nie mamy praktycznie żadnego pola manewru. Inaczej jednak ma się sprawa jeśli
chodzi o pendrive, bo tutaj możemy utworzyć osobną partycję, gdzie będą przechowywane wszystkie
zmiany jakich dokonamy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Squashfs jako system plików obrazów live</title>
      <link>https://morfikov.github.io/post/squashfs-jako-system-plikow-obrazow-live/</link>
      <pubDate>Thu, 11 Jun 2015 17:06:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/squashfs-jako-system-plikow-obrazow-live/</guid>
      <description>&lt;p&gt;System live to nic innego jak spakowany system plików jakieś zainstalowanej dystrybucji, który
podczas startu maszyny jest montowany w trybie tylko do odczytu, a potrzebne pliki są wypakowywane w
czasie rzeczywistym w pamięci operacyjnej RAM. Do implementacji takiego rozwiązania stosuje się
&lt;a href=&#34;https://pl.wikipedia.org/wiki/SquashFS&#34;&gt;squashfs&lt;/a&gt; i jako, że jest to system plików tylko do
odczytu, nie można go jako tako edytować. Nie jesteśmy też zupełnie na straconej pozycji, bo możemy
skorzystać z dwóch rozwiązań:
&lt;a href=&#34;https://morfikov.github.io
/post/persistence-czyli-zachowanie-zmian-w-systemie-live/&#34;&gt;persistence&lt;/a&gt; lub możemy
pokusić się o przepakowanie systemu plików.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wgrać system live na uszkodzony pendrive</title>
      <link>https://morfikov.github.io/post/jak-wgrac-system-live-na-uszkodzony-pendrive/</link>
      <pubDate>Thu, 11 Jun 2015 14:43:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wgrac-system-live-na-uszkodzony-pendrive/</guid>
      <description>&lt;p&gt;Każdy z nas spotkał się już chyba w swoim życiu z systemami live. To taki wynalazek zawierający
domyślne oprogramowanie, tak skonfigurowane, by system zdołał się odpalić na większość maszyn w ich
pamięci operacyjnej, oczywiście zakładając, że wymagania sprzętowe zostaną zaspokojone, głównie
chodzi o pamięć RAM. Takie systemy live są dostarczane w postaci kilku rodzajów obrazów: iso, hdd
oraz hybryda. Pierwszy z nich zwykle wypala się na płytkach, drugi na pendrive, z kolei hybrydowy
obraz można wgrać na każdy rodzaj urządzenia i nawet wykorzystać w przypadku maszyn wirtualnych i
zwykle spotkamy się z tym ostatnim typem, nawet jeśli plik ma rozszerzenie &lt;code&gt;.iso&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatycznie generowane hasło do serwisu www</title>
      <link>https://morfikov.github.io/post/automatycznie-generowane-haslo-do-serwisu-www/</link>
      <pubDate>Wed, 10 Jun 2015 20:51:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/automatycznie-generowane-haslo-do-serwisu-www/</guid>
      <description>&lt;p&gt;Każdy z nas dla wygody, albo raczej przez lenistwo, stara się nie używać zbyt skomplikowanych haseł.
Zwykle też korzystamy z tego samego hasła do większości kont online w internecie. Jeśli zdarzyło nam
się tworzyć proste, krótkie i do tego łatwe do przewidzenia hasła, np. w oparciu o datę urodzenia
lub inne tego typu informacji, to przydałoby się nieco popracować nad zabezpieczeniami tych poufnych
danych, tak by nie były proste do odgadnięcia czy też i złamania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jedna reguła udev&#39;a realizująca dwa zadania</title>
      <link>https://morfikov.github.io/post/jedna-regula-udeva-realizujaca-dwa-zadania/</link>
      <pubDate>Wed, 10 Jun 2015 10:45:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jedna-regula-udeva-realizujaca-dwa-zadania/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem jak podejść do &lt;a href=&#34;https://morfikov.github.io
/post/udev-czyli-jak-pisac-reguly-dla-urzadzen/&#34;&gt;pisania
reguł&lt;/a&gt; dla
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Udev&#34;&gt;udev&#39;a&lt;/a&gt; . W tamtym przypadku wykorzystywana reguła składała się
tak naprawdę z dwóch mniejszych, z których jedna miała ustawioną zmienną &lt;code&gt;ACTION&lt;/code&gt; na &lt;code&gt;add&lt;/code&gt; , z kolei
zaś druga na &lt;code&gt;remove&lt;/code&gt; i w ten oto sposób pierwsza z nich była aplikowana podczas podłączania
określonego urządzenia do komputera, a druga przy jego odłączaniu. Okazuje się jednak, że dwie
reguły nie są konieczne w przypadku gdy mają one dotyczyć tego samego sprzętu i możemy zamiast nich
stworzyć jedną regułę, która będzie stosowana zarówno przy podłączaniu jak i odłączeniu danego
urządzenia.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dokładna data instalacji systemu linux</title>
      <link>https://morfikov.github.io/post/dokladna-data-instalacji-systemu-linux/</link>
      <pubDate>Mon, 08 Jun 2015 20:21:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dokladna-data-instalacji-systemu-linux/</guid>
      <description>&lt;p&gt;Czy zadawaliście sobie kiedyś pytanie na temat tego jaka jest dokładna data instalacji aktualnie
używanego przez was systemu operacyjnego? To chyba powinna być jedna z podstawowych danych, do
których użytkownik powinien mieć swobodny dostęp, by wiedział kiedy instalował swój system. Jednak
w przypadku linux&#39;a z jakiegoś powodu ciężko jest ten fakt ustalić. Postaramy się zatem ocenić
możliwie dokładnie to kiedy proces instalacji linux&#39;a mógł mieć miejsce.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przecinek vs. kropka na klawiaturze numerycznej</title>
      <link>https://morfikov.github.io/post/przecinek-vs-kropka-na-klawiaturze-numerycznej/</link>
      <pubDate>Mon, 08 Jun 2015 16:02:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przecinek-vs-kropka-na-klawiaturze-numerycznej/</guid>
      <description>&lt;p&gt;Jak możemy &lt;a href=&#34;https://en.wikipedia.org/wiki/Decimal_mark&#34;&gt;przeczytać pod tym linkiem&lt;/a&gt; , zróżnicowanie
pod względem zapisu większych liczb jak i części dziesiętnych różni się w zależności od kraju. Jedne
do oddzielania od siebie tysięcy wykorzystują kropki, inne zaś przecinki i vice versa w przypadku
części niecałkowitej. Nie będę tutaj się rozpisywał na temat wyższości kropki nad przecinkiem, bo
problem dotyczy zupełnie czegoś innego, mianowicie, tego jak system interpretuje znaki pochodzące z
klawiatury numerycznej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klawiatura multimedialna i niedziałające klawisze</title>
      <link>https://morfikov.github.io/post/klawiatura-multimedialna-i-niedzialajace-klawisze/</link>
      <pubDate>Mon, 08 Jun 2015 12:51:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/klawiatura-multimedialna-i-niedzialajace-klawisze/</guid>
      <description>&lt;p&gt;Bardzo ciężko spotkać wypasioną klawiaturę, po której podłączeniu wszystkie przyciski będą
funkcjonować jak należy, a to z tego względu, że nie do końca są one wykrywane przez nasz system.
Zwykle są to klawisze multimedialne lub inne niestandardowe przyciski, które nie pasują do układu
104 klawiszy. W większości przypadków &lt;a href=&#34;https://morfikov.github.io
/post/klawiatura-i-jej-konfiguracja-pod-debianem/&#34;&gt;odpowiednie skonfigurowanie modelu
klawiatury&lt;/a&gt; powinno rozwiązać
nasze problemy. Nie zawsze jednak posiadany przez nas model jest do wyboru. Czasami nawet i jego
wskazanie nie pomaga i najzwyczajniej w świecie niektóre klawisze po prostu nie zostaną wykryte
przez system.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kompaktowanie katalogów w Thunderbird</title>
      <link>https://morfikov.github.io/post/kompaktowanie-katalogow-w-thunderbird/</link>
      <pubDate>Thu, 04 Jun 2015 15:51:37 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kompaktowanie-katalogow-w-thunderbird/</guid>
      <description>&lt;p&gt;Postanowiłem się w końcu wziąć za porządki związane z wiadomościami pocztowymi i RSS&#39;ami, bo katalog
Thunderbird&#39;a już zajmował prawie 650 MiB. Jakby nie patrzeć, to trochę dużo, biorąc pod uwagę, że
są to głównie wiadomości tekstowe. W sumie to miałem tam archiwum wszystkich maili z 4-5 ostatnich
lat i trochę się tego nazbierało. Nie byłoby tego wpisu gdyby nie fakt, że nawet usunięcie 120 tyś.
wiadomości praktycznie nie wpłynęło na zajmowane przez nie przestrzeni na dysku.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uwierzytelniające klucze SSH</title>
      <link>https://morfikov.github.io/post/uwierzytelniajace-klucze-ssh/</link>
      <pubDate>Tue, 02 Jun 2015 15:35:53 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uwierzytelniajace-klucze-ssh/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://wiki.archlinux.org/index.php/SSH_keys&#34;&gt;Klucze SSH&lt;/a&gt; mogą być wykorzystane jako sposób
identyfikacji danej osoby przy logowaniu się do zdalnego serwera SSH. Te klucze zawsze występują w
parach -- jeden prywatny, drugi publiczny. Pierwszy z nich jest znany tylko nam i powinien być
trzymany w sekrecie i pilnie strzeżony. Klucz publiczny z kolei zaś jest przesyłany na każdy serwer
SSH, z którym chcemy się połączyć. Gdy serwer jest w posiadaniu naszego klucza publicznego i widzi
przy tym, że próbujemy nawiązać połączenie, używa on tego klucza by wysłać do nas zapytanie
(challange) -- jest ono zakodowane i musi na nie zostać udzielona odpowiednia odpowiedź, a tej może
dokonać ktoś, kto jest w posiadaniu klucza prywatnego. Nie ma innej opcji by rozkodować wiadomość,
dlatego też nikt inny nie może udzielić na nią prawidłowej odpowiedzi. To rozwiązanie eliminuje
wrażliwość na różne formy podsłuchu -- ten kto nasłuchuje nie będzie w stanie przechwycić pakietów
zawierających hasło, bo ono nie jest nigdy transmitowane prze sieć. No i oczywiście jeśli chodzi o
samo hasło -- odpadają nam ataki typu Brute Force pod kątem jego złamania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DKMS, czyli automatycznie budowane moduły</title>
      <link>https://morfikov.github.io/post/dkms-czyli-automatycznie-budowane-moduly/</link>
      <pubDate>Sat, 30 May 2015 21:05:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dkms-czyli-automatycznie-budowane-moduly/</guid>
      <description>&lt;p&gt;Jeśli zamierzamy kupić sprzęt, który dopiero co trafił na półki w sklepach, to prawdopodobnie zaraz
po podłączeniu go do naszego komputera okaże się, że to urządzenie nie jest nawet wykrywane przez
system operacyjny. W przypadku gdy jego producent zapewnia w miarę przyzwoity support, to być może
problemy, których doświadczamy, zostaną rozwiązane wraz z instalacją najnowszego kernela. Co jednak
w przypadku gdy nawet po aktualizacji kernela nie jesteśmy w stanie odpalić, np. nowo zakupionej
karty WiFi? Jako, że te wszystkie sprzęty działają w oparciu określone moduły, wystarczy taki moduł
pozyskać, skompilować i załadować w systemie. Problem w tym, że z każdą nową wersją jądra
operacyjnego, która trafi do repo debiana, będziemy musieli ręcznie budować moduł na nowo i właśnie
w tym artykule opiszę jak nauczyć system, by sam przeprowadzał tę mozolną czynność bez naszego
udziału.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatyczne wyciszanie dźwięku w PulseAudio</title>
      <link>https://morfikov.github.io/post/automatyczne-wyciszanie-dzwieku-w-pulseaudio/</link>
      <pubDate>Thu, 28 May 2015 11:43:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/automatyczne-wyciszanie-dzwieku-w-pulseaudio/</guid>
      <description>&lt;p&gt;Wszystkie główne dystrybucje, a może raczej ich środowiska graficzne, wykorzystują do odtwarzania
dźwięku &lt;a href=&#34;https://www.freedesktop.org/wiki/Software/PulseAudio/&#34;&gt;serwer PulseAudio&lt;/a&gt; . Niektóre wręcz
są tak z nim zżyte, że nie idzie ich oddzielić od siebie. Ja generalnie uważam, że ten kawałek
oprogramowania jest jak najbardziej przydatny człowiekowi i potrafi realizować kilka kwestii, które
bez niego, albo by nie były możliwe do osiągnięcia, albo trzeba by się natrudzić przy ich
implementacji, np. przesyłanie dźwięku przez sieć. U siebie na debianie nigdy nie miałem większych
problemów z PulseAudio, z kolei zaś te, które się przytrafiały na drodze jego użytkowania, szło w
miarę prosty sposób wyeliminować. Jest jednak jeden problem, z którym prawdopodobnie spotkaliśmy się
wszyscy, przynajmniej jeśli wykorzystujemy mikrofon w stopniu większym niż przeciętny użytkownik
komputera. Chodzi o to, że po odpaleniu pewnych aplikacji (lub też i w trakcie ich działania),
takich jak np. Skype, Mumble, czy TeamSpeak3, dźwięk we wszystkich pozostałych programach potrafi
zwyczajnie zdechnąć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problemy wynikające z używania pliku .htaccess</title>
      <link>https://morfikov.github.io/post/problemy-wynikajace-z-uzywania-pliku-htaccess/</link>
      <pubDate>Tue, 26 May 2015 13:25:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problemy-wynikajace-z-uzywania-pliku-htaccess/</guid>
      <description>&lt;p&gt;Na stronie Apache jest &lt;a href=&#34;http://httpd.apache.org/docs/2.0/howto/htaccess.html#when&#34;&gt;kawałek ciekawego
artykułu&lt;/a&gt; na temat zagrożeń jakie niesie
ze sobą stosowanie pliku &lt;code&gt;.htaccess&lt;/code&gt; w katalogach stron trzymanych na serwerze wwww. Oczywiście, w
pewnych sytuacjach, takich jak np. hostingi, nie będziemy mieć innego wyboru jak zdać się na ten
plik ale jeśli mamy bezpośredni dostęp do konfiguracji Apache, możemy przenieść wszystkie te wpisy z
pliku &lt;code&gt;.htaccess&lt;/code&gt; i poprawić tym bezpieczeństwo witryny jak i po części wydajność samego serwera
www.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wymuszenie SSL/TLS przy pomocy vhost&#39;ów w Apache2</title>
      <link>https://morfikov.github.io/post/wymuszenie-ssl-tls-przy-pomocy-vhostow-apache2/</link>
      <pubDate>Tue, 26 May 2015 11:24:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wymuszenie-ssl-tls-przy-pomocy-vhostow-apache2/</guid>
      <description>&lt;p&gt;Mając na stronie www formularze logowania czy rejestracji (ewentualnie panele administracyjne),
rozmyślnym krokiem jest implementacja protokołu SSL/TLS. Jeśli mamy potrzebę, możemy także pokusić
się o zaszyfrowanie całego ruchu w obrębie naszej witryny. Problem w tym, że odwiedzający naszą
stronę użytkownicy mogą korzystać z linków, czy wpisywać adresy, które nie rozpoczynają się od
&lt;code&gt;https://&lt;/code&gt; , a jedynie od &lt;code&gt;http://&lt;/code&gt; . W takim przypadku, nawet jeśli szyfrujemy ruch w serwisie, to
odwiedzenie tego typu adresu zwróci nam stronę kanałem nieszyfrowanym, co może godzić w
bezpieczeństwo samej strony jak i również w naszą/czyjąś prywatność. W tym krótki artykule
spróbujemy tak skonfigurować serwer Apache2, by przekierował tego typu zapytania i słał je
szyfrowanym tunelem.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Logjam, czyli nowa podatność w SSL/TLS</title>
      <link>https://morfikov.github.io/post/logjam-czyli-nowa-podatnosc-w-ssltls/</link>
      <pubDate>Mon, 25 May 2015 08:12:39 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/logjam-czyli-nowa-podatnosc-w-ssltls/</guid>
      <description>&lt;p&gt;Jak donoszą &lt;a href=&#34;https://blog.cryptographyengineering.com/2015/05/22/attack-of-week-logjam/&#34;&gt;ostatnio&lt;/a&gt;
&lt;a href=&#34;https://niebezpiecznik.pl/post/logjam-nowa-podatnosc-w-protokolach-https-ssh-i-ipsec/&#34;&gt;media&lt;/a&gt;, mamy
kolejną dziurę (&lt;em&gt;&lt;strong&gt;logjam&lt;/strong&gt;&lt;/em&gt;) dotyczącą szyfrowania SSL/TLS, a konkretnie rozchodzi się o
powszechnie stosowany na całym świecie protokół
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Protok%C3%B3%C5%82_Diffiego-Hellmana&#34;&gt;Diffiego-Hellmana&lt;/a&gt; . I znów
jest podobny scenariusz, bo ten problem nie powinien mieć miejsca ale z powodu wstecznej
kompatybilności, tj. zapewnienie wsparcia dla wszystkich tych przestarzałych szyfrów tak by te
przedwieczne systemy/maszyny mogły działać, można doprowadzić do osłabienie mechanizmów, które
powinny być wykorzystywane obecnie. OK, może nie tyle osłabić, co wykorzystać te słabsze
odpowiedniki zamiast tych mocniejszych.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja kluczy GPG w repozytorium GIT</title>
      <link>https://morfikov.github.io/post/implementacja-kluczy-gpg-repozytorium-git/</link>
      <pubDate>Sun, 17 May 2015 21:11:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-kluczy-gpg-repozytorium-git/</guid>
      <description>&lt;p&gt;W tym artykule zostanie przedstawiony sposób na wykorzystanie kluczy GPG w przypadku
przeprowadzanych działań w repozytorium GIT. Będziemy w ten sposób w stanie podpisać swoje commit&#39;y
czy tagi, by było wiadomo, że zmiany, które zostały poczynione pochodzą naprawdę od konkretnego
użytkownika. Oczywiście to może się wydać przesadą dla wielu ludzi ale skoro mamy udostępnioną
możliwość wykorzystania kluczy GPG, to czemu z tej opcji nie skorzystać? Potrzebne będą nam tylko
&lt;a href=&#34;https://morfikov.github.io
/post/bezpieczny-klucz-gpg/&#34;&gt;klucze GPG&lt;/a&gt;. Sposób ich tworzenia jak i &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-gpg-w-pliku-gpg-conf/&#34;&gt;konfiguracja
zdefiniowana w pliku gpg.conf&lt;/a&gt; nie
zostaną tutaj opisane. Zamiast tego skupimy się jedynie na implementacji samych kluczy GPG.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Github z obsługą kluczy SSH</title>
      <link>https://morfikov.github.io/post/github-z-obsluga-kluczy-ssh/</link>
      <pubDate>Sun, 17 May 2015 21:06:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/github-z-obsluga-kluczy-ssh/</guid>
      <description>&lt;p&gt;W końcu przyszedł czas na eksperymenty z serwisem github. Jakby nie patrzeć, do tej pory jedyne co
potrafiłem zrobić w przypadku samego gita, to wydać jedno polecenie, którym było &lt;code&gt;git clone&lt;/code&gt; .
Wszelkie inne rzeczy, choć nie było ich wcale tak dużo, robiłem via panel www, co trochę było
upierdliwe. Postanowiłem nauczyć się obsługi gita i nieco uprościć sobie życie. Jeśli chodzi o samą
naukę, to tutaj jest dostępny &lt;a href=&#34;https://git-scm.com/book/en/v2&#34;&gt;dość obszerny pdf&lt;/a&gt; (prawie 500
stron). Nie będę tutaj przerabiał wyżej podlinkowanej książki, bo w sumie jeszcze jej nie
przeczytałem, tylko zajmę się ciekawym tematem jakim jest implementacja kluczy SSH, tak by operować
na gicie bez zbędnych haseł.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Skryptowa nakładka na kernelowski moduł ZRAM</title>
      <link>https://morfikov.github.io/post/skryptowa-nakladka-na-kernelowski-modul-zram/</link>
      <pubDate>Sun, 17 May 2015 21:01:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/skryptowa-nakladka-na-kernelowski-modul-zram/</guid>
      <description>&lt;p&gt;ZRAM to moduł kernela, który tworzy wirtualne urządzenia w pamięci operacyjnej komputera, a te z
kolei można wykorzystać pod system plików lub też i pod przestrzeń wymiany SWAP. Dane w takim
urządzeniu są kompresowane, dzięki czemu mamy do dyspozycji więcej miejsca w pamięci. Jeśli mamy
niepierwszej jakości dysk twardy, lub też wykorzystujemy szyfrowanie i nie mamy przy tym procka ze
wsparciem dla AES, to operacje zapisu/odczytu mogą zająć wieki. Możemy w dość znacznym stopniu
odciążyć dysk przenosząc pliki do pamięci RAM, który jest o wiele szybszy, no i dane w nim nie
podlegają szyfrowaniu. Jeśli mamy dużo pamięci operacyjnej, to ZRAM raczej będzie zbędny i tylko
podniesie nam rachunek za prąd. Natomiast jeśli nasz komputer nie szasta zbytnio pamięcią, możemy
rozszerzyć ją 2-3 krotnie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bezpieczeństwo Xserver&#39;a pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/bezpieczenstwo-xservera-pod-linuxem/</link>
      <pubDate>Sat, 09 May 2015 17:21:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/bezpieczenstwo-xservera-pod-linuxem/</guid>
      <description>&lt;p&gt;Prawdopodobnie każdy z nas korzysta, lub też i korzystał, ze skrótu klawiszy Ctrl-Alt-Backspace do
resetowania środowiska graficznego na linux&#39;ie. Może i to jest wygodny sposób na szybki restart
&lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-xservera-na-debianie-xorg/&#34;&gt;sesji graficznej Xserver&#39;a&lt;/a&gt; ale
&lt;a href=&#34;https://www.jwz.org/xscreensaver/faq.html#no-ctl-alt-bs&#34;&gt;nie do końca jest on bezpieczny&lt;/a&gt;. Nie
mówię tutaj o samej utracie danych towarzyszącej takiej akcji ale o możliwości obejścia ekranu
logowania o ile ta kombinacja klawiszy nie jest wyłączona. Jest też kilka innych rzeczy, które mogą
skompromitować źle zabezpieczony Xserver i tej kwestii będzie poświęcony niniejszy wpis.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>