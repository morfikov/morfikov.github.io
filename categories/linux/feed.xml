<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linux on Morfitronik</title>
    <link>https://morfikov.github.io/categories/linux/</link>
    <description>Recent content in Linux on Morfitronik</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pl-PL</language>
    <lastBuildDate>Wed, 02 Sep 2020 18:36:00 +0200</lastBuildDate><atom:link href="https://morfikov.github.io/categories/linux/feed.xml" rel="self" type="application/rss" />
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak zmusić jeden proces do korzystania z VPN na linux (OpenVPN)</title>
      <link>https://morfikov.github.io/post/jak-zmusic-jeden-proces-do-korzystania-z-vpn-na-linux-openvpn/</link>
      <pubDate>Wed, 02 Sep 2020 18:36:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zmusic-jeden-proces-do-korzystania-z-vpn-na-linux-openvpn/</guid>
      <description>&lt;p&gt;Parę dni temu &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=31514&#34;&gt;na forum dug.net.pl pojawiło się zapytanie&lt;/a&gt; dotyczące skonfigurowania linux&#39;a w
taki sposób, by ten umożliwił pojedynczemu procesowi w systemie (i tylko jemu) korzystanie z VPN,
podczas gdy wszystkie pozostałe aplikacje korzystają ze standardowego łącza internetowego naszego
ISP. Oczywiście to niekoniecznie musi być tylko jeden proces, bo to zagadnienie można rozciągnąć
też na większą grupę procesów jednego lub więcej użytkowników. By to zadanie zrealizować, trzeba
zdać sobie sprawę z faktu, że każdy proces w linux ma swojego właściciela, a ten właściciel
przynależy do co najmniej jednej grupy. Dzięki takiemu rozwiązaniu, każdy proces w systemie ma
przypisany m.in. identyfikator użytkownika (UID) oraz identyfikatory grup (GID), z którymi działa i
na podstawie których to linux przyznaje uprawienia dostępu do różnych części systemu, np. urządzeń
czy plików na dysku. W ten sposób możemy bardzo prosto ograniczyć dostęp do określonych zasobów
konkretnym użytkownikom (bardziej ich procesom). Problem się zaczyna w przypadku sieci, gdzie w
zasadzie dostęp do internetu ma domyślnie przyznany każdy proces. Naturalnie możemy skonfigurować
filtr pakietów i zezwolić tylko części aplikacji na dostęp do sieci ale w dalszym ciągu, gdy tylko
odpalimy VPN (w tym przypadku OpenVPN), to każdy proces mający prawo wysyłać pakiety sieciowe
będzie je przesyłał z automatu przez VPN, jak tylko to połączenie zostanie zestawione. Istnieje
jednak sposób, by nauczyć linux&#39;a aby tylko procesy określonych użytkowników czy grup miały dostęp
do VPN i gdy to połączenie zostanie zerwane, to te procesy nie będą mogły korzystać ze
standardowego łącza internetowego. Trzeba jednak zaprzęgnąć do pracy &lt;code&gt;iptables&lt;/code&gt; / &lt;code&gt;nftables&lt;/code&gt; ,
tablice routingu oraz nieco inaczej skonfigurować klienta OpenVPN.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Zarządzanie Raspberry Pi 4B z LibreELEC przez VNC/SPICE</title>
      <link>https://morfikov.github.io/post/zarzadzanie-raspberry-pi-4b-z-libreelec-przez-vnc-spice/</link>
      <pubDate>Tue, 25 Aug 2020 20:08:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/zarzadzanie-raspberry-pi-4b-z-libreelec-przez-vnc-spice/</guid>
      <description>&lt;p&gt;Do konfiguracji &lt;a href=&#34;https://libreelec.tv/&#34;&gt;systemu LibreELEC&lt;/a&gt;, który jest zainstalowany na moim Raspberry Pi 4B nie
potrzebuję żadnego monitora czy wyświetlacza, a wszystkie prace administracyjne związane z tym
małym komputerem ogarniam po SSH. Niemniej jednak, są pewne rzeczy, których się po SSH nie da
skonfigurować. Chodzi generalnie o konfigurację Kodi i sprawy związane z domowa wideoteką. Ten
Raspberry Pi 4B jest podłączony do TV, zatem bez problemu można przez graficzny interfejs Kodi
skonfigurować to, co potrzeba. Niemniej jednak konfigurowanie Kodi przez aplikację na Androida
(&lt;a href=&#34;https://kodi.wiki/view/Kore&#34;&gt;Kore&lt;/a&gt;) nie należy do najłatwiejszych zadań. Nie uśmiecha mi się też ciągle latać z myszą i
klawiaturą w celu podłączania ich do portów USB maliny. Nie mam też w zasadzie zewnętrznego
monitora HDMI, bo od lat używam jedynie laptopów. Pomyślałem zatem, by zrobić użytek z protokołu
&lt;a href=&#34;https://en.wikipedia.org/wiki/Virtual_Network_Computing&#34;&gt;VNC&lt;/a&gt;/&lt;a href=&#34;https://en.wikipedia.org/wiki/Simple_Protocol_for_Independent_Computing_Environments&#34;&gt;SPICE&lt;/a&gt; i przesłać obraz z Raspberry Pi 4B przez sieć do mojego laptopa. W ten sposób
odpadłoby mi ciągłe przemieszczanie się między pokojami i byłbym w stanie podejrzeć obraz TV na
ekranie monitora w moim laptopie przy jednoczesnym zachowaniu możliwości używania myszy i
klawiatury, co by mi bardzo zaoszczędziło czas przy konfiguracji Kodi.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Raspberry Pi, LibreELEC, Kodi i zdalne logi via rsyslog</title>
      <link>https://morfikov.github.io/post/raspberry-pi-libreelec-kodi-i-zdalne-logi-via-rsyslog/</link>
      <pubDate>Tue, 25 Aug 2020 19:21:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/raspberry-pi-libreelec-kodi-i-zdalne-logi-via-rsyslog/</guid>
      <description>&lt;p&gt;Parę lat temu, gdy pojawił się u mnie w domu bezprzewodowy router WiFi, postanowiłem wgrać na niego
linux&#39;a w postaci OpenWRT. Pierwszym kluczowym elementem konfiguracyjnym tego urządzenia było
&lt;a href=&#34;https://morfikov.github.io
/post/logread-czyli-system-logowania-w-openwrt/&#34;&gt;przesłanie jego logów systemowych przez sieć&lt;/a&gt; do mojego laptopa, tak by wszystkie
zarejestrowane komunikaty zostały wyświetlone na konsoli mojego komputera z zainstalowanym Debianem.
W ten sposób nie musiałem się co chwila logować na router po SSH (czy też przez panel webowy), by
sprawdzić czy aby na pewno z tym urządzeniem jest wszystko w porządku. Teraz, po nabyciu Raspberry
Pi 4B i wgraniu na niego &lt;a href=&#34;https://libreelec.tv/&#34;&gt;LibreELEC&lt;/a&gt; z preinstalowanym Kodi, mam dokładnie to samo zadanie do
zrealizowania. Trzeba zatem znaleźć sposób na przesłanie wszystkich logów generowanych przez system
LibreELEC do demona &lt;code&gt;rsyslogd&lt;/code&gt; , który jest uruchomiony na zdalnej maszynie.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak włączyć stabilne adresy prywatne w IPv6 na linux</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-stabilne-adresy-prywatne-w-ipv6-na-linux/</link>
      <pubDate>Wed, 19 Aug 2020 19:31:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-stabilne-adresy-prywatne-w-ipv6-na-linux/</guid>
      <description>&lt;p&gt;Jakiś już czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/jak-wlaczyc-ipv6-privacy-extensions-w-debianie-slaac/&#34;&gt;jak włączyć rozszerzenia prywatności IPv6 na Debianie&lt;/a&gt; (IPv6
Privacy Extensions) w przypadku korzystania z mechanizmu automatycznej konfiguracji adresacji
hostów SLAAC (StateLess Address AutoConfiguration). Miało to za zadanie poprawić nieco prywatność
osób podłączonych do internetu za sprawą protokołu IPv6, bo generowane adresy IP standardowo
zawierają adresy MAC kart sieciowych (&lt;a href=&#34;https://en.wikipedia.org/wiki/MAC_address&#34;&gt;identyfikator EUI64&lt;/a&gt;). Parę dni temu dowiedziałem się, że
w linux można również aktywować inny mechanizm zwany stabilnymi adresami prywatnymi
(&lt;a href=&#34;https://tools.ietf.org/html/rfc7217&#34;&gt;stable-privacy addresses&lt;/a&gt;), które to wykorzystują inny system przy generowaniu identyfikatorów
interfejsów sieciowych. Ten mechanizm sprawia, że część adresu IPv6 odpowiedzialna za identyfikację
hosta ma losowe, choć stabilne wartości, które nie mają nic wspólnego z adresem MAC karty sieciowej
naszego komputera. W ten sposób możemy ukrócić śledzenie nas w sieci na podstawie adresu IPv6.
Poniższy artykuł ma za zadanie pomóc skonfigurować nam te stabilne adresy prywatne na linux oraz
pokazać w jaki sposób są one w stanie pomóc naszej prywatności.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak odszyfrować linux&#39;a przy pomocy telefonu z Androidem</title>
      <link>https://morfikov.github.io/post/jak-odszyfrowac-linux-przy-pomocy-telefonu-z-androidem/</link>
      <pubDate>Sat, 15 Aug 2020 02:43:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-odszyfrowac-linux-przy-pomocy-telefonu-z-androidem/</guid>
      <description>&lt;p&gt;Zaszyfrowane systemy (desktopy/laptopy) mają jeden poważny problem, gdy chodzi o zapewnianie
bezpieczeństwa chronionym plikom przechowywanym na dyskach twardych. Gdy siedzimy obok naszej
maszyny, możemy czuć się bezpiecznie, bo przecież nikt nie może się włamać do jej systemu bez
naszej wiedzy. Nawet jeśli ktoś będzie próbował się dostać do naszego PC, to istnieje spora szansa,
że takie działanie zostałoby natychmiast przez nas wykryte, przez co moglibyśmy w odpowiedni sposób
zareagować na zaistniałe zagrożenie. Co jednak w przypadku, gdy zostawiamy przykładowo naszego
laptopa samego? Nawet jeśli zablokujemy mu ekran, wyłączymy go albo zahibernujemy, to ta maszyna
wciąż nie jest odpowiednio zabezpieczona, by uniemożliwić osobom postronnym dostęp do naszych
wrażliwych danych. Problem leży w fizycznym dostępie do sprzętu, który ludzie mogą uzyskać, gdy nas
nie ma w pobliżu naszego komputera. W taki sposób osoby trzecie mogą wykorzystać fakt, że tracimy
maszynę z oczu i być w stanie zastawić na nas różne pułapki. By uniknąć zagrożenia związanego z
zostawieniem laptopa/desktopa bez nadzoru, nie możemy w zasadzie pozostawiać tego urządzenia samego,
co jest zadaniem praktycznie nie do wykonania. Komputery stacjonarne czy nawet laptopy nie są
urządzeniami o małych gabarytach i zwykle nie możemy ich wszędzie zabrać ze sobą, w przeciwieństwie
do smartfonów. Postanowiłem zatem tak skonfigurować swojego linux&#39;a, by jego zaszyfrowany dysk
(LUKS + LVM) można było odszyfrować jedynie przy pomocy mojego telefonu z Androidem, z którym w
zasadzie się nie rozstaję.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Migracja bloga z Jekyll na Hugo i jego publikacja w GitHub Pages</title>
      <link>https://morfikov.github.io/post/migracja-bloga-z-jekyll-na-hugo-i-jego-publikacja-w-github-pages/</link>
      <pubDate>Thu, 13 Aug 2020 23:50:00 +0200</pubDate>
      
      <guid>https://morfikov.github.io/post/migracja-bloga-z-jekyll-na-hugo-i-jego-publikacja-w-github-pages/</guid>
      <description>&lt;p&gt;Prawdopodobnie zauważyliście drobne zmiany w wyglądzie tego bloga oraz pewnie też cześć osób miała
w ostatnim czasie problemy z uzyskaniem do niego dostępu. Odpowiedzialne za zaistniałą sytuację są
&lt;a href=&#34;https://docs.github.com/en/github/working-with-github-pages/about-github-pages#usage-limits&#34;&gt;limity narzucone przez GitHub Pages&lt;/a&gt;. Zakładają one maksymalny rozmiar repozytorium pod stronę
WWW w granicach 1 GiB oraz czas budowania takiego serwisu krótszy niż 10 minut. Limit miejsca na
pliki przekroczony został w zasadzie w chwili przeniesienia bloga WordPress na GitHub Pages.
Natomiast parę dni temu został przekroczony limit czasu budowania tego projektu. Do momentu
transformacji, niniejszy blog działał w oparciu o &lt;a href=&#34;https://jekyllrb.com/&#34;&gt;Jekyll&lt;/a&gt;, który generował w zasadzie statyczny
kod HTML ze zwykłych plików tekstowych (np. artykuły pisane w &lt;a href=&#34;https://www.markdownguide.org/&#34;&gt;MarkDown&lt;/a&gt;). &lt;a href=&#34;https://pages.github.com/&#34;&gt;GitHub Pages
posiada wsparcie dla Jekyll&lt;/a&gt;, przez co taką stronę WWW można bardzo prosto wdrożyć. Niemniej
jednak, cały ten mechanizm generowania projektu w obrębie infrastruktury GitHub&#39;a zajmuje bardzo
dużo czasu. Po rozmowie z supportem okazało się, że gdyby chodziło o miejsce na pliki, to mogli by
nagiąć reguły i nie było by problemu ale nie dadzą rady tego zrobić w przypadku przekroczenia czasu
generowania projektu. Dlatego też trzeba było zrezygnować z Jekyll&#39;a i poszukać dla niego jakiejś
alternatywy. Padło na &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;, który w odróżnieniu od Jekyll&#39;a nie jest jako tako wspierany przez
GitHub i by &lt;a href=&#34;https://gohugo.io/hosting-and-deployment/hosting-on-github/&#34;&gt;stronę wygenerowaną przez Hugo podpiąć pod GitHub Pages&lt;/a&gt; trzeba się trochę wysilić,
bo ten proces nie jest automatyczny i właśnie o tym jak dokonać migracji z Jekyll na Hugo w
kontekście GitHub Pages będzie ten poniższy artykuł.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak włączyć w Firefox ESNI (Encrypted SNI)</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-w-firefox-esni-encrypted-sni/</link>
      <pubDate>Mon, 10 Aug 2020 18:15:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-w-firefox-esni-encrypted-sni/</guid>
      <description>&lt;p&gt;Obecnie szyfrowanie zapytań DNS staje się powoli normą za sprawą protokołu DoH (&lt;a href=&#34;https://en.wikipedia.org/wiki/DNS_over_HTTPS&#34;&gt;DNS over HTTPS&lt;/a&gt;)
lub DoT (&lt;a href=&#34;https://en.wikipedia.org/wiki/DNS_over_TLS&#34;&gt;DNS over TLS&lt;/a&gt;). Można by zatem pomyśleć, że wraz z implementacją szyfrowania tego
kluczowego dla działania internetu protokołu (przynajmniej z naszego ludzkiego punktu widzenia),
poprawie ulegnie również nasza prywatność w kwestii odwiedzanych przez nas stron WWW. Niemniej
jednak, w dalszym ciągu można bez problemu wyciągnąć adresy domen, które zamierzamy odwiedzić. Nie
ma przy tym żadnego znaczenia ile stron jest hostowanych na danym adresie IP, ani nawet fakt, że
ruch do serwera WWW będzie szyfrowany (w pasku adresu wpiszemy &lt;code&gt;https://&lt;/code&gt; ) z wykorzystaniem
protokołu SSL/TLS (w tym również TLS v1.3). Wszystko przez rozszerzenie SNI (&lt;a href=&#34;https://en.wikipedia.org/wiki/Server_Name_Indication&#34;&gt;Server Name
Indication&lt;/a&gt;), którego to zadaniem jest umożliwienie jednemu serwerowi na prezentowanie wielu
certyfikatów hostowanych w jego obrębie domen. Dzięki takiemu rozwiązaniu, każda domena może
szyfrować ruch niezależnie od siebie na linii serwer&amp;lt;-&amp;gt;klient (używać innych kluczy szyfrujących).
Niemniej jednak, podczas nawiązywania szyfrowanego połączenia, w pakiecie ClientHello przesyłanym
do takiego serwera musi znaleźć się nazwa domeny, której to certyfikat serwer będzie musiał nam
przedstawić. Niestety ten pakiet jest przesyłany przez sieć otwartym tekstem, przez co każdy, kto
podsłuchuje naszą komunikację (w tym też nasz ISP), bez problemu może ustalić na jakie strony
internetowe wchodzimy. Ostatnimi czasy jednak pojawiły się dwa rozszerzenia ECH (&lt;a href=&#34;https://en.wikipedia.org/wiki/Server_Name_Indication#Encrypted_Client_Hello&#34;&gt;Encrypted Client
Hello&lt;/a&gt;) oraz ESNI (&lt;a href=&#34;https://tools.ietf.org/html/draft-ietf-tls-esni-07&#34;&gt;Encrypted SNI&lt;/a&gt;), które mają zaadresować problemy związane z prywatnością
przez pełne zaszyfrowanie pakietu ClientHello lub też zaszyfrowanie jedynie pola SNI w tym pakiecie.
Póki co, prace nad tymi rozszerzeniami nie są jeszcze skończone ale Firefox w połączeniu z
CloudFlare powoli testują ESNI. Postanowiłem zatem dobrowolnie przyłączyć się do grupy testerów i
wdrożyć na swoim linux&#39;ie to rozszerzenie ESNI dla przeglądarki Firefox.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak zmienić rozmiar obrazu maszyny wirtualnej QEMU/KVM</title>
      <link>https://morfikov.github.io/post/jak-zmienic-rozmiar-obrazu-maszyny-wirtualnej-qemu-kvm/</link>
      <pubDate>Sun, 09 Aug 2020 13:45:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zmienic-rozmiar-obrazu-maszyny-wirtualnej-qemu-kvm/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio &lt;a href=&#34;https://morfikov.github.io
/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/&#34;&gt;maszynami wirtualnymi na bazie QEMU/KVM&lt;/a&gt;, zauważyłem, że sugerowany rozmiar
pliku &lt;code&gt;.qcow2&lt;/code&gt; waha się w okolicach 25 GiB. Nie jest to może jakoś specjalnie dużo ale mało to też
nie jest, zwłaszcza jeśli tworzymy maszyny wirtualne na dysku swojego laptopa. Co jeśli
przeholowaliśmy z szacunkami co do rozmiaru takiego obrazu i po zainstalowaniu systemu operacyjnego
gościa okazało się, że w sumie to ten obraz można by zmniejszyć o połowę? Albo też i w drugą stronę,
tj. co w przypadku, gdy stworzony obraz maszyny wirtualnej okazał się zbyt mały i teraz zachodzi
potrzeba jego powiększenia? Czy w takiej sytuacji musimy na nowo tworzyć maszynę wirtualną
odpowiednio zwiększając lub zmniejszając jej przestrzeń na pliki? A może istnieje jakiś sposób na
zmianę rozmiaru tych istniejących już obrazów maszyn wirtualnych? Postaramy się ten fakt
zweryfikować, a cały proces zostanie opisany przy wykorzystaniu systemu Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Konfiguracja HugePages pod maszyny wirtualne QEMU/KVM</title>
      <link>https://morfikov.github.io/post/konfiguracja-hugepages-pod-maszyny-wirtualne-qemu-kvm/</link>
      <pubDate>Sun, 09 Aug 2020 11:11:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-hugepages-pod-maszyny-wirtualne-qemu-kvm/</guid>
      <description>&lt;p&gt;W linux rozmiar stron pamięci operacyjnej RAM ma domyślnie 4096 bajtów (4 KiB). Maszyny wirtualne
QEMU/KVM mają to do siebie, że wykorzystują dość spore zasoby pamięci (wile GiB), przez co mały
rozmiar strony może niekorzystnie wpływać na wydajność systemów gościa. Chodzi generalnie o to, że
rozrostowi ulega tablica stron, której przeszukiwanie jest czasochłonną operacją. By temu zaradzić,
wymyślono TLB (&lt;a href=&#34;https://en.wikipedia.org/wiki/Translation_lookaside_buffer&#34;&gt;Translation Lookaside Buffer&lt;/a&gt;), który ulokowany jest albo w CPU albo gdzieś
pomiędzy CPU i główną pamięcią operacyjną. TLB to mały ale za to bardzo szybki cache. W przypadku
systemów z duża ilością pamięci RAM, niewielki rozmiar TLB sprawia, że odpowiedzi na zapytania nie
są brane z cache, tylko system wraca do przeszukiwania normalnej tablicy stron zlokalizowanej w
pamięci RAM (TLB miss). Taka sytuacja jest bardzo kosztowna, spowalnia cały system i dlatego trzeba
jej unikać. Na szczęście jest &lt;a href=&#34;https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt&#34;&gt;mechanizm HugePages&lt;/a&gt;, który pozwala na zwiększenie rozmiaru
strony pamięci z domyślnych 4 KiB do 2 MiB lub nawet do 1 GiB w zależności od właściwości głównego
procesora. W tym artykule postaramy się skonfigurować HugePages na potrzeby maszyn wirtualnych dla
systemu Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Wirtualizacja QEMU/KVM (libvirt) na Debian Linux</title>
      <link>https://morfikov.github.io/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/</link>
      <pubDate>Sat, 08 Aug 2020 14:55:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/</guid>
      <description>&lt;p&gt;Prawdopodobnie dla większości użytkowników linux&#39;a, wirtualizacja kojarzy się w zasadzie z jednym
oprogramowaniem, tj. VirtualBox. &lt;a href=&#34;https://www.virtualbox.org/&#34;&gt;Niby strona VBox&#39;a podaje, że jest on na licencji GPL-2&lt;/a&gt; ale
w Debianie nie ma go w głównym repozytorium (jest on obecny w sekcji &lt;code&gt;contrib&lt;/code&gt; ). Problem z
VirtualBox&#39;em jest taki, że &lt;a href=&#34;https://salsa.debian.org/pkg-virtualbox-team/virtualbox/-/blob/master/debian/copyright&#34;&gt;wymaga on kompilatora Open Watcom&lt;/a&gt;, który już wolnym
oprogramowaniem nie jest. VBox też nie jest jedynym oprogramowaniem, które na linux można
wykorzystać w roli hiperwizora do obsługi maszyn wirtualnych. Jest o wiele lepsze rozwiązanie,
mianowicie QEMU, które jest w stanie zrobić użytek z maszyny wirtualnej kernela (Kernel Virtual
Machine, KVM) i realizować dokładnie to samo zadanie, które zwykł ogarniać VirtualBox.
Wirtualizacja na bazie QEMU/KVM jest w pełni OpenSource, co ucieszy pewnie fanów wolnego i
otwartego oprogramowania, choć zarządzanie maszynami wirtualnymi odbywa się za sprawą konsoli.
Oczywiście, osoby które korzystają z VirtualBox&#39;a zdają sobie sprawę, że to narzędzie oferuje
graficzny menadżer maszyn wirtualnych (Virtual Machine Manager, VMM), który usprawnia i znacznie
ułatwia zarządzanie wirtualnymi maszynami. Jeśli GUI jest dla nas ważnym elementem środowiska pracy
i nie uśmiecha nam się konfigurować maszyn wirtualnych przy pomocy terminala, to jest i dobra
wiadomość dla takich osób, bo istnieje &lt;code&gt;virt-manager&lt;/code&gt; , który jest dość rozbudowanym menadżerem
maszyn wirtualnych pozwalającym na ich tworzenie, konfigurowanie i zarządzanie nimi przy
wykorzystaniu graficznego interfejsu użytkownika. W tym artykule postaramy się skonfigurować
naszego Debiana w taki sposób, by przygotować go do pracy z maszynami wirtualnymi posługując się
&lt;code&gt;qemu&lt;/code&gt;/&lt;code&gt;libvirt&lt;/code&gt;/&lt;code&gt;virt-manager&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>BootHole nie taki straszny, o ile ma się własne klucze EFI/UEFI</title>
      <link>https://morfikov.github.io/post/boothole-nie-taki-straszny-o-ile-ma-sie-wlasne-klucze-efi-uefi/</link>
      <pubDate>Fri, 31 Jul 2020 21:07:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/boothole-nie-taki-straszny-o-ile-ma-sie-wlasne-klucze-efi-uefi/</guid>
      <description>&lt;p&gt;Dnia 29-07-2020 do publicznej wiadomości zostały podane informacje na temat podatności BootHole,
która to za sprawą bootloader&#39;a GRUB2 w różnych dystrybucjach linux&#39;a jest w stanie obejść
mechanizm bezpieczeństwa EFI/UEFI, tj. Secure Boot. &lt;a href=&#34;https://www.debian.org/security/2020-GRUB-UEFI-SecureBoot/&#34;&gt;Z informacji&lt;/a&gt;, które opublikował Debian,
sprawa nie wygląda miło jako, że poza aktualizacją GRUB2, shim, jądra linux, Fwupdate oraz Fwupd,
unieważnieniu podlegają również klucze dystrybucji Debian/Ubuntu, przez co praktycznie cały soft
podpisany tymi kluczami (w tym systemy live) przestaną działać w trybie Secure Boot. Czy jest się
czego obawiać i co użytkownik korzystający z mechanizmu SB powinien w takiej sytuacji zrobić?&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Problem z aktualizacją zmiennych PK, KEK, db i dbx via efi-updatevar</title>
      <link>https://morfikov.github.io/post/problem-z-aktualizacja-zmiennych-pk-kek-db-dbx-efi-updatevar/</link>
      <pubDate>Thu, 30 Jul 2020 20:30:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problem-z-aktualizacja-zmiennych-pk-kek-db-dbx-efi-updatevar/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/&#34;&gt;konfigurację własnych kluczy EFI/UEFI&lt;/a&gt;, którymi można zastąpić te
wbudowane standardowo w firmware naszego komputera. W tamtym artykule napotkałem jednak dość dziwny
problem, za sprawą którego nie można było zaktualizować zmiennych &lt;code&gt;PK&lt;/code&gt; , &lt;code&gt;KEK&lt;/code&gt; , &lt;code&gt;db&lt;/code&gt; i &lt;code&gt;dbx&lt;/code&gt; przy
pomocy &lt;code&gt;efi-updatevar&lt;/code&gt; z poziomu działającego linux&#39;a. Gdy próbowało się te zmienne przepisać,
dostawało się błąd typu &lt;code&gt;Operation not permitted&lt;/code&gt; . Niby system został uruchomiony w trybie &lt;code&gt;Setup Mode&lt;/code&gt; ale z jakiegoś powodu odmawiał on współpracy i trzeba było te zmienne aktualizować
bezpośrednio z poziomu firmware EFI/UEFI, co było trochę upierdliwe. Szukając wtedy informacji na
ten temat, jedyne co znalazłem, to fakt, że sporo osób ma podobny problem i najwyraźniej firmware
mojego laptopa jest ździebko niedorobiony, przez co &lt;code&gt;efi-updatevar&lt;/code&gt; nie mógł realizować swojego
zdania. Rzeczywistość okazała się nieco inna, a rozwiązanie samego problemu było wręcz banalne.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Czym jest linux kernel driver binding</title>
      <link>https://morfikov.github.io/post/czym-jest-linux-kernel-driver-binding/</link>
      <pubDate>Tue, 28 Jul 2020 19:39:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czym-jest-linux-kernel-driver-binding/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio QEMU/KVM na swoim laptopie z zainstalowanym Debianem natrafiłem na ciekawe
zagadnienie związane z wirtualizacją, tj. z PCI passthrough. Nie chodzi mi tutaj o samą technikę
PCI passthrough ale o dobór sterowników do urządzeń działających pod kontrolą linux. Każdy sprzęt,
który ma działać w systemie, musi mieć załadowany w pamięci RAM stosowny moduł kernela. Te moduły
zwykle są ładowane automatycznie podczas pracy systemu, np. gdy podłączamy nowy sprzęt do komputera
(można też te moduły ładować i ręcznie via &lt;code&gt;modprobe&lt;/code&gt; ). Gdy nasz linux z jakiegoś powodu dobierze
niewłaściwy (z naszego punktu widzenia) moduł dla jakiegoś urządzenia, to możemy to urządzenie
odłączyć od komputera, a moduł bez problemu wyładować, po czym dokonać stosownych poprawek w
systemie. Problem zaczyna się w sytuacji, gdy mamy do czynienia ze sprzętem, którego nie da się od
komputera fizycznie odłączyć, np. wbudowana w płytę główną karta dźwiękowa, czy też wbudowana
grafika bezpośrednio w CPU. Podobnie sprawa wygląda w przypadku wkompilowania modułów na stałe w
kernel -- jak wyładować moduł, którego się nie da wyładować? By w takich sytuacjach zmienić
przypisany urządzeniu sterownik trzeba dodać parę plików w katalogach &lt;code&gt;/etc/modules-load.d/&lt;/code&gt; /
&lt;code&gt;/etc/modprobe.d/&lt;/code&gt; oraz zrestartować maszynę, tak by podczas fazy boot kernel dobrał sprzętowi
pożądane przez nas moduły i ich konfigurację. Niemniej jednak, istnieje prostszy sposób na zmianę
sterownika działającego w systemie sprzętu i to bez potrzeby fizycznego restartowania maszyny.
Chodzi o mechanizm ręcznego przypisywania urządzeń do konkretnych sterowników (&lt;a href=&#34;https://lwn.net/Articles/143397/&#34;&gt;manual driver
binding and unbinding&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Moduł LKRG (Linux Kernel Runtime Guard)</title>
      <link>https://morfikov.github.io/post/modul-lkrg-linux-kernel-runtime-guard/</link>
      <pubDate>Tue, 09 Jun 2020 20:56:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-lkrg-linux-kernel-runtime-guard/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/modul-tpe-trusted-path-execution-dla-kernela-linux/&#34;&gt;moduł TPE&lt;/a&gt; (Trusted Path Execution) dla kernela linux, który jest w
stanie dość znacznie poprawić bezpieczeństwo naszego systemu. Ostatnio jednak natknąłem się na
&lt;a href=&#34;https://www.openwall.com/lkrg/&#34;&gt;moduł LKRG&lt;/a&gt; (Linux Kernel Runtime Guard), którego to zadaniem jest stać na straży samego jądra
operacyjnego i chronić je w czasie rzeczywistym przed różnego rodzaju zagrożeniami poprzez
wykrywanie eksploitów wykorzystujących luki w jego mechanizmach bezpieczeństwa. Jako, że ja
bardzo lubię zbroić swojego Debiana, to postanowiłem się przyjrzeć nieco bliżej temu całemu LKRG i
sprawdzić jego użyteczność. Trzeba jednak wiedzieć, że LKRG jest dostarczany w formie osobnego
modułu zamiast łaty na kernel, przez co trzeba będzie także postarać się o automatyzację pewnych
rzeczy, m.in. procesu budowania modułu przy aktualizacji kernela via DKMS.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Pendrive multiboot dla EFI/UEFI z Secure Boot</title>
      <link>https://morfikov.github.io/post/pendrive-multiboot-dla-efi-uefi-z-secure-boot/</link>
      <pubDate>Mon, 23 Mar 2020 21:50:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pendrive-multiboot-dla-efi-uefi-z-secure-boot/</guid>
      <description>&lt;p&gt;Przeniesienie mojego Debiana z laptopa mającego konfigurację BIOS i tablicę partycji MBR/MS-DOS do
maszyny wyposażonej w firmware EFI/UEFI nie było jakoś stosunkowo trudnym zadaniem. Nawet &lt;a href=&#34;https://morfikov.github.io
/post/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/&#34;&gt;kwestia
włączenia Secure Boot&lt;/a&gt; okazała się o wiele mniej skomplikowana niż w rzeczywistości mogłoby się
człowiekowi wydawać. Problem jednak pojawił się w przypadku płytek czy pendrive z systemami live.
Nie chodzi przy tym o uruchamianie nośników z dopiero co wypalonymi obrazami ISO/IMG, bo te również
nie sprawiają kłopotów. Chodzi bardziej o rozwiązanie multiboot, które oferuje wgranie wielu
obrazów live na jedno urządzenie i odpalanie tego systemu, który sobie użytkownik w danym momencie
zażyczy. Do tej pory korzystałem z &lt;a href=&#34;https://github.com/thias/glim&#34;&gt;projektu GLIM&lt;/a&gt; i może on posiada wsparcie dla EFI/UEFI ale
już wsparcia dla Secure Boot mu zabrakło. W efekcie w konfiguracji EFI/UEFI + Secure Boot, GLIM stał
się bezużyteczny i trzeba było rozejrzeć się za nieco innym rozwiązaniem. Okazało się, że nie
trzeba daleko szukać, bo &lt;a href=&#34;https://www.rodsbooks.com/refind/&#34;&gt;rEFInd&lt;/a&gt; jest w stanie natywnie uruchomić system z obrazu ISO
praktycznie każdej dystrybucji linux&#39;a (Ubuntu/Debian/Mint/GParted/CloneZilla) i w zasadzie trzeba
tylko nieco inaczej przygotować nośnik, by móc na nowo cieszyć się korzyściami jakie oferuje
pendrive multiboot.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak dodać własne klucze dla Secure Boot do firmware EFI/UEFI pod linux</title>
      <link>https://morfikov.github.io/post/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/</link>
      <pubDate>Mon, 16 Mar 2020 19:15:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/</guid>
      <description>&lt;p&gt;W środowiskach linux&#39;owych Secure Boot nie jest zbyt mile widziany i raczej postrzegany jako
źródło wszelkiego zła na świecie. Sporo użytkowników linux&#39;a dopatruje się w Secure Boot zamachu na
wolność decydowania o swoim sprzęcie, który ma być serwowany przez Microsoft. Niemniej jednak,
odsądzanie tego mechanizmu od czci i wiary jest moim zdaniem lekko nie na miejscu. Niewielu
użytkowników linux&#39;a zdaje sobie sprawę, że od prawie dekady istnieje taki wynalazek jak &lt;a href=&#34;https://github.com/rhboot/shim&#34;&gt;shim&lt;/a&gt;
(no i jest też &lt;a href=&#34;https://blog.hansenpartnership.com/linux-foundation-secure-boot-system-released/&#34;&gt;PreLoader&lt;/a&gt;), który umożliwia dystrybucjom linux&#39;a (jak i ich końcowym
użytkownikom) zaimplementowanie Secure Boot we własnym zakresie. Niemniej jednak, można całkowicie
się obejść bez tych dodatków usuwając wbudowane w firmware EFI/UEFI certyfikaty i dodając na ich
miejsce własnoręcznie wygenerowane klucze kryptograficzne. Takie podejście sprawia, że kod
podpisany tylko i wyłącznie przez nas będzie mógł zostać uruchomiony przez firmware komputera w
trybie Secure Boot, co może ździebko poprawić bezpieczeństwo naszego systemu. Poniższy artykuł ma
na celu pokazać w jaki sposób zastąpić wbudowane w firmware EFI/UEFI klucze swoimi własnymi przy
wykorzystaniu dystrybucji Debiana.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak ograniczyć ładowanie baterii w laptopie ThinkPad T430</title>
      <link>https://morfikov.github.io/post/jak-ograniczyc-ladowanie-baterii-w-laptopie-thinkpad-t430/</link>
      <pubDate>Fri, 13 Mar 2020 18:30:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ograniczyc-ladowanie-baterii-w-laptopie-thinkpad-t430/</guid>
      <description>&lt;p&gt;Czy zastanawialiście się może dlaczego baterie w laptopach zużywają się mimo, że w pewnych
przypadkach nie są one praktycznie wykorzystywane? Rozważmy sobie ideę używania laptopa w roli
przeciętnego komputera stacjonarnego. W takiej sytuacji do laptopa ciągle jest podpięty przewód
zasilający, przez co bateria powinna być używana jedynie w momencie braku zasilania z sieci
energetycznej. Zatem niby pobieramy prąd z gniazdka ale bateria i tak się nam zużyje po pewnym
czasie. Niektórzy radzą, by wyciągnąć akumulator z laptopa i używać takiego komputera bez baterii.
Takie postępowanie ma w moim odczuciu jednak same wady i postanowiłem poszukać jakiegoś bardziej
cywilizowanego rozwiązania wzorowanego na &lt;a href=&#34;https://forum.xda-developers.com/android/apps-games/root-battery-charge-limit-t3557002&#34;&gt;aplikacji Battery Charge Limit&lt;/a&gt; spotykanego w
smartfonach z Androidem. Gdyby udało się ustalić limit ładowania akumulatora w moim ThinkPad T430
na max 40%, to wydłużyłoby dość znacznie żywotność jego baterii. Niekiedy oprogramowanie na windows
umożliwia tego typu funkcjonalność ale co w przypadku linux&#39;a? Czy da radę pod linux powstrzymać
laptopa od degradowania baterii za sprawą ładowania jej ciągle do 100%?&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Brak bluetooth w ThinkPad T430 (BCM20702A1)</title>
      <link>https://morfikov.github.io/post/brak-bluetooth-w-thinkpad-t430/</link>
      <pubDate>Wed, 11 Mar 2020 21:03:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/brak-bluetooth-w-thinkpad-t430/</guid>
      <description>&lt;p&gt;W moim laptopie Lenovo ThinkPad T430 jest obecny bluetooth &lt;code&gt;Broadcom Corp. BCM20702 Bluetooth 4.0&lt;/code&gt;
o vid/pid &lt;code&gt;0a5c:21e6&lt;/code&gt; . Niestety to urządzenie nie działa za dobrze na Debianie z powodu braku
odpowiedniego firmware (plik &lt;code&gt;BCM20702A1-0a5c-21e6.hcd&lt;/code&gt; ), którego jak na złość nie ma w
repozytorium tej dystrybucji. Przydałoby się coś na to poradzić, by zmusić tę kartę/adapter do
pracy pod linux.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Jak przygotować dysk pod instalację Debian linux z EFI/UEFI</title>
      <link>https://morfikov.github.io/post/jak-przygotowac-dysk-pod-instalacje-debian-linux-z-efi-uefi/</link>
      <pubDate>Tue, 10 Mar 2020 03:28:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przygotowac-dysk-pod-instalacje-debian-linux-z-efi-uefi/</guid>
      <description>&lt;p&gt;Instalacja linux&#39;a w trybie EFI/UEFI nieco inaczej wygląda niż tradycyjna instalacja systemu, zwana
często dla odróżnienia trybem BIOS, przynajmniej przy wykorzystaniu &lt;code&gt;debootstrap&lt;/code&gt; Jeśli kupujemy
nowego desktopa czy laptopa, to zwykle będziemy mieli na dysku twardym zainstalowanego windows&#39;a i
tym samym przygotowany cały układ partycji niezbędny do prawidłowego uruchomienia systemu w trybie
EFI/UEFI. Co jednak w przypadku, gdy kupimy komputer bez systemu operacyjnego? W takiej sytuacji
trzeba będzie ręcznie podzielić dysk na partycje oraz zainstalować menadżer rozruchu (rEFInd) lub
też bootloader (grub/grub2/syslinux/extlinux) i skonfigurować wszystkie te elementy samodzielnie.
Prawdopodobnie instalator Debiana jest w stanie za nas te kroki przeprowadzić automatycznie ale my
nie będziemy korzystać z automatycznych rozwiązań, bo one nieco odmóżdżają. Spróbujemy za to
stworzyć sobie uniwersalną konfigurację, która pozwoli nam zainstalować i odpalić dowolną
dystrybucję linux&#39;a w trybie EFI/UEFI.&lt;/p&gt;</description>
    </item>
    
    <item>
	  <author>Mikhail Morfikov</author>
      <title>Zmiana DPI w Openbox/Xorg dla monitora HiDPI</title>
      <link>https://morfikov.github.io/post/zmiana-dpi-w-openbox-xorg-dla-monitora-hidpi/</link>
      <pubDate>Sun, 08 Mar 2020 19:00:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-dpi-w-openbox-xorg-dla-monitora-hidpi/</guid>
      <description>&lt;p&gt;Jeśli mieliśmy do czynienia z monitorami wysokiej rozdzielczości, to za pewne natrafiliśmy na
problem zbyt małych czcionek, które czyniły interfejs aplikacji w naszym linux&#39;ie mało czytelnym. W
przypadku środowisk graficznych takich jak GNOME czy KDE5/Plasma5 skalowanie interfejsu i czcionek
powinno odbywać się automatycznie (&lt;a href=&#34;https://wiki.gnome.org/HowDoI/HiDpi&#34;&gt;jeśli nasz ekran ma 192+ DPI i rozdzielczość 1200+ pikseli&lt;/a&gt;)
lub też za sprawą drobnej zmiany w konfiguracji, tak by użytkownik mógł w miarę komfortowo
korzystać z systemu. O ile w przypadku tych pełnowymiarowych środowisk graficznych można w zasadzie
przełączyć tylko jedną opcję i wszystkie jego aplikacje powinny zostać z powodzeniem odpowiednio
zeskalowane, o tyle problem zaczyna się w momencie, gdy mamy mieszane aplikacje lub też zwyczajnie
używamy jedynie prostego menadżera okien dla Xserver&#39;a, np. Openbox i do tego jeszcze nasz
wyświetlacz ma mniejsze DPI niż 192. W takiej sytuacji konfiguracja interfejsu użytkownika i
czcionek dla ekranów wysokiej rozdzielczości może być nie lada wyzwaniem.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
