<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Morfitronik</title>
    <link>https://morfikov.github.io/</link>
    <description>Recent content on Morfitronik</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pl-PL</language>
    <lastBuildDate>Mon, 10 Aug 2020 18:15:00 +0000</lastBuildDate>
    
	<atom:link href="https://morfikov.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Jak włączyć w Firefox ESNI (Encrypted SNI)</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-w-firefox-esni-encrypted-sni/</link>
      <pubDate>Mon, 10 Aug 2020 18:15:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-w-firefox-esni-encrypted-sni/</guid>
      <description>&lt;p&gt;Obecnie szyfrowanie zapytań DNS staje się powoli normą za sprawą protokołu DoH (&lt;a href=&#34;https://en.wikipedia.org/wiki/DNS_over_HTTPS&#34;&gt;DNS over HTTPS&lt;/a&gt;)
lub DoT (&lt;a href=&#34;https://en.wikipedia.org/wiki/DNS_over_TLS&#34;&gt;DNS over TLS&lt;/a&gt;). Można by zatem pomyśleć, że wraz z implementacją szyfrowania tego
kluczowego dla działania internetu protokołu (przynajmniej z naszego ludzkiego punktu widzenia),
poprawie ulegnie również nasza prywatność w kwestii odwiedzanych przez nas stron WWW. Niemniej
jednak, w dalszym ciągu można bez problemu wyciągnąć adresy domen, które zamierzamy odwiedzić. Nie
ma przy tym żadnego znaczenia ile stron jest hostowanych na danym adresie IP, ani nawet fakt, że
ruch do serwera WWW będzie szyfrowany (w pasku adresu wpiszemy &lt;code&gt;https://&lt;/code&gt; ) z wykorzystaniem
protokołu SSL/TLS (w tym również TLS v1.3). Wszystko przez rozszerzenie SNI (&lt;a href=&#34;https://en.wikipedia.org/wiki/Server_Name_Indication&#34;&gt;Server Name
Indication&lt;/a&gt;), którego to zadaniem jest umożliwienie jednemu serwerowi na prezentowanie wielu
certyfikatów hostowanych w jego obrębie domen. Dzięki takiemu rozwiązaniu, każda domena może
szyfrować ruch niezależnie od siebie na linii serwer&amp;lt;-&amp;gt;klient (używać innych kluczy szyfrujących).
Niemniej jednak, podczas nawiązywania szyfrowanego połączenia, w pakiecie ClientHello przesyłanym
do takiego serwera musi znaleźć się nazwa domeny, której to certyfikat serwer będzie musiał nam
przedstawić. Niestety ten pakiet jest przesyłany przez sieć otwartym tekstem, przez co każdy, kto
podsłuchuje naszą komunikację (w tym też nasz ISP), bez problemu może ustalić na jakie strony
internetowe wchodzimy. Ostatnimi czasy jednak pojawiły się dwa rozszerzenia ECH (&lt;a href=&#34;https://en.wikipedia.org/wiki/Server_Name_Indication#Encrypted_Client_Hello&#34;&gt;Encrypted Client
Hello&lt;/a&gt;) oraz ESNI (&lt;a href=&#34;https://tools.ietf.org/html/draft-ietf-tls-esni-07&#34;&gt;Encrypted SNI&lt;/a&gt;), które mają zaadresować problemy związane z prywatnością
przez pełne zaszyfrowanie pakietu ClientHello lub też zaszyfrowanie jedynie pola SNI w tym pakiecie.
Póki co, prace nad tymi rozszerzeniami nie są jeszcze skończone ale Firefox w połączeniu z
CloudFlare powoli testują ESNI. Postanowiłem zatem dobrowolnie przyłączyć się do grupy testerów i
wdrożyć na swoim linux&#39;ie to rozszerzenie ESNI dla przeglądarki Firefox.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zmienić rozmiar obrazu maszyny wirtualnej QEMU/KVM</title>
      <link>https://morfikov.github.io/post/jak-zmienic-rozmiar-obrazu-maszyny-wirtualnej-qemu-kvm/</link>
      <pubDate>Sun, 09 Aug 2020 13:45:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zmienic-rozmiar-obrazu-maszyny-wirtualnej-qemu-kvm/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio &lt;a href=&#34;https://morfikov.github.io
/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/&#34;&gt;maszynami wirtualnymi na bazie QEMU/KVM&lt;/a&gt;, zauważyłem, że sugerowany rozmiar
pliku &lt;code&gt;.qcow2&lt;/code&gt; waha się w okolicach 25 GiB. Nie jest to może jakoś specjalnie dużo ale mało to też
nie jest, zwłaszcza jeśli tworzymy maszyny wirtualne na dysku swojego laptopa. Co jeśli
przeholowaliśmy z szacunkami co do rozmiaru takiego obrazu i po zainstalowaniu systemu operacyjnego
gościa okazało się, że w sumie to ten obraz można by zmniejszyć o połowę? Albo też i w drugą stronę,
tj. co w przypadku, gdy stworzony obraz maszyny wirtualnej okazał się zbyt mały i teraz zachodzi
potrzeba jego powiększenia? Czy w takiej sytuacji musimy na nowo tworzyć maszynę wirtualną
odpowiednio zwiększając lub zmniejszając jej przestrzeń na pliki? A może istnieje jakiś sposób na
zmianę rozmiaru tych istniejących już obrazów maszyn wirtualnych? Postaramy się ten fakt
zweryfikować, a cały proces zostanie opisany przy wykorzystaniu systemu Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja HugePages pod maszyny wirtualne QEMU/KVM</title>
      <link>https://morfikov.github.io/post/konfiguracja-hugepages-pod-maszyny-wirtualne-qemu-kvm/</link>
      <pubDate>Sun, 09 Aug 2020 11:11:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-hugepages-pod-maszyny-wirtualne-qemu-kvm/</guid>
      <description>&lt;p&gt;W linux rozmiar stron pamięci operacyjnej RAM ma domyślnie 4096 bajtów (4 KiB). Maszyny wirtualne
QEMU/KVM mają to do siebie, że wykorzystują dość spore zasoby pamięci (wile GiB), przez co mały
rozmiar strony może niekorzystnie wpływać na wydajność systemów gościa. Chodzi generalnie o to, że
rozrostowi ulega tablica stron, której przeszukiwanie jest czasochłonną operacją. By temu zaradzić,
wymyślono TLB (&lt;a href=&#34;https://en.wikipedia.org/wiki/Translation_lookaside_buffer&#34;&gt;Translation Lookaside Buffer&lt;/a&gt;), który ulokowany jest albo w CPU albo gdzieś
pomiędzy CPU i główną pamięcią operacyjną. TLB to mały ale za to bardzo szybki cache. W przypadku
systemów z duża ilością pamięci RAM, niewielki rozmiar TLB sprawia, że odpowiedzi na zapytania nie
są brane z cache, tylko system wraca do przeszukiwania normalnej tablicy stron zlokalizowanej w
pamięci RAM (TLB miss). Taka sytuacja jest bardzo kosztowna, spowalnia cały system i dlatego trzeba
jej unikać. Na szczęście jest &lt;a href=&#34;https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt&#34;&gt;mechanizm HugePages&lt;/a&gt;, który pozwala na zwiększenie rozmiaru
strony pamięci z domyślnych 4 KiB do 2 MiB lub nawet do 1 GiB w zależności od właściwości głównego
procesora. W tym artykule postaramy się skonfigurować HugePages na potrzeby maszyn wirtualnych dla
systemu Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wirtualizacja QEMU/KVM (libvirt) na Debian Linux</title>
      <link>https://morfikov.github.io/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/</link>
      <pubDate>Sat, 08 Aug 2020 14:55:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/</guid>
      <description>&lt;p&gt;Prawdopodobnie dla większości użytkowników linux&#39;a, wirtualizacja kojarzy się w zasadzie z jednym
oprogramowaniem, tj. VirtualBox. &lt;a href=&#34;https://www.virtualbox.org/&#34;&gt;Niby strona VBox&#39;a podaje, że jest on na licencji GPL-2&lt;/a&gt; ale
w Debianie nie ma go w głównym repozytorium (jest on obecny w sekcji &lt;code&gt;contrib&lt;/code&gt; ). Problem z
VirtualBox&#39;em jest taki, że &lt;a href=&#34;https://salsa.debian.org/pkg-virtualbox-team/virtualbox/-/blob/master/debian/copyright&#34;&gt;wymaga on kompilatora Open Watcom&lt;/a&gt;, który już wolnym
oprogramowaniem nie jest. VBox też nie jest jedynym oprogramowaniem, które na linux można
wykorzystać w roli hiperwizora do obsługi maszyn wirtualnych. Jest o wiele lepsze rozwiązanie,
mianowicie QEMU, które jest w stanie zrobić użytek z maszyny wirtualnej kernela (Kernel Virtual
Machine, KVM) i realizować dokładnie to samo zadanie, które zwykł ogarniać VirtualBox.
Wirtualizacja na bazie QEMU/KVM jest w pełni OpenSource, co ucieszy pewnie fanów wolnego i
otwartego oprogramowania, choć zarządzanie maszynami wirtualnymi odbywa się za sprawą konsoli.
Oczywiście, osoby które korzystają z VirtualBox&#39;a zdają sobie sprawę, że to narzędzie oferuje
graficzny menadżer maszyn wirtualnych (Virtual Machine Manager, VMM), który usprawnia i znacznie
ułatwia zarządzanie wirtualnymi maszynami. Jeśli GUI jest dla nas ważnym elementem środowiska pracy
i nie uśmiecha nam się konfigurować maszyn wirtualnych przy pomocy terminala, to jest i dobra
wiadomość dla takich osób, bo istnieje &lt;code&gt;virt-manager&lt;/code&gt; , który jest dość rozbudowanym menadżerem
maszyn wirtualnych pozwalającym na ich tworzenie, konfigurowanie i zarządzanie nimi przy
wykorzystaniu graficznego interfejsu użytkownika. W tym artykule postaramy się skonfigurować
naszego Debiana w taki sposób, by przygotować go do pracy z maszynami wirtualnymi posługując się
&lt;code&gt;qemu&lt;/code&gt;/&lt;code&gt;libvirt&lt;/code&gt;/&lt;code&gt;virt-manager&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>BootHole nie taki straszny, o ile ma się własne klucze EFI/UEFI</title>
      <link>https://morfikov.github.io/post/boothole-nie-taki-straszny-o-ile-ma-sie-wlasne-klucze-efi-uefi/</link>
      <pubDate>Fri, 31 Jul 2020 21:07:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/boothole-nie-taki-straszny-o-ile-ma-sie-wlasne-klucze-efi-uefi/</guid>
      <description>&lt;p&gt;Dnia 29-07-2020 do publicznej wiadomości zostały podane informacje na temat podatności BootHole,
która to za sprawą bootloader&#39;a GRUB2 w różnych dystrybucjach linux&#39;a jest w stanie obejść
mechanizm bezpieczeństwa EFI/UEFI, tj. Secure Boot. &lt;a href=&#34;https://www.debian.org/security/2020-GRUB-UEFI-SecureBoot/&#34;&gt;Z informacji&lt;/a&gt;, które opublikował Debian,
sprawa nie wygląda miło jako, że poza aktualizacją GRUB2, shim, jądra linux, Fwupdate oraz Fwupd,
unieważnieniu podlegają również klucze dystrybucji Debian/Ubuntu, przez co praktycznie cały soft
podpisany tymi kluczami (w tym systemy live) przestaną działać w trybie Secure Boot. Czy jest się
czego obawiać i co użytkownik korzystający z mechanizmu SB powinien w takiej sytuacji zrobić?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problem z aktualizacją zmiennych PK, KEK, db i dbx via efi-updatevar</title>
      <link>https://morfikov.github.io/post/problem-z-aktualizacja-zmiennych-pk-kek-db-dbx-efi-updatevar/</link>
      <pubDate>Thu, 30 Jul 2020 20:30:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problem-z-aktualizacja-zmiennych-pk-kek-db-dbx-efi-updatevar/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/&#34;&gt;konfigurację własnych kluczy EFI/UEFI&lt;/a&gt;, którymi można zastąpić te
wbudowane standardowo w firmware naszego komputera. W tamtym artykule napotkałem jednak dość dziwny
problem, za sprawą którego nie można było zaktualizować zmiennych &lt;code&gt;PK&lt;/code&gt; , &lt;code&gt;KEK&lt;/code&gt; , &lt;code&gt;db&lt;/code&gt; i &lt;code&gt;dbx&lt;/code&gt; przy
pomocy &lt;code&gt;efi-updatevar&lt;/code&gt; z poziomu działającego linux&#39;a. Gdy próbowało się te zmienne przepisać,
dostawało się błąd typu &lt;code&gt;Operation not permitted&lt;/code&gt; . Niby system został uruchomiony w trybie &lt;code&gt;Setup Mode&lt;/code&gt; ale z jakiegoś powodu odmawiał on współpracy i trzeba było te zmienne aktualizować
bezpośrednio z poziomu firmware EFI/UEFI, co było trochę upierdliwe. Szukając wtedy informacji na
ten temat, jedyne co znalazłem, to fakt, że sporo osób ma podobny problem i najwyraźniej firmware
mojego laptopa jest ździebko niedorobiony, przez co &lt;code&gt;efi-updatevar&lt;/code&gt; nie mógł realizować swojego
zdania. Rzeczywistość okazała się nieco inna, a rozwiązanie samego problemu było wręcz banalne.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czym jest linux kernel driver binding</title>
      <link>https://morfikov.github.io/post/czym-jest-linux-kernel-driver-binding/</link>
      <pubDate>Tue, 28 Jul 2020 19:39:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czym-jest-linux-kernel-driver-binding/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio QEMU/KVM na swoim laptopie z zainstalowanym Debianem natrafiłem na ciekawe
zagadnienie związane z wirtualizacją, tj. z PCI passthrough. Nie chodzi mi tutaj o samą technikę
PCI passthrough ale o dobór sterowników do urządzeń działających pod kontrolą linux. Każdy sprzęt,
który ma działać w systemie, musi mieć załadowany w pamięci RAM stosowny moduł kernela. Te moduły
zwykle są ładowane automatycznie podczas pracy systemu, np. gdy podłączamy nowy sprzęt do komputera
(można też te moduły ładować i ręcznie via &lt;code&gt;modprobe&lt;/code&gt; ). Gdy nasz linux z jakiegoś powodu dobierze
niewłaściwy (z naszego punktu widzenia) moduł dla jakiegoś urządzenia, to możemy to urządzenie
odłączyć od komputera, a moduł bez problemu wyładować, po czym dokonać stosownych poprawek w
systemie. Problem zaczyna się w sytuacji, gdy mamy do czynienia ze sprzętem, którego nie da się od
komputera fizycznie odłączyć, np. wbudowana w płytę główną karta dźwiękowa, czy też wbudowana
grafika bezpośrednio w CPU. Podobnie sprawa wygląda w przypadku wkompilowania modułów na stałe w
kernel -- jak wyładować moduł, którego się nie da wyładować? By w takich sytuacjach zmienić
przypisany urządzeniu sterownik trzeba dodać parę plików w katalogach &lt;code&gt;/etc/modules-load.d/&lt;/code&gt; /
&lt;code&gt;/etc/modprobe.d/&lt;/code&gt; oraz zrestartować maszynę, tak by podczas fazy boot kernel dobrał sprzętowi
pożądane przez nas moduły i ich konfigurację. Niemniej jednak, istnieje prostszy sposób na zmianę
sterownika działającego w systemie sprzętu i to bez potrzeby fizycznego restartowania maszyny.
Chodzi o mechanizm ręcznego przypisywania urządzeń do konkretnych sterowników (&lt;a href=&#34;https://lwn.net/Articles/143397/&#34;&gt;manual driver
binding and unbinding&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Moduł LKRG (Linux Kernel Runtime Guard)</title>
      <link>https://morfikov.github.io/post/modul-lkrg-linux-kernel-runtime-guard/</link>
      <pubDate>Tue, 09 Jun 2020 20:56:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-lkrg-linux-kernel-runtime-guard/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/modul-tpe-trusted-path-execution-dla-kernela-linux/&#34;&gt;moduł TPE&lt;/a&gt; (Trusted Path Execution) dla kernela linux, który jest w
stanie dość znacznie poprawić bezpieczeństwo naszego systemu. Ostatnio jednak natknąłem się na
&lt;a href=&#34;https://www.openwall.com/lkrg/&#34;&gt;moduł LKRG&lt;/a&gt; (Linux Kernel Runtime Guard), którego to zadaniem jest stać na straży samego jądra
operacyjnego i chronić je w czasie rzeczywistym przed różnego rodzaju zagrożeniami poprzez
wykrywanie eksploitów wykorzystujących luki w jego mechanizmach bezpieczeństwa. Jako, że ja
bardzo lubię zbroić swojego Debiana, to postanowiłem się przyjrzeć nieco bliżej temu całemu LKRG i
sprawdzić jego użyteczność. Trzeba jednak wiedzieć, że LKRG jest dostarczany w formie osobnego
modułu zamiast łaty na kernel, przez co trzeba będzie także postarać się o automatyzację pewnych
rzeczy, m.in. procesu budowania modułu przy aktualizacji kernela via DKMS.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instalacja i konfiguracja AdGuard na routerze z OpenWRT</title>
      <link>https://morfikov.github.io/post/instalacja-konfiguracja-adguard-na-routerze-z-openwrt/</link>
      <pubDate>Tue, 12 May 2020 21:03:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/instalacja-konfiguracja-adguard-na-routerze-z-openwrt/</guid>
      <description>&lt;p&gt;Jakiś już czas temu opisywałem w jaki sposób &lt;a href=&#34;https://morfikov.github.io
/post/blokowanie-reklam-adblock-na-domowym-routerze-wifi/&#34;&gt;skonfigurować AdBlock&#39;a na routerze WiFi z wgranym
firmware OpenWRT&lt;/a&gt; oraz jak wdrożyć &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-dnscrypt-proxy-w-openwrt/&#34;&gt;szyfrowanie zapytań DNS w oparciu o dnscrypt-proxy dla
wszystkich klientów naszej sieci domowej&lt;/a&gt;. Zarówno AdBlock jak i dnscrypt-proxy można w dalszym
ciągu wykorzystywać, zwłaszcza na routerach wyposażonych w niewielkich rozmiarów flash i mało
pamięci RAM. Niemniej jednak, nie każdy lubi konfigurować swój bezprzewodowy router za
pośrednictwem terminala. Dla takich osób powstał właśnie &lt;a href=&#34;https://github.com/AdguardTeam/AdGuardHome#comparison&#34;&gt;AdGuard Home&lt;/a&gt;, który ma na celu
możliwie uprościć konfigurację routera, przynajmniej jeśli chodzi o rzeczy związane z protokołem
DNS. W tym artykule przyjrzymy się nieco bliżej AdGuard&#39;owi i zobaczymy czy można z niego zrobić
jakiś większy użytek.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zbudować/uaktualnić firmware OpenWRT dla routera WiFi</title>
      <link>https://morfikov.github.io/post/jak-zbudowac-uaktualnic-firmware-openwrt-dla-routera-wifi/</link>
      <pubDate>Mon, 13 Apr 2020 21:03:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zbudowac-uaktualnic-firmware-openwrt-dla-routera-wifi/</guid>
      <description>&lt;p&gt;Od dłuższego już czasu na swoich routerach WiFi wykorzystuję firmware OpenWRT. W przypadku mojego
domowego routera TP-Link Archer C7 v2 zarządzanie jego oprogramowaniem sprowadza się w zasadzie do
przeprowadzania aktualizacji raz na kilka tygodni czy miesięcy. Z reguły nie jest to jakoś
czasochłonne zadanie, bo wystarczy pobrać stosowny obraz z &lt;a href=&#34;http://dl.eko.one.pl/openwrt-19.07/targets/ath79/generic/&#34;&gt;serwera eko.one.pl&lt;/a&gt; i wrzucić go na
router czy to przez interfejs LuCI, czy też przez &lt;code&gt;sysupgrade&lt;/code&gt; . No tak tylko, że po wgraniu
OpenWRT na flash routera trzeba zwykle też dograć szereg pakietów, których nie ma w standardzie,
przynajmniej jeśli chodzi akurat o ten mój router bezprzewodowy. Podobnie sprawa ma się z
odtwarzaniem konfiguracji, której pewne elementy pozostają niezmienne nawet po aktualizacji ze
starszego wydania OpenWRT do nowszego. Postanowiłem zatem zgłębić nieco proces kompilacji źródeł i
budowy obrazu z firmware OpenWRT, tak by nieco zautomatyzować sobie (czy też wręcz wyeliminować)
chociaż część z kroków, które zwykle przeprowadzam chwilę po wgraniu obrazu na router. Cały ten
proces budowy obrazu zostanie opisany przy wykorzystaniu dystrybucji Debian linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pendrive multiboot dla EFI/UEFI z Secure Boot</title>
      <link>https://morfikov.github.io/post/pendrive-multiboot-dla-efi-uefi-z-secure-boot/</link>
      <pubDate>Mon, 23 Mar 2020 21:50:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pendrive-multiboot-dla-efi-uefi-z-secure-boot/</guid>
      <description>&lt;p&gt;Przeniesienie mojego Debiana z laptopa mającego konfigurację BIOS i tablicę partycji MBR/MS-DOS do
maszyny wyposażonej w firmware EFI/UEFI nie było jakoś stosunkowo trudnym zadaniem. Nawet &lt;a href=&#34;https://morfikov.github.io
/post/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/&#34;&gt;kwestia
włączenia Secure Boot&lt;/a&gt; okazała się o wiele mniej skomplikowana niż w rzeczywistości mogłoby się
człowiekowi wydawać. Problem jednak pojawił się w przypadku płytek czy pendrive z systemami live.
Nie chodzi przy tym o uruchamianie nośników z dopiero co wypalonymi obrazami ISO/IMG, bo te również
nie sprawiają kłopotów. Chodzi bardziej o rozwiązanie multiboot, które oferuje wgranie wielu
obrazów live na jedno urządzenie i odpalanie tego systemu, który sobie użytkownik w danym momencie
zażyczy. Do tej pory korzystałem z &lt;a href=&#34;https://github.com/thias/glim&#34;&gt;projektu GLIM&lt;/a&gt; i może on posiada wsparcie dla EFI/UEFI ale
już wsparcia dla Secure Boot mu zabrakło. W efekcie w konfiguracji EFI/UEFI + Secure Boot, GLIM stał
się bezużyteczny i trzeba było rozejrzeć się za nieco innym rozwiązaniem. Okazało się, że nie
trzeba daleko szukać, bo &lt;a href=&#34;https://www.rodsbooks.com/refind/&#34;&gt;rEFInd&lt;/a&gt; jest w stanie natywnie uruchomić system z obrazu ISO
praktycznie każdej dystrybucji linux&#39;a (Ubuntu/Debian/Mint/GParted/CloneZilla) i w zasadzie trzeba
tylko nieco inaczej przygotować nośnik, by móc na nowo cieszyć się korzyściami jakie oferuje
pendrive multiboot.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak dodać własne klucze dla Secure Boot do firmware EFI/UEFI pod linux</title>
      <link>https://morfikov.github.io/post/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/</link>
      <pubDate>Mon, 16 Mar 2020 19:15:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/</guid>
      <description>&lt;p&gt;W środowiskach linux&#39;owych Secure Boot nie jest zbyt mile widziany i raczej postrzegany jako
źródło wszelkiego zła na świecie. Sporo użytkowników linux&#39;a dopatruje się w Secure Boot zamachu na
wolność decydowania o swoim sprzęcie, który ma być serwowany przez Microsoft. Niemniej jednak,
odsądzanie tego mechanizmu od czci i wiary jest moim zdaniem lekko nie na miejscu. Niewielu
użytkowników linux&#39;a zdaje sobie sprawę, że od prawie dekady istnieje taki wynalazek jak &lt;a href=&#34;https://github.com/rhboot/shim&#34;&gt;shim&lt;/a&gt;
(no i jest też &lt;a href=&#34;https://blog.hansenpartnership.com/linux-foundation-secure-boot-system-released/&#34;&gt;PreLoader&lt;/a&gt;), który umożliwia dystrybucjom linux&#39;a (jak i ich końcowym
użytkownikom) zaimplementowanie Secure Boot we własnym zakresie. Niemniej jednak, można całkowicie
się obejść bez tych dodatków usuwając wbudowane w firmware EFI/UEFI certyfikaty i dodając na ich
miejsce własnoręcznie wygenerowane klucze kryptograficzne. Takie podejście sprawia, że kod
podpisany tylko i wyłącznie przez nas będzie mógł zostać uruchomiony przez firmware komputera w
trybie Secure Boot, co może ździebko poprawić bezpieczeństwo naszego systemu. Poniższy artykuł ma
na celu pokazać w jaki sposób zastąpić wbudowane w firmware EFI/UEFI klucze swoimi własnymi przy
wykorzystaniu dystrybucji Debiana.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ograniczyć ładowanie baterii w laptopie ThinkPad T430</title>
      <link>https://morfikov.github.io/post/jak-ograniczyc-ladowanie-baterii-w-laptopie-thinkpad-t430/</link>
      <pubDate>Fri, 13 Mar 2020 18:30:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ograniczyc-ladowanie-baterii-w-laptopie-thinkpad-t430/</guid>
      <description>&lt;p&gt;Czy zastanawialiście się może dlaczego baterie w laptopach zużywają się mimo, że w pewnych
przypadkach nie są one praktycznie wykorzystywane? Rozważmy sobie ideę używania laptopa w roli
przeciętnego komputera stacjonarnego. W takiej sytuacji do laptopa ciągle jest podpięty przewód
zasilający, przez co bateria powinna być używana jedynie w momencie braku zasilania z sieci
energetycznej. Zatem niby pobieramy prąd z gniazdka ale bateria i tak się nam zużyje po pewnym
czasie. Niektórzy radzą, by wyciągnąć akumulator z laptopa i używać takiego komputera bez baterii.
Takie postępowanie ma w moim odczuciu jednak same wady i postanowiłem poszukać jakiegoś bardziej
cywilizowanego rozwiązania wzorowanego na &lt;a href=&#34;https://forum.xda-developers.com/android/apps-games/root-battery-charge-limit-t3557002&#34;&gt;aplikacji Battery Charge Limit&lt;/a&gt; spotykanego w
smartfonach z Androidem. Gdyby udało się ustalić limit ładowania akumulatora w moim ThinkPad T430
na max 40%, to wydłużyłoby dość znacznie żywotność jego baterii. Niekiedy oprogramowanie na windows
umożliwia tego typu funkcjonalność ale co w przypadku linux&#39;a? Czy da radę pod linux powstrzymać
laptopa od degradowania baterii za sprawą ładowania jej ciągle do 100%?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Brak bluetooth w ThinkPad T430 (BCM20702A1)</title>
      <link>https://morfikov.github.io/post/brak-bluetooth-w-thinkpad-t430/</link>
      <pubDate>Wed, 11 Mar 2020 21:03:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/brak-bluetooth-w-thinkpad-t430/</guid>
      <description>&lt;p&gt;W moim laptopie Lenovo ThinkPad T430 jest obecny bluetooth &lt;code&gt;Broadcom Corp. BCM20702 Bluetooth 4.0&lt;/code&gt;
o vid/pid &lt;code&gt;0a5c:21e6&lt;/code&gt; . Niestety to urządzenie nie działa za dobrze na Debianie z powodu braku
odpowiedniego firmware (plik &lt;code&gt;BCM20702A1-0a5c-21e6.hcd&lt;/code&gt; ), którego jak na złość nie ma w
repozytorium tej dystrybucji. Przydałoby się coś na to poradzić, by zmusić tę kartę/adapter do
pracy pod linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przygotować dysk pod instalację Debian linux z EFI/UEFI</title>
      <link>https://morfikov.github.io/post/jak-przygotowac-dysk-pod-instalacje-debian-linux-z-efi-uefi/</link>
      <pubDate>Tue, 10 Mar 2020 03:28:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przygotowac-dysk-pod-instalacje-debian-linux-z-efi-uefi/</guid>
      <description>&lt;p&gt;Instalacja linux&#39;a w trybie EFI/UEFI nieco inaczej wygląda niż tradycyjna instalacja systemu, zwana
często dla odróżnienia trybem BIOS, przynajmniej przy wykorzystaniu &lt;code&gt;debootstrap&lt;/code&gt; Jeśli kupujemy
nowego desktopa czy laptopa, to zwykle będziemy mieli na dysku twardym zainstalowanego windows&#39;a i
tym samym przygotowany cały układ partycji niezbędny do prawidłowego uruchomienia systemu w trybie
EFI/UEFI. Co jednak w przypadku, gdy kupimy komputer bez systemu operacyjnego? W takiej sytuacji
trzeba będzie ręcznie podzielić dysk na partycje oraz zainstalować menadżer rozruchu (rEFInd) lub
też bootloader (grub/grub2/syslinux/extlinux) i skonfigurować wszystkie te elementy samodzielnie.
Prawdopodobnie instalator Debiana jest w stanie za nas te kroki przeprowadzić automatycznie ale my
nie będziemy korzystać z automatycznych rozwiązań, bo one nieco odmóżdżają. Spróbujemy za to
stworzyć sobie uniwersalną konfigurację, która pozwoli nam zainstalować i odpalić dowolną
dystrybucję linux&#39;a w trybie EFI/UEFI.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana DPI w Openbox/Xorg dla monitora HiDPI</title>
      <link>https://morfikov.github.io/post/zmiana-dpi-w-openbox-xorg-dla-monitora-hidpi/</link>
      <pubDate>Sun, 08 Mar 2020 19:00:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-dpi-w-openbox-xorg-dla-monitora-hidpi/</guid>
      <description>&lt;p&gt;Jeśli mieliśmy do czynienia z monitorami wysokiej rozdzielczości, to za pewne natrafiliśmy na
problem zbyt małych czcionek, które czyniły interfejs aplikacji w naszym linux&#39;ie mało czytelnym. W
przypadku środowisk graficznych takich jak GNOME czy KDE5/Plasma5 skalowanie interfejsu i czcionek
powinno odbywać się automatycznie (&lt;a href=&#34;https://wiki.gnome.org/HowDoI/HiDpi&#34;&gt;jeśli nasz ekran ma 192+ DPI i rozdzielczość 1200+ pikseli&lt;/a&gt;)
lub też za sprawą drobnej zmiany w konfiguracji, tak by użytkownik mógł w miarę komfortowo
korzystać z systemu. O ile w przypadku tych pełnowymiarowych środowisk graficznych można w zasadzie
przełączyć tylko jedną opcję i wszystkie jego aplikacje powinny zostać z powodzeniem odpowiednio
zeskalowane, o tyle problem zaczyna się w momencie, gdy mamy mieszane aplikacje lub też zwyczajnie
używamy jedynie prostego menadżera okien dla Xserver&#39;a, np. Openbox i do tego jeszcze nasz
wyświetlacz ma mniejsze DPI niż 192. W takiej sytuacji konfiguracja interfejsu użytkownika i
czcionek dla ekranów wysokiej rozdzielczości może być nie lada wyzwaniem.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak załadować firmware karty WiFi przed initrd/initramfs</title>
      <link>https://morfikov.github.io/post/jak-zaladowac-firmware-karty-wifi-przed-initrd-initramfs/</link>
      <pubDate>Fri, 06 Mar 2020 02:45:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zaladowac-firmware-karty-wifi-przed-initrd-initramfs/</guid>
      <description>&lt;p&gt;Każdy kto ma laptopa wyposażonego w kartę WiFi, czy też ogólnie komputer posiadający bezprzewodową
sieciówkę, ten prawdopodobnie spotkał się z błędem podobnym do tego: &lt;code&gt;Direct firmware load for iwlwifi-6000g2a-6.ucode failed with error -2&lt;/code&gt; . W tym przypadku sprawa dotyczyła karty &lt;code&gt;Intel Corporation Centrino Advanced-N 6205 [Taylor Peak]&lt;/code&gt; działającej w oparciu o moduł kernela
&lt;code&gt;iwlwifi&lt;/code&gt; . W takich przypadkach zwykle wystarczy zainstalować firmware od określonego modułu i po
kłopocie. No i faktycznie w Debianie jest dostępny pakiet &lt;code&gt;firmware-iwlwifi&lt;/code&gt; , który zawiera ten
potrzebny plik &lt;code&gt;iwlwifi-6000g2a-6.ucode&lt;/code&gt; . Problem jednak w tym, że instalacja paczki z firmware
niekoniecznie może nam pomóc. Ten powyższy przykład nie jest odosobniony i czasami pliki z firmware
muszą być dostępne w chwili ładowania kernela do pamięci RAM czy też na etapie initramfs/initrd. W
takim przypadku zainstalowanie paczki z firmware w naszym linux&#39;ie nic nam nie da, bo pliki
rezydują na niezamontowanym jeszcze dysku. Jak zatem wybrnąć z tej wydawać by się było patowej
sytuacji?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Memtest86 dla EFI/UEFI i rEFInd</title>
      <link>https://morfikov.github.io/post/memtest86-dla-efi-uefi-i-refind/</link>
      <pubDate>Tue, 03 Mar 2020 04:05:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/memtest86-dla-efi-uefi-i-refind/</guid>
      <description>&lt;p&gt;Zapewne każdy z nas słyszał o narzędziu do testowania pamięci operacyjnej RAM zwanym memtest86. W
Debianie są dostępne dwa pakiety &lt;a href=&#34;https://tracker.debian.org/pkg/memtest86&#34;&gt;memtest86&lt;/a&gt; (&lt;a href=&#34;https://www.memtest86.com/&#34;&gt;strona projektu&lt;/a&gt;) oraz &lt;a href=&#34;https://tracker.debian.org/pkg/memtest86+&#34;&gt;memtest86+&lt;/a&gt;
(&lt;a href=&#34;http://www.memtest.org/&#34;&gt;strona projektu&lt;/a&gt;) , które można sobie zainstalować w systemie. Niemniej jednak, jak się
popatrzy na daty ostatnich wersji obu tych aplikacji (rok 2014), to mamy do czynienia z dość starym
oprogramowaniem. Tak czy inaczej, jeśli dany soft działa, to bez znaczenia powinno być jak stary on
jest. Problem w przypadku memtest86 dostarczanego w tych dwóch pakietach jest taki, że działa on w
zasadzie jedynie w konfiguracji BIOS, a nie EFI/UEFI. Dodatkowo, oryginalny memtest86 został
sprzedany PassMark&#39;owi, który &lt;a href=&#34;https://en.wikipedia.org/wiki/Memtest86&#34;&gt;od wersji 5.0 uczynił go własnościowym softem&lt;/a&gt;. To dlatego w
Debianie nie będzie już nowszej wersji memtest86. W dalszym ciągu memtest86 może działać w
konfiguracji EFI/UEFI ale potrzebna nam jest wersja, która to EFI/UEFI wspiera. Memtest86 zaczął
wspierać EFI/UEFI od wersji 5.0. Jeśli nam nie przeszkadza licencja własnościowa, to możemy sobie
przygotować memtest86, tak by można go było bez problemu odpalić z menadżera rozruchu &lt;a href=&#34;https://www.rodsbooks.com/refind/&#34;&gt;rEFInd&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Linux kernel EFI boot stub i zaszyfrowany Debian (LUKS&#43;LVM)</title>
      <link>https://morfikov.github.io/post/linux-kernel-efi-boot-stub-i-zaszyfrowany-debian-luks-lvm/</link>
      <pubDate>Mon, 02 Mar 2020 03:08:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/linux-kernel-efi-boot-stub-i-zaszyfrowany-debian-luks-lvm/</guid>
      <description>&lt;p&gt;Szukając informacji na temat uruchamiania mojego zaszyfrowanego Debiana (LUKSv2+LVM) na laptopie z
EFI/UEFI, natrafiłem na dość ciekawy mechanizm zwany &lt;a href=&#34;https://www.kernel.org/doc/Documentation/efi-stub.txt&#34;&gt;kernel EFI boot stub&lt;/a&gt;, czasem też zwany
kernel EFISTUB. Zadaniem tego mechanizmu jest uruchomienie linux&#39;a bezpośrednio z poziomu firmware
EFI z pominięciem czy też bez potrzeby stosowania dodatkowych menadżerów rozruchu (rEFInd) czy
bootloader&#39;ów (grub/grub2/syslinux/extlinux). Jakby nie patrzeć bardzo ciekawa alternatywa, która
wymaga, by się z nią zapoznać i ocenić jej przydatność pod kątem użyteczności.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przepisać linki initrd.img{,.old} i vmlinuz{,.old} z / do /boot/</title>
      <link>https://morfikov.github.io/post/jak-przepisac-linki-initrd-img-old-i-vmlinuz-old-do-boot/</link>
      <pubDate>Sun, 01 Mar 2020 20:30:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przepisac-linki-initrd-img-old-i-vmlinuz-old-do-boot/</guid>
      <description>&lt;p&gt;Mając możliwość skonfigurowania EFI/UEFI na moim laptopie, postanowiłem jak najbardziej się za to
przedsięwzięcie zabrać. Okazało się jednak, że w przypadku takiej dystrybucji linux&#39;a jak Debian,
to zadanie może być nieco problematyczne, zwłaszcza gdy chce się korzystać jedynie z menadżera
rozruchu jakim jest &lt;a href=&#34;https://www.rodsbooks.com/refind/&#34;&gt;rEFInd&lt;/a&gt;, czyli bez dodatkowego bootloader&#39;a (grub/grub2/syslinux/extlinux)
instalowanego bezpośrednio na dysku twardym i jednocześnie posiadając w pełni zaszyfrowany system
(LUKSv2 + LVM). Rzecz w tym, że w takiej sytuacji w konfiguracji rEFInd trzeba podawać ścieżki
bezpośrednio do plików &lt;code&gt;initrd.img&lt;/code&gt; oraz &lt;code&gt;vmlinuz&lt;/code&gt; (obecnych na partycji &lt;code&gt;/boot/&lt;/code&gt; ). W Debianie
nazwy tych plików mają format &lt;code&gt;initrd.img-x.x.x-x-amd64&lt;/code&gt; i &lt;code&gt;vmlinuz-x.x.x-x-amd64&lt;/code&gt; . Za każdym
razem, gdy wypuszczany jest nowy kernel, to ten numerek ( &lt;code&gt;x.x.x-x&lt;/code&gt; ) ulega zmianie, co pociąga za
sobą potrzebę ręcznego dostosowania konfiguracji rEFInd. Może i aktualizacje kernela w Debianie nie
są jakoś stosunkowo częste ale może istnieje sposób, by ten problem z dostosowaniem konfiguracji
rozwiązać?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Regulacja obrotów wentylatora w zależności od zmian temperatury w ThinkPad T430</title>
      <link>https://morfikov.github.io/post/regulacja-obrotow-wentylatora-w-zaleznosci-od-zmian-temperatury-w-thinkpad-t430/</link>
      <pubDate>Fri, 28 Feb 2020 23:00:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/regulacja-obrotow-wentylatora-w-zaleznosci-od-zmian-temperatury-w-thinkpad-t430/</guid>
      <description>&lt;p&gt;Ostatnio udało mi się nabyć dość niedrogo laptop Lenovo, a konkretnie był to model ThinkPad T430.
Maszyna jakby nie patrzeć jest bardzo kompatybilna z linux i w zasadzie nie mogę jej nic zarzucić,
przynajmniej póki co. Niemniej jednak, jest pewien szkopuł, który mnie zaczął ździebko irytować od
praktycznie samego początku jak tylko podłączyłem ten komputer do prądu. Chodzi o wentylator
chłodzący radiator procesora, który no troszkę daje o sobie znać i to mimo faktu, że temperatura
CPU jest w granicach 40 stopni. Przeglądając opcje w BIOS nie natrafiłem na nic co mogło by te
obroty wyregulować. Na szczęście w przypadku laptopów Lenovo można programowo zdefiniować obroty
wiatraka posługując się narzędziem &lt;a href=&#34;https://github.com/vmatare/thinkfan&#34;&gt;thinkfan&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zmienić hostname w telefonie z Androidem</title>
      <link>https://morfikov.github.io/post/jak-zmienic-hostname-w-telefonie-z-androidem/</link>
      <pubDate>Wed, 29 Jan 2020 19:00:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zmienic-hostname-w-telefonie-z-androidem/</guid>
      <description>&lt;p&gt;Przeglądając ostatnio listę sprzętów podłączonych do mojego routera WiFi, zauważyłem, że niektóre
pozycje na niej w polu z hostname mają coś na wzór &lt;code&gt;android-4c52c33baae0b4fa&lt;/code&gt; . Pierwsza część
nazwy tego hosta wskazuje na system operacyjny, a drugi kawałek to unikalny numerek ID.  Nie jestem
zbytnio fanem rozgłaszania takich informacji publicznie, bo mogą one ułatwić ewentualne ataki, oraz
też identyfikują jednoznacznie dane urządzenie (&lt;a href=&#34;https://source.android.com/devices/tech/connect/wifi-mac-randomization&#34;&gt;osobną kwestią jest adres MAC karty sieciowej&lt;/a&gt;).
Ponadto, mając w sieci wiele mobilnych urządzeń, ciężko jest czasem połapać się który telefon ma
przypisany konkretny adres IP (bez patrzenia w ustawienia telefonu). Z reguły na linux&#39;owym
desktopie czy laptopie zmiana hostname jest stosunkowo łatwym zadaniem ale w przypadku smartfona z
Androidem ten zabieg okazał się niezmiernie trudnym procesem. Jak zatem zmienić hostname telefonu,
by można było mu przypisać jakaś w miarę ludzką nazwę?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zweryfikować plik APK aplikacji na Androida</title>
      <link>https://morfikov.github.io/post/jak-zweryfikowac-plik-apk-aplikacji-na-androida/</link>
      <pubDate>Fri, 13 Dec 2019 19:26:14 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zweryfikowac-plik-apk-aplikacji-na-androida/</guid>
      <description>&lt;p&gt;Część użytkowników smartfonów z Androidem na pokładzie żyje w głębokim przekonaniu, że instalowanie
aplikacji spoza sklepu Google Play nie jest zbyt rozważnym posunięciem. Nie chodzi tutaj tylko o
szeroko rozumiane alternatywne źródła aplikacji, np. serwis apkmirror ale również o Yalp/Aurora
Store czy też repozytoria F-Droid. Zdaniem tych osób pobieranie aplikacji z zewnętrznych źródeł
może skompromitować bezpieczeństwo systemu oraz zagrozić naszej prywatności. No jakby nie patrzeć
wgrywanie czegokolwiek bez zastanowienia się co tak naprawdę instalujemy w systemie nie jest zbyt
mądre. Dlaczego zatem nie weryfikujemy aplikacji obecnych w oficjalnym sklepie Google? Co chwila
przecież można usłyszeć w mediach o syfie, który udało się co prawda z tego sklepu usunąć ale też
jakaś większa liczba użytkowników taką aplikację zdążyła już zainstalować i używała jej przez
dłuższy lub krótszy okres czasu. Rozumowanie na zasadzie, że aplikacje ze sklepu Google Play są
bezpieczne, bo są obecne w sklepie Google Play, daje nam jedynie fałszywe poczucie bezpieczeństwa,
które jest gorsze od całkowitego braku bezpieczeństwa, bo w tym drugim przypadku człowiek
przynajmniej jest świadom czyhających na niego niebezpieczeństw i włącza myślenie. Jak zatem
odróżnić aplikacje, które są w stanie nam wyrządzić krzywdę od tych, które tego nie mają na celu i
czy faktycznie pobieranie aplikacji na Androida z innego źródła niż oficjalny sklep Google Play
jest takie niebezpieczne?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pendrive multiboot z GRUB2 i obrazami ISO różnych dystrybucji Linux</title>
      <link>https://morfikov.github.io/post/pendrive-multiboot-z-grub2-i-obrazami-iso-roznych-dystrybucji-linux/</link>
      <pubDate>Fri, 08 Nov 2019 18:02:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pendrive-multiboot-z-grub2-i-obrazami-iso-roznych-dystrybucji-linux/</guid>
      <description>&lt;p&gt;Obrazy ISO różnych dystrybucji Linux, szczególnie te live, bywają niezastąpione w sytuacjach
kryzysowych. Dzięki takiej płytce CD/DVD czy pendrive (może być też i karta SD) można wybrnąć nawet
z najgorszych opresji bez potrzeby rezygnowania przy tym z graficznego środowiska pracy
podłączonego do internetu. Zwykle jednak użytkownicy są stawiani przed wyborem systemu, który mogą
sobie wgrać na zewnętrzny nośnik, by w późniejszym czasie przeprowadzać ewentualne prace naprawcze.
Chodzi generalnie o fakt, że taki obraz ISO czy IMG przy wgrywaniu konsumuje całe urządzenie bez
względu na jego rozmiar, i tak mając 32G pamięci na flash możemy wgrać w zasadzie tylko jeden
obraz, np. Debiana, a by wgrać obraz Ubuntu, to już trzeba albo osobnego pendrive albo nadpisać ten
poprzednio wgrany obraz. Takie rozwiązanie jest mało praktyczne i też generuje koszty. Na szczęście
można stworzyć boot&#39;owalny pendrive (w oparciu o GRUB/GRUB2), na którym można umieścić dowolną
ilość obrazów ISO i w fazie rozruchu wybrać sobie ten system, który nas interesuje, a wszystko
dzięki &lt;a href=&#34;https://github.com/thias/glim&#34;&gt;projektowi GLIM&lt;/a&gt; (GRUB Live ISO Multiboot).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak załadować profile AppArmor w fazie initrd/initramfs na Debian Linux</title>
      <link>https://morfikov.github.io/post/jak-zaladowac-profile-apparmor-w-fazie-initrd-initramfs-na-debian-linux/</link>
      <pubDate>Mon, 23 Sep 2019 19:05:21 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zaladowac-profile-apparmor-w-fazie-initrd-initramfs-na-debian-linux/</guid>
      <description>&lt;p&gt;Zapewne wielu użytkowników Debiana zdążyło już zauważyć, że od wydania 10 (Buster), AppArmor jest
włączony domyślnie. Nie powinien on raczej sprawiać żadnych problemów po doinstalowaniu pakietów
&lt;code&gt;apparmor-profiles&lt;/code&gt; oraz &lt;code&gt;apparmor-profiles-extra&lt;/code&gt; , które zawierają szereg profili pod różne
aplikacje użytkowe. Niemniej jednak, pewnych procesów nie da się ograniczyć przez AppArmor,
przynajmniej nie w standardowy sposób. Chodzi o to, że jeśli mamy już odpalony jakiś proces, to nie
ma możliwości zamknąć go w profilu AA do momentu aż zakończy on swoje działanie i zostanie
uruchomiony ponownie. Profile AppArmor&#39;a są ładowane podczas startu systemu w pewnym określonym
momencie ale szereg procesów systemowych startuje sporo wcześniej w stosunku do usługi AppArmor&#39;a.
W taki sposób nawet jeśli w późniejszym czasie profile zostaną załadowane, to i tak część procesów
nie będzie ograniczona bez względu na to czy zdefiniowaliśmy im zestaw reguł. Oczywiście można
próbować restartować usługi lub szeregować je po &lt;code&gt;apparmor.service&lt;/code&gt; ale nie zawsze tak się da
zrobić. Alternatywnym rozwiązaniem tego problemu jest ładowanie polityki AppArmor&#39;a w fazie
initrd/initramfs, czyli w momencie, w którym nasz system nie ma jeszcze nawet uruchomionego procesu
z PID z numerkiem &lt;code&gt;1&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Capability dac_read_search i dac_override w profilu AppArmor&#39;a</title>
      <link>https://morfikov.github.io/post/capability-dac_read_search-dac_override-w-profilu-apparmor/</link>
      <pubDate>Mon, 16 Sep 2019 18:20:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/capability-dac_read_search-dac_override-w-profilu-apparmor/</guid>
      <description>&lt;p&gt;Od jakiegoś czasu tworzę dla aplikacji w moim Debianie &lt;a href=&#34;https://gitlab.com/morfikov/debian-files/tree/master/configs/etc/apparmor.d&#34;&gt;profile pod AppArmor&lt;/a&gt;, tak by ograniczyć
programom swobodny dostęp do plików czy urządzeń. Tych profili zebrało się już trochę i podczas
pisania jednego z nich, zacząłem się zastanawiać czy wszystkie CAP&#39;y (linux capabilities), których
żądają procesy, są im faktycznie niezbędne do prawidłowego funkcjonowania. Chodzi póki co o
&lt;code&gt;dac_read_search&lt;/code&gt; i &lt;code&gt;dac_override&lt;/code&gt; . Co ciekawe, odmowa &lt;code&gt;dac_override&lt;/code&gt; w części aplikacji nie
powodowała żadnych negatywnych konsekwencji. Idąc dalej tym tropem, postanowiłem z paru profili AA
usunąć linijkę zawierającą &lt;code&gt;capability dac_override,&lt;/code&gt; zostawiając tym samym jedynie
&lt;code&gt;capability dac_read_search,&lt;/code&gt;  i zobaczyć co się stanie. Okazało się, że sporo programów już o
&lt;code&gt;dac_override&lt;/code&gt; nie prosi. Zatem co się zmieniło przez tych parę lat i czy ta zmiana dotyczy samych
aplikacji, a może kernela linux&#39;a?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wybudzanie linux&#39;a ze stanu uśpienia za sprawą myszy</title>
      <link>https://morfikov.github.io/post/wybudzanie-linuxa-ze-stanu-uspienia-za-sprawa-myszy/</link>
      <pubDate>Thu, 06 Jun 2019 16:10:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wybudzanie-linuxa-ze-stanu-uspienia-za-sprawa-myszy/</guid>
      <description>&lt;p&gt;Parę dni temu na jednych z forów, które czasem odwiedzam, &lt;a href=&#34;https://forum.linuxmint.pl/showthread.php?tid=323&#34;&gt;pojawił się wątek&lt;/a&gt; dotyczący problemu
jaki może nieść ze sobą budzenie linux&#39;a ze stanu uśpienia/wstrzymania (Suspend to RAM, STR) za
sprawą myszy. O ile w przypadku klawiatury sprawa wybudzania komputera zdaje się być dość oczywista,
to w przypadku tego małego gryzonia już niekoniecznie, bo wystarczy lekko mysz przemieścić po
blacie stołu czy innego biurka i system się nam wybudzi. Część komputerów ma stosowne opcje w
BIOS/UEFI i można za ich sprawą skonfigurować to jakie urządzenia będą mieć możliwość wybudzania
systemu. Niekiedy jednak, opcje w BIOS są tak ubogie, że nie mamy możliwości skonfigurowania tego
aspektu pracy naszej maszyny. Trzeba zatem w nieco inny sposób podejść do tego zagadnienia. Na
necie można się spotkać z radami odnośnie zapisu pliku &lt;code&gt;/proc/acpi/wakeup&lt;/code&gt; przez przesłanie do
niego czteroznakowych kodów, np. &lt;code&gt;EHC1&lt;/code&gt; czy &lt;code&gt;USB1&lt;/code&gt; . Takie rozwiązanie może nieść ze sobą negatywne
konsekwencje i powinno się go unikać. Lepszym rozwiązaniem jest napisanie reguły dla UDEV&#39;a dla
konkretnego urządzenia, gdzie będziemy mogli łatwo sterować (przez plik &lt;code&gt;power/wakeup&lt;/code&gt; ) tym czy
dane urządzenie ma mieć możliwość wybudzania systemu czy też nie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Montowanie dysków jako zwykły użytkownik z UDisks i PolicyKit</title>
      <link>https://morfikov.github.io/post/montowanie-dyskow-jako-zwykly-uzytkownik-z-udisks-i-policykit/</link>
      <pubDate>Fri, 26 Apr 2019 21:10:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/montowanie-dyskow-jako-zwykly-uzytkownik-z-udisks-i-policykit/</guid>
      <description>&lt;p&gt;Jeszcze nie tak dawno temu przeciętnej klasy desktop był wyposażony w pojedynczy i do tego
niewielkiej pojemności dysk twardy, który był w stanie pomieścić wszystkie pliki swojego
właściciela. Obecnie jednak większość maszyn ma tych nośników już kilka. Mowa tutaj nie tylko o
dyskach systemowych, które są fizycznie na stałe zamontowane w komputerze ale również o tych
wszystkich urządzeniach, które można podłączyć do portu USB. Polityka linux&#39;a wymusza, by wszystkie
nośniki pamięci masowej (HDD, SSD, pendrive czy też karty SD) były montowane w systemie jedynie
przez użytkowników posiadających uprawnienia administratora. Domyślnie taki przywilej ma jedynie
root. Zatem by uzyskać dostęp do danych na takim zewnętrznym nośniku musimy logować się na root&#39;a.
Jakby nie patrzeć ma to swoje plusy patrząc z perspektywy bezpieczeństwa, niemniej jednak czy
naprawdę potrzebny nam jest root do wgrania czegoś na nasz ulubiony pendrive? Widać nie tylko ja
zadawałem sobie takie pytanie i ktoś postanowił stworzyć narzędzie UDisks (lub jego nowszą wersję
UDisks2), które za pomocą mechanizmu PolicyKit (zwanym też PolKit) jest w stanie nadać stosowne
uprawnienia konkretnym użytkownikom systemu, przez co można określić zespół akcji, które będą oni w
stanie przeprowadzić bez potrzeby podawania hasła, np. montowanie czy odmontowanie zasobu.
Postanowiłem zatem zobaczyć jak ten duet sobie radzi na moim Debianie przy tradycyjnym użytkowaniu
systemu i ocenić jego stopień przydatności.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czy smartfon z Androidem bez Google Apps/Services ma sens</title>
      <link>https://morfikov.github.io/post/czy-smartfon-z-androidem-bez-google-apps-services-ma-sens/</link>
      <pubDate>Tue, 16 Apr 2019 21:00:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czy-smartfon-z-androidem-bez-google-apps-services-ma-sens/</guid>
      <description>&lt;p&gt;Jakiś czas
temu &lt;a href=&#34;https://android.com.pl/programowanie/188397-po-co-nam-uslugi-google-play/&#34;&gt;natknąłem się na artykuł&lt;/a&gt;
chwalący Google Play Services i sugerujący zarazem, że nasz smartfon bez tych usług (i appek
zależnych od nich) na niewiele się zda człowiekowi. Nie jest to jednak do końca prawdą i
postanowiłem pokazać na żywym przykładzie jak wygląda operowanie na telefonie z Androidem
pozbawionym jakichkolwiek usług czy aplikacji własnościowych od Google. W rolach głównych wystąpi
mój smartfon LG G4C, który jest już dość leciwy ale można na niego wgrać LineageOS (lub też inny
ROM na bazie AOSP). Po wgraniu ROM&#39;u, w telefonie znajduje się jedynie garstka podstawowych
aplikacji (przeglądarka, galeria, itp), które po pierwsze są opensource, a po drugie można je bez
problemu wyłączyć jeśli nie zamierzamy z nich korzystać. Z telefonu można dzwonić, przeglądać net
(WiFi/LTE), robić zdjęcia i używać tego urządzenia do różnego rodzaju multimediów. W zasadzie czego
oczekiwać więcej od telefonu? Niektórzy jednak chcieli by mieć możliwość używania, np. nawigacji.
No i tu już zaczynają się schody, bo na takim w pełni otwartoźródłowym Androidzie, GPS nie zadziała
OOTB i potrzebna nam jest jakaś alternatywa w postaci pośrednika między aplikacjami a GPS.
Standardowo w Andkach tym zadaniem zajmują się właśnie te usługi Google. Jak więc zatem zmusić GPS
do poprawnej pracy nie chcąc przy tym wgrywać sobie tego rozbudowanego w uprawnieniach szpiega od
Google? Problemów naturalnie może być więcej, a to czy doświadczymy któregokolwiek z nich zależy
głównie od odpowiedniej konfiguracji systemu. Niniejszy artykuł postara się zebrać wszystkie te
niezbędne informacje mające na celu zaimplementowanie w naszym smartfonie otwartoźródłowej
alternatywy dla Google Play Services w postaci microG.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mechanizm trigger&#39;ów dla apt/aptitude w Debianie</title>
      <link>https://morfikov.github.io/post/mechanizm-trigger-dla-apt-aptitude-w-debianie/</link>
      <pubDate>Sun, 14 Apr 2019 00:10:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mechanizm-trigger-dla-apt-aptitude-w-debianie/</guid>
      <description>&lt;p&gt;Czasami pewna niestandardowa konfiguracja naszego linux&#39;a może sprawiać pewne problemy podczas
aktualizacji zainstalowanych w nim pakietów. Dla przykładu, wykorzystując mechanizm AppArmor do
okrojenia profilów Firefox&#39;a, muszę tworzyć osobne twarde dowiązania do binarki tej przeglądarki.
Te dowiązania mają taki problem, że jak usunie się plik, na który wskazywały, np. podczas
aktualizacji paczki, to utworzenie pliku w tym samym miejscu przez menadżer pakietów
&lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;aptitude&lt;/code&gt; nie sprawi, że te dowiązania zaczną ponownie funkcjonować poprawnie (tak jak to
jest w przypadku dowiązań symbolicznych). Z początku usuwałem te stare dowiązania i tworzyłem nowe
ale postanowiłem w końcu &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=30382&#34;&gt;poszukać rozwiązania&lt;/a&gt;,
które by zautomatyzowało cały ten proces i uczyniło go transparentnym dla użytkownika końcowego.
Tak natrafiłem na mechanizm Debianowych
trigger&#39;ów (&lt;a href=&#34;https://manpages.debian.org/unstable/dpkg-dev/deb-triggers.5.en.html&#34;&gt;deb-trigger&lt;/a&gt;),
które aktywują się za każdym razem ilekroć pliki w konkretnych ścieżkach są ruszane w jakiś sposób
przez menadżer pakietów. W tym artykule spróbujemy sobie zaprojektować taki trigger i obadać czy
może on nam się w ogóle do czegoś przydać&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Blokowanie niepożądanej komunikacji z nftables na linux</title>
      <link>https://morfikov.github.io/post/blokowanie-niepozadanej-komunikacji-z-nftables-na-linux/</link>
      <pubDate>Fri, 12 Apr 2019 20:53:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/blokowanie-niepozadanej-komunikacji-z-nftables-na-linux/</guid>
      <description>&lt;p&gt;Minęło już trochę czasu od momentu, w którym postanowiłem się przerzucić z &lt;code&gt;iptables&lt;/code&gt; na &lt;code&gt;nftables&lt;/code&gt;
w swoim Debianie i w zasadzie większość mechanizmów obronnych mojego laptopowego firewall&#39;a została
już z powodzeniem przeportowana na ten nowy filtr pakietów. Poza tymi starymi regułami próbuję
czasem ogarniać nieco bardziej wyrafinowane sposoby na unikanie zagrożeń sieciowych, choć
implementacja niektórych rzeczy nie zawsze jest taka oczywista, z tym, że niekoniecznie niemożliwa
do zrealizowana. Tak było w przypadku mechanizmu automatycznego blokowania hostów próbujących się
łączyć z daną maszyną, która sobie najwyraźniej tego nie życzy. Dla przykładu, jest serwer
udostępniający usługę SSH na porcie &lt;code&gt;11111&lt;/code&gt; i tylko ten port jest wystawiony na świat. Wszelkiego
rodzaju boty próbujące dostać się do maszyn linux&#39;owych próbkują z kolei głównie standardowe porty,
w tym przypadku &lt;code&gt;22&lt;/code&gt; . Ci użytkownicy, którzy powinni mieć dostęp do usługi SSH, wiedzą na jakim
porcie ona nasłuchuje. Można zatem założyć, że wszystkie połączenia na port &lt;code&gt;22&lt;/code&gt; będą dokonywane
przez boty albo przez użytkowników, którzy mają niecne zamiary. Wszystkie te połączenia można by
zatem zablokować tworząc mechanizm automatycznego banowania hostów w oparciu o czas ostatniej próby
połączenia, tak jak to zostało opisane mniej
więcej &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?pid=269383&#34;&gt;w tym wątku na forum&lt;/a&gt;. Problem w tym, że
tamto rozwiązanie dotyczy jedynie &lt;code&gt;iptables&lt;/code&gt; w połączeniu z &lt;code&gt;ipset&lt;/code&gt; , co nieco komplikuje wdrożenie
go w przypadku &lt;code&gt;nftables&lt;/code&gt; ale to zadanie jest jak najbardziej możliwe.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Unikanie SYN/ICMP/UDP/PING flood w linux z nftables</title>
      <link>https://morfikov.github.io/post/unikanie-syn-icmp-udp-ping-flood-w-linux-z-nftables/</link>
      <pubDate>Fri, 12 Apr 2019 20:12:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/unikanie-syn-icmp-udp-ping-flood-w-linux-z-nftables/</guid>
      <description>&lt;p&gt;Obecnie &lt;code&gt;nftables&lt;/code&gt; cierpi dość mocno z powodu pewnych problemów związanych z wydajnością przy
aplikowaniu reguł zapory sieciowej. Niemniej jednak, w stosunku do &lt;code&gt;iptables&lt;/code&gt; , &lt;code&gt;nftables&lt;/code&gt; posiada
tablicę &lt;code&gt;netdev&lt;/code&gt; , która jest w stanie nieco zyskać w oczach tych nieco bardziej wybrednych
użytkowników linux&#39;a. Chodzi generalnie o fakt, że ta tablica jest umieszczona zaraz na początku
drogi pakietów, tuż po odebraniu ich z NIC (interfejsu karty sieciowej), a biorąc pod uwagę fakt,
że ruch sieciowy, który nigdy ma nie trafić do naszej maszyny, powinien być zrzucany jak
najwcześniej (by nie marnować zasobów procesora i pamięci), to ta tablica wydaje się być idealnym
miejscem by zablokować cały niepożądany ruch przychodzący. Przy wykorzystaniu &lt;code&gt;iptables&lt;/code&gt; , takie
pakiety zrzuca się w tablicy &lt;code&gt;raw&lt;/code&gt; . Jeśli zaś chodzi o &lt;code&gt;nftables&lt;/code&gt; , to zrzucanie pakietów w
tablicy &lt;code&gt;netdev&lt;/code&gt; jest ponad dwu lub nawet trzykrotnie bardziej wydajne (szybsze i mniej
zasobożerne). Można zatem dość dobrze poradzić sobie z wszelkiego rodzaju atakami DOS/DDOS, np.
ICMP/PING flood czy SYN flood. Zastanawiające może być natomiast ogarnięcie ataku UDP flood ale
przed tym rodzajem ataku linux również jest w stanie się bez problemu ochronić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ograniczenie su do jednego użytkownika w Debianie</title>
      <link>https://morfikov.github.io/post/ograniczanie-su-do-jednego-uzytkownika-w-debianie/</link>
      <pubDate>Fri, 12 Apr 2019 19:40:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ograniczanie-su-do-jednego-uzytkownika-w-debianie/</guid>
      <description>&lt;p&gt;W dzisiejszych czasach dystrybucje linux&#39;a wykorzystują mechanizm &lt;code&gt;sudo&lt;/code&gt; do wykonywania operacji
jako administrator systemu. Zanika więc potrzeba stosowania polecenia &lt;code&gt;su&lt;/code&gt; , by zalogować się na
konto root i to z jego poziomu wykonywać wszystkie niezbędne rzeczy. Jednym z argumentów
zwolenników &lt;code&gt;sudo&lt;/code&gt; za takim sanem rzeczy jest możliwość nadania jedynie konkretnym użytkownikom w
systemie uprawnień do wykonywania poleceń jako administrator, podczas gdy inni użytkownicy
(niebędący w grupie &lt;code&gt;sudo&lt;/code&gt; ) nie mogą w ogóle korzystać z tego mechanizmu . No faktycznie, dostęp
do &lt;code&gt;su&lt;/code&gt; jest w zasadzie dla każdego użytkownika w systemie i tylko hasło konta admina dzieli ich od
uzyskania dość szerokich uprawnień. Niewiele jednak osób wie, że można skonfigurować &lt;code&gt;su&lt;/code&gt; w taki
sposób, by dostęp do niego mieli tylko ci
użytkownicy, &lt;a href=&#34;https://wiki.debian.org/WHEEL/PAM&#34;&gt;którzy powinni&lt;/a&gt;, np. ci obecni w grupie &lt;code&gt;wheel&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Badsector dysku HDD w kontenerze LUKS zawierającym LVM</title>
      <link>https://morfikov.github.io/post/badsector-dysku-hdd-w-kontenerze-luks-zawierajacym-lvm/</link>
      <pubDate>Sun, 31 Mar 2019 12:23:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/badsector-dysku-hdd-w-kontenerze-luks-zawierajacym-lvm/</guid>
      <description>&lt;p&gt;Podczas rutynowego skanu powierzchni dysków HDD w moim laptopie, S.M.A.R.T wykrył w jednym z nich
podejrzany blok, który zdawał się wyzionąć już ducha, przez co proces weryfikacji integralności
powierzchni dysku twardego nie był w stanie zakończyć się z powodzeniem. Komunikat zwracany przy
czytaniu padniętego sektora też był nieco dziwny: &lt;code&gt;bad/missing sense data, sb[]&lt;/code&gt; . Jakiś czas temu
już opisywałem
jak &lt;a href=&#34;https://morfikov.github.io
/post/uszkodzony-sektor-na-dysku-i-jego-realokoacja/&#34;&gt;realokować uszkodzony sektor dysku HDD&lt;/a&gt;
i w zasadzie wszystkie informacje zawarte w tamtym artykule można by wykorzystać do próby
poprawienia zaistniałego problemu, gdyby tylko nie fakt, że w tym przypadku badblock znalazł się w
obszarze voluminu logicznego LVM na partycji zaszyfrowanej przy pomocy mechanizmu LUKS. Taki
schemat układu partycji sprawia, że do realokowania błędnego bloku trzeba podejść nieco inaczej
uwzględniając w tym procesie kilka offset&#39;ów, bez których w zasadzie nic nie da się zrobić.
Postanowiłem zatem napisać na konkretnym przykładzie jak realokować badsector dysku, gdy do
czynienia mamy z zaszyfrowanym linux&#39;em zainstalowanym na voluminach LVM.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Format źródeł 3.0 (git) przy budowaniu paczek Debiana</title>
      <link>https://morfikov.github.io/post/format-zrodel-git-przy-budowaniu-paczek-debiana/</link>
      <pubDate>Wed, 27 Mar 2019 05:23:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/format-zrodel-git-przy-budowaniu-paczek-debiana/</guid>
      <description>&lt;p&gt;Pisząc jakiś czas
temu &lt;a href=&#34;https://morfikov.github.io
/post/poradnik-maintainera-czyli-jak-zrobic-pakiet-deb/&#34;&gt;poradnik na temat budowania paczek .deb&lt;/a&gt;
dla dystrybucji linux&#39;a Debian, poruszyłem w nim kwestię związaną z aktualizacją paczki, która
zawierała projekt utrzymywany w systemie kontroli wersji (CVS), np. git. Rozchodzi się tutaj o
format źródeł. Do niedawna myślałem, że są w zasadzie dwa formaty (tych, z których się zwykle
korzysta): &lt;code&gt;3.0 (native)&lt;/code&gt; oraz &lt;code&gt;3.0 (quilt)&lt;/code&gt; . Wszystkie moje pakiety budowane do tej pory miały
ten drugi format. Podglądając ostatnio kilka paczek &lt;code&gt;.deb&lt;/code&gt; , natrafiłem w jednej z nich na format
źródeł &lt;code&gt;3.0 (git)&lt;/code&gt; . Okazuje się, że ten format jest w stanie bardzo łatwo ogarnąć projekty
hostowane w takich serwisach jak GitHub, czy GitLab i można za jego sprawą nieco ułatwić sobie
życie. Wypadałoby zatem rzucić na niego okiem i ocenić go pod kątem przydatności przy budowaniu
pakietów dla Debiana.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problemy z plikiem wymiany SWAP przy hibernacji linux&#39;a</title>
      <link>https://morfikov.github.io/post/problemy-z-plikiem-wymiany-swap-przy-hibernacji-linuxa/</link>
      <pubDate>Sat, 23 Mar 2019 19:30:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problemy-z-plikiem-wymiany-swap-przy-hibernacji-linuxa/</guid>
      <description>&lt;p&gt;Po wyjaśnieniu paru rzeczy w kwestii przestrzeni wymiany, a
konkretnie [co jest lepsze: plik SWAP czy osobna partycja]({{ site.baseurl  }}/post/czy-w-linux-plik-swap-jest-lepszy-niz-partycja-wymiany/),
postanowiłem nieco zmienić układ partycji na dysku mojego laptopa (LUKS+LVM) i zaimplementować
sobie przestrzeń wymiany w postaci pliku SWAP. Standardowo jednak plik SWAP nie działa w przypadku
hibernacji linux&#39;a i kernel ma problemy z wybudzeniem maszyny z głębokiego snu. Jeśli zamierzamy
korzystać z hibernacji, to trzeba inaczej skonfigurować system, by nauczyć go korzystać z
przestrzeni wymiany w postaci pliku. W tym artykule rzucimy sobie okiem na ten niezbyt
skomplikowany proces.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Moduł TPE (Trusted Path Execution) dla kernela linux</title>
      <link>https://morfikov.github.io/post/modul-tpe-trusted-path-execution-dla-kernela-linux/</link>
      <pubDate>Fri, 22 Mar 2019 20:10:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-tpe-trusted-path-execution-dla-kernela-linux/</guid>
      <description>&lt;p&gt;Użytkownicy linux&#39;a są zwykle chronieni przez mechanizmy bezpieczeństwa, które ten system jest w
stanie zaoferować. Oczywiście deweloperzy różnych dystrybucji, np. Debiana, dokładają wszelkich
możliwych starań, by system jako całość był wstępnie skonfigurowany tak, by końcowy użytkownik nie
musiał za wiele majstrować przy zabezpieczeniach i mógł się czuć i być (przynajmniej względnie)
bezpieczny. No i faktycznie złowrogie oprogramowanie ma czasem spore problemy dostać się do maszyny,
którą operuje linux. Niemniej jednak, gdy już taki syf się do systemu dostanie, to zwykle niewiele
dzieli go od przejęcia kontroli nad komputerem. Może i część zabezpieczeń linux&#39;a zadziała i sprawi,
że taki wirus/trojan czy nawet zwykły skrypt będzie miał ograniczone pole manewru, to i tak będzie
on mógł przeprowadzić te akcje, które zwyczajny użytkownik systemu (nie root) jest zwykle w stanie
poczynić, np. odebrać dźwięk i video ze stosownych urządzeń i przesłać te dane przez sieć. My z
kolei możemy nawet tego faktu nie być świadomi. Jasne, że powinno się zwracać uwagę na to jakie
pliki się pobiera z internetu i nie uruchamiać wszystkiego lekkomyślnie ale też trzeba mieć na
uwadze fakt, że często jedna maszyna jest współdzielona, np. z członkami rodziny i oni już
niekoniecznie muszą władać zaawansowaną wiedza z zakresu IT, by przewidzieć wszystkie możliwe
zagrożenia czyhające na nich w sieci. Można za to postarać się, by uczynić naszą maszynę nieco
bardziej odporną na niezbyt przemyślane zachowania użytkowników jej systemu operacyjnego. Jednym z
kroków, które możemy podjąć, jest wdrożenie mechanizmu Trusted Path Execution (TPE), który póki co
jest dostępny jedynie w &lt;a href=&#34;https://patchwork.kernel.org/patch/9773791/&#34;&gt;formie patch&#39;a&lt;/a&gt; na kernel
linux&#39;a lub też jako jego &lt;a href=&#34;https://github.com/cormander/tpe-lkm&#34;&gt;osobny moduł&lt;/a&gt; oferujący sporo
więcej możliwości w stosunku do wspomnianej wcześniej łaty. W niniejszym artykule rzucimy sobie
okiem na ten cały mechanizm TPE i zobaczymy jak jest on w stanie uchronić nasz OS przed niezbyt
zaawansowaną ludzką inteligencją.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czy w linux plik SWAP jest lepszy niż partycja wymiany</title>
      <link>https://morfikov.github.io/post/czy-w-linux-plik-swap-jest-lepszy-niz-partycja-wymiany/</link>
      <pubDate>Fri, 22 Mar 2019 16:23:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czy-w-linux-plik-swap-jest-lepszy-niz-partycja-wymiany/</guid>
      <description>&lt;p&gt;Ostatnimi czasy, z racji rozwoju technologicznego, mamy do dyspozycji coraz to szybsze komputery,
co przekłada się w znacznym stopniu na prędkość wykonywania operacji przez ich systemy operacyjne.
Obecnie przeciętnej klasy desktop czy laptop jest już wyposażony w 16G czy nawet 32G pamięci
operacyjnej (w niedługim czasie
nawet &lt;a href=&#34;https://android.com.pl/news/200097-samsung-12-gb-ram-lpddr4x/&#34;&gt;smartfony będą posiadać 12G RAM&lt;/a&gt;).
Spada zatem zapotrzebowanie wykorzystania dysku twardego jako pamięci RAM. W linux używanie
dysku twardego jako rozszerzenie pamięci operacyjnej było i jest w dalszym ciągu realizowane za
sprawą przestrzeni wymiany SWAP. Ta przestrzeń wymiany może być zaimplementowana w postaci osobnej
partycji dysku twardego albo też jako plik umieszczony w obrębie systemu plików, np. ext4. Część
dystrybucji linux&#39;a decyduję się na porzucenie partycji wymiany na rzecz pliku SWAP. Czy taki krok
jest uzasadniony i czy korzystając aktualnie z partycji wymiany powinniśmy zmigrować na plik SWAP?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czym jest Online ext4 Metadata Check w linux&#39;owym LVM</title>
      <link>https://morfikov.github.io/post/czym-jest-online-ext4-metadata-check-w-linuxowym-lvm/</link>
      <pubDate>Sun, 17 Mar 2019 19:10:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czym-jest-online-ext4-metadata-check-w-linuxowym-lvm/</guid>
      <description>&lt;p&gt;Przeglądając dzisiaj rano logi systemowe wpadł mi w oczy komunikat, którego treść brzmiała mniej
więcej tak: &lt;code&gt;e2scrub Volume group &amp;quot;wd_blue_label&amp;quot; has insufficient free space (0 extents): 64 required&lt;/code&gt; , po którym z kolei można zanotować &lt;code&gt;e2scrub snapshot FAILED, will not check!&lt;/code&gt; oraz
&lt;code&gt;Failed to start Online ext4 Metadata Check for /media/Debian&lt;/code&gt; . Oczywiście ten punkt montowania to
nazwa partycji odnosząca się do jednego z dysków logicznych struktury LVM. Skąd się te błędy
wzięły? Przecież jeszcze do niedawna (przez ostatnich parę lat) wszystko z moim linux&#39;em
rezydującym na dysku (LUKS+LVM) było w porządku, a teraz nagle takie bardzo niepokojące błędy.
Czym jest w ogóle ten &lt;code&gt;e2scrub&lt;/code&gt; i czym jest ten cały &lt;code&gt;Online ext4 Metadata Check&lt;/code&gt; , który
najwyraźniej ma coś wspólnego ze sprawdzaniem systemu plików voluminów logicznych w locie? No i
najważniejsze chyba pytanie -- czemu to nie działa jak należy?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak na Debianie zrobić pakiet .deb zawierający moduł kernela linux (DKMS)</title>
      <link>https://morfikov.github.io/post/jak-na-debianie-zrobic-pakiet-deb-zawierajacy-modul-kernela-linux-dkms/</link>
      <pubDate>Sun, 17 Mar 2019 09:37:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-na-debianie-zrobic-pakiet-deb-zawierajacy-modul-kernela-linux-dkms/</guid>
      <description>&lt;p&gt;Kernel linux&#39;a jest dość złożonym organizmem, który może zostać rozbudowany przy pomocy dodatkowego
kodu ładowanego w postaci zewnętrznych modułów. Czasem ze względu na wczesny etap prac nad nową
funkcjonalnością jądra, taki moduł może zachowywać się dość nieprzewidywalnie, co przekreśla jego
szanse na pojawienie się w stabilnych wydaniach kernela. Czasem też z jakiegoś niezrozumiałego
powodu pewne rzeczy nie są celowo dodawane do jądra operacyjnego. Jedną z nich
jest &lt;a href=&#34;https://github.com/cormander/tpe-lkm&#34;&gt;moduł Trusted Path Execution&lt;/a&gt; (TPE), który jest w
stanie znacznie poprawić bezpieczeństwo systemu uniemożliwiając przeprowadzenie w nim szeregu
podejrzanych działań. W Debianie tego typu niedogodności związane z brakiem pewnych modułów można
obejść przez
zastosowanie &lt;a href=&#34;https://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support&#34;&gt;mechanizmu DKMS&lt;/a&gt;, który
przy instalacji modułu spoza głównego drzewa kernela linux&#39;a jest nam go w stanie automatycznie
zbudować. W repozytorium dystrybucji Debiana znajduje się już szereg pakietów z modułami (mają
końcówki &lt;code&gt;-dkms&lt;/code&gt; ) i w prosty sposób można je sobie doinstalować. Co jednak w przypadku, gdy mamy
moduł, którego nikt jeszcze nie przygotował i nie wrzucił do repozytorium? Co, gdy takich modułów
mamy kilka, a przy tym korzystamy z najnowszego stabilnego kernela, który jest aktualizowany
średnio co kilka dni? Ręczna budowa wszystkich zewnętrznych modułów za każdym razem jak tylko
wyjdzie nowsza wersja kernela, to nie najlepsze wyjście, zwłaszcza jak dojdzie nam do tego
aktualizacja samych modułów. Można za to zrobić sobie paczkę &lt;code&gt;.deb&lt;/code&gt; tak, by przy instalacji nowego
jądra operacyjnego, system nam automatycznie zbudował wszystkie dodatkowe moduły, których nasz
komputer wymaga do poprawnej pracy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czy linux&#39;owy firewall powinien blokować pakiety not-syn w stanie NEW</title>
      <link>https://morfikov.github.io/post/czy-linuxowy-firewall-powinien-blokowac-pakiety-not-syn-w-stanie-new/</link>
      <pubDate>Fri, 15 Mar 2019 18:02:21 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czy-linuxowy-firewall-powinien-blokowac-pakiety-not-syn-w-stanie-new/</guid>
      <description>&lt;p&gt;Od czasu do czasu w logu systemowym mojego Debiana można zanotować szereg pakietów przychodzących,
które są zrzucane przez linux&#39;owy firewall (&lt;code&gt;nftables&lt;/code&gt;/&lt;code&gt;iptables&lt;/code&gt; ). Po krótkiej analizie okazało
się, że są to pakiety protokołu TCP mające stan &lt;code&gt;NEW&lt;/code&gt; (czyli są to nowe połączenia) ale
niezawierające przy tym flagi &lt;code&gt;SYN&lt;/code&gt; . Mój laptop nie ma aktualnie przydzielonego zewnętrznego
routowalnego adresu IPv4/IPv6, więc nasunęło się pytanie o przyczynę takiego stanu
rzeczy -- przecie będąc za NAT, nikt spoza sieci nie powinien być w stanie nawiązać połączenia z
moją maszyną, a ewidentnie co się do jej bram dobija i to nie z adresu lokalnego. Niby mam też
odfiltrowane pakiety w stanie &lt;code&gt;INVALID&lt;/code&gt; (np. te mające niepoprawny zestaw flag) ale widać te
pakiety, o których mowa, nie zaliczają się do tego stanu, więc wygląda na to, że wszystko z nimi
jest w porządku. Czy tego typu pakiety TCP w stanie &lt;code&gt;NEW&lt;/code&gt; niemające ustawionej flagi &lt;code&gt;SYN&lt;/code&gt;
stanowią jakieś zagrożenie dla naszego komputera? Czy powinno się je zablokować, a może przepuścić
w filtrze pakietów? A jeśli zablokować, to czy zwykły &lt;code&gt;DROP&lt;/code&gt; wystarczy czy może powinno się te
pakiety potraktować przy pomocy &lt;code&gt;REJECT&lt;/code&gt; ?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak optymalnie podzielić dysk HDD/SSD na partycje pod linux</title>
      <link>https://morfikov.github.io/post/jak-optymalnie-podzielic-dysk-hdd-ssd-na-partycje-pod-linux/</link>
      <pubDate>Fri, 15 Mar 2019 17:05:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-optymalnie-podzielic-dysk-hdd-ssd-na-partycje-pod-linux/</guid>
      <description>&lt;p&gt;Ostatnio przeglądając nowe wpisy na forach trafiłem
na &lt;a href=&#34;https://forum.linuxmint.pl/showthread.php?tid=112&#34;&gt;pytanie o podział dysku&lt;/a&gt; pod instalację
linux&#39;a. Autorowi wątku chodziło o jak najlepszy podział dysku HDD ale najwyraźniej pogubił się on
w tym całym bałaganie informacyjnym, który tyczy się procesu partycjonowania nośnika pod kątem jego
optymalnego wykorzystania przez linux. Zagadnienie podziału dysków HDD/SSD nie jest zbytnio jakoś
skomplikowane, a mimo to wciąż pojawiają się pytania o poprawne przeprowadzenie tego procesu i to
pomimo faktu, że mamy obecnie już dość sporych rozmiarów dyski. To pytanie powoli przestaje mieć
jakikolwiek sens, przynajmniej jeśli chodzi o przeciętnego Kowalskiego instalującego linux&#39;a u
siebie na kompie (desktop/laptop). Postanowiłem jednak napisać parę słów na temat tego całego
podziału dysku na partycje, tak by dobrać optymalny ich rozmiar przy instalowaniu dowolnej
dystrybucji linux&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Brak wsparcia dla ipset w nftables</title>
      <link>https://morfikov.github.io/post/brak-wsparcia-dla-ipset-w-nftables/</link>
      <pubDate>Sat, 02 Mar 2019 02:21:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/brak-wsparcia-dla-ipset-w-nftables/</guid>
      <description>&lt;p&gt;Użytkownicy Debiana często w roli firewall&#39;a wykorzystują już dość leciwy &lt;code&gt;iptables&lt;/code&gt; . W zasadzie,
to tej implementacji linux&#39;owego filtra pakietów sieciowych nic nie dolega, no może poza szeregiem
wad konstrukcyjnych, które są obecnie tak ciężkie do zaadresowania, że w sumie trzeba by cały ten
&lt;code&gt;iptables&lt;/code&gt; napisać od początku. Wszystko przez rozwój internetu, za sprawą którego pojawiło się
zapotrzebowanie na tworzenie całej masy reguł (w postaci adresów/portów źródłowych/docelowych),
gdzie w standardowym &lt;code&gt;iptables&lt;/code&gt; trzeba tworzyć osobne wpisy. Im więcej reguł w filtrze, tym
przechodzenie pakietów przez zaporę sieciową trwa dłużej i wiąże się z mocnym obciążeniem dla
procesora (zwłaszcza, gdy tych reguł jest kilkadziesiąt tysięcy). By jakoś uporać się z tymi
problemami (nieznanymi w innych filtrach sieciowych) stworzono &lt;code&gt;ipset&lt;/code&gt; . I faktycznie odciążył on
mocno procesor maszyny ale i tak nie wyeliminował on podstawowych wad &lt;code&gt;iptables&lt;/code&gt; . Dlatego też
zaczęto szukać innego rozwiązania i tak pojawiła się alternatywa m.in. w postaci &lt;code&gt;nftables&lt;/code&gt; . W
przyszłym stabilnym Debianie (buster) &lt;code&gt;nftables&lt;/code&gt; będzie wykorzystywany jako domyślny filtr pakietów
i ci, który korzystali z &lt;code&gt;ipset&lt;/code&gt; mogą się nieco zdziwić, że &lt;code&gt;nftables&lt;/code&gt; nie posiada dla niego
wsparcia. Rzecz w tym, że &lt;code&gt;nftables&lt;/code&gt; potrafi natywnie obsługiwać listy adresów/portów i &lt;code&gt;ipset&lt;/code&gt;
nie jest mu w tym do niczego potrzebny.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przy pomocy USBguard zabezpieczyć porty USB przed złośliwymi urządzeniami</title>
      <link>https://morfikov.github.io/post/jak-przy-pomocy-usbguard-zabezpieczyc-porty-usb-przed-zlosliwymi-urzadzeniami/</link>
      <pubDate>Sun, 24 Feb 2019 12:00:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przy-pomocy-usbguard-zabezpieczyc-porty-usb-przed-zlosliwymi-urzadzeniami/</guid>
      <description>&lt;p&gt;Ostatnio na
Niebezpieczniku &lt;a href=&#34;https://niebezpiecznik.pl/post/zlosliwy-kabel-usb-ktory-zmienia-sie-w-klawiature-i-infekuje-twoj-komputer/&#34;&gt;pojawił się artykuł&lt;/a&gt;
na temat niezbyt przyjaznych urządzeń podłączanych do komputera za sprawą portów USB (opisanych na
przykładzie niepozornego przewodu) i tego jaką szkodę tego typu hardware może nam wyrządzić w
systemie. Ataki z wykorzystaniem podstawionych urządzeń zadziałają nawet na linux, choć pewnie cała
masa użytkowników wyznaje jeszcze mit, że ich komputer jest bezpieczny, bo przecie używają
alternatywnego systemu operacyjnego, który jest OpenSource i za priorytet obrał sobie szeroko
rozumiane bezpieczeństwo. Niestety nie jest tak różowo jakby mogło się co niektórym wydawać ale
można ten stan rzeczy naturalnie zmienić i nie trzeba przy tym rekompilować kernela z zamiarem
wyłączenia obsługi modułu USB, co ten opisany w podlinkowanym artykule atak oczywiście by również
powstrzymało. Zamiast tego możemy zainstalować sobie narzędzie &lt;code&gt;usbguard&lt;/code&gt; i przy jego pomocy
skonfigurować politykę podłączanych do portów USB urządzeń.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak włączyć dźwięk w kontenerze Docker&#39;a za sprawą PulseAudio</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-dzwiek-w-kontenerze-dockera-za-sprawa-pulseaudio/</link>
      <pubDate>Sat, 16 Feb 2019 13:22:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-dzwiek-w-kontenerze-dockera-za-sprawa-pulseaudio/</guid>
      <description>&lt;p&gt;Jakiś czas temu postanowiłem przetestować sposób zamknięcia graficznych aplikacji w kontenerze
Docker&#39;a. Całe rozwiązanie zostało opisane na
przykładzie &lt;a href=&#34;https://morfikov.github.io
/post/uruchamianie-graficznych-aplikacji-w-kontenerach-dockera/&#34;&gt;skonteneryzowania przeglądarki Firefox&lt;/a&gt;.
Ten opisany w podlinkowanym artykule pomysł był nawet całkiem przyzwoity ale nie nadaje się on, gdy
w grę wchodzą programy odtwarzające dźwięk. No może to za dużo powiedziane, że się nie nadaje, ale
z pewnością brakuje mu jednego istotnego elementu. Nawet ta przykładowa przeglądarka internetowa
jest w stanie odtwarzać dźwięki jeśli się odwiedzi stosowną stronę WWW. Standardowo jednak nic nie
usłyszymy w głośnikach, gdy odpalimy dajmy na to stronę YouTube i puścimy jakiś materiał video.
Dlatego też wypadałoby skonfigurować dźwięk i przesłać go do serwera PulseAudio, który będzie
odpalony na naszym linux&#39;owym hoście. Kiedyś już tego typu rozwiązanie nawet opisywałem na
przykładzie &lt;a href=&#34;https://morfikov.github.io
/post/pulseaudio-i-przesylanie-dzwieku-przez-siec/&#34;&gt;zintegrowania PulseAudio z kontenerami LXC&lt;/a&gt;.
Okazuje się, że tamto rozwiązanie znajduje również zastosowanie w przypadku Docker&#39;a. Trzeba tylko
nieco inaczej skonfigurować kontener i właśnie tej kwestii będzie dotyczył niniejszy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migracja z iptables na nftables w Debianie</title>
      <link>https://morfikov.github.io/post/migracja-z-iptables-na-nftables-w-debianie/</link>
      <pubDate>Sat, 16 Feb 2019 11:05:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/migracja-z-iptables-na-nftables-w-debianie/</guid>
      <description>&lt;p&gt;Zgodnie z &lt;a href=&#34;http://ral-arturo.org/2018/06/16/nfws2018.html&#34;&gt;informacją&lt;/a&gt;, która pojawiła się już ponad pół roku temu, dystrybucje linux&#39;a powoli
zaczynają odchodzić od &lt;code&gt;iptables&lt;/code&gt; . Prawdopodobnie w niedługim czasie &lt;code&gt;iptables&lt;/code&gt; zostanie już
całkowicie wyparty i zastąpiony przez &lt;code&gt;nftables&lt;/code&gt; , przynajmniej jeśli chodzi o desktopy. Nawet
&lt;a href=&#34;https://wiki.debian.org/nftables#Current_status&#34;&gt;Debian zakomunikował&lt;/a&gt;, że następne wydanie stabilne tej dystrybucji (Buster) będzie domyślnie
wykorzystywało &lt;code&gt;nftables&lt;/code&gt; . Wypadałoby zatem się przenieść na ten nowy framework i przygotować
sobie kilka podstawowych reguł firewall&#39;a, które zabezpieczoną naszą maszynę przed nieautoryzowanym
dostępem z sieci.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czy brak wsparcia dla SYNPROXY w nftables jest problemem</title>
      <link>https://morfikov.github.io/post/czy-brak-wsparcia-dla-synproxy-w-nftables-jest-problemem/</link>
      <pubDate>Sat, 16 Feb 2019 10:20:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czy-brak-wsparcia-dla-synproxy-w-nftables-jest-problemem/</guid>
      <description>&lt;p&gt;Przenosząc swoje reguły z &lt;code&gt;iptables&lt;/code&gt; na &lt;code&gt;nftables&lt;/code&gt; zauważyłem, że jedna z nich (gdyby tylko jedna)
nie została przetłumaczona przez ten dedykowany translator do reguł. Chodzi
o &lt;a href=&#34;https://morfikov.github.io
/post/unikanie-atakow-ddos-z-synproxy/&#34;&gt;mechanizm SYNPROXY&lt;/a&gt;, który jest zwykle wykorzystywany do ograniczenia skali ataków DDOS z
wykorzystaniem pakietów SYN. Co by nie mówić, to ochrona jaką daje SYNPROXY jest jak najbardziej
pożądana z perspektywy serwerów. Dlaczego zatem, gdy się zajrzy na stronę
&lt;a href=&#34;https://wiki.nftables.org/wiki-nftables/index.php/Supported_features_compared_to_xtables&#34;&gt;wspieranych rzeczy w nftables&lt;/a&gt;, to przy SYNPROXY widnieje bliżej nieokreślone sformułowanie
&lt;code&gt;consider native interface&lt;/code&gt; ? Po rozmowach z deweloperami udało się ustalić, że ten zapis oznacza
brak wsparcia dla SYNPROXY w &lt;code&gt;nftables&lt;/code&gt; . Jeśli zatem ktoś wykorzystuje ten mechanizm mając dodane
stosowne reguły w &lt;code&gt;iptables&lt;/code&gt; , to czy powinien się on obawiać przejścia na &lt;code&gt;nftables&lt;/code&gt; ?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak sklonować duże repozytorium git na niestabilnym łączu sieciowym</title>
      <link>https://morfikov.github.io/post/jak-sklonowac-duze-repozytorium-git-na-niestabilnym-laczu-sieciowym/</link>
      <pubDate>Sat, 16 Feb 2019 05:29:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-sklonowac-duze-repozytorium-git-na-niestabilnym-laczu-sieciowym/</guid>
      <description>&lt;p&gt;Połączenie z internetem, z którego ostatnio przyszło mi korzystać, nie należało zbytnio do tych
najbardziej wydajnych pod względem prędkości przesyłu danych. O ile szybkość transferu można by
jeszcze przemilczeć, to owe łącze nie należało też do tych najstabilniejszych i czasem kontakt
ze światem był zwyczajnie zrywany. Krótko rzecz ujmując, ten net nadawał się chyba jedynie do
przeglądania stron WWW. Pech jednak chciał, że potrzebowałem zassać na takim
połączeniu &lt;a href=&#34;https://salsa.debian.org/kernel-team/linux&#34;&gt;repozytorium git&#39;a z patch&#39;ami Debiana&lt;/a&gt;
nakładanymi na kernel linux&#39;a. To repozytorium nie należy do największych ale też do małych ono
się nie zalicza -- waży około 2 GiB. Oczywiście można by zrobić jedynie płytki klon takiego repo za
sprawą &lt;code&gt;git clone --depth=1&lt;/code&gt; , co skutkowałoby pobraniem plików w wersji z ostatniego commit&#39;a, co
z kolei zredukowałoby w znacznym stopniu wielkość pobieranych danych (parę-paręnaście MiB). Co
jednak zrobić w przypadku, gdy musimy sklonować sporych rozmiarów repozytorium git, a dysponujemy
przy tym dość wolnym połączeniem sieciowym? Czy jest to w ogóle możliwe, bo przecież git nie ma
zaimplementowanej opcji wznawiania przerwanej synchronizacji i każde zakłócenie tego procesu
skutkować będzie tym, że całe repozytorium trzeba będzie pobrać jeszcze raz i to bez względu na to,
czy proces się zawiesi zaraz na początku, czy też pod koniec operacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak włączyć IPv6 Privacy Extensions w Debianie (SLAAC)</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-ipv6-privacy-extensions-w-debianie-slaac/</link>
      <pubDate>Sun, 10 Feb 2019 08:22:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-ipv6-privacy-extensions-w-debianie-slaac/</guid>
      <description>&lt;p&gt;Protokół IPv6 został opracowany już dość dawno temu, a jednak ilość hostów w internecie
komunikujących się za jego pomocą wciąż nie jest zbyt wysoka
i &lt;a href=&#34;https://www.google.com/intl/en/ipv6/statistics.html&#34;&gt;oscyluje w granicach 25%&lt;/a&gt;. Faktem jest, że
migracja z IPv4 na IPv6 może być sporym kosztem dla niektórych podmiotów jeśli chodzi o kwestię
związaną z wymianą sprzętu i ze zmianą konfiguracji sieci, co pewnie zniechęca część ISP do
wdrożenia tego protokołu. Użytkownicy korzystający z sieci z kolei nie wiedzieć czemu też
preferują IPv4 nad IPv6. Jakiś czas temu czytałem nawet artykuł na temat zagrożenia prywatności
jakie może nieść ze sobą protokół IPv6. Chodzi generalnie o to, że obecnie wszyscy przywykliśmy do
rozwiązania jakie oferuje nam NAT, które jest w stanie utrudnić nieco naszą identyfikację i analizę
naszej aktywności w internecie. W przypadku IPv6 adresy IP są dość unikatowe w skali globalnej, a
część odpowiedzialna za identyfikację hosta (ostatnie 64 bity) stanowi identyfikator EUI64, który z
kolei jest generowany na podstawie adresu MAC karty sieciowej. W taki oto sposób interfejs tej
karty będzie miał stały identyfikator EUI64, a hosta będzie można zidentyfikować bez problemu i
bez względu na to u którego ISP podłączymy nasz komputer. Rozwiązaniem tego problemu jest mechanizm
zwany IPv6 Privacy Extensions. Przydałoby się zatem rzucić na niego okiem i jeśli okaże się
użyteczny, to wypadałoby go włączyć w naszym Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ustalić nazwę procesu korzystającego z sieci</title>
      <link>https://morfikov.github.io/post/jak-ustalic-nazwe-procesu-korzystajacego-z-sieci/</link>
      <pubDate>Fri, 08 Feb 2019 20:10:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ustalic-nazwe-procesu-korzystajacego-z-sieci/</guid>
      <description>&lt;p&gt;Konfigurując filtr pakietów &lt;code&gt;iptables&lt;/code&gt;/&lt;code&gt;nftables&lt;/code&gt; na Debianie zwykle nie przykładamy większej wagi
do procesów, które chcą nawiązać połączenia wychodzące z naszego linux&#39;owego hosta. Mamy przecież
&amp;quot;skonfigurowany&amp;quot; firewall w łańcuchach &lt;code&gt;INPUT&lt;/code&gt; i &lt;code&gt;FORWARD&lt;/code&gt; i wszelkie zagrożenia z sieci nie
powinny nas dotyczyć. Problem w tym, że jeśli jakiś złowrogi proces zostanie uruchomiony w naszym
systemie, to jest on w stanie komunikować się ze światem zewnętrznym praktycznie bez żadnych
ograniczeń za sprawą braku jakichkolwiek reguł w łańcuchu &lt;code&gt;OUTPUT&lt;/code&gt; . Można oczywiście temu zaradzić
budując zaporę sieciową na bazie &lt;code&gt;cgroups&lt;/code&gt; , gdzie każda aplikacja będzie miała oznaczone pakiety,
przez co będzie można je rozróżnić i zablokować albo przepuścić przez filter. W tym wpisie jednak
nie będziemy się zajmować konstrukcją tego typu FW, tylko spróbujemy sobie odpowiedzieć na pytanie
jak namierzyć proces, który komunikuje się z siecią (lub też próbuje), posiadając jedynie log
&lt;code&gt;iptables&lt;/code&gt;/&lt;code&gt;nftables&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak uruchomić kilka usług w kontenerze Docker&#39;a</title>
      <link>https://morfikov.github.io/post/jak-uruchomic-kilka-uslug-w-kontenerze-dockera/</link>
      <pubDate>Sat, 02 Feb 2019 07:20:43 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-uruchomic-kilka-uslug-w-kontenerze-dockera/</guid>
      <description>&lt;p&gt;W kontenerach Docker&#39;a nie powinno się uruchamiać więcej usług niż jedna. Czasami jednak zachodzi
potrzeba, by właśnie uruchomić kilka niezależnych od siebie procesów, które będą ze sobą
współpracować w obrębie takiego pojedynczego kontenera. Weźmy sobie na przykład serwer WWW Apache2
i bazę danych MySQL/MariaDB. Każda z tych usług posiada swój dedykowany kontener (nawet oficjalny)
i generalnie skonfigurowanie komunikacji między tymi dwoma kontenerami Docker&#39;a nie jest niczym
trudnym. Jeśli jednak ktoś by się uparł, to może stworzyć sobie taki kontener, który będzie
uruchamiał obie te usługi. Oczywiście w tym przypadku raczej nikt nie będzie łączył tych dwóch
kontenerów w jeden ale są pewne sytuacje, w których będziemy chcieli uruchomić więcej niż jeden
proces wewnątrz kontenera i gdy ten czas nadejdzie, to wypadałoby wiedzieć jak się do tego
przedsięwzięcia zabrać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Większy stopień kompresii pliku recovery.img (TWRP)</title>
      <link>https://morfikov.github.io/post/wiekszy-stopien-kompresii-pliku-recovery-img-twrp/</link>
      <pubDate>Sat, 02 Feb 2019 06:33:44 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wiekszy-stopien-kompresii-pliku-recovery-img-twrp/</guid>
      <description>&lt;p&gt;Ostatnio próbowałem zaktualizować obraz TWRP recovery dla jednego z moich telefonów. Ja generalnie
buduje te obrazy ze źródeł OMNI ROM, a tam jest dostępnych szereg gałęzi, np. 6.0, 7.1, 8.1 , etc,
które naturalnie pasują do odpowiadających im wersji Androida. Do tej pory budowałem w oparciu o
gałąź 7.1 ale po wydaniu polecenia &lt;code&gt;repo sync&lt;/code&gt; , szereg aktualizacji w stosunku do repozytorium
&lt;code&gt;bootable/recovery&lt;/code&gt; zostało pobranych, w tym też i jedna trefna, która uwalała proces kompilacji.
Ostatecznie &lt;a href=&#34;https://gerrit.omnirom.org/#/c/android_bootable_recovery/+/33485/&#34;&gt;udało się problem namierzyć i zlikwidować&lt;/a&gt;
ale w międzyczasie próbowałem zbudować obraz TWRP recovery z gałęzi 8.1. Wygląda na to, że im
nowszy Android, tym obrazy recovery rosną w objętość i 16M, które u mnie jest limitem, zostało
przekroczone o jakieś 500K i to przy najbardziej okrojonej funkcjonalności trybu recovery. Czy
istnieje jakieś rozwiązanie, które by umożliwiło zmniejszenie rozmiaru obrazu
&lt;code&gt;ramdisk-recovery.img&lt;/code&gt; , co przełożyłoby się również na wagę pliku &lt;code&gt;recovery.img&lt;/code&gt; ? Tak, trzeba
tylko zmienić rodzaj kompresji z domyślnego &lt;code&gt;gzip&lt;/code&gt; na &lt;code&gt;lzma&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zalogować błędy podczas zamykania systemu Debian Linux</title>
      <link>https://morfikov.github.io/post/jak-zalogowac-bledy-podczas-zamykania-systemu-debian-linux/</link>
      <pubDate>Sat, 02 Feb 2019 06:12:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zalogowac-bledy-podczas-zamykania-systemu-debian-linux/</guid>
      <description>&lt;p&gt;By wyłączyć komputer, jego system operacyjny musi pierw zatrzymać (lub też ubić siłowo) wszystkie
działające usługi za wyjątkiem tego mającego PID z numerkiem 1. Zwykle proces zamykania się systemu
Debian Linux nie trwa więcej niż parę sekund ale czasami pojawiają się dziwne problemy, które mogą
to zadanie utrudnić lub też całkowicie uniemożliwić. Nawet jeśli system będzie się w stanie
zresetować, to zanim to nastąpi, to na konsoli mogą pojawić się komunikaty mogące pomóc nam w
zdiagnozowaniu dolegliwości, która doskwiera naszej maszynie. Problem w tym, że część tych
wiadomości nie zostanie nigdy zalogowana do pliku, gdzie moglibyśmy ich poszukać. Dzieje się tak
dlatego, że w pewnym określonym momencie zamykania się systemu trzeba wyłączyć usługę logowania, co
zwykle widać w logu jako &lt;code&gt;systemd-journald[]: Journal stopped&lt;/code&gt; . Gdy dziennik zostanie zatrzymany,
żadna wiadomość, która od tego momentu pojawi się na ekranie, nie zostanie już zalogowana do pliku.
Jeśli teraz pojawią nam się ostrzeżenia lub błędy, a po chwili komputer się zresetuje, to możemy
mieć nie lada problem z ustaleniem przyczyny mimo, że system nam ją zgłasza. Przydałoby się zapisać
te komunikaty, tylko jak to zrobić, skoro usługa logowania jest już nieaktywna?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uruchamianie graficznych aplikacji w kontenerach Docker&#39;a</title>
      <link>https://morfikov.github.io/post/uruchamianie-graficznych-aplikacji-w-kontenerach-dockera/</link>
      <pubDate>Sun, 27 Jan 2019 11:32:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uruchamianie-graficznych-aplikacji-w-kontenerach-dockera/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/jak-uruchomic-firefoxa-w-osobnej-przestrzeni-nazw-sieciowych/&#34;&gt;Bawiąc się ostatnio na Debianie przestrzeniami nazw sieciowych&lt;/a&gt;,
wpadł mi do głowy pomysł na nieco bardziej zautomatyzowaną formę separacji procesów użytkownika od
pozostałej części systemu. Co by nie mówić, opisany w podlinkowanym artykule sposób uruchomienia
Firefox&#39;a niezbyt mi przypadł do gustu. Nowy sposób separacji zakłada za to wykorzystanie
kontenerów Docker&#39;a, w których to będzie uruchamiany dowolny proces, np. Firefox, a całym
przedsięwzięciem związanym z procesem konteneryzacji będzie zajmował się już Docker. W ten sposób
uruchomienie dowolnej aplikacji, w tym też tych graficznych (GUI), będzie sprowadzać się do wydania
w terminalu tylko jednego polecenia. Zatem do dzieła.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak usunąć aplikacje bloatware ze smartfona z Androidem bez root</title>
      <link>https://morfikov.github.io/post/jak-usunac-aplikacje-bloatware-ze-smartfona-z-androidem-bez-root/</link>
      <pubDate>Sun, 27 Jan 2019 06:01:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-usunac-aplikacje-bloatware-ze-smartfona-z-androidem-bez-root/</guid>
      <description>&lt;p&gt;Jeśli mamy smartfon z Androidem na pokładzie, to zapewne każdy za nas zadawał sobie pytanie, czy da
radę z takiego telefonu pozbyć się szeregu aplikacji, z których praktycznie nie korzystamy na co
dzień. Część z tych programów można wyłączyć w ustawieniach systemowych ale są też i takie
aplikacje (głównie producenta telefonu, czy też operatora GSM albo te od Google), których
standardowo nie da się wyłączyć z poziomu działającego Androida. Nawet jeśli wymusimy zatrzymanie
stosownych usług, to za chwilę (lub po restarcie urządzenia) one i tak nam automatycznie wystartują.
Im więcej zbędnych aplikacji działa w tle, tym częstsze wybudzanie telefonu, a więc i szybsze
wyczerpywanie się baterii. Dlatego też jeśli nie korzystamy z wbudowanego w
ROM &lt;a href=&#34;https://en.wikipedia.org/wiki/Software_bloat&#34;&gt;bloatware&lt;/a&gt;, to przydałoby się go usunąć lub
chociaż trwale wyłączyć. Co ciekawe, tego typu proces nie musi odbywać się za sprawą administratora
systemu (root), bo w zasadzie każda aplikacja w Androidzie może zostać zainstalowana/odinstalowana
dla konkretnego użytkownika w systemie. Nie potrzebujemy mieć zatem nawet ukorzenionego Androida,
by pozbyć się tego całego syfu z systemu, który naszemu urządzeniu spędza sen z powiek i nie daje
mu się przy tym porządnie wyspać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ręcznie zweryfikować sygnaturę modułu kernela linux</title>
      <link>https://morfikov.github.io/post/jak-recznie-zweryfikowac-sygnature-modulu-kernela-linux/</link>
      <pubDate>Sat, 26 Jan 2019 10:10:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-recznie-zweryfikowac-sygnature-modulu-kernela-linux/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio kernelem linux na dystrybucji Debian i opcjami mającymi poprawić jego
bezpieczeństwo, włączyłem
sobie &lt;a href=&#34;https://morfikov.github.io
/post/automatyczne-podpisywanie-modulow-kernela-przez-dkms/&#34;&gt;mechanizm podpisywania modułów&lt;/a&gt;.
W ten sposób żaden zewnętrzny moduł nie zostanie załadowany przez jądro operacyjne, no chyba, że
taki moduł będzie podpisany przez ten sam klucz co i kernel. Zdziwiłem się odrobinę, gdy moim
oczom pokazał się hash &lt;code&gt;md4&lt;/code&gt; w wyjściu polecenia &lt;code&gt;modinfo&lt;/code&gt; . Jak się okazało później, to niezbyt
dokładne zinterpretowanie wiadomości PKCS#7 przez &lt;code&gt;kmod&lt;/code&gt; było (i nadal jest) wynikiem &lt;a href=&#34;https://bugzilla.redhat.com/show_bug.cgi?id=1320921&#34;&gt;błędu
obecnego w tym pakiecie od już paru lat&lt;/a&gt;. W
efekcie &lt;code&gt;modinfo&lt;/code&gt; nie jest w stanie zweryfikować tej sygnatury, a w moim umyśle zaistniało pytanie:
czy istnieje w ogóle możliwość manualnego sprawdzenia czy ta sygnatura jest w porządku? Kernel co
prawda ten cały zabieg przeprowadza automatycznie ale przydałoby się ręcznie zweryfikować
poprawność sygnatury modułu i przy okazji obadać sobie co tak naprawdę się dzieje podczas tego
procesu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak uruchomić Firefox&#39;a w osobnej przestrzeni nazw sieciowych</title>
      <link>https://morfikov.github.io/post/jak-uruchomic-firefoxa-w-osobnej-przestrzeni-nazw-sieciowych/</link>
      <pubDate>Sun, 20 Jan 2019 21:10:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-uruchomic-firefoxa-w-osobnej-przestrzeni-nazw-sieciowych/</guid>
      <description>&lt;p&gt;Domyślnie każdy proces uruchomiony na linux (w tym przypadku Debian) dziedziczy swoją przestrzeń
nazw sieciowych (network namespaces) od procesu nadrzędnego, standardowo od procesu init (tego z
pid 1). W takim przypadku, wszystkie procesy współdzielą tę samą przestrzeń nazw sieciowych, przez
co mają dostęp do tych samych interfejsów sieciowych, tych samych tras routingu, a reguły
firewall&#39;a czy ustawienia serwerów DNS w jednakowym stopniu dotyczą wszystkich procesów i
zmieniając sieciową konfigurację systemu robimy to globalnie dla wszystkich tych procesów
jednocześnie. Czasami tego typu mechanika działania sieci nie jest zbyt pożądana z punktu
widzenia bezpieczeństwa lub też prywatności użytkownika. Przykładem mogą być przeglądarki
internetowe, np. Firefox, Opera czy Google Chrome/Chromium, które mogą zdradzić nasz lokalny adres
IP (w przypadku stosowania NAT). Jako, że też zostawiamy wszędzie nasz namiar w postaci
zewnętrznego adresu IP, to oba te adresy mogą nas bez większego problemu zidentyfikować w
internecie. Można jednak postarać się, by ten adres lokalny, który zwróci przeglądarka
internetowa, różnił się od tego, który przydziela nam nasz operator ISP.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przy pomocy Magisk&#39;a pogodzić SafetyNet i ADB/USB debug</title>
      <link>https://morfikov.github.io/post/jak-przy-pomocy-magiska-pogodzic-safetynet-i-adb-usb-debug/</link>
      <pubDate>Sat, 19 Jan 2019 21:12:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przy-pomocy-magiska-pogodzic-safetynet-i-adb-usb-debug/</guid>
      <description>&lt;p&gt;Do tej pory zbytnio nie interesowałem się zagadnieniami dotyczącymi
mechanizmu &lt;a href=&#34;https://lineageos.org/Safetynet/&#34;&gt;SafetyNet&lt;/a&gt;, który ma na celu
utrudnić nieco życie użytkownikom smartfonów z Androidem lubiącym posiadać pełny dostęp do
systemu swoich urządzeń za sprawą uzyskania praw administratora (root). To co się zmieniło na
przestrzeni ostatnich paru miesięcy, to fakt, że coraz więcej aplikacji polega na tym całym
SafetyNet, a przynajmniej ja zaczynam coraz częściej korzystać z tego typu oprogramowania. Jeśli
jednak nasze urządzenie nie przejdzie testów SafetyNet, to funkcjonalność aplikacji polegających na
tym mechanizmie może zostać dość znacznie ograniczona. Przykładem może być appka Revolut i jej
odblokowanie za pomocą czytnika linii papilarnych. Bez SafetyNet trzeba podawać PIN za każdym
razem, gdy się do tej aplikacji będziemy próbowali zalogować. Zwykle do obejścia SafetyNet używa
się Magisk&#39;a ale w pewnych sytuacjach, nawet i on nie jest w stanie z tym zdaniem sobie poradzić,
przynajmniej nie bez dodatkowej konfiguracji. Jeśli na co dzień korzystamy z opcji debugowania
ADB/USB, to może nas spotkać nie lada dylemat -- ADB/USB debug vs. SafetyNet. Okazuje się, że można
pogodzić te dwie rzeczy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatyczne podpisywanie modułów kernela przez DKMS</title>
      <link>https://morfikov.github.io/post/automatyczne-podpisywanie-modulow-kernela-przez-dkms/</link>
      <pubDate>Sat, 05 Jan 2019 04:10:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/automatyczne-podpisywanie-modulow-kernela-przez-dkms/</guid>
      <description>&lt;p&gt;Budując kernel linux&#39;a trzeba zastanowić się nad kwestią modułów, które nie są wbudowane
bezpośrednio w samo jądro operacyjne. Nie chodzi tutaj bezpośrednio o funkcjonalność kernela,
którą można zbudować jako moduł w procesie jego kompilacji ale raczej o wszystkie zewnętrzne
moduły, które przez zespół kernela są traktowane jako &lt;code&gt;out-of-tree&lt;/code&gt; . By poprawić nieco
bezpieczeństwo związane z takimi modułami, można wdrożyć podpisy cyfrowe, które takie moduły
muszą okazać podczas próby załadowania ich w systemie. Gdy moduł nie został podpisany, to kernel
go nie załaduje zwracając przy tym błąd &lt;code&gt;modprobe: ERROR: could not insert &#39;module&#39;: Required key not available&lt;/code&gt; . W ten sposób można ochronić się przed częścią ataków, w których moduły pochodzenia
trzeciego mogą zostać załadowane i poczynić nam ogromne spustoszenie w systemie. Problem w tym, że
w dystrybucji Debian wykorzystywany jest mechanizm DKMS (Dynamic Kernel Module Support). Może i
mamy dzięki niemu możliwość instalacji w systemie całej masy dodatkowych modułów ale ich również
nie będzie można załadować, bo nie zostały podpisane kluczem, którego certyfikat został zaszyty
w kernelu. Można jednak zmusić mechanizm DKMS, by wskazane przez nas moduły podpisywał
automatycznie przy ich instalacji i aktualizacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Budowanie kernela linux dla konkretnej maszyny z Debianem</title>
      <link>https://morfikov.github.io/post/budowanie-kernela-linux-dla-konkretnej-maszyny-z-debianem/</link>
      <pubDate>Thu, 27 Dec 2018 22:14:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/budowanie-kernela-linux-dla-konkretnej-maszyny-z-debianem/</guid>
      <description>&lt;p&gt;Każda maszyna działająca pod kontrolą dystrybucji linux ma na swoim pokładzie kernel, czyli jądro
operacyjne, które zarządza praktycznie każdym aspektem pracy takiego komputera. W dystrybucji
Debian, kernel jest dostarczany w pakietach mających nazwy zaczynające się od &lt;code&gt;linux-image-*&lt;/code&gt;.
Te pakiety są budowane przez odpowiednie osoby z zespołu Debiana i udostępniane do łatwej
instalacji użytkownikowi końcowemu. Niemniej jednak, taki kernel ma za zadanie działać na jak
największej ilości komputerów, a przez to posiada całą masę modułów, które na naszej maszynie nigdy
nie będą wykorzystane. Ten fakt nie wpływa w jakimś ogromnym stopniu na pracę maszyny, ale gdy
później zachodzi potrzeba skonfigurowania kernela w nieco inny sposób, np. włączenie jednej czy
dwóch opcji czy też nałożenie patch&#39;a, który nie został zaaplikowany przez dev&#39;ów Debiana, to
trzeba taki kernel na nowo skompilować już samodzielnie, a to zajmie nam bardzo dużo czasu. Zamiast
tego można pokusić się o przygotowanie kernela pod konkretny hardware wyłączając przy tym całą masę
zbędnych rzeczy i ograniczając przy tym czas jaki jest potrzebny na zbudowanie całego jądra
operacyjnego. Czy istnieje jakiś prosty sposób, by taki kernel zbudować sobie samemu mając przy tym
minimalną wiedzę co do opcji kernela, które mogą nas przysporzyć o ból... głowy? Okazuje się, że
tak i w tym artykule prześledzimy sobie cały ten proces.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kernel crash przy szyfrowaniu smartfona lub próbie resetu ustawień do fabrycznych</title>
      <link>https://morfikov.github.io/post/kernel-crash-przy-szyfrowaniu-smartfona-lub-probie-resetu-ustawien-do-fabrycznych/</link>
      <pubDate>Sat, 22 Sep 2018 11:13:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kernel-crash-przy-szyfrowaniu-smartfona-lub-probie-resetu-ustawien-do-fabrycznych/</guid>
      <description>&lt;p&gt;Parę dni temu dowiedziałem się o &lt;a href=&#34;https://e.foundation/&#34;&gt;projekcie /e/&lt;/a&gt;. Z racji, że ten ROM jest
dostępny na mój smartfon LG G4C (jeszcze nieoficjalnie), to postanowiłem go sobie wgrać i zobaczyć
jak się będzie sprawował. Podczas testów nowego oprogramowania spróbowałem zaszyfrować partycję
&lt;code&gt;/data/&lt;/code&gt; . Problem w tym, że po automatycznym zresetowaniu się systemu, urządzenie już nie chciało
się uruchomić. Przez dłuższy czas widniało logo LG, a po chwili pojawił się czarny ekran z
informacją &amp;quot;Kernel Crash&amp;quot; lub niebieski ekran z informacją &amp;quot;Subsystem Crash&amp;quot;. Czy telefon w takiej
sytuacji nadaje się jedynie do wyrzucenia?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana domyślnego hasła szyfrującego klucz główny w Neffos X1 i X1 Max</title>
      <link>https://morfikov.github.io/post/zmiana-domyslnego-hasla-szyfrujacego-klucz-glowny-w-neffos-x1-i-x1-max/</link>
      <pubDate>Wed, 16 May 2018 17:17:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-domyslnego-hasla-szyfrujacego-klucz-glowny-w-neffos-x1-i-x1-max/</guid>
      <description>&lt;p&gt;Nie bawiłem się ostatnio Neffos&#39;ami ale w końcu udało mi się doprowadzić szyfrowanie w X1 Max (i
pewnie X1 też) do ładu. Dla przypomnienia, to w tych modelach najwyraźniej system zapomniał by
pytać użytkownika o hasło podczas konfiguracji, a że partycja z danymi użytkownikami jest
zaszyfrowana w standardzie (bez możliwości zmiany), to ustawiane jest domyślne hasło tj.
&lt;code&gt;default_password&lt;/code&gt; . W ten sposób z technicznego punktu widzenia wilk jest syty i owca cała,
no bo użytkownik nie jest dręczony dodatkowym hasłem przy uruchamianiu systemu (obok hasła blokady
ekranu), no i dane są zaszyfrowane, no chyba, że ktoś wpisze ten nieszczęsny
&lt;code&gt;default_password&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ustalić IP i nazwę pliku trybu recovery w routerach TP-Link</title>
      <link>https://morfikov.github.io/post/jak-ustalic-ip-i-nazwe-pliku-trybu-recovery-w-routerach-tp-link/</link>
      <pubDate>Thu, 17 Aug 2017 21:22:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ustalic-ip-i-nazwe-pliku-trybu-recovery-w-routerach-tp-link/</guid>
      <description>&lt;p&gt;Jeden z moich routerów, a konkretnie był
to &lt;a href=&#34;http://www.tp-link.com/us/download/Archer-C7.html&#34;&gt;Archer C7&lt;/a&gt; v2 wymagał, by powrócić jego
firmware z LEDE/OpenWRT do tego, który widnieje na oficjalnej stronie TP-Link. Niby ta czynność nie
jest zbyt skomplikowana ale jak zwykle coś poszło nie tak. Konkretnie to odłączyłem zasilanie nie w
tej listwie co trzeba i w efekcie podczas flash&#39;owania routera nowym firmware, to urządzenie się
zwyczajnie wyłączyło. Zawału oczywiście nie dostałem, bo przecież obraz, który był wgrywany na
router nie zawierał uboot&#39;a, czyli części z bootloader&#39;em, więc wiedziałem, że wystarczy przez tryb
recovery wgrać obraz jeszcze raz i po sprawie. Problem w tylko w tym, że nie znałem w zasadzie ani
nazwy pliku obrazu, ani też adresu IP, który jest wymagany dla połączenia w przypadku routera
Archer C7 v2. Te dane można naturalnie znaleźć w sieci ale co w przypadku, gdy ubijemy sobie w taki
sposób nasz jedyny router, przez co pozbawimy się jednocześnie dostępu do internetu? Czy istnieje
jakiś sposób na ustalenie tych danych, inny niż przez konsolę szeregową?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak sprawdzić czy smartfon z Androidem podlega gwarancji</title>
      <link>https://morfikov.github.io/post/jak-sprawdzic-czy-smartfon-z-androidem-podlega-gwarancji/</link>
      <pubDate>Tue, 02 May 2017 17:19:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-sprawdzic-czy-smartfon-z-androidem-podlega-gwarancji/</guid>
      <description>&lt;p&gt;Gdy kupujemy smartfon, to jego producent daje nam na ten sprzęt gwarancję i przez pewien okres czasu
możemy nie martwić się o koszty ewentualnej naprawy. Niestety żyjemy w takich czasach, że sprzęt
elektroniczny potrafi nam paść sam z siebie i to do tego jeszcze w niewyjaśnionych okolicznościach.
Cześć wad jest fabrycznych (zwykle fizycznych) i te z reguły są oczywiste i łatwe do zdiagnozowania
przez support producenta sprzętu, który nabyliśmy. Niemniej jednak, czasami wady są natury czysto
programowej i tu z kolei ustalenie, gdzie dokładnie leży problem może już sprawiać kłopoty. Dlatego
też producenci telefonów zabezpieczają się przed zmianą firmware przez użytkownika. W ten sposób
wgrywając, np. TWRP recovery czy przeprowadzając proces root Androida, zwykle pozbawiamy się
gwarancji i mamy problem, gdy telefon w późniejszym czasie popsuje się nie z naszej winy. Nawet
jeśli wgramy stock&#39;owe oprogramowanie, to i tak producent sprzętu jest w stanie ustalić czy coś w
firmware mieszaliśmy. Zastanawialiście się może zatem skąd producent smartfona wie czy firmware
takiego urządzenia został w jakiś sposób przez nas zmieniony?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak usunąć blokadę bootloader&#39;a (OEM lock) w smartfonie z Androidem</title>
      <link>https://morfikov.github.io/post/jak-usunac-blokade-bootloadera-oem-lock-w-smartfonie-z-androidem/</link>
      <pubDate>Sun, 30 Apr 2017 19:17:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-usunac-blokade-bootloadera-oem-lock-w-smartfonie-z-androidem/</guid>
      <description>&lt;p&gt;Eksperymentując ostatnimi czasy ze smartfonami mającymi na pokładzie system Android nie zdarzyło mi
się jeszcze, by jakoś poważniej taki telefon uszkodzić. Oczywiście wiele razy złapałem soft brick&#39;a
(bootloop i inne takie) ale w zasadzie bez większego problemu szło z takiej sytuacji wybrnąć. Dziś
jednak sprawa była nieco bardziej poważna, bo mój &lt;a href=&#34;http://www.neffos.com/en/product/details/X1&#34;&gt;Neffos
X1&lt;/a&gt; nie chciał się po prostu uruchomić, a konkretnie to
pojawiało się logo TP-LINK i Android i telefon na tym ekranie startowym się zwyczajnie zawieszał.
Pikanterii dodaje jeszcze fakt, że przed sprawdzeniem czy telefon działa poprawnie, zablokowałem
bootloader przez &lt;code&gt;fastboot oem lock&lt;/code&gt; . Naturalnie bootloader można odblokować też przy użyciu
&lt;code&gt;fastboot&lt;/code&gt; ale po zresetowaniu urządzenia, ta opcja, którą się przełącza w ustawieniach
deweloperskich automatycznie wraca do pozycji zablokowanej. W taki sposób, by odblokować bootloader
ponownie, trzeba wejść w te opcje jeszcze raz i tam ściągnąć pierw blokadę OEM, a dopiero później
można mówić o bawieniu się &lt;code&gt;fastboot&lt;/code&gt; . A jak niby mamy wejść w te ustawienia jeśli system nie chce
wystartować, a my mamy stock&#39;owy firmware producenta smartfona? Czy taki stan rzeczy oznacza trwałe
uszkodzenie telefonu?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Smartfon Neffos X1 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-smartfon-neffos-x1-od-tp-link/</link>
      <pubDate>Sat, 22 Apr 2017 18:51:37 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-smartfon-neffos-x1-od-tp-link/</guid>
      <description>&lt;p&gt;Stosunkowo niedawno do polskiej oferty TP-LINK trafił &lt;a href=&#34;http://www.neffos.com/en/product/details/X1&#34;&gt;smartfon Neffos
X1&lt;/a&gt;. To urządzenie było dostępne już dłuższy czas na
rynku (zaprezentowane w Berlinie na targach IFA we wrześniu 2016) ale do Polski trafiło ono z dość
mocnym opóźnieniem. Tak czy inaczej, ten telefon można już nabyć w sklepach, przez co wypadałoby
rzucić na niego okiem i przyjrzeć się mu nieco bliżej. Dzięki uprzejmości TP-LINK Polska, Neffos X1
trafił do mnie na testy i postanowiłem napisać krótką recenzję tego sprzętu w kontekście pozostałych
smartfonów Neffos, którymi miałem okazję się bawić w przeszłości, tj. modelami
&lt;a href=&#34;https://morfikov.github.io
/post/recenzja-smartfon-neffos-c5-od-tp-link/&#34;&gt;C5&lt;/a&gt;, &lt;a href=&#34;https://morfikov.github.io
/post/recenzja-smartfon-neffos-c5-max-od-tp-link/&#34;&gt;C5
MAX&lt;/a&gt;,
&lt;a href=&#34;https://morfikov.github.io
/post/recenzja-smartfon-neffos-y5-od-tp-link/&#34;&gt;Y5&lt;/a&gt; i
&lt;a href=&#34;https://morfikov.github.io
/post/recenzja-smartfon-neffos-y5l-od-tp-link/&#34;&gt;Y5L&lt;/a&gt;. Czy Neffos X1 jest nas w
stanie czymś zaskoczyć w stosunku do wcześniejszych modelów tych TP-LINK&#39;owych smartfonów?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Test wydajności smartfona Neffos X1 od TP-LINK</title>
      <link>https://morfikov.github.io/post/test-wydajnosci-smartfona-neffos-x1-od-tp-link/</link>
      <pubDate>Sat, 22 Apr 2017 17:49:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/test-wydajnosci-smartfona-neffos-x1-od-tp-link/</guid>
      <description>&lt;p&gt;Dzięki uprzejmości TP-LINK Polska od paru dni mam możliwość bawić się smartfonem Neffos X1.
Postanowiłem więc przetestować możliwości tego telefonu dostępnymi benchmarkami na Androida, które
można pobrać ze sklepu Google Play. Mnie generalnie tego typu benchmarki średnio interesują, bo
zwykle nijak się mają do standardowego użytkowania telefonu ale wiem, że sporo użytkowników
mobilnych technologi chciałaby tego typu test zobaczyć. Dlatego w oparciu o AnTuTu, 3DMark, PCMark
oraz GFXBench zrobiłem kilka testów i sprawdziłem jak Neffos X1 sobie w nich poradził.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Podzespoły w smartfonie Neffos C5 od TP-LINK</title>
      <link>https://morfikov.github.io/post/podzespoly-w-smartfonie-neffos-c5-od-tp-link/</link>
      <pubDate>Sun, 09 Apr 2017 20:09:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/podzespoly-w-smartfonie-neffos-c5-od-tp-link/</guid>
      <description>&lt;p&gt;Jak można było wywnioskować z &lt;a href=&#34;https://morfikov.github.io
/post/recenzja-smartfon-neffos-c5-od-tp-link/&#34;&gt;recenzji Neffos C5 od
TP-LINK&lt;/a&gt;, ten smartfon to w zasadzie
niedrogie i dość przyzwoite urządzenie. Korzystając z okazji postanowiłem zrobić kilka dodatkowych
zdjęć tego telefonu, z tym, że tym razem fotki obrazują to, co było wewnątrz obudowy. Jeśli
posiadacie Neffos&#39;a C5 i jesteście ciekawi co to urządzenie skrywa pod maską, to w tym wpisie
znajdziecie odpowiedzi na dręczące was pytania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Podzespoły w smartfonie Neffos C5 MAX od TP-LINK</title>
      <link>https://morfikov.github.io/post/podzespoly-w-smartfonie-neffos-c5-max-od-tp-link/</link>
      <pubDate>Fri, 07 Apr 2017 20:44:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/podzespoly-w-smartfonie-neffos-c5-max-od-tp-link/</guid>
      <description>&lt;p&gt;Jakiś czas temu &lt;a href=&#34;https://morfikov.github.io
/post/recenzja-smartfon-neffos-c5-max-od-tp-link/&#34;&gt;recenzowałem smartfon Neffos C5 MAX od
TP-LINK&lt;/a&gt;. W tamtym wpisie
praktycznie wszystko już zostało powiedziane na temat tego telefonu ale jednej rzeczy nie mogłem w
czasie pisania tamtego artykułu zamieścić. Chodzi o fotki podzespołów tego urządzenia. Na dobrą
sprawę producent podaje jedynie model SoC i nie wiadomo praktycznie nic w przypadku pozostałych
układów, no może poza pobieżnymi informacjami na temat WiFi, bluetooth czy GPS. Postanowiłem zatem
rozkręcić swojego Neffos&#39;a C5 MAX i przekonać się co wewnątrz skrywa jego obudowa.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Repartycjonowanie flash&#39;a w Neffos C5 i C5 MAX od TP-LINK</title>
      <link>https://morfikov.github.io/post/repartycjonowanie-flash-w-neffos-c5-i-c5-max-od-tp-link/</link>
      <pubDate>Mon, 03 Apr 2017 19:51:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/repartycjonowanie-flash-w-neffos-c5-i-c5-max-od-tp-link/</guid>
      <description>&lt;p&gt;Analizując sobie fabryczny podział przestrzeni flash w TP-LINK&#39;owych smartfonach, a konkretnie w
modelach Neffos C5 i C5 MAX, doszedłem do wniosku, że producent tych urządzeń nieco zaszalał
przeznaczając aż 4 GiB przestrzeni na partycję &lt;code&gt;/system/&lt;/code&gt; . W zasadzie ROM w tych telefonach zajmuje
około 2 GiB. Zatem pozostałe 2 GiB zwyczajnie się marnuje i przeciętny użytkownik smartfona nie
będzie w stanie tego obszaru w żaden sposób wykorzystać. Można by zatem inaczej przepartycjonować
ten flash, tak by nieco skurczyć samą partycję &lt;code&gt;/system/&lt;/code&gt; , przeznaczając jednocześnie odzyskane
miejsce na powiększenie partycji &lt;code&gt;/data/&lt;/code&gt; . W tym wpisie postaramy się właśnie taki zabieg zmiany
rozmiaru partycji &lt;code&gt;/system/&lt;/code&gt; przeprowadzić dla tych dwóch wyżej wymienionych modeli smartfonów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Root w smartfonach Neffos od TP-LINK (X1, C5, C5 MAX, Y5, Y5L)</title>
      <link>https://morfikov.github.io/post/root-w-smartfonach-neffos-od-tp-link-x1-c5-c5-max-y5-y5l/</link>
      <pubDate>Sun, 02 Apr 2017 19:27:56 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/root-w-smartfonach-neffos-od-tp-link-x1-c5-c5-max-y5-y5l/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem proces ukorzeniania (root) smartfonów Neffos, a konkretnie były to modele
&lt;a href=&#34;http://www.neffos.pl/product/details/C5&#34;&gt;C5&lt;/a&gt;, &lt;a href=&#34;http://www.neffos.pl/product/details/C5-Max&#34;&gt;C5
MAX&lt;/a&gt;, &lt;a href=&#34;http://www.neffos.pl/product/details/Y5&#34;&gt;Y5&lt;/a&gt; i
&lt;a href=&#34;http://www.neffos.pl/product/details/Y5L&#34;&gt;Y5L&lt;/a&gt;. Od tamtego czasu zdążyłem się nieco bardziej
zagłębić w struktury Androida i udało mi się ze źródeł &lt;a href=&#34;https://omnirom.org/&#34;&gt;OMNI ROM&lt;/a&gt; zbudować
natwyne obrazy TWRP dla każdego z tych ww. telefonów. Oczywiście TP-LINK ma w swojej ofercie jeszcze
modele &lt;a href=&#34;http://www.neffos.pl/product/details/C5L&#34;&gt;C5L&lt;/a&gt;,
&lt;a href=&#34;http://www.neffos.com/en/product/details/Y50&#34;&gt;Y50&lt;/a&gt;,
&lt;a href=&#34;http://www.neffos.com/en/product/details/X1&#34;&gt;X1&lt;/a&gt; oraz &lt;a href=&#34;http://www.neffos.com/en/product/details/X1Max&#34;&gt;X1
MAX&lt;/a&gt; ale póki co nie będę w stanie przygotować
obrazu TWRP i opisu jak ukorzenić Androidy w trzech z tych czterech smartfonów. Chodzi o to, że C5L
został wycofany z produkcji i raczej nie wpadnie on w moje łapki. Natomiast modele Y50 oraz X1 MAX
nie są jeszcze dostępne w polskiej ofercie TP-LINK&#39;a, przez co minie trochę czasu zanim uda mi się
do nich dobrać. Postanowiłem napisać świeży artykuł dotyczący procesu root w smartfonach Neffos C5,
C5 MAX, Y5, Y5L oraz X1. Po co pisać kolejny artykuł o ukorzenianiu Androida w Neffos&#39;ach?
Generalnie rzecz biorąc, w tych poprzednich wpisach było bardzo dużo informacji zbędnych z punktu
widzenia przeciętnego użytkownika, który chce zrootować system w swoim telefonie. Teraz, gdy
dysponuję natywnymi obrazami TWRP własnej roboty i zdobyłem nieco wiedzy z zakresu operowania na
Androidzie, to proces root jest o wiele prostszy i właśnie dlatego przydałoby się to wszystko opisać
na nowo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Szyfrowanie rozmów i SMS&#39;ów na smartfonie z Androidem (Signal)</title>
      <link>https://morfikov.github.io/post/szyfrowanie-rozmow-i-smsow-na-smartfonie-z-androidem-signal/</link>
      <pubDate>Sun, 26 Mar 2017 18:35:14 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/szyfrowanie-rozmow-i-smsow-na-smartfonie-z-androidem-signal/</guid>
      <description>&lt;p&gt;Każdy z nas ma już raczej w swoim posiadaniu telefon, czy jego nieco bardziej zaawansowaną wersję
określaną mianem smartfona. Te urządzenia to w zasadzie przenośne i do tego bardzo małe komputery,
które umożliwiają nam komunikowanie się z osobami na całym świecie. Wykonywanie połączeń głosowych,
przesyłanie SMS&#39;ów/MMS&#39;ów czy też korzystanie z Internetu w naszych komórkach od dawna jest już
standardem i ciężko byłoby nam się obejść bez tej technologii obecnie. Problem w tym, że nasza
komunikacja jest narażona na podsłuch. W przypadku Internetu większość połączeń jest już szyfrowana
na linii dwóch klientów (E2E, End To End). Natomiast jeśli chodzi o telefony, to tutaj sprawa kuleje
i to bardzo poważnie, bo w zasadzie nasze połączenia głosowe czy SMS&#39;y są do wglądu dla każdych
służb, które z jakiegoś powodu uznają, że mogą naruszać naszą prywatność. Jedyna opcja, która jest
w stanie zabezpieczyć nas przed tego typu praktykami, to szyfrowanie rozmów. Tak się składa, że jest
kilka aplikacji na Androida, które są w stanie realizować tego typu przedsięwzięcie. Jedną z nich
jest darmowa i otwartoźródłowa aplikacja Signal, której się przyjrzymy nieco bliżej w tym artykule.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja serwera XMPP/Jabber pod linux (ejabberd)</title>
      <link>https://morfikov.github.io/post/konfiguracja-serwer-xmpp-jabber-linux-ejabberd/</link>
      <pubDate>Mon, 20 Mar 2017 20:26:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-serwer-xmpp-jabber-linux-ejabberd/</guid>
      <description>&lt;p&gt;Użytkownicy internetu mają całą masę różnych sposobów na komunikację miedzy sobą. Kiedyś wszyscy
korzystali z komunikatorów typu Gadu-Gadu. Ja byłem jedyną osobą, która od samego początku wolała
alternatywne rozwiązania i jechałem na komunikatorze Tlen (ten od O2), a w niedługim czasie
przesiadłem się na Jabber&#39;a i tak z niego korzystam do dziś. W zasadzie GG i Tlen są obecnie już
chyba na wymarciu, bo większość ludzi (jak nie wszyscy) przerzuciła się na Facebook&#39;a czy Twitter&#39;a.
Niemniej jednak, pisanie o sprawach prywatnych w tych serwisach nie jest najlepszym rozwiązaniem.
Jeśli chcemy zadbać o poufność przesyłanych przez internet komunikatów, to trzeba to robić na inne
sposoby. Jednym z nich jest właśnie korzystanie z &lt;a href=&#34;https://xmpp.org/&#34;&gt;protokołu XMPP/Jabber&lt;/a&gt;. To co
odróżnia Jabber&#39;a od innych technologii na rynku, to fakt zdecentralizowania sieci, czyli mamy całą
masę serwerów Jabber&#39;a, na których możemy sobie stworzyć konto. Uwalenie jednego serwera nie wpływa
na działanie pozostałych. Google także wykorzystuje protokół XMPP/Jabber i mając konto na gmail&#39;u,
mamy również stosowny JID w postaci adresu email, który możemy sobie wklepać do jednego z klientów
Jabber&#39;a, np. &lt;a href=&#34;https://xmpp.org/software/clients.html&#34;&gt;PSI czy Gajim&lt;/a&gt;, i jesteśmy już w stanie
rozmawiać z osobami, które mają konta na innych serwerach. Właśnie, inne serwery, a może by tak
sobie postawić własny serwer Jabber&#39;a? Tak się składa, że w repozytorium Debiana znajduje się
&lt;a href=&#34;https://www.ejabberd.im/&#34;&gt;oprogramowanie ejabberd&lt;/a&gt;, które jest nam w stanie umożliwić realizację
tego przedsięwzięcia.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Wgrywanie update.zip przez ADB sideload via TWRP recovery</title>
      <link>https://morfikov.github.io/post/android-wgrywanie-update-zip-przez-adb-sideload-via-twrp-recovery/</link>
      <pubDate>Thu, 09 Mar 2017 18:31:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-wgrywanie-update-zip-przez-adb-sideload-via-twrp-recovery/</guid>
      <description>&lt;p&gt;Po uszkodzeniu jednego z moich smartfonów TP-LINK i skasowaniu na nim wszystkich danych na partycji
&lt;code&gt;/system/&lt;/code&gt; trzeba było pomyśleć nad przywróceniem tego urządzenia do życia. Jednym z rozwiązać było
&lt;a href=&#34;https://morfikov.github.io
/post/android-jak-odratowac-smartfon-po-usunieciu-partycji-system/&#34;&gt;binarne wgranie obrazu systemowej partycji bezpośrednio na flash przy pomocy narzędzia
dd&lt;/a&gt;. Co jednak
w przypadku, gdy nie mamy dostępu do backup&#39;u lub tez zwyczajnie go nie zrobiliśmy? Co w takiej
sytuacji uczynić i czy jest jakaś nadzieja dla naszego telefonu? Odpowiedź jest naturalnie
twierdząca ale wymagane są dwie rzeczy: działający tryb recovery (najlepiej TWRP) ze wsparciem dla
trybu &amp;quot;ADB sideload&amp;quot; oraz paczka &lt;code&gt;update.zip&lt;/code&gt; z firmware, którą można pobrać bezpośrednio ze strony
TP-LINK/Neffos. By ulżyć nieco osobom, które do mnie piszą z zapytaniem o pomoc w przypadku
skasowania danych na partycji &lt;code&gt;/system/&lt;/code&gt; (czy uszkodzenia jej w jakiś sposób), postanowiłem napisać
krótkie howto na temat używania trybu ADB sideload. W tym artykule w rolach głównych weźmie udział
&lt;a href=&#34;http://www.neffos.pl/product/details/Y5&#34;&gt;Neffos Y5&lt;/a&gt; ale bez problemu można te kroki przeprowadzić
chyba na każdym innym smartfonie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Jak odratować smartfon po usunięciu partycji /system/</title>
      <link>https://morfikov.github.io/post/android-jak-odratowac-smartfon-po-usunieciu-partycji-system/</link>
      <pubDate>Thu, 09 Mar 2017 14:24:44 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-jak-odratowac-smartfon-po-usunieciu-partycji-system/</guid>
      <description>&lt;p&gt;Zawsze mnie zastanawiało jak to jest możliwe, by przez przypadek można było usunąć dane na jeden z
kluczowych partycji w smartfonie jaką jest partycja &lt;code&gt;/system/&lt;/code&gt; . Ostatnio wiele osób do mnie pisało
z tego typu problemami i zapytaniem &amp;quot;jak odratować w takiej sytuacji telefon&amp;quot;. Odpowiedź wydawała mi
się prosta: wystarczy wgrać uprzednio zrobiony backup wyczyszczonej partycji via &lt;code&gt;fastboot&lt;/code&gt; .
Problem w tym, że po usunięciu danych z partycji &lt;code&gt;/system/&lt;/code&gt; , &lt;code&gt;fastboot&lt;/code&gt; nie działa. A skąd to wiem?
Ano &amp;quot;przez przypadek&amp;quot; usunąłem sobie dane na tej partycji. W sumie to tylko testowałem &lt;a href=&#34;https://twrp.me/faq/ADBSideload.html&#34;&gt;ficzer w
TWRP zwany ADB Sideload&lt;/a&gt;, który niby ma za zadanie wgrać ROM z
paczki &lt;code&gt;.zip&lt;/code&gt; . Coś poszło nie tak i w zasadzie zostałem z pustą partycją &lt;code&gt;/system/&lt;/code&gt; . Przy
odpalaniu telefonu w takim stanie, ten w zasadzie jedynie się resetuje co kilka chwil. Może i
&lt;code&gt;fastboot&lt;/code&gt; nie działa ale można wbić do trybu recovery. Jeśli tylko mamy wgrany TWRP, to jest spora
szansa na odratowanie smartfona. W tym artykule w rolach głównych wystąpi &lt;a href=&#34;http://www.neffos.pl/product/details/Y5L&#34;&gt;Neffos
Y5L&lt;/a&gt;, który ma SoC od Qualcomm&#39;a, zatem nie damy rady się
pobawić SP Flash Tool i całą robotę trzeba będzie odwalić ręcznie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Zmiana trybu USB z Charge-Only na MTP w Marshmallow</title>
      <link>https://morfikov.github.io/post/android-zmiana-trybu-usb-z-charge-only-na-mtp-w-marshmallow/</link>
      <pubDate>Sun, 05 Mar 2017 18:25:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-zmiana-trybu-usb-z-charge-only-na-mtp-w-marshmallow/</guid>
      <description>&lt;p&gt;System Android w większej lub mniejszej części zmienia się z wydania na wydanie. Te nowsze wersje
zwykle zawierają całą masę nowych mechanizmów i rozbudowują te już istniejące, tak by ten OS w
lepszym stopniu zaspokajał zachcianki użytkowników smartfonów. Problem w tym, że niektóre kroki
deweloperów Androida potrafią wprawić w zastanowienie niejednego logicznie myślącego osobnika.
Przykładem może być przestawienie domyślnego trybu USB w Marshmallow z MTP na Charge-Only (tylko
ładowanie). Jedni mówią, że takie posunięcie jest podyktowane względami bezpieczeństwa, a inni, że
chodzi o performance przy ładowaniu baterii, gdzie moduł USB nie działa w tym drugim trybie i nie
konsumuje energii, przez co ładowanie ma przebiegać szybciej. Ile w tym prawdy, tego nie wiem ale ja
za bardzo nie widzę żadnych wymiernych korzyści z przestawienia tego trybu na Charge-Only. Natomiast
widzę bardzo wyraźnie utrudnienia przy interakcji telefonu z komputerem za sprawą tej zmiany.
Poszukałem trochę informacji na ten temat i znalazłem rozwiązanie w postaci aplikacji MTP enabler.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Framework Xposed i moduły do YouTube</title>
      <link>https://morfikov.github.io/post/android-framework-xposed-i-moduly-do-youtube/</link>
      <pubDate>Sat, 04 Mar 2017 21:56:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-framework-xposed-i-moduly-do-youtube/</guid>
      <description>&lt;p&gt;Stock&#39;owe Androidy w smartfonach mają ten problem, że zawierają całą masę preinstalowanych aplikacji
od Google. Nie to by jakoś mnie to bolało, no może za wyjątkiem braku możliwości ich wywalenia czy
wyłączenia. To co mnie trochę irytuje, to fakt obecności reklam w aplikacji YouTube. Nie da rady się
ich pozbyć praktycznie w żaden sposób. Zdaję sobie sprawę, że serwis YT można przeglądać w
Firefox&#39;ie i jeśli mamy &lt;a href=&#34;https://morfikov.github.io
/post/android-blokowanie-reklam-z-adaway-na-smartfonie/&#34;&gt;zainstalowanego w telefonie adblock&#39;a, np.
AdAway&lt;/a&gt;, czy też &lt;a href=&#34;https://morfikov.github.io
/post/blokowanie-reklam-adblock-na-domowym-routerze-wifi/&#34;&gt;wdrożony
podobny filtr na domowym routerze WiFi z
LEDE/OpenWRT&lt;/a&gt;, to te
reklamy mogą zostać z powodzeniem odfiltrowane, przynajmniej w Firefox&#39;ie. Jestem też świadom
istnienia &lt;a href=&#34;https://morfikov.github.io
/post/android-youtube-bez-reklam-na-smartfonie-newpipe/&#34;&gt;aplikacji
NewPipe&lt;/a&gt; , która jest
zubożonym klientem YouTube. Niemniej jednak, te opisane wyżej sposoby mają jedną podstawową wadę.
Mianowicie tracimy lwią część funkcjonalności serwisu YouTube. Przykładem mogą być powiadamiania w
przypadku, gdy na jeden z subskrybowanych kanałów zostanie wrzucony jaki materiał video. Taką opcję
ma ta aplikacja od Google ale klikając w powiadomienie jest niemal pewne, że włączy nam się jakaś
wredna reklama o wiele głośniejsza niż sam filmik, który zamierzamy obejrzeć. Innym problemem w
przypadku tej góglowskiej aplikacji jest brak możliwości odtwarzania video w tle czy też przy
zgaszonym wyświetlaczu. Postanowiłem w końcu wziąć się za ogarnięcie tej góglowskiej aplikacji
YouTube i wyeliminować te drażniące mnie problemy &lt;a href=&#34;http://repo.xposed.info/module/de.robv.android.xposed.installer&#34;&gt;instalując w smartfonie framework
Xposed&lt;/a&gt; wraz z odpowiednimi
modułami: &lt;a href=&#34;http://repo.xposed.info/module/com.pyler.youtubebackgroundplayback&#34;&gt;YouTube Background
Playback&lt;/a&gt; oraz &lt;a href=&#34;http://repo.xposed.info/module/ma.wanam.youtubeadaway&#34;&gt;YouTube
AdAway&lt;/a&gt;. Jako, że nie jest to proces łatwy,
to postanowiłem go opisać krok po kroku.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zmienić hasło do zaszyfrowanego smartfona z Androidem</title>
      <link>https://morfikov.github.io/post/jak-zmienic-haslo-do-zaszyfrowanego-smartfona-z-androidem/</link>
      <pubDate>Fri, 03 Mar 2017 17:58:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zmienic-haslo-do-zaszyfrowanego-smartfona-z-androidem/</guid>
      <description>&lt;p&gt;Każdy nowszy smartfon z Androidem oferuje możliwość zaszyfrowania wszystkich danych użytkownika
zlokalizowanych na partycji &lt;code&gt;/data/&lt;/code&gt; . Cały proces można przeprowadzić w bardzo prosty sposób i bez
większych problemów. Raz zaszyfrowanego telefonu nie da rady cofnąć do stadium przed szyfrowaniem i
w zasadzie to zabezpieczenie można zdjąć jedynie przez przywrócenie urządzenia do ustawień
fabrycznych. My tutaj jednak nie będziemy zajmować się samym szyfrowaniem smartfona i skupimy się
bardziej na hasłach zabezpieczających mających stać na straży dostępu do naszych cennych danych,
które mamy w telefonie. Większość z nas wykorzystuje krótkie hasło do odblokowania ekranu. To samo
hasło z kolei jest wykorzystywane do zaszyfrowania klucza używanego w procesie
szyfrowania/deszyfrowania danych na flash&#39;u smartfona. W ustawieniach Androida nie ma jednak opcji
rozdzielenia tych haseł i można by pomyśleć, że wykorzystanie czterocyfrowego kodu PIN jako
zabezpieczenie mija się z celem. Na pewno w części smartfonów tak ale niekoniecznie we wszystkich
modelach. Tak się składa, że akurat leży u mnie nieużywany Neffos Y5 od TP-LINK, to postanowiłem
przyjrzeć się nieco bliżej tej kwestii haseł i sprawdzić czy jest się czego obawiać stosując krótkie
hasła w zaszyfrowanych Androidach.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Budowanie obrazu TWRP recovery ze źródeł OMNI ROM</title>
      <link>https://morfikov.github.io/post/budowanie-obrazu-twrp-recovery-ze-zrodel-omni-rom/</link>
      <pubDate>Sun, 19 Feb 2017 21:06:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/budowanie-obrazu-twrp-recovery-ze-zrodel-omni-rom/</guid>
      <description>&lt;p&gt;Gdy zamierzamy zbudować sobie własny ROM na smartfon z Androidem, np.
&lt;a href=&#34;https://lineageos.org/&#34;&gt;LineageOS&lt;/a&gt; (CyanogenMod nie jest już rozwijany) czy nawet jedynie obraz
recovery (&lt;a href=&#34;https://twrp.me/&#34;&gt;TWRP&lt;/a&gt; albo &lt;a href=&#34;https://www.clockworkmod.com/&#34;&gt;CWM&lt;/a&gt;), to potrzebne nam jest
stosowne urządzenie oraz odpowiedni kod źródłowy. Skoro chcemy budować te ww. rzeczy, to
prawdopodobnie nasz telefon nie jest przez to oprogramowanie jeszcze wspierany lub też sam soft nie
jest regularnie aktualizowany przez dewelopera. W zasadzie zarówno pełne ROM&#39;y jak i obrazy recovery
są budowane ze źródeł Androida. Niemniej jednak, oficjalny kod dostarczany przez Google budzi czasem
wiele kontrowersji i ci nieco bardziej zaawansowani użytkownicy zmieniają go, np. czyniąc go w pełni
OpenSource czy też implementując w nim pewną niestandardową funkcjonalność. Tak powstają Custom
ROM&#39;y, które w późniejszym czasie z racji swojej popularności przestają być &amp;quot;Custom&amp;quot; i zaczynają żyć
swoim własnym życiem obok tego Góglowskiego Androida. W przypadku budowania obrazu recovery nie są
nam potrzebne całe źródła konkretnego ROM&#39;u. Jakby nie patrzeć, potrafią one zajmować trochę
miejsca, a poza tym proces ich budowania jest stosunkowo czasochłonny. Tak czy inaczej, jakieś
źródła trzeba pozyskać i przygotować je do dalszej pracy. W tym artykule nie będziemy sobie
jeszcze budować całego ROM&#39;u i skupimy się na zbudowaniu od podstaw jedynie obrazu TWRP recovery ze
źródeł &lt;a href=&#34;https://omnirom.org/&#34;&gt;OMNI ROM&lt;/a&gt;. Ten proces zostanie pokazany na przykładzie smartfona
Neffos Y5 od TP-LINK przy wykorzystaniu systemu linux, a konkretnie dystrybucji Debian.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problem z zaszyfrowaniem partycji /data/ na smartfonie z Androidem</title>
      <link>https://morfikov.github.io/post/problem-z-zaszyfrowaniem-partycji-data-na-smartfonie-z-androidem/</link>
      <pubDate>Sat, 11 Feb 2017 18:59:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problem-z-zaszyfrowaniem-partycji-data-na-smartfonie-z-androidem/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio trochę mechanizmami szyfrującymi w moich smartfonach Neffos podesłanych przez
TP-LINK, po raz kolejny coś nieopatrznie uszkodziłem. Tym razem sprawa wygląda nieco bardziej
poważnie, bo uwalony został cały moduł szyfrujący urządzenie. Chodzi generalnie o to, że w
Androidzie w wersji 4.4/5.0 została wprowadzona &lt;a href=&#34;https://source.android.com/security/encryption/full-disk&#34;&gt;możliwość zaszyfrowania wszystkich danych
użytkownika&lt;/a&gt;, tj. informacji
przechowywanych na partycji &lt;code&gt;/data/&lt;/code&gt; . Do odszyfrowania tej partycji potrzebny jest klucz
szyfrujący. Problem w tym, że Android musi gdzieś ten klucz trzymać i to w taki sposób, by proces
Factory Reset był w stanie ten klucz usunąć, choćby na wypadek zapomnienia hasła i próby odzyskania
w takiej sytuacji władzy nad smartfonem. Pech chciał, że akurat na moim Neffos Y5 mam wgrane TWRP
recovery i z jakiegoś powodu nie mogłem zresetować ustawień telefonu do fabrycznych przez ten tryb i
posłużyłem się narzędziem &lt;code&gt;fastboot&lt;/code&gt; . Ono najwyraźniej nieco inaczej formatuje partycję &lt;code&gt;/data/&lt;/code&gt; i
w ten sposób uwala cały mechanizm szyfrowania oferowany przez Androida. Czy da radę jakoś poprawić
ten problem, a jeśli tak to w jaki sposób?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak odszyfrować zawartość karty SD w smartfonie z Androidem</title>
      <link>https://morfikov.github.io/post/jak-odszyfrowac-zawartosc-karty-sd-w-smartfonie-z-androidem/</link>
      <pubDate>Thu, 09 Feb 2017 18:01:56 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-odszyfrowac-zawartosc-karty-sd-w-smartfonie-z-androidem/</guid>
      <description>&lt;p&gt;W Androidzie 6.0 Marshmallow został wprowadzony ciekawy mechanizm zwany &lt;a href=&#34;https://source.android.com/devices/storage/adoptable&#34;&gt;Adoptable
Storage&lt;/a&gt;, który umożliwia &lt;a href=&#34;https://morfikov.github.io
/post/android-formatowanie-karty-sd-jako-pamiec-wewnetrzna/&#34;&gt;zamontowanie karty
SD w smartfonie jako pamięć
wewnętrzna&lt;/a&gt;. W ten
sposób pamięć flash w telefonach, które mają jej niewiele, może zostać nieco rozbudowana. Jedyny
problem z tym całym Adoptable Storage jest taki, że Android szyfruje zawartość karty SD
automatycznie, przez co nie jesteśmy w stanie odczytać żadnych informacji z takiego nośnika na
innych urządzeniach. Istnieje jednak sposób, by rozszyfrować i tym samym uzyskać dostęp do danych
zgromadzonych na karcie SD z poziomu linux&#39;a, np. dystrybucji Debian. W tym artykule prześledzimy
sobie właśnie ten proces na przykładzie &lt;a href=&#34;http://www.neffos.pl/product/details/Y5&#34;&gt;smartfona Neffos
Y5&lt;/a&gt; od TP-LINK.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Kamera IP NC450 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-kamera-ip-nc450-od-tp-link/</link>
      <pubDate>Thu, 02 Feb 2017 19:27:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-kamera-ip-nc450-od-tp-link/</guid>
      <description>&lt;p&gt;Kamery do monitoringu ostatnimi czasy stają się coraz bardziej popularne. Na dobrą sprawę możemy je
spotkać praktycznie wszędzie, zwłaszcza w miejscach, w których dochodzi do kradzieży czy innych
przestępstw, które cechują się podwyższonym odsetkiem niewykrywalności sprawców przez służby
mundurowe. Oczywiście taki profesjonalny sprzęt, którym można zabezpieczyć duże obiekty, trochę
kosztuje. Niemniej jednak, kamery przemysłowe nadają się głównie do zastosowań firmowych i
przeciętnego Kowalskiego te rozwiązania zwykle nie interesują ze względu na ich wysoką cenę. Może
niekoniecznie każdy z nas posiada dużą firmę ale są sytuacje, w których taka kamera bardzo by nam
się przydała. Garaż czy piwnica często są obiektami zainteresowań podejrzanych typów i narażone na
włamania. Dlatego też od czasu do czasu warto zajrzeć w te miejsca, by się upewnić czy aby na pewno
wszystko jest w porządku. Zwykle jednak nikt nie ma na to czasu, a gdy już ktoś nam się włamie, to
nie dość, że orientujemy się parę dni/tygodni po fakcie, to jeszcze nawet nie mamy pojęcia kto, jak
i kiedy się tego czynu zabronionego dopuścił. Dlatego monitoring warto sobie zainstalować i
niekoniecznie musimy przy tym wydawać dziesiątki tysięcy złotych. TP-LINK ma w swojej ofercie kilka
niedrogich kamer IP, które można wykorzystać do zastosować domowych. W tym artykule rzucimy sobie
okiem na &lt;a href=&#34;http://www.tp-link.com.pl/products/details/cat-19_NC450.html&#34;&gt;obrotową kamerę NC450&lt;/a&gt;,
która jest w stanie zapisywać obraz i dźwięk na kartę SD.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android Studio i Android SDK pod linux</title>
      <link>https://morfikov.github.io/post/android-studio-i-android-sdk-pod-linux/</link>
      <pubDate>Sun, 29 Jan 2017 18:29:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-studio-i-android-sdk-pod-linux/</guid>
      <description>&lt;p&gt;Rozpoczynając przygodę z Androidem (tylko taką nieco bardziej deweloperską) trzeba posiadać w
systemie szereg niezbędnych narzędzi. Chodzi tutaj oczywiście o Android SDK. Metod na instalację
tego pakietu na linux&#39;ie, a konkretnie w dystrybucji Debian, jest co najmniej kilka. Chodzi o to, że
Google udostępnia paczkę &lt;code&gt;.zip&lt;/code&gt; z Android SDK, którą można pobrać sobie z oficjalnej strony
Androida. Dodatkowo, na tej samej stronie mamy coś o nazwie Android Studio, które również jest w
stanie nam potrzebne narzędzia dostarczyć. Poza tym, te narzędzia można także skompilować sobie ze
źródeł Androida, jak i również zainstalować bezpośrednio z repozytorium samego Debiana. Niemniej
jednak, część z tych sposobów nie jest zbytnio wygodna, a pozostała część zakłada, że korzystamy z
najnowszej wersji Androida (obecnie Nougat). A co w przypadku, gdybyśmy chcieli operować na
Androidzie 5.1 (Lollipop) czy 6.0 (Marshmallow)? Jak zainstalować pasujące wersje narzędzi, by nic
nam się nie gryzło ze sobą?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Gigabitowy adapter Ethernet na USB UE300 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-gigabitowy-adapter-ethernet-na-usb-ue300-od-tp-link/</link>
      <pubDate>Sat, 28 Jan 2017 19:12:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-gigabitowy-adapter-ethernet-na-usb-ue300-od-tp-link/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/recenzja-karta-sieciowa-ethernet-usb-ue200-tp-link/&#34;&gt;kartę sieciową na USB
UE200&lt;/a&gt; od TP-LINK. Taki
adapter jest bardzo przydatny w momencie, gdy nie posiadamy z jakiegoś powodu standardowej karty
sieciowej, tak by za jej sprawą przewodowo połączyć komputer do domowej sieci. Jeden z moich
komputerów cierpi właśnie na tego typu przypadłość z powodu jakiegoś bliżej nieznanego mi
uszkodzenia jego wbudowanej karty sieciowej. Generalnie rzecz biorąc w ofercie TP-LINK poza tym
wspomnianym UE200 jest także dostępny &lt;a href=&#34;http://www.tp-link.com.pl/products/details/cat-5688_UE300.html&#34;&gt;adapter
UE300&lt;/a&gt;, który różni się głównie tym,
że ma gigabitowy port Ethernet oraz karta jest na USB 3.0. Jako, że jestem w posiadaniu adaptera
UE300, to postanowiłem sprawdzić jak (i czy w ogóle) jest rozpoznawany przez system z rodziny linux,
a konkretnie na dystrybucji Debian, której używam na co dzień.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zlokalizować skradziony/zagubiony smartfon z Androidem</title>
      <link>https://morfikov.github.io/post/jak-zlokalizowac-skradziony-zagubiony-smartfon-z-androidem/</link>
      <pubDate>Fri, 27 Jan 2017 18:52:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zlokalizowac-skradziony-zagubiony-smartfon-z-androidem/</guid>
      <description>&lt;p&gt;Smartfony towarzyszą nam w codziennym życiu praktycznie cały czas. Dlatego też zaczynamy
przechowywać w tych urządzeniach coraz to więcej informacji osobistych, które są w stanie dość
dokładnie opisać nasze życie prywatne. Co jednak w przypadku, gdy taki telefon zgubimy lub też
zostanie nam on skradziony przez kogoś? Gdy chodzi o urządzenia z Androidem, to Google oferuje
usługę, która jest w stanie połączyć się z naszym smartfonem i przy odrobinie szczęścia ujawnić
nam jego położenie geograficzne lub też pozwolić nam na zdalne zablokowanie systemu w telefonie.
Chodzi oczywiście o usługę &amp;quot;Znajdź telefon/smartfon&amp;quot; (find my phone), na którą rzucimy sobie okiem w
tym artykule.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Redshift i dostosowanie temperatury kolorów ekranu</title>
      <link>https://morfikov.github.io/post/redshift-i-dostosowanie-temperatury-kolorow-ekranu/</link>
      <pubDate>Sun, 22 Jan 2017 18:48:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/redshift-i-dostosowanie-temperatury-kolorow-ekranu/</guid>
      <description>&lt;p&gt;Pewnie spotkaliście się już wiele razy z informacją, że ekrany naszych smartfonów, tabletów czy
komputerów szkodzą naszym oczom. Chodzi generalnie o to, że wyświetlacze LCD emitują światło
niebieskie, które w nadmiarze nie wpływa dla nas (i naszego wzroku) korzystnie, a przecie każdy z
nas siedzi godzinami przed komputerem. W zasadzie te negatywne efekty ciągłego spoglądania na
wyświetlacz nasilają się zwłaszcza wieczorami i w nocy. Jeśli pracujemy na laptopie do późna i przy
okazji mamy na tej maszynie zainstalowaną jakąś dystrybucję linux&#39;a, np. Debian, to możemy złagodzić
skutki zmęczenia oczu przez dobór nieco innej temperatury kolorów wyświetlanego obrazu. W tym
zadaniu może nam pomóc oprogramowanie &lt;a href=&#34;http://jonls.dk/redshift/&#34;&gt;redshift&lt;/a&gt; i to jemu będzie
poświęcony poniższy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Factory Reset Protection (FRP) w smartfonach z Androidem</title>
      <link>https://morfikov.github.io/post/factory-reset-protection-frp-w-smartfonach-z-androidem/</link>
      <pubDate>Fri, 20 Jan 2017 18:37:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/factory-reset-protection-frp-w-smartfonach-z-androidem/</guid>
      <description>&lt;p&gt;Kupowanie telefonów czy smartfonów z Androidem z innych źródeł niż oficjalne punkty sprzedaży nie
zawsze jest bezpieczną opcją. Gdy nabywamy takie urządzenie od znajomego, to raczej nie powinniśmy
się martwić o to, że ten telefon może być kradziony. Niemniej jednak, po zakupie takiego urządzenia,
poprzedni użytkownik zwykle resetuje jego ustawienia do fabrycznych, by klient miał świeży system i
nie był w stanie uzyskać dostępu do prywatnych danych poprzedniego właściciela smartfona. Nie byłoby
w tym nic nadzwyczajnego, gdyby nie fakt, że nabywca tak odsprzedanego telefonu może mieć pewne
problemy ze skonfigurowaniem Androida, bo ten system zwróci mu komunikat: &amp;quot;Urządzenie zostało
zresetowane. Aby kontynuować, zaloguj się na konto Google, które było wcześniej synchronizowane na
tym urządzeniu&amp;quot;, czyli telefon został zablokowany przez mechanizm Factory Reset Protection Lock (FRP
Lock). Jeśli znajomy mieszka blisko nas, to naturalnie możemy się przejść do niego w celu zdjęcia
tej blokady. A co w przypadku, gdy nabyliśmy urządzenie na odległość? Czy jest jakiś sposób na
obejście tej blokady w przypadku smartfonów Neffos od TP-LINK?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Backup partycji /data/ w smartfonach przez recovery TWRP</title>
      <link>https://morfikov.github.io/post/backup-partycji-data-w-smartfonach-przez-recovery-twrp/</link>
      <pubDate>Sun, 15 Jan 2017 18:20:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/backup-partycji-data-w-smartfonach-przez-recovery-twrp/</guid>
      <description>&lt;p&gt;W artykułach dotyczących przeprowadzania procesu root na smartfonach Neffos
&lt;a href=&#34;https://morfikov.github.io
/post/android-root-smartfona-neffos-y5-od-tp-link/&#34;&gt;Y5&lt;/a&gt; oraz
&lt;a href=&#34;https://morfikov.github.io
/post/android-root-smartfona-neffos-y5l-tp-link/&#34;&gt;Y5L&lt;/a&gt; był pokazany sposób na
dokonanie backup&#39;u całego flash&#39;a tych urządzeń. Jeśli Android w naszym telefonie jest ukorzeniony
albo chociaż mamy wgrany obraz TWRP na partycję &lt;code&gt;/recovery/&lt;/code&gt; , to jesteśmy w stanie przeprowadzać
regularny backup wszystkich danych użytkownika z poziomu trybu recovery. Proces takiego backup&#39;u
będzie się nieco różnił w stosunku do tego opisywanego w wyżej podlinkowanych artykułach. W tym
przypadku nie będziemy robić kopii binarnej, a jedynie zgramy sobie wszystkie pliki znajdujące się
na partycji &lt;code&gt;/data/&lt;/code&gt; . W tym artykule zostanie pokazany sposób na przeprowadzanie procesu kopii
zapasowej w smartfonie Neffos Y5. Niemniej jednak, taki regularny backup można przeprowadzać
praktycznie w każdym smartfonie posiadającym recovery z TWRP.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wymusić pasmo/częstotliwość LTE pod LEDE/OpenWRT</title>
      <link>https://morfikov.github.io/post/jak-wymusic-pasmo-czestotliwosc-lte-pod-lede-openwrt/</link>
      <pubDate>Fri, 13 Jan 2017 18:43:37 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wymusic-pasmo-czestotliwosc-lte-pod-lede-openwrt/</guid>
      <description>&lt;p&gt;Zainspirowany &lt;a href=&#34;http://forum.jdtech.pl/Watek-wybor-czestotliwosci-lte-na-przykladzie-huawei-e3372&#34;&gt;wątkiem na forum
JDtech&lt;/a&gt; na temat
testów transferów w konkretnych pasmach/częstotliwościach LTE, postanowiłem sprawdzić jak ta sprawa
wygląda w mojej okolicy. Generalnie ja obecnie u siebie mam modem Huawei E3372s-153 w wersji
NON-HiLink podpięty do &lt;a href=&#34;http://www.tp-link.com.pl/products/details/Archer-C2600.html&#34;&gt;routera TP-LINK Archer
C2600&lt;/a&gt;. Oczywiście na tym routerze
jest wgrany alternatywny firmware LEDE/OpenWRT, bo inaczej nie miałbym możliwości skorzystać z tego
modemu. Standardowa konfiguracja LTE w LEDE/OpenWRT daje nam jedynie możliwość wyboru między
ustawieniami &lt;code&gt;auto&lt;/code&gt; , &lt;code&gt;gsm&lt;/code&gt; , &lt;code&gt;umts&lt;/code&gt; , &lt;code&gt;lte&lt;/code&gt; , &lt;code&gt;preferumts&lt;/code&gt; oraz &lt;code&gt;preferlte&lt;/code&gt; . W przypadku internetu
LTE, zwykle wybieramy tutaj tryb &lt;code&gt;auto&lt;/code&gt; , ewentualnie też &lt;code&gt;lte&lt;/code&gt; , by wymusić konkretny tryb pracy
modemu, co może mieć kolosalne znaczenie przy darmowym internecie od RBM/Play. Niemniej jednak,
nawet w przypadku wyboru &lt;code&gt;lte&lt;/code&gt; , częstotliwość na jakiej będzie pracował modem w dalszym ciągu jest
dobierana automatycznie w oparciu o parametry sygnału docierającego z dostępnych w okolicy BTS&#39;ów. W
przypadku modemu E3372 można jednak wymusić, by połączenie LTE było realizowane na konkretnej
częstotliwości, np. 2100/1800/2600/900/800 MHz i by taki stan rzeczy osiągnąć, trzeba nieco
przerobić konfigurację tego alternatywnego oprogramowania znajdującego się w naszym routerze WiFi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przeprowadzić unroot na smartfonie Neffos Y5L od TP-LINK</title>
      <link>https://morfikov.github.io/post/jak-przeprowadzic-unroot-na-smartfonie-neffos-y5l-tp-link/</link>
      <pubDate>Thu, 12 Jan 2017 20:07:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przeprowadzic-unroot-na-smartfonie-neffos-y5l-tp-link/</guid>
      <description>&lt;p&gt;Przeprowadzenie &lt;a href=&#34;https://morfikov.github.io
/post/android-root-smartfona-neffos-y5l-tp-link/&#34;&gt;procesu root na smartfonie Neffos
Y5L&lt;/a&gt; od TP-LINK nie było tak
łatwe jak w przypadku innych modeli telefonów tego producenta. Niemniej jednak, trzeba zdawać sobie
sprawę, że ukorzenianie Androida niesie za sobą pewne zagrożenia. Nie chodzi tutaj tylko o
niezaufane aplikacje ale też trzeba brać pod uwagę możliwość przypadkowego (przypadki nie istnieją)
skasowania czy zmienienia plików systemowych, przez co nasz telefon może przestać nam działać
poprawnie lub też przestanie się w ogóle uruchamiać. Jeśli natomiast wgraliśmy SuperSU i praktycznie
w ogóle z niego nie korzystamy, to moim zdaniem lepiej jest przeprowadzić proces unroot i korzystać
z Neffos&#39;a Y5L, tak jak ze zwykłego urządzenia z Androidem na pokładzie. Proces cofania zmian w
systemie nie jest jakoś specjalnie trudny ale trzeba uważać, by w jego trakcie nie uszkodzić
smartfona. Ten artykuł ma na celu pokazanie jak cofnąć wszelkie zmiany wprowadzone w telefonie za
sprawą dostępu do praw administracyjnych w Neffos Y5L.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Root smartfona Neffos Y5L od TP-LINK</title>
      <link>https://morfikov.github.io/post/android-root-smartfona-neffos-y5l-tp-link/</link>
      <pubDate>Wed, 11 Jan 2017 19:30:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-root-smartfona-neffos-y5l-tp-link/</guid>
      <description>&lt;p&gt;Może i ten najtańszy smartfon w ofercie TP-LINK nie może popisać się najmocniejszymi podzespołami
ale w zasadzie ten fakt nie przeszkadza nam, by przeprowadzić na Neffos Y5L (TP801A) proces root.
Ten smartfon ma zbliżony SoC do Neffos Y5, a konkretnie mamy tutaj do czynienia z Snapdragon 210
(MSM8209) od Qualcomm&#39;a. Ten fakt sprawia, że w przypadku Neffos Y5L cały proces uzyskiwania
uprawnień administratora systemu przebiega bardzo podobnie do tego &lt;a href=&#34;https://morfikov.github.io
/post/android-root-smartfona-neffos-y5-od-tp-link/&#34;&gt;opisywanego wcześniej dla Neffos
Y5&lt;/a&gt;. Dlatego też poniższy
artykuł za bardzo się nie różni i w zasadzie został jedynie lekko przerobiony pod kątem zgodności ze
smartfonem Neffos Y5L.&lt;/p&gt;
&lt;p&gt;Prostszy sposób na przeprowadzanie procesu root w smartfonach Neffos od TP-LINK z wykorzystaniem
natywnych obrazów TWRP &lt;a href=&#34;https://morfikov.github.io
/post/root-w-smartfonach-neffos-od-tp-link-x1-c5-c5-max-y5-y5l/&#34;&gt;został opisany w nowym wątku&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Root Integrity Check w smartfonach z Androidem</title>
      <link>https://morfikov.github.io/post/root-integrity-check-w-smartfonach-z-androidem/</link>
      <pubDate>Tue, 10 Jan 2017 18:24:47 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/root-integrity-check-w-smartfonach-z-androidem/</guid>
      <description>&lt;p&gt;W smartfonach Neffos od TP-LINK, którymi mam możliwość się bawić, standardowo jest dostępny tryb
recovery, a telefon można uruchomić w tym trybie przez przyciśnięcie przycisków VolumeUP + Power. W
zasadzie jest to jeden z podstawowych trybów pracy smartfona, który może nam pomóc, gdy mamy
problemy z uruchomieniem urządzenia. Zwykle w trybie recovery przeprowadza się takie czynności jak
czyszczenie partycji &lt;code&gt;/cache/&lt;/code&gt; i &lt;code&gt;/data/&lt;/code&gt; (Factory Reset). Z poziomu trybu recovery jesteśmy także w
stanie przeprowadzić aktualizację firmware (tego oprogramowania, które zarządza naszym telefonem). W
tym artykule jednak nie będziemy dokonywać żadnych z tych powyżej opisanych czynności. W menu trybu
recovery jest jeszcze jedna ciekawa opcja, tj. Root Integrity Check. Do czego ona służy i jak
interpretować wynik skanowania?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przeprowadzić unroot na smartfonie Neffos Y5 od TP-LINK</title>
      <link>https://morfikov.github.io/post/jak-przeprowadzic-unroot-na-smartfonie-neffos-y5-od-tp-link/</link>
      <pubDate>Sat, 07 Jan 2017 18:56:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przeprowadzic-unroot-na-smartfonie-neffos-y5-od-tp-link/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/android-root-smartfona-neffos-y5-od-tp-link/&#34;&gt;Przeprowadzenie procesu root na smartfonie Neffos
Y5&lt;/a&gt; od TP-LINK nie było tak
łatwe jak w przypadku innych modeli telefonów tego producenta. Niemniej jednak, trzeba zdawać sobie
sprawę, że ukorzenianie Androida niesie za sobą pewne zagrożenia. Nie chodzi tutaj tylko o
niezaufane aplikacje ale też trzeba brać pod uwagę możliwość przypadkowego (przypadki nie istnieją)
skasowania czy zmienienia plików systemowych, przez co nasz telefon może przestać nam działać
poprawnie lub też przestanie się w ogóle uruchamiać. Jeśli natomiast wgraliśmy SuperSU i praktycznie
w ogóle z niego nie korzystamy, to moim zdaniem lepiej jest przeprowadzić proces unroot i korzystać
z Neffos&#39;a Y5, tak jak ze zwykłego urządzenia z Androidem na pokładzie. Proces cofania zmian w
systemie nie jest jakoś specjalnie trudny ale trzeba uważać, by w jego trakcie nie uszkodzić
smartfona. Ten artykuł ma na celu pokazanie jak cofnąć wszelkie zmiany wprowadzone w telefonie za
sprawą dostępu do praw administracyjnych w Neffos Y5.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Root smartfona Neffos Y5 od TP-LINK</title>
      <link>https://morfikov.github.io/post/android-root-smartfona-neffos-y5-od-tp-link/</link>
      <pubDate>Fri, 06 Jan 2017 18:16:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-root-smartfona-neffos-y5-od-tp-link/</guid>
      <description>&lt;p&gt;Nie we wszystkich smartfonach Neffos da radę przeprowadzić proces root tak łatwo jak to miało
miejsce w przypadku modeli &lt;a href=&#34;https://morfikov.github.io
/post/android-root-smartfona-neffos-c5-od-tp-link/&#34;&gt;Neffos
C5&lt;/a&gt; i &lt;a href=&#34;https://morfikov.github.io
/post/android-root-smartfona-neffos-c5-max-od-tp-link/&#34;&gt;Neffos C5
MAX&lt;/a&gt;. TP-LINK ma w swojej
ofercie również &lt;a href=&#34;http://www.neffos.pl/product/details/Y5&#34;&gt;model Neffos Y5&lt;/a&gt; (TP802A) i on w
odróżnieniu do tych dwóch poprzednich ma inne podzespoły, a konkretnie SoC, którzy pochodzi od
producenta Qualcomm (Snapdragon 210, model MSM8909). Root smartfonów opartych o tego typu SoC
przebiega nieco inaczej ale jest generalnie do zrobienia, choć trzeba trochę się przyłożyć do
procesu backup&#39;u flash&#39;a telefonu. Pozostała część jest w miarę standardowa. W tym wpisie zostanie
przeprowadzony proces root smartfona Neffos Y5.&lt;/p&gt;
&lt;p&gt;Prostszy sposób na przeprowadzanie procesu root w smartfonach Neffos od TP-LINK z wykorzystaniem
natywnych obrazów TWRP &lt;a href=&#34;https://morfikov.github.io
/post/root-w-smartfonach-neffos-od-tp-link-x1-c5-c5-max-y5-y5l/&#34;&gt;został opisany w nowym wątku&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przenoszenie danych ze ZRAM do RAM na smartfonie z Androidem</title>
      <link>https://morfikov.github.io/post/przenoszenie-danych-ze-zram-do-ram-na-smartfonie-z-androidem/</link>
      <pubDate>Mon, 02 Jan 2017 17:19:47 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przenoszenie-danych-ze-zram-do-ram-na-smartfonie-z-androidem/</guid>
      <description>&lt;p&gt;Jak często zdarza się wam uruchamiać ponownie telefon czy smartfon? Raczej nikt z nas nie robi tego
zbyt często, tak jak ma to miejsce w przypadku desktopów, laptopów i innych tego typu standardowych
komputerów. System w smartfonie zwykle działa bez resetowania wiele tygodni czy nawet miesięcy, bo
niewiele rzeczy instalujemy, no i praktycznie nic nie aktualizujemy. Dlatego też nie ma potrzeby
uruchamiać ponownie Androida. Niemniej jednak są pewne przypadki, w których taki system jest w
stanie zachowywać się bardzo dziwnie i restart smartfona zwykle poprawia zaistniałe problemy. Chodzi
generalnie o utylizowanie baterii w większym stopniu, czy o ogólne uczucie spowolnienia pracy
systemu. Przyczyn takiego stanu rzeczy może być cała masa ale w tym konkretnym przypadku znaczenie
zdaje się mieć zbyt duże wykorzystanie pamięci RAM. W efekcie Android robi użytek z &lt;a href=&#34;https://www.kernel.org/doc/Documentation/blockdev/zram.txt&#34;&gt;urządzenia
ZRAM,&lt;/a&gt; które jest niczym innym jak tylko
skompresowanym wycinkiem pamięci operacyjnej, gdzie system stara się upchnąć dane w przypadku
kończenia się zasobów pamięci, a kompresja to przecież bardzo zasobożerny proces. Możemy taki
telefon wyłączać co jakiś czas ale istnieje prostsza metoda wyeliminowania problemu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Power Bank TL-PBG6700 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-power-bank-tl-pbg6700-od-tp-link/</link>
      <pubDate>Fri, 30 Dec 2016 19:40:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-power-bank-tl-pbg6700-od-tp-link/</guid>
      <description>&lt;p&gt;Energii nigdy nie jest za dużo. Problem w tym, że w przypadku jej nadmiaru, część zasobów zwyczajnie
się marnuje. Można naturalnie takiemu stanu rzeczy przeciwdziałać próbując zmagazynować energię w
jakimś obiekcie tak, by można ją było wykorzystać w późniejszym czasie, gdy zajdzie taka potrzeba.
Większość sprzętów elektronicznych, takich jak smartfony, tablety czy nawet przenośne routery WiFi,
posiada wbudowane baterie, które mają na celu umożliwić im działanie, gdy zostaną one odcięte od
stałego źródła zasilania. Niemniej jednak, akumulator w takich urządzeniach zwykle nie wystarcza na
długo, choć generalnie jego zużycie zależy od sposobu użytkowania. Dlatego też można pokusić się o
zakupienie dodatkowych baterii zdolnych zmagazynować energię w większym stopniu niż samo urządzenie,
które wymaga zasilania. Mowa oczywiście o power bankach, które cenowo nie są zbyt wygórowane, a w
krytycznych sytuacjach są wręcz niezastąpione. W tym artykule rzucimy sobie okiem na &lt;a href=&#34;http://www.tp-link.com.pl/products/details/cat-5689_TL-PBG6700.html&#34;&gt;power bank
TL-PBG6700&lt;/a&gt; od TP-LINK.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Router LTE Archer MR200 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-router-lte-archer-mr200-tp-link/</link>
      <pubDate>Thu, 29 Dec 2016 18:53:07 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-router-lte-archer-mr200-tp-link/</guid>
      <description>&lt;p&gt;Do momentu upowszechnienia się technologii LTE, ludzkość była zdana na przewodowe łącza internetowe
oferowane przez lokalnych ISP. Jeśli chodzi o tych lokalnych providerów, to zwykle nie mają oni
praktycznie żadnej konkurencji w danej części miasta/wsi. Czy taki stan rzeczy jest wynikiem
dostarczania najlepszych jakościowo usług za najniższą cenę? W moim przypadku nie były to ani
najlepsze usługi, ani też najniższa cena, tylko tak dobrane przepisy prawne, by zewnętrznemu ISP nie
opłacało się świadczyć usług w mojej okolicy, bo za ten fakt dostawał on z miejsca szereg opłat/kar.
Teraz, gdy już praktycznie każdy z nas jest w zasięgu LTE, możemy porzucić tych lokalnych ISP i
obserwować ich nieuchronny upadek, no chyba, że w końcu zaczną dbać o swoich klientów. Niemniej
jednak, w dalszym ciągu, by korzystać z technologi LTE potrzebny nam jest odpowiedni sprzęt, zwykle
jest to jakiś modem, np. Huawei E3372s-153. Problem z modemem jest taki, że standardowo można go
podłączyć tylko do jednego komputera w danej chwili, no chyba, że mamy router WiFi z wgranym
alternatywnym oprogramowaniem pokroju OpenWRT/LEDE. Niemniej jednak, w dalszym ciągu trzeba nieco
wprawy, by ten modem ogarnąć i udostępnić połączenie internetowe hostom w lokalnej sieci. Dlatego
też od jakiegoś czasu na rynku zaczęły pojawiać się routery WiFi, które mają wbudowany modemem LTE.
Jedno z takich urządzeń dotarło do mnie kilka dni temu, a konkretnie jest &lt;a href=&#34;http://www.tp-link.com.pl/products/details/cat-4691_Archer-MR200.html&#34;&gt;model Archer
MR200&lt;/a&gt; od TP-LINK.
Postanowiłem zatem zobaczyć co oferuje ten sprzęt w standardzie, oraz czy jest dla niego jakieś
alternatywne oprogramowanie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Power Bank TL-PB2600 TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-power-bank-tl-pb2600-tp-link/</link>
      <pubDate>Wed, 28 Dec 2016 17:59:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-power-bank-tl-pb2600-tp-link/</guid>
      <description>&lt;p&gt;Nowsze technologie wymagają do działania energii elektrycznej. Ta z kolei musi być dostarczana
danemu urządzeniu na bieżąco, by było ono w stanie w ogóle funkcjonować i realizować swoje zadanie.
Niemniej jednak, od już dłuższego czasu specyfikacja otaczającej nas rzeczywistości wymaga od
naszych urządzeń, by potrafiły one gromadzić w sobie jakiś zapas energii i pracować nawet nie będąc
podłączone do stałego źródła zasilania. Dlatego też nasze smartfony, tablety, mp3player&#39;y i innego
tego typu sprzęty elektroniczne mają wbudowany mniej lub bardziej pojemny akumulator. Tak czy
inaczej, ta pojemność jest skończona i zwykle wystarcza na kilka dni, najwyżej tydzień pracy, np.
naszego telefonu. Dlatego też w pewnych okolicznościach dobrze jest mieć zapas energii zgromadzony w
jakimś power banku. Na rynku jest cała masa takich banków energetycznych i różnią się one pod
względem parametrów. W tym artykule rzucimy sobie okiem na &lt;a href=&#34;http://www.tp-link.com.pl/products/details/cat-5689_TL-PB2600.html&#34;&gt;bank energii
TL-PB2600&lt;/a&gt; od TP-LINK.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Smartfon Neffos Y5L od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-smartfon-neffos-y5l-od-tp-link/</link>
      <pubDate>Sun, 18 Dec 2016 20:15:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-smartfon-neffos-y5l-od-tp-link/</guid>
      <description>&lt;p&gt;Wśród ludzi panuje przekonanie, że by zakupić smartfona trzeba wydać niemałą sumkę pieniędzy, bo
przecież te urządzenia muszą sporo kosztować. No i nie da się ukryć, że na rynku są dostępne modele
telefonów, których cena przekracza kilka tysięcy złotych. Niemniej jednak, w ofertach niektórych
producentów takich sprzętów są również i sporo tańsze modele, które byłyby w stanie zaspokoić
niejednego użytkownika mobilnych technologii. Oczywiście te tańsze smartfony nie mają zwykle w sobie
całej masy wynalazków ale czy tak naprawdę każdy z nas ich potrzebuje? Znam sporo ludzi, którzy
wyznają zasadę, że telefon jest &amp;quot;tylko do dzwonienia&amp;quot; ale znowu korzystanie z 5-10 letnich zabawek
jest trochę pozbawione sensu, podobnie zresztą jak kupowanie przez takie osoby smartfona za
równowartość ich miesięcznej pensji. W ofercie TP-LINK jest dostępny jeden smartfon, którego cena
zamyka się w granicach 300 zł. Mowa tutaj o &lt;a href=&#34;http://www.neffos.pl/product/details/Y5L&#34;&gt;Neffos Y5L&lt;/a&gt;.
Czy taki telefon jest nam w stanie w ogóle coś zaoferować?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Smartfon Neffos Y5 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-smartfon-neffos-y5-od-tp-link/</link>
      <pubDate>Sat, 17 Dec 2016 19:10:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-smartfon-neffos-y5-od-tp-link/</guid>
      <description>&lt;p&gt;Oferta TP-LINK&#39;a ciągle powiększa się o nowe urządzenia. Nie chodzi mi tutaj o routery WiFi, z
których ten producent jest znany nam wszystkim ale raczej o nowe modele smartfonów
niskobudżetowych. Jakiś czas temu TP-LINK wprowadził do obiegu smartfony &lt;a href=&#34;http://www.neffos.pl/product/details/Y5&#34;&gt;Neffos
Y5&lt;/a&gt; oraz &lt;a href=&#34;http://www.neffos.pl/product/details/Y5L&#34;&gt;Neffos
Y5L&lt;/a&gt;. Ten artykuł będzie dotyczył jedynie tego pierwszego
urządzenia ale w niedługim czasie pojawi się również recenzja drugiego z wyżej wymienionych
telefonów. Czy w przypadku Neffos&#39;a Y5 (TP802A), TP-LINK jest nas w stanie czymś zaskoczyć?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przeprowadzić unroot na smartfonie Neffos C5 MAX od TP-LINK</title>
      <link>https://morfikov.github.io/post/jak-przeprowadzic-unroot-na-smartfonie-neffos-c5-max-od-tp-link/</link>
      <pubDate>Wed, 14 Dec 2016 19:08:01 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przeprowadzic-unroot-na-smartfonie-neffos-c5-max-od-tp-link/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/android-root-smartfona-neffos-c5-max-od-tp-link/&#34;&gt;Proces root na smartfonie Neffos C5
MAX&lt;/a&gt; od TP-LINK można
przeprowadzić w miarę bez większych problemów, choć nie jest to rozwiązanie działające OOTB.
Niemniej jednak, taki root telefonu czyni go bardziej podatnym na zagrożenia ze strony wrogich
aplikacji. Ponadto, kasując czy też zmieniając pliki systemowe, możemy sprawić, że nasze urządzenie
zwyczajnie przestanie nam działać, tj. już się nie uruchomi. Niektórzy użytkownicy smartfonów nie
zdają sobie z tego sprawy i ukorzeniają Androida bez głębszego zastanowienia się. Mi jako
linux&#39;iarzowi, root jest niezbędny do pracy ale czy aby na pewno każdy musi go mieć? Ci z was,
którzy taki root systemu przeprowadzili i nie korzystają z niego praktycznie wcale, zastanawiają
się pewnie czy istnieje sposób, by cofnąć wprowadzone zmiany i przywrócić Androida do stanu
pierwotnego. Krótka odpowiedź brzmi: &amp;quot;oczywiście, że tak&amp;quot; i temu procesowi przyjrzymy się w
niniejszym artykule.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Root smartfona Neffos C5 MAX od TP-LINK</title>
      <link>https://morfikov.github.io/post/android-root-smartfona-neffos-c5-max-od-tp-link/</link>
      <pubDate>Tue, 13 Dec 2016 17:27:37 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-root-smartfona-neffos-c5-max-od-tp-link/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio &lt;a href=&#34;https://morfikov.github.io
/post/recenzja-smartfon-neffos-c5-max-od-tp-link/&#34;&gt;smartfonem Neffos C5
MAX&lt;/a&gt; od TP-LINK, obiecałem
sobie, że jak tylko będę miał chwilę czasu, to postaram się ukorzenić Androida, który w tym
telefonie siedzi (Lollipop). Generalnie rzecz biorąc, sposób root&#39;owania tego urządzenia jest bardzo
podobny do tego, który miałem już możliwość &lt;a href=&#34;https://morfikov.github.io
/post/android-root-smartfona-neffos-c5-od-tp-link/&#34;&gt;przeprowadzić na innym modelu TP-LINK&#39;a, tj. Neffos
C5&lt;/a&gt;. Dlatego też poniższy
artykuł jest bardzo zbliżony treścią, choć lekko zaktualizowany pod kątem Neffos&#39;a C5 MAX. Grunt, że
nie było żadnych problemów z przeprowadzeniem backup&#39;u flash&#39;a telefonu jak i samego procesu root.&lt;/p&gt;
&lt;p&gt;Prostszy sposób na przeprowadzanie procesu root w smartfonach Neffos od TP-LINK z wykorzystaniem
natywnych obrazów TWRP &lt;a href=&#34;https://morfikov.github.io
/post/root-w-smartfonach-neffos-od-tp-link-x1-c5-c5-max-y5-y5l/&#34;&gt;został opisany w nowym wątku&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Smartfon Neffos C5 MAX od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-smartfon-neffos-c5-max-od-tp-link/</link>
      <pubDate>Mon, 12 Dec 2016 20:37:43 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-smartfon-neffos-c5-max-od-tp-link/</guid>
      <description>&lt;p&gt;Jeszcze nie tak dawno temu ludzkość była w stanie obejść się bez komputera, a dzisiaj raczej już
wszyscy mamy z nim styczność w większym lub mniejszym stopniu. Spora część osób nawet sobie tego
faktu nie uświadamia mając jednocześnie w kieszeni smartfona czy jakiś inny telefon, a przecie te
urządzenia są w zasadzie komputerami, tylko nieco mniejszymi w porównaniu do desktopowych
odpowiedników. Na dobrą sprawę to właśnie dzięki tym sprzętom jesteśmy w stanie komunikować się z
osobami na drugim końcu świata prawie w czasie rzeczywistym. Jakby wyglądał nasz świat bez tych
malutkich i niepozornych stworzeń informatycznych, które towarzyszą nam w codziennym życiu
praktycznie non stop? Na to pytanie raczej każdy z nas musi sobie sam udzielić odpowiedzi, bo ta
technologia niekoniecznie zmieniła otaczającą nas rzeczywistość w stopniu jednakowym dla nas
wszystkich. Niemniej jednak, rozwój technologiczny ciągle postępuje i obecnie mamy na rynku
smartfony 4 czy nawet 8 rdzeniowe wyposażone w 2-4 GiB RAM. Jakiś czas temu byłem w stanie
przetestować &lt;a href=&#34;https://morfikov.github.io
/post/recenzja-smartfon-neffos-c5-od-tp-link/&#34;&gt;smartfon Neffos C5 od&lt;/a&gt;
TP-LINK, który miał właśnie 4 rdzenie i 2 GiB pamięci operacyjnej. Niemniej jednak, ten producent ma
również w ofercie i inne modele telefonów, min. &lt;a href=&#34;http://www.neffos.pl/product/details/C5-Max&#34;&gt;Neffos C5
MAX&lt;/a&gt; (TP702A), który również trafił w moje łapki.
Postanowiłem zatem go poddać testom i sprawdzić czy jest on w stanie zadowolić takiego wybrednego
linux&#39;iarza jak ja.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować połączenie VPN przez SSH</title>
      <link>https://morfikov.github.io/post/jak-skonfigurowac-polaczenie-vpn-przez-ssh/</link>
      <pubDate>Sun, 11 Dec 2016 15:59:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-skonfigurowac-polaczenie-vpn-przez-ssh/</guid>
      <description>&lt;p&gt;Szukając informacji na &lt;a href=&#34;https://morfikov.github.io
/post/jak-ukryc-ruch-openvpn-przy-pomocy-stunnel/&#34;&gt;temat ukrycia ruchu generowanego przez
OpenVPN&lt;/a&gt;, natrafiłem także na
sposób, który &lt;a href=&#34;https://help.ubuntu.com/community/SSH_VPN&#34;&gt;wykorzystuje do tego celu połączenie SSH&lt;/a&gt;.
W efekcie jesteśmy w stanie upodobnić ruch VPN do tego, który zwykle służy do zarządzania zdalnymi
systemami linux. Jako, że temat maskowania połączenia VPN jest kluczowy w walce z cenzurą internetu,
to im więcej sposobów, by taki zabieg przeprowadzić, tym lepiej. Dlatego też postanowiłem odświeżyć
nieco podlinkowany wyżej artykuł i sprawdzić czy jest on jeszcze aktualny. Wprawdzie nie dysponuję
Ubuntu, a jedynie dystrybucją Debian ale raczej nie powinno być problemów z odwzorowaniem
konfiguracji na tym systemie, choć artykuł jest dość leciwy już i pewnie trzeba będzie kilka rzeczy
zaktualizować.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ukryć ruch OpenVPN przy pomocy stunnel</title>
      <link>https://morfikov.github.io/post/jak-ukryc-ruch-openvpn-przy-pomocy-stunnel/</link>
      <pubDate>Sat, 10 Dec 2016 15:18:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ukryc-ruch-openvpn-przy-pomocy-stunnel/</guid>
      <description>&lt;p&gt;Ci z nas, którzy korzystają codziennie z internetu, wiedzą, że większość nawiązywanych połączeń
między dwoma punktami w tej sieci globalnej przechodzi przez szereg węzłów i jest podatnych na
przechwycenie i podsłuchanie. Nawet jeśli ruch z określonymi serwisami jest szyfrowany, to w dalszym
ciągu nie jesteśmy w stanie ukryć pewnych newralgicznych informacji, takich jak docelowy adres IP i
port, na którym nasłuchuje zdalna usługa. Wszystkie połączenia sieciowe zestawiane z naszego
komputera czy routera domowego przechodzą przez infrastrukturę ISP, u którego mamy wykupiony
internet. Tacy ISP są nam w stanie pod naciskiem rządu zablokować połączenia z konkretnymi adresami
wprowadzając na terenie danego kraju cenzurę treści dostępnej w internecie, czego obecnie jesteśmy
świadkami w Europie, no i w Polsce. Można oczywiście posiłkować się rozwiązaniami opartymi o VPN,
np. &lt;a href=&#34;https://morfikov.github.io
/post/jak-skonfigurowac-serwer-vpn-na-debianie-openvpn/&#34;&gt;stawiając serwer OpenVPN w innym
kraju&lt;/a&gt;. Problem jednak w
tym, że ruch OpenVPN różni się od tego, z którym mamy do czynienia w przypadku choćby HTTPS. Jest
zatem możliwość rozpoznania ruchu VPN i zablokowania go stosując &lt;a href=&#34;https://en.wikipedia.org/wiki/Deep_packet_inspection&#34;&gt;głęboką analizę
pakietów&lt;/a&gt; (Deep Packet Inspection, DPI). By
się przed tego typu sytuacją ochronić, trzeba upodobnić ruch generowany przez OpenVPN do zwykłego
ruchu SSL/TLS. Do tego celu służy &lt;a href=&#34;https://www.stunnel.org/index.html&#34;&gt;narzędzie stunnel&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować klienta VPN na routerze z LEDE/OpenWRT</title>
      <link>https://morfikov.github.io/post/jak-skonfigurowac-klienta-vpn-na-routerze-z-ledeopenwrt/</link>
      <pubDate>Thu, 08 Dec 2016 18:13:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-skonfigurowac-klienta-vpn-na-routerze-z-ledeopenwrt/</guid>
      <description>&lt;p&gt;Ostatnio pisałem trochę o &lt;a href=&#34;https://morfikov.github.io
/post/jak-skonfigurowac-serwer-vpn-na-debianie-openvpn/&#34;&gt;konfiguracji serwera VPN na
Debianie&lt;/a&gt; oraz podłączaniu
do niego różnych linux&#39;owych klientów, w tym też &lt;a href=&#34;https://morfikov.github.io
/post/jak-skonfigurowac-polaczenie-vpn-na-smartfonie-z-androidem/&#34;&gt;smartfonów wyposażonych w system
Android&lt;/a&gt;. O ile
konfiguracja pojedynczego klienta OpenVPN nie jest jakoś szczególnie trudna, to mając w swojej sieci
domowej kilka urządzeń zdolnych łączyć się z internetem zarówno przewodowo jak i bezprzewodowo, to
dostosowanie konfiguracji na każdym z tych sprzętów może być ździebko problematyczne. To co łączy te
wszystkie urządzenia w naszym domu, to router WiFi. Zwykle każdy komputer, nawet ten najmniejszy,
łączy się z takim routerem w celu nawiązania połączenia ze światem. Dlatego też zamiast
konfigurować osobno wszystkie te urządzenia elektroniczne, możemy skonfigurować sobie router w taki
sposób, by cały zebrany ruch z sieci lokalnej przesłał do serwera VPN. Standardowej klasy routery
nie wspierają połączeń VPN i by taki mechanizm zaimplementować potrzebne nam będzie alternatywne
firmware pokroju LEDE/OpenWRT. W tym artykule postaramy się skonfigurować połączenie VPN dla sieci
domowej w oparciu o &lt;a href=&#34;http://www.tp-link.com.pl/products/details/Archer-C2600.html&#34;&gt;router Archer
C2600&lt;/a&gt; od TP-LINK, który ma wgrany
najnowszy snapshot LEDE Chaos Calmer (r2392).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować połączenie VPN na smartfonie z Androidem</title>
      <link>https://morfikov.github.io/post/jak-skonfigurowac-polaczenie-vpn-na-smartfonie-z-androidem/</link>
      <pubDate>Wed, 07 Dec 2016 18:54:37 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-skonfigurowac-polaczenie-vpn-na-smartfonie-z-androidem/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/jak-skonfigurowac-serwer-vpn-na-debianie-openvpn/&#34;&gt;W artykule o postawieniu serwera
VPN&lt;/a&gt; poruszyłem jedynie
kwestię konfiguracji klienta mającego system operacyjny z rodziny linux, a konkretnie była to
dystrybucja Debian. Niemniej jednak, mając działający serwer VPN gdzieś tam za granicą, możemy
również do niego podłączyć się za pomocą smartfona z Androidem i to praktycznie z dowolnego miejsca
na ziemi. W ten sposób możemy zabezpieczyć nasze połączenie przed cenzurą internetu, która obecnie
jest przeprowadzana na naszych oczach. Jako, że smartfony są popularniejsze od komputerów czy
laptopów i zwykle przesyłamy z nich tak samo ważne (albo i ważniejsze) dane, to wypadałoby
zaszyfrować cały ruch z takiego telefonu. Niniejszy wpis będzie właśnie dotyczył tego tematu, który
zostanie opisany w oparciu &lt;a href=&#34;http://www.neffos.pl/product/details/C5&#34;&gt;smartfon Neffos C5&lt;/a&gt; od TP-LINK
mający na pokładzie Androida w wersji 5.1 (Lollipop).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować serwer VPN na Debianie (OpenVPN)</title>
      <link>https://morfikov.github.io/post/jak-skonfigurowac-serwer-vpn-na-debianie-openvpn/</link>
      <pubDate>Tue, 06 Dec 2016 19:22:49 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-skonfigurowac-serwer-vpn-na-debianie-openvpn/</guid>
      <description>&lt;p&gt;Co raz częściej słychać w mediach o próbie cenzurowania internetu i blokowaniu dostępu do kolejnych
serwisów i stron www. Ostatnio znowu podnieśli kwestię blokowania pokemonów bezpośrednio u ISP tak,
by za zgodą ISP (władzy) można przeglądać tego typu serwisy. W sumie mam już tego dość i korzystając
z okazji, że posiadam za granicą niewielkich rozmiarów VPS, który i tak nie jest zbytnio obciążony,
to postanowiłem sobie skonfigurować na nim serwer VPN w oparciu o &lt;a href=&#34;https://openvpn.net/index.php/open-source/documentation/howto.html&#34;&gt;oprogramowanie
OpenVPN&lt;/a&gt;, które jest standardowo
dostępne w każdej dystrybucji linux&#39;a. Proces konfiguracji serwera jak i klienta z zainstalowanym
Debianem zostanie opisany poniżej. Niemniej jednak, inne urządzenia takie jak routery WiFi i
smartfony również wymagają zaimplementowania w nich mechanizmu szyfrującego ruch ale te rozwiązania
zostaną opisane w osobnych wątkach.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Formatowanie karty SD jako pamięć wewnętrzna</title>
      <link>https://morfikov.github.io/post/android-formatowanie-karty-sd-jako-pamiec-wewnetrzna/</link>
      <pubDate>Sun, 04 Dec 2016 19:18:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-formatowanie-karty-sd-jako-pamiec-wewnetrzna/</guid>
      <description>&lt;p&gt;Jakiś czas temu bawiąc się jednym z TP-LINK&#39;owch smartfonów, konkretnie to był &lt;a href=&#34;http://www.neffos.pl/product/details/C5&#34;&gt;model Neffos
C5&lt;/a&gt;, nie byłem zbytnio zadowolony z faktu, że karta SD w
takim telefonie może być sformatowana jedynie systemem plików z rodziny FAT. Takie rozwiązanie
niesie ze sobą pewne niedogodności, bo &lt;a href=&#34;https://pl.wikipedia.org/wiki/FAT32&#34;&gt;system plików FAT ma dość spore
ograniczenia&lt;/a&gt; jeśli chodzi o przechowywanie informacji.
Niekoniecznie wszyscy musimy wgrywać na smartfona bardzo duże pliki czy też trzymać ich tam setki
GiB, bo to jest raczej rzadkością, ale brak wsparcia uprawnień do plików i katalogów w systemie
plików FAT powoduje, że aplikacje w Androidzie nie chcą zapisywać swoich danych na karcie SD, która
taki system plików wykorzystuje. W efekcie trzeba kombinować, by &lt;a href=&#34;https://morfikov.github.io
/post/android-brak-mozliwosci-zapisu-danych-na-karcie-sd-neffos-c5/&#34;&gt;aplikacja kamery/aparatu
zapisywała zdjęcia czy materiał video na karcie
SD&lt;/a&gt;. Na
smartfonach TP-LINK&#39;a, które mają zainstalowany Android 6.0 Marshmallow, np.
&lt;a href=&#34;http://www.neffos.pl/product/details/Y5L&#34;&gt;Y5&lt;/a&gt; czy &lt;a href=&#34;http://www.neffos.pl/product/details/Y5L&#34;&gt;Y5L&lt;/a&gt;),
jesteśmy w stanie sformatować karty SD jako pamięć wewnętrzna za sprawą wprowadzonego w tej wersji
Androida &lt;a href=&#34;https://source.android.com/devices/storage/adoptable&#34;&gt;mechanizmu Adoptable Storage&lt;/a&gt;.
Postanowiłem zatem sprawdzić jak taki proces formatowania karty SD przebiega i co dokładnie może nam
przynieść jego przeprowadzenie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Test wydajności smartfona Neffos C5 MAX od TP-LINK</title>
      <link>https://morfikov.github.io/post/test-wydajnosci-smartfona-neffos-c5-max-od-tp-link/</link>
      <pubDate>Sat, 03 Dec 2016 16:59:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/test-wydajnosci-smartfona-neffos-c5-max-od-tp-link/</guid>
      <description>&lt;p&gt;Dzięki uprzejmości TP-LINK Polska od jakiegoś czasu mam możliwość bawić się smartfonami Neffos, co
można odczuć po sporej ilości artykułów dotyczących tych urządzeń. Postanowiłem przetestować
możliwości każdego z tych telefonów dostępnymi benchmarkami na Androida, które można pobrać ze
sklepu Google Play. Mnie generalnie tego typu benchmarki średnio interesują, bo zwykle nijak się
mają do standardowego użytkowania telefonu ale wiem, że sporo użytkowników mobilnych technologi
chciałaby tego typu test zobaczyć. Dlatego w oparciu o AnTuTu, 3DMark, PCMark oraz GFXBench zrobiłem
kilka testów na każdym z podesłanych mi przez TP-LINK urządzeń. Smartfony, które wzięły udział w tym
teście to: Neffos C5 MAX, Neffos C5, Neffos Y5 oraz Neffos Y5L. Ten artykuł dotyczy jedynie
smartfona Neffos C5 MAX. Testy pozostałych modeli smartfonów zostaną opisane osobno.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Test wydajności smartfona Neffos C5 od TP-LINK</title>
      <link>https://morfikov.github.io/post/test-wydajnosci-smartfona-neffos-c5-od-tp-link/</link>
      <pubDate>Sat, 03 Dec 2016 16:57:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/test-wydajnosci-smartfona-neffos-c5-od-tp-link/</guid>
      <description>&lt;p&gt;Dzięki uprzejmości TP-LINK Polska od jakiegoś czasu mam możliwość bawić się smartfonami Neffos, co
można odczuć po sporej ilości artykułów dotyczących tych urządzeń. Postanowiłem przetestować
możliwości każdego z tych telefonów dostępnymi benchmarkami na Androida, które można pobrać ze
sklepu Google Play. Mnie generalnie tego typu benchmarki średnio interesują, bo zwykle nijak się
mają do standardowego użytkowania telefonu ale wiem, że sporo użytkowników mobilnych technologi
chciałaby tego typu test zobaczyć. Dlatego w oparciu o AnTuTu, 3DMark, PCMark oraz GFXBench zrobiłem
kilka testów na każdym z podesłanych mi przez TP-LINK urządzeń. Smartfony, które wzięły udział w tym
teście to: Neffos C5 MAX, Neffos C5, Neffos Y5 oraz Neffos Y5L. Ten artykuł dotyczy jedynie
smartfona Neffos C5. Testy pozostałych modeli smartfonów zostaną opisane osobno.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Test wydajności smartfona Neffos Y5L od TP-LINK</title>
      <link>https://morfikov.github.io/post/test-wydajnosci-smartfona-neffos-y5l-od-tp-link/</link>
      <pubDate>Sat, 03 Dec 2016 16:56:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/test-wydajnosci-smartfona-neffos-y5l-od-tp-link/</guid>
      <description>&lt;p&gt;Dzięki uprzejmości TP-LINK Polska od jakiegoś czasu mam możliwość bawić się smartfonami Neffos, co
można odczuć po sporej ilości artykułów dotyczących tych urządzeń. Postanowiłem przetestować
możliwości każdego z tych telefonów dostępnymi benchmarkami na Androida, które można pobrać ze
sklepu Google Play. Mnie generalnie tego typu benchmarki średnio interesują, bo zwykle nijak się
mają do standardowego użytkowania telefonu ale wiem, że sporo użytkowników mobilnych technologi
chciałaby tego typu test zobaczyć. Dlatego w oparciu o AnTuTu, 3DMark, PCMark oraz GFXBench zrobiłem
kilka testów na każdym z podesłanych mi przez TP-LINK urządzeń. Smartfony, które wzięły udział w tym
teście to: Neffos C5 MAX, Neffos C5, Neffos Y5 oraz Neffos Y5L. Ten artykuł dotyczy jedynie
smartfona Neffos Y5L. Testy pozostałych modeli smartfonów zostaną opisane osobno.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Test wydajności smartfona Neffos Y5 od TP-LINK</title>
      <link>https://morfikov.github.io/post/test-wydajnosci-smartfona-neffos-y5-od-tp-link/</link>
      <pubDate>Sat, 03 Dec 2016 16:55:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/test-wydajnosci-smartfona-neffos-y5-od-tp-link/</guid>
      <description>&lt;p&gt;Dzięki uprzejmości TP-LINK Polska od jakiegoś czasu mam możliwość bawić się smartfonami Neffos, co
można odczuć po sporej ilości artykułów dotyczących tych urządzeń. Postanowiłem przetestować
możliwości każdego z tych telefonów dostępnymi benchmarkami na Androida, które można pobrać ze
sklepu Google Play. Mnie generalnie tego typu benchmarki średnio interesują, bo zwykle nijak się
mają do standardowego użytkowania telefonu ale wiem, że sporo użytkowników mobilnych technologi
chciałaby tego typu test zobaczyć. Dlatego w oparciu o AnTuTu, 3DMark, PCMark oraz GFXBench zrobiłem
kilka testów na każdym z podesłanych mi przez TP-LINK urządzeń. Smartfony, które wzięły udział w tym
teście to: Neffos C5 MAX, Neffos C5, Neffos Y5 oraz Neffos Y5L. Ten artykuł dotyczy jedynie
smartfona Neffos Y5. Testy pozostałych modeli smartfonów zostaną opisane osobno.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aplikacja tpMiFi do zarządzania routerami 3G/LTE od TP-LINK</title>
      <link>https://morfikov.github.io/post/aplikacja-tpmifi-do-zarzadzania-routerami-3g-lte-tp-link/</link>
      <pubDate>Fri, 25 Nov 2016 20:57:39 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aplikacja-tpmifi-do-zarzadzania-routerami-3g-lte-tp-link/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem jeden z mobilnych routerów WiFi, który był w stanie realizować połączenie
LTE i udostępniać je w obrębie swojej sieci. Konkretnie był to &lt;a href=&#34;https://morfikov.github.io
/post/recenzja-przenosny-router-lte3g-mifi-m7310-od-tp-link/&#34;&gt;hotspot
M7310&lt;/a&gt;. W recenzji
tego urządzenia wspomniałem o tym, że dysponując smartfonem jesteśmy w stanie przy jego pomocy
zarządzać tym routerem. Oczywiście potrzebna jest do tego celu specjalna aplikacja tpMiFi
wypuszczona również przez TP-LINK, którą można pobrać bez większego problemu z Google Play. Jako, że
w tamtym wpisie potraktowałem temat tej aplikacji jedynie powierzchownie, to postanowiłem nieco
bardziej się jej przyjrzeć i dokładnie opisać jej właściwości.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aplikacja Tether do zarządzania urządzeniami TP-LINK przez smartfon</title>
      <link>https://morfikov.github.io/post/aplikacja-tether-do-zarzadzania-urzadzeniami-tp-link-przez-smartfon/</link>
      <pubDate>Thu, 24 Nov 2016 21:02:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aplikacja-tether-do-zarzadzania-urzadzeniami-tp-link-przez-smartfon/</guid>
      <description>&lt;p&gt;TP-LINK ma w swojej ofercie szereg urządzeń, którymi można zarządzać z grubsza na dwa sposoby.
Pierwszym jest raczej znany nam wszystkim panel administracyjny dostępny z poziomu przeglądarki
internetowej zainstalowanej na dowolnym komputerze czy laptopie. Drugim ze sposobów jest
wykorzystanie smartfona i dedykowanej aplikacji Tether na Androida/iOS. Webowy panel administracyjny
zwykł udostępniać nam całą masę opcji, a jak jest w przypadku aplikacji Tether?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przesyłanie dźwięku i plików ze smartfona przez bluetooth</title>
      <link>https://morfikov.github.io/post/przesylanie-dzwieku-plikow-ze-smartfona-bluetooth/</link>
      <pubDate>Sat, 19 Nov 2016 19:40:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przesylanie-dzwieku-plikow-ze-smartfona-bluetooth/</guid>
      <description>&lt;p&gt;Praktycznie każdy telefon czy komputer/laptop jest wyposażony już w adapter bluetooth. Obecnie coraz
rzadziej ten protokół jest wykorzystywany do przesyłania plików jako takich, bo przecie mamy WiFi.
Niemniej jednak, w starszych modelach urządzeń bluetooth może być dla nas jedyną opcją, by przesłać
pliki bezprzewodowo. Nawet jeśli dysponujemy smartfonem z jednym z nowszych Androidów, to i tak są
pewne sytuacje, w których bluetooth może znaleźć ciekawe zastosowanie, np. streaming dźwięku.
Urządzenia bluetooth bardzo często sprawiają problemy pod linux i przydałoby się zebrać trochę
informacji na temat ich konfiguracji, by przesyłanie dźwięku i plików nie stanowiło dla nas
większego wyzwania w sytuacjach podbramkowych, gdzie wszelkie inne alternatywy komunikacji zawodzą.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Kamera IP NC250 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-kamera-ip-nc250-od-tp-link/</link>
      <pubDate>Sun, 13 Nov 2016 20:43:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-kamera-ip-nc250-od-tp-link/</guid>
      <description>&lt;p&gt;Ludzkie oko ma to do siebie, że nie widzi całej masy szczegółów w postrzeganym obrazie. Nawet jeśli
część z nas jest w stanie &amp;quot;widzieć więcej&amp;quot; niż inni, to i tak nie zawsze możemy znaleźć się w danym
miejscu i czasie, by te konkretne zdarzenia być w stanie zarejestrować. Subiektywna opinia kogoś,
kto próbuje nam jedynie opisać dane wydarzenie, nie zawsze oddaje sendo sytuacji, a i tak przecież
są rzeczy, które wolelibyśmy zobaczyć sami na własne oczy. Dlatego właśnie dobrze jest mieć jakiś
rejestrator w postaci kamery, który będzie w stanie uwiecznić obraz w formie niezmienionej. Taki
materiał video możemy później sobie odtworzyć w dowolnym czasie i raczej żaden szczegół nie umknie
naszej uwadze, zwłaszcza w przypadku włamań do monitorowanych przez nas pomieszczeń. Jako, że mam na
wyposażeniu &lt;a href=&#34;http://www.tp-link.com.pl/products/details/cat-19_NC250.html&#34;&gt;kamerę IP NC250&lt;/a&gt; od
TP-LINK, to postanowiłem napisać o miej kilka słów w kontekście wykorzystania tego sprzętu pod
linux&#39;em.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aplikacja tpCamera do obsługi kamer TP-LINK z poziomu smartfona</title>
      <link>https://morfikov.github.io/post/aplikacja-tpcamera-do-obslugi-kamer-tp-link-z-poziomu-smartfona/</link>
      <pubDate>Thu, 10 Nov 2016 22:59:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aplikacja-tpcamera-do-obslugi-kamer-tp-link-z-poziomu-smartfona/</guid>
      <description>&lt;p&gt;Kamery IP to bardzo użyteczne urządzenia, choć ich obsługa nie zawsze jest wygodna. Nie chodzi tutaj
o zarządzenie nimi, bo taka kamera ma przecie swój własny adres IP i możemy bez większego problemu
dostać się do jej panelu administracyjnego przez sieć, w tym też nawet i po WiFi. Niemniej jednak,
gdy jesteśmy w terenie, to bardzo rzadko mamy przy sobie komputer czy nawet laptop, na którym
moglibyśmy zainstalować odpowiedni soft w celu uzyskania podglądu obrazu z takiej kamery. W
przypadku kamer od TP-LINK sprawa wygląda nieco inaczej, bo mamy tutaj możliwość zaprzęgnięcia do
pracy smartfona. Taki telefon można bez problemu połączyć z kamerą, z tym, że potrzebna nam będzie
do tego specjalna aplikacja: tpCamera. Zobaczmy zatem do czego może ona nam się przydać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>XDA Labs: Repozytorium aplikacji i modułów Xposed</title>
      <link>https://morfikov.github.io/post/xda-labs-repozytorium-aplikacji-modulow-xposed/</link>
      <pubDate>Thu, 10 Nov 2016 16:44:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/xda-labs-repozytorium-aplikacji-modulow-xposed/</guid>
      <description>&lt;p&gt;Przeglądając sobie forum XDA w poszukiwaniu pewnych informacji natrafiłem na &lt;a href=&#34;https://forum.xda-developers.com/android/apps-games/labs-t3241866&#34;&gt;XDA
Labs&lt;/a&gt;. Niby jest to aplikacja
mająca na celu poprawę doznań przy przeglądaniu tego forum na urządzeniach mobilnych ale posiada
ona też kilka użytecznych funkcji niekoniecznie związanych bezpośrednio z interakcją ze stroną
xda-developers. Przede wszystkim, mamy tutaj dostęp do repozytorium aplikacji na Androida, mniej
więcej coś jak
&lt;a href=&#34;https://morfikov.github.io
/post/android-repozytorium-aplikacji-opensource-f-droid/&#34;&gt;F-Droid&lt;/a&gt;. Przy pomocy
XDA Labs jesteśmy też w stanie w prosty sposób instalować moduły Xposed. Te powyższe rzeczy
sprawiły, że postanowiłem się nieco bliżej przyjrzeć aplikacji XDA Labs.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przerabianie zdjęć i innych plików graficznych z Imagemagick</title>
      <link>https://morfikov.github.io/post/przerabianie-zdjec-innych-plikow-graficznych-imagemagick/</link>
      <pubDate>Sun, 06 Nov 2016 12:40:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przerabianie-zdjec-innych-plikow-graficznych-imagemagick/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.imagemagick.org/script/index.php&#34;&gt;Imagemagick to zestaw tekstowych narzędzi&lt;/a&gt; do
manipulacji obrazami graficznymi. Łapie on takie formaty jak DPX, EXR, GIF, JPEG, JPEG-2000, PDF,
PhotoCD, PNG, Postscript, SVG, oraz TIFF. Przy pomocy Imagemagick można przeprowadzać cała masę
operacji na plikach począwszy od tych podstawowych, kończąc na tych najbardziej zaawansowanych. W
sumie to nie wiem czy jest coś czego by nie dało się zrobić przy pomocy tego magika. Czasami
korzystanie z wiersza poleceń jest też o wile wygodniejsze w przypadku przeróbki całej masy zdjęć,
gdzie graficzne narzędzia typu GIMP raczej średnio się nadają. Postanowiłem zatem zrobić wpis o
Imagemagick (pakiet &lt;code&gt;imagemagick&lt;/code&gt; w dystrybucji Debian) i zawrzeć w nim wszystkie te ciekawsze
polecenia, na które w przyszłości natrafię podczas przerabiania fotek, skrinów czy innych grafik.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wifi Roaming Fix i SWIFI, czyli roaming w smartfonie</title>
      <link>https://morfikov.github.io/post/wifi-roaming-fix-swifi-roaming-w-smartfonie/</link>
      <pubDate>Thu, 03 Nov 2016 19:33:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wifi-roaming-fix-swifi-roaming-w-smartfonie/</guid>
      <description>&lt;p&gt;Ostatnimi czasy coraz więcej sieci domowych zaczyna być wyposażanych w sprzęt umożliwiający
połączenie bezprzewodowe. Router WiFi ma już chyba znaczna większość z nas ale nie są to jedyne
urządzenia, które są w stanie świadczyć bezprzewodowe usługi sieciowe. Im większy dystans dzieli
odbiornik od nadajnika lub też im więcej przeszkód stoi na bezpośredniej drodze komunikacji, tym
sygnał ulega większej degradacji. Zwykle w takiej sytuacji dokupujemy drugi router WiFi, ewentualnie
&lt;a href=&#34;http://www.tp-link.com.pl/products/list-12.html&#34;&gt;prosty AP&lt;/a&gt;, &lt;a href=&#34;http://www.tp-link.com.pl/products/list-10.html&#34;&gt;wzmacniacz sygnału
WiFi&lt;/a&gt; czy też &lt;a href=&#34;http://www.tp-link.com.pl/products/list-18.html&#34;&gt;ekstendery
powerline&lt;/a&gt; (PLC). Wszystko po to, by jakoś
przyzwoicie pokryć sygnałem całą przestrzeń użytkową naszego domu czy też miejsc, w których spędzamy
wolny czas. Każde takie urządzenie realizuje połączenie WiFi mniej więcej w ten sam sposób, tj.
zestawia punkt dostępu, do którego podłączamy komputer albo smartfona. O ile w przypadku desktopów
czy laptopów przełączanie się między tymi AP w zależności od siły sygnału nie stanowi większego
problemu, o tyle w przypadku smartfonów z Androidem nie jest już tak różowo, bo przełączenie
następuje jedynie przy całkowitej utracie sygnału z AP. Takiej sytuacji można zaradzić ale trzeba
posiłkować się dodatkowymi aplikacjami. W poniższym artykule zostaną opisane dwa takie programiki:
&lt;a href=&#34;https://play.google.com/store/apps/details?id=com.seah0rse.swififree&#34;&gt;SWIFI&lt;/a&gt; i &lt;a href=&#34;https://play.google.com/store/apps/details?id=com.heleron.wifiroamingfix&#34;&gt;Wifi Roaming
Fix&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Udostępnianie LTE/3G ze smartfona przez router OpenWRT (tethering)</title>
      <link>https://morfikov.github.io/post/udostepnianie-lte-3g-ze-smartfona-przez-router-openwrt-tethering/</link>
      <pubDate>Tue, 01 Nov 2016 18:14:53 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/udostepnianie-lte-3g-ze-smartfona-przez-router-openwrt-tethering/</guid>
      <description>&lt;p&gt;Przeglądając &lt;a href=&#34;http://eko.one.pl/forum/viewtopic.php?pid=175547&#34;&gt;forum eko.one.pl natrafiłem ciekawy
problem&lt;/a&gt;, nad którym też się zastanawiałem jakiś
czas temu. Chodzi o udostępnienie internetu komórkowego (LTE/3G) komputerom w domowej sieci za
pomocą smartfona (tzw. &lt;a href=&#34;https://pl.wikipedia.org/wiki/Tethering&#34;&gt;tethering&lt;/a&gt;). W takiej sytuacji, w
przypadku problemów z lokalnym dostawcą internetu moglibyśmy przepiąć wszystkie komputery na
internet świadczony przez operatora GSM, z którego korzystamy. Z reguły standardowy firmware
routerów WiFi nie pozwala na tego typu rozwiązania. Niemniej jednak, mając do dyspozycji router z
OpenWRT można spróbować połączyć go z naszym smartfonem udostępniając sieci lokalnej internet
LTE/3G. W tym artykule zostanie przedstawione tego typu rozwiązanie przy wykorzystaniu &lt;a href=&#34;http://www.tp-link.com.pl/en/products/details/cat-9_Archer-C7.html&#34;&gt;routera
Archer C7&lt;/a&gt; v2 od TP-LINK oraz
&lt;a href=&#34;http://www.neffos.com/en/product/details/C5&#34;&gt;smartfona Neffos C5&lt;/a&gt;, również od TP-LINK. Na routerze
zaś jest wgrana najnowsza stabilna wersja OpenWRT (Chaos Calmer). Sprawdzimy sobie jak takie
rozwiązanie wygląda oraz sprawuje się w praktyce i czy jest ono w ogóle godne jakiegoś większego
zainteresowania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Blokowanie reklam z AdAway na smartfonie</title>
      <link>https://morfikov.github.io/post/android-blokowanie-reklam-z-adaway-na-smartfonie/</link>
      <pubDate>Sun, 30 Oct 2016 16:21:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-blokowanie-reklam-z-adaway-na-smartfonie/</guid>
      <description>&lt;p&gt;Dzięki &lt;a href=&#34;https://dnscrypt.org/&#34;&gt;dnscrypt-proxy&lt;/a&gt; jesteśmy w stanie &lt;a href=&#34;https://morfikov.github.io
/post/jak-zaszyfrowac-zapytania-dns-na-smartfonie-dnscrypt-proxy/&#34;&gt;zaszyfrować zapytania
DNS&lt;/a&gt;
bezpośrednio na naszych smartfonach. Niemniej jednak, w przypadku mojego Neffos&#39;a C5 od TP-LINK, w
wielu aplikacjach pojawiły się reklamy po wdrożeniu mechanizmu szyfrującego. Wcześniej oczywiście
wykorzystywałem &lt;a href=&#34;https://morfikov.github.io
/post/blokowanie-reklam-adblock-na-domowym-routerze-wifi/&#34;&gt;adblock&#39;a bezpośrednio na routerze z wgranym firmware
OpenWRT/LEDE&lt;/a&gt;, gdzie
zapytania DNS do adserwerów były filtrowane i blokowane bezpośrednio na tym urządzeniu. Po
zaszyfrowaniu ruchu DNS w telefonie, straciłem dostęp do mojego filtra reklam na routerze.
Przydałoby się zatem zaimplementować podobny mechanizm blokujący bezpośrednio na Androidzie, tak by
ponownie wszystkie te reklamy zniknęły przy jednoczesnym zachowaniu całej funkcjonalności płynącej
za sprawą szyfrowanego ruchu DNS. Jednym z rozwiązań jest wykorzystanie &lt;a href=&#34;https://adaway.org/&#34;&gt;narzędzia
AdAway&lt;/a&gt;, które przy pomocy pliku &lt;code&gt;/etc/hosts&lt;/code&gt; i lokalnego serwera www jest w
stanie zablokować sporą większość reklam, na które możemy natknąć się w internecie. Opis instalacji
i konfiguracji AdAway zostanie przedstawiony w niniejszym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zaszyfrować zapytania DNS na smartfonie (dnscrypt-proxy)</title>
      <link>https://morfikov.github.io/post/jak-zaszyfrowac-zapytania-dns-na-smartfonie-dnscrypt-proxy/</link>
      <pubDate>Thu, 27 Oct 2016 18:52:19 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zaszyfrowac-zapytania-dns-na-smartfonie-dnscrypt-proxy/</guid>
      <description>&lt;p&gt;Smartfony to takie małe komputery, z których praktycznie każdy z nas korzysta na co dzień. Nie
różnią się one zbytnio od tych domowych PC czy laptopów, no może za wyjątkiem rozmiarów.
Wszystkie elementy tyczące się spraw sieciowych, np. korzystanie z internetu za pomocą przeglądarki,
są dokładnie taka same co w przypadku zwykłych komputerów. Na smartfonach domeny również trzeba
jakoś rozwiązać. Standardowo w Androidzie są wykorzystywane serwery od Google (8.8.8.8 i 8.8.4.4).
Jeśli nasza sieć WiFi oferuje inne DNS&#39;y, to wtedy one mają pierwszeństwo. Niemniej jednak, nie
zawsze będziemy w stanie kontrolować środowisko sieciowe, do którego zostaniemy podłączeni. W takiej
sytuacji będziemy zdani na łaskę admina obcej sieci w kwestii poufności odwiedzanych przez nas stron
www czy jakichkolwiek innych domen w internecie. Z doświadczenia wiem, by nie składać swojej
prywatności w czyjeś ręce i dlatego też postanowiłem poszukać sposobu na zaszyfrowanie zapytań DNS
bezpośrednio na smartfonie. Długo nie musiałem szukać, bo okazuje się, że &lt;a href=&#34;https://dnscrypt.org/#dnscrypt-android&#34;&gt;dnscrypt-proxy jest
dostępny również na Androida&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ukryć zaszyfrowany kontener LUKS pod linux</title>
      <link>https://morfikov.github.io/post/jak-ukryc-zaszyfrowany-kontener-luks-pod-linux/</link>
      <pubDate>Tue, 25 Oct 2016 19:30:23 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ukryc-zaszyfrowany-kontener-luks-pod-linux/</guid>
      <description>&lt;p&gt;Gdy w grę wchodzi poufność informacji, to przeciętny użytkownik komputera od razu zaczyna rozważać
szyfrowanie danych. Są różne narzędzia, które te kwestię realizują w mniejszym lub większym stopniu.
Kiedyś wszyscy korzystali z &lt;a href=&#34;http://truecrypt.sourceforge.net/&#34;&gt;TrueCrypt&lt;/a&gt; ale po jego dziwnych
przygodach ludzie stopniowo zaczęli od tego oprogramowania odchodzić. W jego miejscu zaczęły
pojawiać się różne forki, np. &lt;a href=&#34;https://veracrypt.codeplex.com/&#34;&gt;VeraCrypt&lt;/a&gt;. Abstrahując od tych ww.
narzędzi, w każdym linux&#39;ie mamy również dostępny &lt;a href=&#34;https://gitlab.com/cryptsetup/cryptsetup/wikis/FrequentlyAskedQuestions&#34;&gt;mechanizm szyfrujący na bazie
LUKS&lt;/a&gt; i jego gołą wersję
wykorzystującą dm-crypt. Przy pomocy każdego z tych narzędzi jesteśmy w stanie zaszyfrować dysk
komputera, pendrive, czy nawet kartę SD, w taki sposób, by nikt inny nie uzyskał dostępu do danych
zgromadzonych na tych nośnikach informacji. Problem w tym, że w dalszym ciągu ktoś może nas
torturować, by wydobyć od nas hasło czy keyfile i uzyskać dostęp do tych zaszyfrowanych danych bez
większego trudu. Dlatego też pojawiło się coś nazwanego &lt;a href=&#34;https://en.wikipedia.org/wiki/Plausible_deniability&#34;&gt;Plausible
Deniability&lt;/a&gt;, gdzie wykorzystywane są tak
naprawdę dwa nośniki z czego jeden robi za przykrywkę, a na drugim mamy zgromadzone poufne pliki. W
ten sposób agresorowi podajemy hasło do trefnego kontenera i wszyscy są zadowoleni. Czy aby na
pewno?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przy pomocy trybu recovery odzyskać router TP-LINK</title>
      <link>https://morfikov.github.io/post/jak-przy-pomocy-trybu-recovery-odzyskac-router-tp-link/</link>
      <pubDate>Sat, 22 Oct 2016 21:22:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przy-pomocy-trybu-recovery-odzyskac-router-tp-link/</guid>
      <description>&lt;p&gt;Przy okazji zabawy z &lt;a href=&#34;https://morfikov.github.io
/post/konsola-szeregowa-adapter-usb-uart-uszkodzony-router-tp-link/&#34;&gt;konsolą szeregową przy ratowaniu jednego z moich routerów
TP-LINK&lt;/a&gt;
(&lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WR1043ND.html&#34;&gt;TL-WR1043ND&lt;/a&gt; V2), parokrotnie
przewinęła mi się informacja na temat trybu recovery, który ma być dostępny w części routerów. W
czym nam taki tryb może pomóc i czy nasz router go obsługuje? Jeśli tak, to jak za jego pomocą
naprawić urządzenie, które nie chce wystartować, np. po przerwanym procesie wgrywania firmware
TP-LINK czy też OpenWRT/LEDE? W trym artykule postaramy się odpowiedzieć na te pytania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przeprowadzić unroot na smartfonie Neffos C5 od TP-LINK</title>
      <link>https://morfikov.github.io/post/jak-przeprowadzic-unroot-na-smartfonie-neffos-c5-od-tp-link/</link>
      <pubDate>Thu, 20 Oct 2016 22:58:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przeprowadzic-unroot-na-smartfonie-neffos-c5-od-tp-link/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/android-root-smartfona-neffos-c5-od-tp-link/&#34;&gt;Proces root na smartfonie Neffos
C5&lt;/a&gt; od TP-LINK można
przeprowadzić w miarę bez większych problemów, choć nie jest to rozwiązanie działające OOTB.
Niemniej jednak, taki root telefonu czyni go bardziej podatnym na zagrożenia ze strony wrogich
aplikacji. Ponadto, kasując czy też zmieniając pliki systemowe, możemy sprawić, że nasze urządzenie
zwyczajnie przestanie nam działać, tj. już się nie uruchomi. Niektórzy użytkownicy smartfonów nie
zdają sobie z tego sprawy i ukorzeniają Androida bez głębszego zastanowienia się. Mi jako
linux&#39;iarzowi, root jest niezbędny do pracy ale czy aby na pewno każdy musi go mieć? Ci z was,
którzy taki root systemu przeprowadzili i nie korzystają z niego praktycznie wcale, zastanawiają
się pewnie czy istnieje sposób, by cofnąć wprowadzone zmiany i przywrócić Androida do stanu
pierwotnego. Krótka odpowiedź brzmi: &amp;quot;oczywiście, że tak&amp;quot; i temu procesowi przyjrzymy się w
niniejszym artykule.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: YouTube bez reklam na smartfonie (NewPipe)</title>
      <link>https://morfikov.github.io/post/android-youtube-bez-reklam-na-smartfonie-newpipe/</link>
      <pubDate>Thu, 20 Oct 2016 19:41:01 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-youtube-bez-reklam-na-smartfonie-newpipe/</guid>
      <description>&lt;p&gt;Ja generalnie zaliczam się do grona osób bardzo spokojnych ale tylko do czasu aż się zdenerwuję.
Jedną taką bardziej wyprowadzającą mnie z równowagi kwestią są reklamy w serwisie YouTube. Problem
jest o wiele bardziej dotkliwy, gdy w grę wchodzą urządzenia mobilne, np. smartfony. Na komputerze
nie mam większego problemu, bo wszystkie reklamy mogę zablokować stosując adblock/ublock w
przeglądarce lub też korzystać z aplikacji
&lt;a href=&#34;https://github.com/mps-youtube/mps-youtube&#34;&gt;mpsyt&lt;/a&gt;/&lt;a href=&#34;http://flavio.tordini.org/minitube&#34;&gt;minitube&lt;/a&gt;.
Gdy chcę wesprzeć kogoś, to odpalam kilka kanałów z reklamami, wyciszam dźwięk i mój linux ogląda za
mnie ten cały syf reklamowy, a ja go ani nie słyszę, ani nie widzę i wszyscy są happy. W przypadku
smartfonów oglądanie serwisu YT jest nieco problematyczne. Nie dość, że nie ma jak obejść tych
reklam, to jeszcze zwykle są one głośniejsze niż ścieżka dźwiękowa materiału video, co bardzo
wnerwia w godzinach nocnych. Przy szukaniu rozwiązania tego problemu natknąłem się na
&lt;a href=&#34;https://github.com/TeamNewPipe/NewPipe&#34;&gt;NewPipe&lt;/a&gt;. Jest to przeglądarkę YT z otwartym kodem
źródłowym (OpenSource), która działa podobnie do mpsyt/minitube i to ten programik zostanie
opisany w niniejszym artykule.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: OpenCamera i aparat w Neffos C5</title>
      <link>https://morfikov.github.io/post/android-opencamera-i-aparat-w-neffos-c5/</link>
      <pubDate>Tue, 18 Oct 2016 22:53:19 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-opencamera-i-aparat-w-neffos-c5/</guid>
      <description>&lt;p&gt;Ci z was, którzy czytali moją &lt;a href=&#34;https://morfikov.github.io
/post/recenzja-smartfon-neffos-c5-od-tp-link/&#34;&gt;recenzję na temat smartfona Neffos
C5&lt;/a&gt; od TP-LINK, widzą, że niezbyt
spodobał mi się aparat/kamera zaimplementowany w tym telefonie. Niby jest tutaj 8 mpix na aparacie
głównym (i 5 mpix na selfie) ale przy niezbyt dobrym oświetleniu jakość zdjęć siada dość znacznie.
Abstrahując od samej jakości aparatu, chciałbym się nieco bardziej skupić na oprogramowaniu do jego
obsługi, które Neffos C5 oferuje. Jest ono dość ubogie pod względem funkcjonalności i mi generalnie
przydałoby się nieco więcej opcji, z których mógłbym zrobić jakiś użytek. Jest wiele aplikacji na
Androida, które oferują poszerzenie możliwości aparatu czy kamery w telefonie. Większość z nich
zawiera jednak reklamy, które niezbyt pasują na smartfonie wyrafinowanego linux&#39;iarza. Postanowiłem
zatem poszukać nieco głębiej i w &lt;a href=&#34;https://morfikov.github.io
/post/android-repozytorium-aplikacji-opensource-f-droid/&#34;&gt;repozytorium
F-Droid&#39;a&lt;/a&gt; znalazłem
&lt;a href=&#34;http://opencamera.org.uk/&#34;&gt;OpenCamera&lt;/a&gt;. Programik bardzo przyzwoity, bez reklam, no i najważniejsze
jest on OpenSource. W tym artykule rzucimy sobie okiem na ten kawałek oprogramowania i zobaczymy
jaką funkcjonalność ono oferuje.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konsola szeregowa, adapter USB-UART i uszkodzony router TP-LINK</title>
      <link>https://morfikov.github.io/post/konsola-szeregowa-adapter-usb-uart-uszkodzony-router-tp-link/</link>
      <pubDate>Sun, 16 Oct 2016 20:36:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konsola-szeregowa-adapter-usb-uart-uszkodzony-router-tp-link/</guid>
      <description>&lt;p&gt;Każdy z nas słyszał o alternatywnym firmware na bezprzewodowe routery WiFi. Mam tutaj na myśli
oczywiście &lt;a href=&#34;https://openwrt.org/&#34;&gt;OpenWRT&lt;/a&gt;/&lt;a href=&#34;https://lede-project.org/&#34;&gt;LEDE&lt;/a&gt; oraz jego GUI
&lt;a href=&#34;https://www.gargoyle-router.com/&#34;&gt;Gargoyle&lt;/a&gt; i &lt;a href=&#34;http://eko.one.pl/?p=openwrt-luci&#34;&gt;LUCI&lt;/a&gt;. Przy
zabawach z takim oprogramowaniem bardzo łatwo jest uszkodzić router w sytuacji, gdy tak na dobrą
sprawę nie wiemy co robimy. Mi się jeszcze nie zdarzyło ubić żadnej z moich maszyn, a mam ich kilka.
Problem w tym, że tak naprawdę nie wiem jak wygląda proces odzyskiwania routera w przypadku
zaistnienia takiego złego scenariusza. Dlatego też postanowiłem zainicjować zdarzenie, które
doprowadziło do ubicia systemu w moim
&lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WR1043ND.html&#34;&gt;TL-WR1043ND&lt;/a&gt; V2 od TP-LINK. Co zrobić
w takim przypadku, gdy system routera nie chce wystartować, a na obudowie diody sygnalizują
nieprawidłową pracę urządzenia? W takiej sytuacji będziemy musieli rozebrać sprzęt i podłączyć się
do portu szeregowego na PCB za pomocą adaptera USB-UART, najlepiej na układzie CP2102, który bez
problemu działa pod linux. Ten artykuł nie powstałby (tak szybko), &lt;a href=&#34;http://tplink-forum.pl/index.php?/topic/5322-jak-ustali%C4%87-oznaczenia-port%C3%B3w-konsoli-szeregowej-na-pcb/&#34;&gt;gdyby nie pomoc ze strony
@Heinz&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Brak możliwości zapisu danych na karcie SD w Neffos C5</title>
      <link>https://morfikov.github.io/post/android-brak-mozliwosci-zapisu-danych-na-karcie-sd-neffos-c5/</link>
      <pubDate>Fri, 14 Oct 2016 20:56:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-brak-mozliwosci-zapisu-danych-na-karcie-sd-neffos-c5/</guid>
      <description>&lt;p&gt;Może i obecne smartfony dają nam w standardzie sporo wolnego miejsca na swoim flash&#39;u ale dla
niektórych to ciągle za mało. Nie ważne ile tej pamięci będziemy mieć dostępnej, to i tak zawsze
będzie nam jej brakować. Mój &lt;a href=&#34;http://www.neffos.pl/product/details/C5&#34;&gt;Neffos C5&lt;/a&gt; ma na pokładzie
16 GiB flash, z czego około 10 GiB jest udostępnione użytkownikowi. Mi by się przydał flash 64 GiB.
Jako, że ten telefon obsługuje karty SDHC, max 32 GiB, to postanowiłem dokupić tego typu kartę i
zamontować ją w smartfonie. Problem pojawił się w momencie próby przeniesienia danych aplikacji z
pamięci wewnętrznej na pamięć zewnętrzną jaką jest karta SD. Chodzi na przykład o zapisywanie zdjęć
czy filmów z kamery bezpośrednio na karcie SD. Okazuje się jednak, że&lt;a href=&#34;https://developer.android.com/about/versions/android-4.4.html&#34;&gt;Android począwszy od
wersji 4.4&lt;/a&gt; zablokował możliwość
umieszczania danych aplikacji na karatach SD. Czy słusznie i czy istnieje jakiś sposób by wybrnąć z
tej sytuacji?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Nova Launcher w Neffos C5</title>
      <link>https://morfikov.github.io/post/android-nova-launcher-neffos-c5/</link>
      <pubDate>Wed, 12 Oct 2016 19:18:31 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-nova-launcher-neffos-c5/</guid>
      <description>&lt;p&gt;Jedną z rzeczy, która wychodzi przy użytkowaniu &lt;a href=&#34;http://www.neffos.pl/product/details/C5&#34;&gt;smartfona Neffos
C5&lt;/a&gt; od TP-LINK jest ździebko problematyczny interfejs.
Chodzi o launcher aplikacji, do których odnośniki mamy na pulpicie. Standardowo jest tutaj podziałka
4x4, czyli na jednym pulpicie możemy mieć maksymalnie tylko 16 ikonek. Gdy do tego jeszcze dojdą nam
widżety, to korzystanie z pewnych aplikacji może być dość uciążliwe. Ja korzystam z bardzo wielu
programów i standardowo w Neffos&#39;ie C5 muszę mieć co najmniej 5 pulpitów, a jeszcze nie skończyłem
się bawić aplikacjami. Nie byłoby pewnie żadnego problemu, gdyby nie fakt, że nie można zmienić
ilości wyświetlanych ikonek, przynajmniej ja nie znalazłem takiej opcji. Dlatego też byłem zmuszony
rozejrzeć się za innym launcher&#39;em i znalazłem &lt;a href=&#34;https://play.google.com/store/apps/details?id=com.teslacoilsw.launcher&#34;&gt;Nova
Launcher&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Repozytorium aplikacji OpenSource (F-Droid)</title>
      <link>https://morfikov.github.io/post/android-repozytorium-aplikacji-opensource-f-droid/</link>
      <pubDate>Tue, 11 Oct 2016 20:47:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-repozytorium-aplikacji-opensource-f-droid/</guid>
      <description>&lt;p&gt;Przeszukując sklep Google Play za nowymi aplikacjami, które mógłbym wgrać na swojego &lt;a href=&#34;https://morfikov.github.io
/post/recenzja-smartfon-neffos-c5-od-tp-link/&#34;&gt;Neffos&#39;a
C5&lt;/a&gt;, zawsze staram się zwracać uwagę
co tak naprawdę zamierzam zainstalować. Nie chodzi tutaj tylko o poleconą mi przez kogoś aplikację,
a konkretnie jej nazwę, bo te mogą być przecież bardzo podobne i łatwo zainstalować nie tego app&#39;ka,
którego powinniśmy. Android jest prawie jak windows, no może z tą różnicą, że jest udostępniany na
wolnych licencjach. Z racji swojej popularności musi być bardzo prosty w obsłudze, by nie generować
żadnych błędów i problemów wśród korzystających z niego użytkowników. Z doświadczenia wiem, że
prostota obsługi nie zawsze idzie w parze z bezpieczeństwem, a gdy mamy przed sobą tak popularny
system operacyjny jak Android, to już tylko krok dzieli nas od kompromitacji systemu przez wgranie
jakiejś trefnej aplikacji ze sklepu Google. Nie znam tych wszystkich programików, które są w nim
dostępne ale można zrobić lekki przesiew instalując jedynie aplikacje OpenSource. Przeszukiwanie
Google Play pod tym kątem nie jest zbyt wygodne, dlatego też ktoś postanowił uruchomić &lt;a href=&#34;https://f-droid.org/&#34;&gt;projekt
F-Droid&lt;/a&gt; zrzeszający wolne aplikacje, które możemy wgrać na swój telefon bez
większego problemu. Ten wpis będzie poświęcony właśnie aplikacji F-Droid.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Root smartfona Neffos C5 od TP-LINK</title>
      <link>https://morfikov.github.io/post/android-root-smartfona-neffos-c5-od-tp-link/</link>
      <pubDate>Sun, 09 Oct 2016 18:08:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-root-smartfona-neffos-c5-od-tp-link/</guid>
      <description>&lt;p&gt;Smartfony mają to do siebie, że ogromna większość z nich pracuje pod kontrolą systemu linux, a
konkretnie jest to jakiś Android. Tak też jest w przypadku &lt;a href=&#34;http://www.neffos.pl/product/details/C5&#34;&gt;Neffos&#39;a
C5&lt;/a&gt; od TP-LINK, gdzie mamy zainstalowaną wersję 5.1
(Lollipop). My linux&#39;iarze chcemy mieć pełny dostęp do systemu operacyjnego, by bez większych
przeszkód móc zarządzać urządzeniem, które pod jego kontrolą pracuje. Problem w tym, że ten Neffos
C5 nie ma w standardzie root&#39;a i nie mamy administracyjnego dostępu do całego systemu plików
telefonu. Jest kilka metod root&#39;owania smartfona, np. za pomocą Kingoroot/Kingroot ale nie działają
one w przypadku tego telefonu (i całe szczęście). W tym artykule zostanie pokazany sposób na root
systemu Neffos&#39;a C5 przy zachowaniu wszelkich norm bezpieczeństwa, które w sytuacjach podbramkowych
pomogą nam odzyskać kontrolę nad telefonem.&lt;/p&gt;
&lt;p&gt;Prostszy sposób na przeprowadzanie procesu root w smartfonach Neffos od TP-LINK z wykorzystaniem
natywnych obrazów TWRP &lt;a href=&#34;https://morfikov.github.io
/post/root-w-smartfonach-neffos-od-tp-link-x1-c5-c5-max-y5-y5l/&#34;&gt;został opisany w nowym wątku&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Jak zainstalować ADB i fastboot pod linux</title>
      <link>https://morfikov.github.io/post/android-jak-zainstalowac-adb-i-fastboot-pod-linux/</link>
      <pubDate>Sat, 08 Oct 2016 20:34:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-jak-zainstalowac-adb-i-fastboot-pod-linux/</guid>
      <description>&lt;p&gt;Bawiąc się &lt;a href=&#34;http://www.neffos.pl/product/details/C5&#34;&gt;smartfonem Neffos C5&lt;/a&gt; od TP-LINK chciałem
sprawdzić czy da radę zainstalowanemu na nim Androidowi 5.1 (Lollipop) zrobić root&#39;a. Chodzi o
uzyskanie dostępu administracyjnego do systemu plików na flash&#39;u telefonu. Proces się powiódł, z
tym, że by do niego przystąpić, potrzebne są narzędzia takie jak &lt;code&gt;adb&lt;/code&gt; i &lt;code&gt;fastboot&lt;/code&gt; , bo przy ich
pomocy możemy sterować telefonem, np. z poziomu jakiegoś linux&#39;a. Niemniej jednak, system komputera
jak i smartfona trzeba pierw przygotować odpowiednio, by taka komunikacja była możliwa i ten proces
zostanie właśnie opisany poniżej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Smartfon Neffos C5 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-smartfon-neffos-c5-od-tp-link/</link>
      <pubDate>Sat, 08 Oct 2016 13:20:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-smartfon-neffos-c5-od-tp-link/</guid>
      <description>&lt;p&gt;Większość z nas zawierała już jakaś umowę abonamentową na telefon z operatorami GSM. Ja jestem chyba
jednym z nielicznych wyjątków, które tego jeszcze nie uczyniły. Mam prepaid&#39;a od lat i w sumie nie
uśmiecha mi się wiązanie na dłuższy okres czasu umową z operatorem, którego stosunek do użytkownika
zwykle się drastycznie obniża tuż po podpisaniu papierowego świstka. Niemniej jednak, prepaid&#39;y mają
tę wadę (dla niektórych zaletę), że sami musimy zadbać o odpowiednie urządzenie, za pomocą którego
będą realizowane usługi telefoniczne. Problem w tym, że te bardziej zaawansowane technicznie
smartfony są w stanie kosztować niemałe pieniądze, przez co niewielu z nas jest w stanie pokusić się
o ich zakup i z reguły pozostaje nam tylko opcja pakietowa przy zawieraniu umowy z operatorem GSM.
Jeśli już się jednak zdecydujemy na zakup takiego sprzętu, to ciężko jest też znaleźć takie
urządzenie, które będzie w miarę tanie i jednocześnie dostosowane do realiów otaczającej nas
rzeczywistości. TP-LINK był chyba tego samego zdania i od jakiegoś już czasu wypuszcza na rynek
smartfony. Czym ten producent może się pochwalić jeśli chodzi o te urządzenia? Na pewno
niewygórowaną ceną. A jak sprawa wygląda w przypadku parametrów technicznych oferowanych nam
telefonów? To trzeba by sprawdzić i tak się składa, że mam właśnie na wyposażeniu taki smartfon, a
konkretnie jest to &lt;a href=&#34;http://www.neffos.pl/product/details/C5&#34;&gt;model Neffos C5&lt;/a&gt; (TP701A).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android: Reset ustawień do fabrycznych (factory defaults)</title>
      <link>https://morfikov.github.io/post/android-reset-ustawien-do-fabrycznych-factory-defaults/</link>
      <pubDate>Tue, 04 Oct 2016 20:39:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-reset-ustawien-do-fabrycznych-factory-defaults/</guid>
      <description>&lt;p&gt;Android zadomowił się w większości smartfonów. Jest to mniej więcej taki sam system operacyjny, co w
przypadku stacjonarnych komputerów czy laptopów. W obu przypadkach instalujemy i konfigurujemy różne
rzeczy, tak by ten system oraz jego aplikacje były dostosowane do naszych potrzeb w sposób
optymalny. Niemniej jednak, każdy system wymaga odpowiedniego traktowania i mam na myśli tutaj
regularne czyszczenie go ze zbędnych aplikacji czy plików, które nie są nam już do niczego
potrzebne. W przypadku desktopowych systemów zwykliśmy wgrywać je na nowo za pomocą płytki CD/DVD
czy też pendrive live. Ten proces z reguły jest szybki i w miarę bezproblemowy. Później trzeba tylko
trochę czasu poświęcić, by ten świeży system skonfigurować. A jak sprawa wygląda w przypadku
smartfona z Androidem? Nie mamy jak za bardzo wgrać świeżego systemu, no i na dobrą sprawę nie
musimy. Zamiast tego, możemy przywrócić ustawienia do fabrycznych (factory reset). W tym artykule
postaramy się obadać proces resetu ustawień telefonu na przykładzie &lt;a href=&#34;http://www.neffos.pl/product/details/C5&#34;&gt;smartfona Neffos
C5&lt;/a&gt; od TP-LINK z Androidem 5.1 (Lollipop).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Serwer druku MFP TL-PS310U od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-serwer-druku-mfp-tl-ps310u-tp-link/</link>
      <pubDate>Sat, 01 Oct 2016 18:09:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-serwer-druku-mfp-tl-ps310u-tp-link/</guid>
      <description>&lt;p&gt;Przeglądając ofertę na stronie TP-LINK, zaciekawiło mnie pewne urządzenie. Chodzi o &lt;a href=&#34;http://www.tp-link.com.pl/products/details/cat-5688_TL-PS310U.html&#34;&gt;serwer druku
MFP i pamięci masowej
TL-PS310U&lt;/a&gt;. Niby słyszałem
kiedyś w przeszłości frazę &amp;quot;Print Server&amp;quot; ale nigdy zbytnio się nie zastanawiałem nad tym do czego
takie coś ma w istocie służyć. Po nazwie można jedynie przypuszczać, że chodzi o coś związanego z
sieciowymi urządzeniami drukującymi. Niemniej jednak, ten serwer wydruku, który dotarł do mnie nie
przypomina zbytnio drukarki sieciowej. To co to w takim razie jest?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wykryć komputer w sieci przy pomocy nmap</title>
      <link>https://morfikov.github.io/post/jak-wykryc-komputer-w-sieci-przy-pomocy-nmap/</link>
      <pubDate>Mon, 26 Sep 2016 18:29:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wykryc-komputer-w-sieci-przy-pomocy-nmap/</guid>
      <description>&lt;p&gt;Opisywane jakiś czas temu przeze mnie &lt;a href=&#34;https://morfikov.github.io
/post/transmitery-sieciowe-tl-wpa4226t-kit-tp-link/&#34;&gt;ekstendery
powerline&lt;/a&gt;, tak bardzo mi
przypadły do gustu, że korzystam z nich praktycznie bez przerwy. Po skonfigurowaniu &lt;a href=&#34;https://morfikov.github.io
/post/jak-skonfigurowac-roaming-wifi-wpa_supplicant-linux/&#34;&gt;roamingu sieci
WiFi w linux&#39;ie&lt;/a&gt;, mój
laptop w nieodczuwalny dla mnie w sposób rekonfiguruje połączenie w obrębie sieci domowej. Sygnał
jest na prawdę bardzo dobrej jakości w każdym zakątku domu, przez co w ogóle zapomniałem o istnieniu
tych transmiterów sieciowych. Chciałem przenieść jeden z ekstenderów z kanału 1 (domyślny), na kanał
6, który jest najmniej zatłoczony. Problem w tym, że zapomniałem jakim adresem IP dysponuje AP tego
urządzenia. Przestrzeń adresowa tej sieci to 192.168.1.0/24, czyli adresów jest 254 (192.168.1.0,
192.168.0.255 zarezerwowane dla broadcast). Nie uśmiechało mi się wpisywanie każdego z tych adresów
w przeglądarce, by ten panel admina odszukać metodą na chybił trafił. Na szczęście są o wiele
szybsze metody szukania maszyn w sieci, np. zapytania o adres IP w protokole ARP. A przy pomocy
&lt;a href=&#34;https://nmap.org/&#34;&gt;skanera nmap&lt;/a&gt; możemy w parę sekund ustalić adres IP wszystkich aktualnie
podłączonych komputerów do sieci.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Przenośny router LTE/3G (MiFi) M7310 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-przenosny-router-lte3g-mifi-m7310-od-tp-link/</link>
      <pubDate>Sun, 25 Sep 2016 22:06:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-przenosny-router-lte3g-mifi-m7310-od-tp-link/</guid>
      <description>&lt;p&gt;Wielu zaawansowanych użytkowników komputera, zwłaszcza tych korzystających z linux&#39;a, bardzo ceni
sobie możliwość bezgranicznego zarządzania posiadanym sprzętem elektronicznym. Nie chodzi tylko o
zwykłego desktopa czy laptopa ale też o urządzenia z systemami wbudowanymi jak, np. routery WiFi.
Większość routerów nie obsługuje modemów LTE ale mogłaby, gdyby pozwalało im na to zainstalowane na
nich oprogramowanie. Na moim blogu jest kilka artykułów dotyczących &lt;a href=&#34;https://morfikov.github.io
/post/tag/modem/&#34;&gt;instalacji i konfiguracji
modemów LTE&lt;/a&gt; właśnie na takich routerach, z tym, że w oparciu o
firmware OpenWRT/LEDE. Niemniej jednak, w przypadku takiego alternatywnego firmware wymagana jest
drobna znajomość obsługi komputera, a cała masa użytkowników nie chce poświęcać czasu na zgłębianie
technik informatycznych. Te osoby chcą zwyczajnie podłączyć dane urządzenie do prądu i móc z niego
korzystać tuż po wyjęciu go z pudełka. Mam właśnie jedno takie urządzenie, które byłoby w stanie
zaspokoić większość osób z tego grona. Nie jest to co prawda pełnowymiarowy router WiFi z modemem
LTE na pokładzie ale w przeciwieństwie do swoich kolegów jest o wiele bardziej mobilny. Mowa o
&lt;a href=&#34;http://www.tp-link.com.pl/products/details/M7310.html&#34;&gt;przenośnym hotspocie LTE M7310&lt;/a&gt; od TP-LINK.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przenieść kontakty ze starego telefonu do smartfona</title>
      <link>https://morfikov.github.io/post/jak-przeniesc-kontakty-telefon-smartfon/</link>
      <pubDate>Sat, 24 Sep 2016 00:53:01 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przeniesc-kontakty-telefon-smartfon/</guid>
      <description>&lt;p&gt;Przy zmianie telefonu, zwłaszcza z tych nieco starszych na te nowsze smartfony, może pojawić się
problem z przeniesieniem listy kontaktów. Jeśli nasz stary telefon ma slot na kartę SD, to kontakty
zapisane w pamięci tego telefonu można zrzucić na kartę SD i na nowym telefonie z niej zaimportować.
Co jednak w przypadku, gdy nasz stary telefon nie dysponuje takim slotem, a my na liście kontaktów
mamy zapisanych ze 100-200 pozycji albo nawet i więcej? Nie będziemy raczej przepisywać każdego
kontaktu ręcznie, bo trochę się nam z tym zejdzie. Możemy za to nieco inaczej podejść do procesu
przenoszenia kontaktów. Najprościej to wykonać backup listy kontaktów starego telefonu do pliku i
zapisać go na komputerze. Oczywiście zwykle jest do tego celu potrzebny przewód USB, bluetooth czy
IrDA. Na linux&#39;ach będzie nam także niezbędne &lt;a href=&#34;&#34;&gt;narzędzie Wammu&lt;/a&gt;, które umożliwi nam zrobienie
takiego backupu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instalacja i konfiguracja firmware OpenWRT (Chaos Calmer)</title>
      <link>https://morfikov.github.io/post/instalacja-konfiguracja-firmware-openwrt-chaos-calmer/</link>
      <pubDate>Fri, 23 Sep 2016 18:27:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/instalacja-konfiguracja-firmware-openwrt-chaos-calmer/</guid>
      <description>&lt;p&gt;Ten post ma na celu zebranie wszystkich wpisów dotyczących instalacji i konfiguracji alternatywnego
firmware OpenWRT, które znajdują się na tym blogu i umieszczenie ich w jednym wpisie. Chodzi
generalnie o to, by wszystkie te artykuły były dostępne na jednej stronie w formie spisu treści
odwołującego się do poszczególnych tekstów. &lt;a href=&#34;https://tplinkforum.pl/t/openwrt-w-pigulce-konfiguracja-w-oparciu-o-tl-wr1043nd-oraz-archer-c7/6960/&#34;&gt;Na tplinkforum.pl znajduje się post &amp;quot;OpenWRT w
pigułce&amp;quot;&lt;/a&gt;
, z tym, że tamten artykuł dotyczy wydania Barrier Breaker. Artykuły, do których linki znajdują się
poniżej, odwołują się do wydania Chaos Calmer i rozwiązania opisane w nich powinny na tej wersji
firmware działać bez problemu. Mogą natomiast pojawić się problemy w przypadku konfiguracji
starszych wersji OpenWRT na naszym routerze WiFi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Smartfon z Androidem pod linux&#39;em (MTP/PTP)</title>
      <link>https://morfikov.github.io/post/smartfon-android-linux-mtp-ptp/</link>
      <pubDate>Thu, 22 Sep 2016 21:54:23 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/smartfon-android-linux-mtp-ptp/</guid>
      <description>&lt;p&gt;Wpadł mi w łapki &lt;a href=&#34;http://www.neffos.pl/product/details/C5&#34;&gt;smartfon Neffos C5&lt;/a&gt; od TP-LINK, który ma
na pokładzie Androida. Chciałem nim zrobić parę fotek, tylko pojawił się problem uzyskania dostępu
do zasobów tego telefonu. Samo urządzenie pod linux&#39;em identyfikowane jest jako &lt;code&gt;idVendor=2357&lt;/code&gt; oraz
&lt;code&gt;idProduct=0314&lt;/code&gt; ale po jego podłączeniu do portu USB komputera nie pojawiły się żadne nowe dyski,
które można by przejrzeć w celu zgania ich zawartości. Problem tkwił w konfiguracji mojego Debiana,
w którym to brakowało obsługi protokołu MTP. Po chwili rozgryzłem tę zagadkę instalując w systemie
pakiet &lt;code&gt;jmtpfs&lt;/code&gt; , co umożliwiło interakcję z systemem plików telefonu i zgranie zrobionych zdjęć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Karta sieciowa Ethernet na USB UE200 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-karta-sieciowa-ethernet-usb-ue200-tp-link/</link>
      <pubDate>Thu, 22 Sep 2016 17:24:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-karta-sieciowa-ethernet-usb-ue200-tp-link/</guid>
      <description>&lt;p&gt;Czasami bardzo dziwne rzeczy mogą się przytrafić naszym komputerom. Kilka tygodni temu, z
niewiadomych przyczyn port ethernet w moim laptopie zwyczajnie zamarł. Linux go nie rozpoznaje i nie
da rady za jego pośrednictwem podłączyć się do sieci. Można oczywiście skorzystać z WiFi ale w
pewnych sytuacjach ta opcja odpada i zostaje nam jedynie łącze przewodowe. Tak się składa, że mam na
wyposażeniu &lt;a href=&#34;http://www.tp-link.com.pl/products/details/UE200.html&#34;&gt;adapter UE200&lt;/a&gt; od TP-LINK. Jest
to karta sieciowa mająca z jednej strony gniazdko ethernet, z drugiej zaś złącze USB, dzięki któremu
łatwo tę kartę można podłączyć do komputera. Pytanie tylko jak taka sieciówka na USB zachowa się pod
linux&#39;em. W tym wpisie obadamy sobie właśnie tę kwestię.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Inteligentne gniazdko HS110 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-inteligentne-gniazdko-hs110-tp-link/</link>
      <pubDate>Wed, 21 Sep 2016 18:23:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-inteligentne-gniazdko-hs110-tp-link/</guid>
      <description>&lt;p&gt;Technologia wymaga energii. Ostatnio ktoś wspominał mi o tym, że infrastruktura internetowa zjada
jakieś 10% ogólnoświatowego zapotrzebowania na prąd. Czy tak jest w istocie, to nie wiem ale jedna
kwestia zdaje się być jasna, tj. wzrost ilości urządzeń, które bez elektryczności zwyczajnie nie
działają. Każdy z nas ma w swoim domu takie sprzęty, z tym, że część z nich mogłaby pracować krócej
niż 24 godziny na dobę. Weźmy sobie taki domowy router WiFi, czy też pierwszy z brzega TV. W nocy
zwykle nie ma potrzeby, by te urządzenia działały. Niemniej jednak, rano po przebudzeniu raczej
ostatnią rzeczą, o której myślimy, to włączanie czegoś co naszym zdaniem powinno być już
uruchomione. Poza tym, rozruch sprzętu elektronicznego zawsze zajmuje te parę minut. Tryb
oszczędzania energii implementowany przez producentów ma łagodzić dolegliwości związane z potrzebą
wyłączania sprzętu, gdy ten jest nieużywany. Niemniej jednak, takie urządzenie w dalszym ciągu prąd
pobiera, niewiele ale zawsze, no i zużywa się szybciej. TP-LINK ma w swojej ofercie inteligentne
gniazdka (smart plug), które są w stanie nam pomóc. Urządzenia te możemy programować, tak by
automatycznie odcinały dopływ prądu do tego naszego przykładowego routera WiFi. W tym artykule
rzucimy sobie okiem na takie gniazdko, a konkretnie będzie to &lt;a href=&#34;http://www.tp-link.com.pl/products/details/cat-5258_HS110.html&#34;&gt;model
HS110&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Blokowanie reklam z adblock na domowym routerze WiFi</title>
      <link>https://morfikov.github.io/post/blokowanie-reklam-adblock-na-domowym-routerze-wifi/</link>
      <pubDate>Mon, 19 Sep 2016 22:22:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/blokowanie-reklam-adblock-na-domowym-routerze-wifi/</guid>
      <description>&lt;p&gt;Na sporej części stron internetowych są nam prezentowane reklamy w miej lub bardziej nachalny
sposób. Takie banery są w stanie w dużej mierze przesłonić faktyczną treść serwisu albo też wręcz
uniemożliwić nam spokojne czytanie tekstu, który się w takiej witrynie znajduje. By walczyć z tego
typu praktykami, powstała cała masa dodatków do przeglądarek, np.
&lt;a href=&#34;https://adblockplus.org/&#34;&gt;adblock&lt;/a&gt; czy &lt;a href=&#34;https://www.ublock.org/&#34;&gt;ublock&lt;/a&gt;, które są w stanie
odfiltrować praktycznie wszystkie reklamy. Możemy pokusić się o zaimplementowanie takiego adblock&#39;a
bezpośrednio na naszym routerze WiFi, z tym, że by taki filtr reklam wdrożyć w naszej sieci domowej,
na routerze musimy zainstalować alternatywny firmware OpenWRT/LEDE.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mostek eth0 &#43; wlan0 z bridge-utils i wpa_supplicant</title>
      <link>https://morfikov.github.io/post/mostek-eth0-wlan0-bridge-utils-wpa_supplicant/</link>
      <pubDate>Sun, 18 Sep 2016 13:01:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mostek-eth0-wlan0-bridge-utils-wpa_supplicant/</guid>
      <description>&lt;p&gt;Posiadając w komputerze kilka interfejsów sieciowych, prędzej czy później dostrzeżemy wady jakie
niesie ze sobą konfiguracja wszystkich posiadanych kart sieciowych. Skonfigurowanie szeregu
interfejsów przewodowych nie stanowi raczej większego wyzwania. Można je spiąć w jeden za pomocą
bonding&#39;u czy też konfigurując wirtualny interfejs mostka (bridge). A co w przypadku bezprzewodowych
interfejsów? Tu również możemy &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-interfejsow-bond-bonding/&#34;&gt;skonfigurować interfejs
bond0&lt;/a&gt; lub też podpiąć interfejs
&lt;code&gt;wlan0&lt;/code&gt; pod mostek. Jako, że bonding już opisywałem, to w tym artykule zajmiemy się mostkowaniem
interfejsu przewodowego i bezprzewodowego, które zwykle dostępne są w naszych laptopach. Ten proces
zostanie opisany w oparciu o dystrybucję linux&#39;a Debian i skontrastujemy go sobie z w/w bonding&#39;iem.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DD-WRT: Jak powrócić do firmware TP-LINK&#39;a</title>
      <link>https://morfikov.github.io/post/dd-wrt-jak-powrocic-do-firmware-tp-linka/</link>
      <pubDate>Fri, 16 Sep 2016 19:10:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dd-wrt-jak-powrocic-do-firmware-tp-linka/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.dd-wrt.com/site/&#34;&gt;DD-WRT&lt;/a&gt; nie każdemu może przypaść do gustu. Może się zdarzyć też tak,
że pewne rzeczy na routerze za sprawą tego firmware przestaną nam zwyczajnie działać, bo nie każde
urządzenie jest w pełni wspierane przez to oprogramowanie. W takim przypadku jedyną opcją będzie
powrót do oryginalnego firmware, który oferuje producent routera. Ja dysponuję &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WDR3600.html&#34;&gt;routerem model
TL-WDR3600&lt;/a&gt; od TP-LINK. On akurat jest w
pełni wspierany przez DD-WRT. Niemniej jednak, na jego przykładzie zostanie pokazane jak powrócić do
oryginalnego oprogramowania posługując się panelem webowym dostępnym DD-WRT.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Router Archer C2600 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-router-archer-c2600-od-tp-link/</link>
      <pubDate>Wed, 14 Sep 2016 18:20:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-router-archer-c2600-od-tp-link/</guid>
      <description>&lt;p&gt;Któż z nas nie ma gdzieś koło swojego domowego ogniska takiego małego urządzenia z antenami, które
nic tylko sobie leży gdzieś na półce i od czasu do czasu tylko mignie do nas swoimi diodami? Mowa
oczywiście o routerach WiFi, które można powoli chyba zacząć traktować jak nowych członków naszej
rodziny. Te elektroniczne stworzenia są tak bardzo użyteczne, że wielu z nas już sobie życia bez
nich nie wyobraża. Technologia bezprzewodowej łączności rozwija się bardzo prężnie i, gdy niecałe
dwa lata temu sprawiłem sobie mój pierwszy router WiFi (model
&lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WR1043ND.html&#34;&gt;TL-WR1043ND&lt;/a&gt; v2), to myślałem, że
wystarczy mi on na jakiś dłuższy czas. Wtedy 450 mbit/s w paśmie 2,4 GHz to były naprawdę przyzwoite
osiągi, przynajmniej teoretycznie rzecz ujmując. Od tamtego czasu bardzo dużo się zmieniło w kwestii
WiFi, nie tylko pod względem przepustowości ale także technologii, które znajdują zastosowanie w tym
bezprzewodowym wymiarze otaczającej nas rzeczywistości. Tak się składa, że mam jedno z tych bardziej
zaawansowanych urządzeń i postanowiłem sobie je dokładnie obadać. Jest to &lt;a href=&#34;http://www.tp-link.com.pl/products/details/Archer-C2600.html&#34;&gt;router Archer
C2600&lt;/a&gt; od TP-LINK, który ma być zdolny
przesłać sygnał po WiFi z prędkością 800 mbit/s w paśmie 2,4 GHz i 1733 mbit/s w paśmie 5 GHz, także
zobaczmy co to jest za maszyna.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DD-WRT: Reset ustawień (Hard Reset i factory defaults)</title>
      <link>https://morfikov.github.io/post/dd-wrt-reset-ustawien-hard-reset-factory-defaults/</link>
      <pubDate>Tue, 13 Sep 2016 19:06:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dd-wrt-reset-ustawien-hard-reset-factory-defaults/</guid>
      <description>&lt;p&gt;Prawdopodobnie zdarzy się nam taka sytuacja, że nie będziemy w stanie zalogować się do panelu
administracyjnego naszego routera wyposażonego w firmware DD-WRT. Przyczyny mogą być różne, choć
zwykle leżą one gdzieś w konfiguracji urządzenia. Jeśli dodatkowo wystąpią problemy z dostępem do
sieci/internetu, to wybrnięcie z tej sytuacji może być dość kłopotliwe. DD-WRT posiada mechanizm
resetu, tzw. factory defaults, który jest w stanie zresetować router do ustawień fabrycznych i
przywrócić nam nad nim kontrolę. W tym wpisie zobaczymy jak przeprowadzić taki reset ustawień na
przykładzie mojego &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WDR3600.html&#34;&gt;routera TL-WDR3600&lt;/a&gt;
od TP-LINK.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DD-WRT: SSH port forwarding i panel aministracyjny</title>
      <link>https://morfikov.github.io/post/dd-wrt-ssh-port-forwarding-panel-aministracyjny/</link>
      <pubDate>Mon, 12 Sep 2016 17:29:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dd-wrt-ssh-port-forwarding-panel-aministracyjny/</guid>
      <description>&lt;p&gt;Firmware DD-WRT oferuje kilka sposobów na uzyskanie dostępu do naszego domowego routera. Poza
graficznym panelem webowym, gdzie wszystko możemy sobie wyklikać, mamy jeszcze tekstowy telnet i
SSH. DD-WRT jest nam w stanie także zaoferować SSH port forwarding. Ten mechanizm z kolei bardzo
przydaje się w momencie, gdy chcemy uzyskać dostęp do routera przez panel administracyjny ale nie
uśmiecha nam się wystawianie go na widok publiczny po niezabezpieczonym protokole HTTP. Z kolei
serwer www posiadający zaimplementowany protokół SSL/TLS jest dość zasobożerny i jego zastosowanie
średnio nadaje się w przypadku małych routerów. Za pomocą przekierowania portów SSH możemy uzyskać
dostęp do lokalnej instancji panelu webowego omijając obydwa te powyższe problemy. Panel admina
pozostaje schowany w sieci lokalnej, a my logujemy się do niego wykorzystując połączenie SSH.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenWRT: Dwa różne adresy MAC na porcie WAN</title>
      <link>https://morfikov.github.io/post/openwrt-dwa-rozne-adresy-mac-na-porcie-wan/</link>
      <pubDate>Sun, 11 Sep 2016 18:42:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/openwrt-dwa-rozne-adresy-mac-na-porcie-wan/</guid>
      <description>&lt;p&gt;Na forum eko.one.pl pojawił się ciekawy temat dotyczący &lt;a href=&#34;http://eko.one.pl/forum/viewtopic.php?id=14224&#34;&gt;problemów z adresami MAC w
OpenWRT.&lt;/a&gt; Chodzi o to, że by uzyskać połączenie u
pewnych ISP, trzeba im podać adres MAC tego urządzenia, które będzie wpięte bezpośrednio w strukturę
sieci ISP. Niby normalna sprawa ale w pewnych przypadkach, ISP potrafi uwalić połączenie, gdy inne
urządzenie zostanie podpięte do sieci w miejscu starego. Zwykle wystarczy telefon do ISP z prośbą o
aktualizację adresu MAC ale w przypadku firmware OpenWRT może to być ździebko problematyczna
kwestia. Wychodzi na to, że OpenWRT identyfikuje się dwoma adresami MAC na porcie WAN. Jeden z nich
to ten standardowy MAC, który powinien być wykorzystywany i podany ISP. Drugim zaś jest MAC, który
pojawia się przy rozgłaszaniu trybu failsafe podczas fazy startu routera WiFi. Ja nigdy nie
zaobserwowałem problemów z tego powodu. Niemniej jednak, postanowiłem sprawdzić, jak ta sytuacja
dokładnie wygląda i jak sobie z nią poradzić już teraz, na wypadek, gdyby w przyszłości trafił mi
się jeden z takich dziwnych ISP.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DD-WRT: Dostęp do routera (telnet, ssh, panel web)</title>
      <link>https://morfikov.github.io/post/dd-wrt-dostep-do-routera-telnet-ssh-panel-web/</link>
      <pubDate>Sun, 11 Sep 2016 12:42:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dd-wrt-dostep-do-routera-telnet-ssh-panel-web/</guid>
      <description>&lt;p&gt;Do routera posiadającego na pokładzie firmware DD-WRT możemy uzyskać dostęp na kilka sposobów. Ten
najbardziej popularny, to oczywiście panel administracyjny dostępny z poziomu www, na który możemy
się dostać wpisując w pasku adresu przeglądarki &lt;code&gt;http://192.168.1.1/&lt;/code&gt; . Niemniej jednak, to nie jest
jedyna droga do zarządzania routerem. Standardowo również mamy aktywną usługę telnet. Dodatkowo
możemy aktywować SSL/TLS w panelu admina oraz dorobić usługę SSH. W tym artykule omówimy sobie
wszystkie te formy dostępu do routera.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cannot move /etc/resolv.conf.dhclient-new to /etc/resolv.conf: Operation not permitted</title>
      <link>https://morfikov.github.io/post/cannot-move-etcresolv-conf-dhclient-new-to-etcresolv-conf-operation-not-permitted/</link>
      <pubDate>Sat, 10 Sep 2016 20:54:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/cannot-move-etcresolv-conf-dhclient-new-to-etcresolv-conf-operation-not-permitted/</guid>
      <description>&lt;p&gt;Użytkownicy linux&#39;a przykładają nieco większą wagę do konfiguracji swojego systemu. Te nieco
bardziej świadome jednostki zdają sobie sprawę, że różnego rodzaju automaty są w stanie przepisywać
konfigurację systemową bez naszej wiedzy. Weźmy sobie resolver DNS. To bardzo krytyczna usługa, nie
tylko z punktu widzenia bezpieczeństwa ale też i prywatności. Zakładając, że chcemy korzystać z
pewnych określonych serwerów DNS lub też mamy &lt;a href=&#34;https://morfikov.github.io
/post/dnscrypt-proxy-czyli-szyfrowanie-zapytan-dns/&#34;&gt;skonfigurowaną usługę
dnscrypt-proxy&lt;/a&gt;, trzeba zadbać
o to, by adresy w pliku &lt;code&gt;/etc/resolv.conf&lt;/code&gt; nie zostały z jakiegoś powodu przepisane. Użytkownicy
zwykle nadają temu plikowi atrybut odporności ( &lt;code&gt;chattr +i&lt;/code&gt; ) . Niemniej jednak, przy pobieraniu
konfiguracji sieciowej za sprawą protokołu DHCP, w logu można zaobserwować komunikat: &lt;code&gt;mv: cannot move &#39;/etc/resolv.conf.dhclient-new&#39; to &#39;/etc/resolv.conf&#39;: Operation not permitted&lt;/code&gt; . Niby w niczym
on nie przeszkadza ale możemy tak skonfigurować demona &lt;code&gt;dhclient&lt;/code&gt; , by tę wiadomość wyeliminować.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować roaming WiFi z wpa_supplicant w linux&#39;ie</title>
      <link>https://morfikov.github.io/post/jak-skonfigurowac-roaming-wifi-wpa_supplicant-linux/</link>
      <pubDate>Sat, 10 Sep 2016 12:13:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-skonfigurowac-roaming-wifi-wpa_supplicant-linux/</guid>
      <description>&lt;p&gt;Bezprzewodowe sieci WiFi są wszędzie. Wystarczy tylko przejść się kawałek po okolicy i przeskanować
eter, a sami zobaczymy, że wynik takiego skanowania zidentyfikuje nam całą masę domowych nadajników.
Oczywiście do większości z nich raczej nigdy nie będziemy mieć dostępu ale są wśród nich takie AP,
do których zwykliśmy się logować. Niekoniecznie te AP muszą należeć do naszej własnej domowej sieci
WiFi. Mogą to być, np. firmowe hotspoty. Nawet jeśli ograniczymy się tylko do naszego domu, to gdy
ten jest nieco większy, to prawdopodobnie jeden bezprzewodowy router nie wystarczy, by pokryć
zasięgiem całą dostępną przestrzeń użytkową. Będziemy musieli dokupić drugi router, czy jakiś
wzmacniacz sygnału. Być może też zdecydujemy się na &lt;a href=&#34;https://morfikov.github.io
/post/transmitery-sieciowe-tl-wpa4226t-kit-tp-link/&#34;&gt;transmitery sieciowe
(powerline)&lt;/a&gt;. Jest cała masa
urządzeń, które mogą nam pomóc rozwiązać problem słabego zasięgu. To co zwykle łączy te urządzenia,
to fakt, że wszystkie z nich zawierają dodatkowy AP, który trzeba skonfigurować. Pojawia się zatem
problem przełączania między tymi punktami dostępowymi. Można sobie z tym poradzić konfigurując
roaming. W takiej sytuacji przełączanie między sieciami będzie następowało automatycznie, szybko i
bez naszego udziału. W linux&#39;ach roaming można włączyć przy pomocy narzędzia &lt;code&gt;wpa_supplicant&lt;/code&gt; i w
tym artykule zobaczymy jak tego dokonać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenWRT: Konfiguracja anten via txantenna/rxantenna</title>
      <link>https://morfikov.github.io/post/openwrt-konfiguracja-anten-via-txantenna-rxantenna/</link>
      <pubDate>Fri, 09 Sep 2016 17:59:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/openwrt-konfiguracja-anten-via-txantenna-rxantenna/</guid>
      <description>&lt;p&gt;Przeglądając forum eko.one.pl wpadł mi w oko &lt;a href=&#34;http://eko.one.pl/forum/viewtopic.php?pid=171898#p171898&#34;&gt;taki oto
temat&lt;/a&gt;. Problem, który został w nim
poruszony dotyczył wykorzystywania pewnej określonej anteny routera. Zakładając, że przeciętny
router ma trzy anteny, powiedzmy, że chcemy wykorzystywać tylko jedną z nich. Dlaczego mielibyśmy
rozważać w ogóle taką sytuację? Przy trzech antenach, teoretyczny transfer w paśmie 2,4 GHz to, w
zależności od routera, 450-600 mbit/s. Przy jednej antenie będziemy mieli max 150-200 mbit/s. Z tego
co czytałem wcześniej w różnych źródłach, uszkodzenie w jakiś sposób toru antenowego może
drastycznie pogorszyć lub wręcz uniemożliwić routerowi transmisję sygnału. Opisana w podlinkowanym
wyżej wątku sytuacja dotyczyła właśnie tego typu zdarzenia, gdzie jedno z gniazd antenowych routera
zostało uszkodzone. Firmware OpenWRT/LEDE jest nam w stanie umożliwić wybór określonych anten przy
pomocy parametrów &lt;code&gt;diversity&lt;/code&gt; , &lt;code&gt;txantenna&lt;/code&gt; oraz &lt;code&gt;rxantenna&lt;/code&gt; . W tym wpisie zobaczymy jak
skonfigurować sobie anteny na przykładzie &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WR1043ND.html&#34;&gt;routera TL-WR1043ND
V2&lt;/a&gt; od TP-LINK.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DD-WRT: Aktualizacja firmware do najnowszej wersji</title>
      <link>https://morfikov.github.io/post/dd-wrt-aktualizacja-firmware-do-najnowszej-wersji/</link>
      <pubDate>Thu, 08 Sep 2016 19:56:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dd-wrt-aktualizacja-firmware-do-najnowszej-wersji/</guid>
      <description>&lt;p&gt;Firmware, który jest dostępny na &lt;a href=&#34;https://www.dd-wrt.com/site/support/router-database&#34;&gt;stronie
DD-WRT&lt;/a&gt; nie jest zbyt aktualny. Ten obraz,
który pobrałem dla swojego routera TL-WDR3600 jest datowany na rok 2013. Szukając informacji na ten
temat, okazało się, że &lt;a href=&#34;ftp://ftp.dd-wrt.com/betas/&#34;&gt;nowsze obrazy są dostępne w nieco innym
miejscu&lt;/a&gt;. Różnica między tymi obrazami jest taka, że te pierwsze są w
wersji stabilnej, a te drugie w wersji beta i wypuszczane tak średnio raz na tydzień. Przydałoby się
zatem co jakiś czas zaktualizować firmware DD-WRT do nowszej wersji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DD-WRT: Jak wgrać firmware na router TP-LINK</title>
      <link>https://morfikov.github.io/post/dd-wrt-jak-wgrac-firmware-router-tp-link/</link>
      <pubDate>Wed, 07 Sep 2016 18:08:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dd-wrt-jak-wgrac-firmware-router-tp-link/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://openwrt.org/&#34;&gt;OpenWRT&lt;/a&gt;/&lt;a href=&#34;https://lede-project.org/&#34;&gt;LEDE&lt;/a&gt; nie jest jedynym alternatywnym
firmware, który możemy wgrać na router TP-LINK&#39;a. Jest także &lt;a href=&#34;https://www.dd-wrt.com/site/&#34;&gt;projekt
DD-WRT&lt;/a&gt;, który oferuje oprogramowanie dla większości modeli routerów
tego producenta. Tak się składa, że mam router TL-WDR3600 i posiada on pełne wsparcie w DD-WRT.
Postanowiłem zatem zainstalować to oprogramowanie na tym urządzeniu i opisać jak wygląda cały proces
instalacyjny.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Debian: Profilowanie sieci z guessnet, ifplugd i wpasupplicant</title>
      <link>https://morfikov.github.io/post/debian-profilowanie-sieci-guessnet-ifplugd-wpasupplicant/</link>
      <pubDate>Mon, 05 Sep 2016 13:01:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/debian-profilowanie-sieci-guessnet-ifplugd-wpasupplicant/</guid>
      <description>&lt;p&gt;Kilka dni temu na &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=28903&#34;&gt;forum dug.net.pl&lt;/a&gt; pojawił się
ciekawy wątek dotyczący problemu skonfigurowania profilowanych sieci. Chodzi o to, że praktycznie
każdy z nas jest po części w jakiś sposób mobilny i zabiera laptopa ze sobą w dziwne miejsca. Sieci
w tych lokalizacjach mogą cechować się różnym poziomem bezpieczeństwa. Dlatego też zamiast korzystać
z jednej konfiguracji sieci na linux&#39;ie, można stworzyć szereg profili i w oparciu o nie dostosować
sobie połączenie sieciowe. W tym artykule spróbujemy zaimplementować takie rozwiązanie na Debianie
wyposażonym w menadżer okien Openbox. W skrócie stworzymy automat, który będzie nam działał w
oparciu o pakiety guessnet, &lt;a href=&#34;http://0pointer.de/lennart/projects/ifplugd/&#34;&gt;ifplugd&lt;/a&gt; oraz
&lt;a href=&#34;https://w1.fi/wpa_supplicant/&#34;&gt;wpasupplicant&lt;/a&gt;. Cała konfiguracja zaś sprowadzać się będzie jedynie
do edycji plików &lt;code&gt;/etc/network/interfaces&lt;/code&gt; oraz &lt;code&gt;/etc/wpa_supplicant/wpa_supplicant.conf&lt;/code&gt; .&lt;/p&gt;
&lt;p&gt;Niniejszy artykuł został nieco przerobiony po fazach eksperymentów. Przede wszystkim, zrezygnowałem
z zaprzęgania &lt;code&gt;guessnet&lt;/code&gt; do rozpoznawania sieci WiFi i aplikowania roamingu. Zamiast tego zostały
wykorzystane natywne rozwiązania roamingowe oferowane przez &lt;code&gt;wpa_supplicant&lt;/code&gt; . Zaowocowało to
uproszczeniem całej konfiguracji, co przełożyło się na wyeliminowanie pewnych błędów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Metryki tras interfejsów eth0 i wlan0 w laptopie (metric)</title>
      <link>https://morfikov.github.io/post/metryki-tras-interfejsow-eth0-wlan0-laptop-metric/</link>
      <pubDate>Fri, 02 Sep 2016 17:50:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/metryki-tras-interfejsow-eth0-wlan0-laptop-metric/</guid>
      <description>&lt;p&gt;W obecnych czasach posiadanie komputera, który dysponuje kilkoma interfejsami sieciowymi nie jest
niczym niezwykłym. Praktycznie każdy laptop posiada już na pokładzie co najmniej jedną kartę WiFi i
minimum jeden port ethernet. W efekcie czego jesteśmy w stanie podłączyć się do sieci zarówno
przewodowo jak i bezprzewodowo. Problem jednak pojawia się w momencie, gdy chcemy wykorzystywać oba
te interfejsy, z tym, że dysponujemy jedynie niezbyt zaawansowanym menadżerem okien Openbox. Takie
środowiska zwykle nie mają na pokładzie automatów pokroju Network Manager, przez co bardziej
zaawansowana konfiguracja sieci może być dość skomplikowana. Do tej pory wykorzystywałem &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-interfejsow-bond-bonding/&#34;&gt;interfejs
bond0&lt;/a&gt;, by mieć możliwość łatwego
przełączania się miedzy sieciami. Istnieje inny sposób konfiguracji interfejsów &lt;code&gt;eth0&lt;/code&gt; i &lt;code&gt;wlan0&lt;/code&gt; w
pliku &lt;code&gt;/etc/network/interfaces&lt;/code&gt; tak, by działały one nam równolegle i nie powodowały problemów z
połączeniem, a wszystko za sprawą opcji &lt;code&gt;metric&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dynamiczna konfiguracja sieci w oparciu o ifplugd</title>
      <link>https://morfikov.github.io/post/dynamiczna-konfiguracja-sieci-ifplugd/</link>
      <pubDate>Thu, 01 Sep 2016 12:24:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dynamiczna-konfiguracja-sieci-ifplugd/</guid>
      <description>&lt;p&gt;Sporo użytkowników różnego rodzaju linux&#39;ów, zwłaszcza dystrybucji Debian, niezbyt chwali sobie
automaty konfigurujące połączenie sieciowe typu &lt;a href=&#34;https://wiki.gnome.org/Projects/NetworkManager&#34;&gt;Network
Manager&lt;/a&gt;. W sumie nigdy się jemu bliżej nie
przyglądałem ale na necie nie cieszy się on najlepszą opinią. Niemniej jednak, Network Manager
potrafi automatyzować pewne aspekty pracy w sieci. Weźmy przykład korzystania z dwóch różnych pod
względem parametrów sieci przewodowych. Jak się zachowa nasz OS w chwili przełączania się między
tymi sieciami w przypadku, gdy nie będziemy mieli zainstalowanego jakiegoś automatu dynamicznie
konfigurującego połączenie? W przypadku jednej sieci, połączenie będzie nam działać, w przypadku
drugiej zaś napotkamy problemy. W lekkich środowiskach opartych o menadżery okien, np. Openbox, nie
musimy instalować Network Manager&#39;a, by ogarnąć tę kwestię konfiguracyjną. Możemy posiłkować się
demonem &lt;code&gt;ifplugd&lt;/code&gt; i to tym narzędziu będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Przenośny router 3G/4G TL-MR3020  od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-router-3g-4g-tl-mr3020-tp-link/</link>
      <pubDate>Tue, 30 Aug 2016 17:44:53 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-router-3g-4g-tl-mr3020-tp-link/</guid>
      <description>&lt;p&gt;Coraz więcej użytkowników migruje od lokalnych providerów internetowych na technologię LTE, która
zapewnia nam połączenie z siecią globalną niezależnie od naszej fizycznej lokalizacji. Do obsługi
LTE potrzebny jest odpowiedni modem lub router WiFi, który już ma taki modem wbudowany. Jeśli
posiadamy modem LTE, to może się pojawić problem z udostępnianiem połączenia, np. w sieci domowej.
Jakby nie patrzeć taki modem jest przeznaczony na jedno urządzenie. Oczywiście w dalszym ciągu
możemy przerobić nasz router WiFi i dodać do niego obsługę modemów LTE ale takie rozwiązanie wymaga
firmware OpenWRT/LEDE. Istnieje prostsza alternatywa, która, można by rzec, działa OOTB i nie trzeba
się zbytnio wysilać przy jej implementacji. Musimy jednak posiadać odpowiednie urządzenie. W tym
artykule obadamy sobie &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-MR3020.html&#34;&gt;przenośny router 3G/4G
TL-MR3020&lt;/a&gt; od TP-LINK.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Transmitery sieciowe TL-WPA4226T KIT od TP-LINK</title>
      <link>https://morfikov.github.io/post/transmitery-sieciowe-tl-wpa4226t-kit-tp-link/</link>
      <pubDate>Mon, 29 Aug 2016 18:01:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/transmitery-sieciowe-tl-wpa4226t-kit-tp-link/</guid>
      <description>&lt;p&gt;Wszystkim nam jest znany problem z niewielkim zasięgiem bezprzewodowych sieci WiFi. Nierzadko bywa
też tak, że sygnał z routera nie może się przebić przez grube ściany naszego domu, czy też większego
mieszkania. W takiej sytuacji szereg osób próbuje przestawiać router w bardziej dogodne miejsce, by
pokryć zasięgiem całą przestrzeń użytkową. Nie zawsze tego typu rozwiązanie jest jednak możliwe. Ci
bardziej majętni użytkownicy dokupują drugi router i spinają oba urządzenia mostem bezprzewodowym
WDS. O ile takie rozwiązanie może nam pomóc, to trzeba wziąć pod uwagę fakt, że punkty dostępowe
(AP) muszą być w swoim zasięgu oraz muszą wysyłać i odbierać dane, zatem użytkowa przepustowość
sieci WiFi spadnie nam dwukrotnie. Gdy do tego w grę wejdą nam jeszcze zakłócenia generowane przez
inne sieci w okolicy, to efekty mogą być niezbyt zadowalające. Poza tym, trzeba mieć również na
uwadze kompatybilność protokołu WDS, bo różni producenci inaczej go implementują. By rozwiązać ten
cały problem zasięgu w sieciach bezprzewodowych, możemy pokusić się o zakup czegoś, co nazywa się
transmiter sieciowy (ekstender powerline). Te urządzenia są w stanie &amp;quot;przebić się przez każdą
ścianę&amp;quot; i zapewnić nam połączenie z routerem WiFi na dystansie nawet do 300 metrów. Jak to
możliwe? W tym artykule odpowiemy na to pytanie testując jeden z &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WPA4226T-KIT.html&#34;&gt;ekstenderów powerline TL-WPA4226T
KIT (AV500)&lt;/a&gt; od TP-LINK&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Aktywny HUB USB 3.0 UH720 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-aktywny-hub-usb-3-0-uh720-tp-link/</link>
      <pubDate>Sun, 28 Aug 2016 14:50:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-aktywny-hub-usb-3-0-uh720-tp-link/</guid>
      <description>&lt;p&gt;Nasze potrzeby są zawsze nieograniczone i raczej nigdy nie uda się nam ich zaspokoić. Weźmy sobie
dla przykładu urządzenia, które można podpiąć do komputera. Obecnie mamy całą masę sprzętu, a nasz
PC, laptop czy router ma skończoną i często też bardzo niewielką ilość portów USB. Problematyczne
może być zatem podłączenie do komputera w tym samym czasie kamer, pendrive, dysków,
telefonów/smartfonów, mp3player&#39;ów, drukarek, myszy czy klawiatury. Można oczywiście wyciągać z
gniazdek jedne urządzenia, by zrobić miejsce dla innych ale istnieje przecie taki wynalazek jak HUB
USB, który umożliwiają nam podłączone kilku urządzeń do jednego portu USB. Jakość tych HUB&#39;ów oraz
ich właściwości są różne i w tym wpisie zobaczymy co ma nam do zaoferowania&lt;a href=&#34;http://www.tp-link.com.pl/products/details/UH720.html&#34;&gt;HUB USB 3.0
UH720&lt;/a&gt;od TP-LINK&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Antena TL-ANT2408C (8dBi, 2,4GHz) od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-antena-tl-ant2408c-8dbi-tp-link/</link>
      <pubDate>Fri, 26 Aug 2016 20:48:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-antena-tl-ant2408c-8dbi-tp-link/</guid>
      <description>&lt;p&gt;Jako użytkownik alternatywnych systemów operacyjnych wiem, że nie łatwo o sprzęt, który po
podłączeniu do komputera działa OOTB. Niemniej jednak, na rynku jest sporo urządzeń, które są w
stanie działać pod linux&#39;em nawet dość przyzwoicie, z tym, że trzeba pierw się naprawdę wysilić, by
je znaleźć. Tak było w przypadku &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WN722N.html&#34;&gt;adaptera WiFi
TL-WN722N&lt;/a&gt; od TP-LINK, który jest już ze
mną kilka lat. Nie miałem z nim problemów na swoim Debianie i praktycznie nie mam mu nic do
zarzucenia. No może za wyjątkiem bardzo przeciętnego zasięgu, choć ta karta dysponuje zewnętrzną
anteną 4 dBi. Postanowiłem zatem rozejrzeć się za nieco większymi antenami w celu wyeliminowania
problemów z zasięgiem. W ofercie TP-LINK&#39;a była &lt;a href=&#34;http://www.tp-link.com.pl/products/details/cat-5691_TL-ANT2408C.html&#34;&gt;antena
TL-ANT2408C&lt;/a&gt; (8 dBi, 2,4 GHz),
to pomyślałem, że przetestują ją i sprawdzę czy problem słabego zasięgu zostanie w końcu
wyeliminowany.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Blokowanie zapytań DNS z dnscrypt-proxy na linux&#39;ie</title>
      <link>https://morfikov.github.io/post/blokowanie-zapytan-dns-dnscrypt-proxy-linux/</link>
      <pubDate>Thu, 25 Aug 2016 20:04:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/blokowanie-zapytan-dns-dnscrypt-proxy-linux/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://dnscrypt.org/&#34;&gt;Narzędzie dnscrypt-proxy&lt;/a&gt; począwszy od
&lt;a href=&#34;https://github.com/jedisct1/dnscrypt-proxy/releases&#34;&gt;wersji 1.7.0&lt;/a&gt; ma domyślnie włączoną obsługę
wtyczek. W standardzie nie ma ich dużo, bo jedynie trzy ale mogą one się okazać dla pewnych osób
bardzo użyteczne. Dzięki tym plugin&#39;om możemy, np. zablokować rozwiązywanie nazw w protokole IPv6 na
wypadek, gdyby ten protokół nie był wspierany w naszej sieci domowej czy też u naszego ISP. Możemy
także zdefiniować sobie adresy/domeny, które powinny zostać zablokowane i w efekcie użytkownicy nie
będą w stanie odwiedzić tych miejsc w internecie. Jest także wtyczka, która może nam pomóc zalogować
zapytania DNS. Jak widać, całkiem przyzwoite są te dodatki. W tym wpisie przyjrzymy się nieco bliżej
konfiguracji poszczególnych wtyczek dla &lt;code&gt;dnscrypt-proxy&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Request body exceeds maximum size (131072) for SSL buffer</title>
      <link>https://morfikov.github.io/post/request-body-exceeds-maximum-size-131072-for-ssl-buffer/</link>
      <pubDate>Wed, 24 Aug 2016 22:52:29 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/request-body-exceeds-maximum-size-131072-for-ssl-buffer/</guid>
      <description>&lt;p&gt;Dziś chciałem zaktualizować jeden z moich bardziej obszerniejszych wpisów na tym blogu ale
oczywiście nie mogło odbyć się bez problemów. Gdy już wszystkie poprawki zostały naniesione i cały
artykuł trafił do formularza WordPress&#39;a, przeglądarka zwróciła mi błąd &lt;code&gt;Request Entity Too Large&lt;/code&gt; .
Z początku nie wiedziałem o co chodzi ale, że ten aktualizowany artykuł był naprawdę długi, to
domyśliłem się, że chodzi o ilość bajtów, które chciałem przesłać w zapytaniu. Przeglądając logi
serwera Apache2, znalazłem tam jeszcze dodatkowo komunikaty &lt;code&gt;[ssl:error] request body exceeds maximum size (131072) for SSL buffer&lt;/code&gt; oraz &lt;code&gt;[ssl:error] could not buffer message body to allow SSL renegotiation to proceed&lt;/code&gt; . Może ta cała sytuacja brzmi groźnie ale wybrnięcie z niej jest wręcz
banalne. Wystarczy dostosować wartość dyrektywy &lt;code&gt;SSLRenegBufferSize&lt;/code&gt; w konfiguracji serwera Apache2.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chroot Apache2 vs dyrektywa open_basedir w PHP</title>
      <link>https://morfikov.github.io/post/chroot-apache2-vs-dyrektywa-open_basedir-w-php/</link>
      <pubDate>Mon, 22 Aug 2016 22:03:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/chroot-apache2-vs-dyrektywa-open_basedir-w-php/</guid>
      <description>&lt;p&gt;Kilka dni temu wpadł mi w oko artykuł na temat wykonania &lt;a href=&#34;https://nfsec.pl/root/5874&#34;&gt;chroot serwera
Apache2&lt;/a&gt;. Problem z tamtym tekstem jest taki, że nie uwzględnia on
serwera bazy danych MySQL. W efekcie, taki chroot&#39;owany Apache2 będzie miał problemy z połączeniem
się do bazy, a nasz serwis bez niej raczej nie będzie działał prawidłowo. Przydałoby się zatem
dopracować nieco ten artykuł i wypracować takie rozwiązanie, które nie popsuje przy okazji naszego
serwisu www. Dlatego też w tym wpisie wykonamy sobie chroot zarówno serwera Apache2 z obsługą PHP i
bazy danych MySQL za sprawą modułu &lt;code&gt;unixd&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zrobić screenshot całej strony www w Firefox</title>
      <link>https://morfikov.github.io/post/jak-zrobic-screenshot-strony-www-firefox/</link>
      <pubDate>Mon, 22 Aug 2016 08:38:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zrobic-screenshot-strony-www-firefox/</guid>
      <description>&lt;p&gt;Każdy z nas potrafi raczej zrobić prostego &amp;quot;skrina&amp;quot; tego co wyświetla się w danej chwili na ekranie
naszego komputera. Nie jest to jakaś zaawansowana wiedza i wystarczy przycisnąć przycisk PrintScreen
na klawiaturze i zrzut ekranu powinien zostać przechwycony przez system i zwykle gdzieś zapisany.
Niemniej jednak, strony www w przeglądarce internetowej bardzo rzadko są nam pokazywane w całej
swojej okazałości. Zwykle mamy po prawej stronie pasek przewijania (scrollbar), za pomocą którego
możemy przewinąć stronę w górę lub w dół. Pojawia się zatem pytanie: jak w takiej sytuacji zrobić
screenshot całej strony www? Można, co prawda, przewinąć stronę kilka razy, zrobić zrzut każdego
kawałka i scalić obraz w jakimś programie graficznym ale raczej za dużo z tym zachodu. Można także
zaprzęgnąć jakiś plugin do przeglądarki, np. Firefox ma na wyposażeniu &lt;a href=&#34;https://addons.mozilla.org/en-us/firefox/addon/screenshot-capture-annotate/&#34;&gt;Awesome
Screenshot&lt;/a&gt;. Istnieje
jednak prostsza alternatywa i do tego natywnie zaimplementowana w Firefox&#39;ie. Mowa o &lt;a href=&#34;https://developer.mozilla.org/en/docs/Tools/GCLI&#34;&gt;wierszu
poleceń Firefox&#39;a&lt;/a&gt;. W tym krótkim wpisie
zobaczymy jak przy pomocy tego narzędzia w bardzo prosty sposób zrobić fotkę całej witryny www.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Transmiter sieciowy i jego panel admina pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/transmiter-sieciowy-panel-admina-linux/</link>
      <pubDate>Sat, 20 Aug 2016 21:54:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/transmiter-sieciowy-panel-admina-linux/</guid>
      <description>&lt;p&gt;Bawię się ostatnio trochę transmiterem sieciowym (powerline ekstender). Konkretnie jest to zestaw
&lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WPA4226T-KIT.html&#34;&gt;TL-WPA4226T KIT (AV500)&lt;/a&gt; od
TP-LINK. Same urządzenia działają przyzwoicie i realizują powierzane im funkcje w sposób bardzo
zadowalający ale był jeden problem, który mi nie dawał spokoju. Do tych ekstenderów jest dołączona
płytka. Na płytce są aplikacje, które umożliwiają konfigurację tych transmiterów sieciowych. Te
programiki nie mają wersji dla linux&#39;a. Nasunęło mi się zatem pytanie: to jak mam niby te
transmitery skonfigurować pod tym systemem operacyjny? Niby one działają OOTB ale w przypadku
bezprzewodowego routera WiFi z alternatywnym firmware OpenWRT/LEDE na pokładzie występuje kolizja
adresów IP. Zarówno ekstendery jak i router roszczą sobie prawo do adresu 192.168.1.1 . Panel admina
takich transmiterów umożliwia zmianę tego adresu, tylko nie mamy jak się do niego dobrać z poziomu
linux&#39;a. W tym artykule postaramy się rozwiązać problem kolizji adresów IP i skonfigurujemy nasz
transmiter tak, by miał inny adres.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Karta WiFi TP-LINK Archer T1U</title>
      <link>https://morfikov.github.io/post/recenzja-karta-wifi-tp-link-archer-t1u/</link>
      <pubDate>Fri, 19 Aug 2016 19:10:44 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-karta-wifi-tp-link-archer-t1u/</guid>
      <description>&lt;p&gt;Ostatnio recenzowałem dwie bezprzewodowe karty WiFi w standardzie mini/mikro, które podesłał mi
TP-LINK. W zestawie był jeszcze jeden adapter, a konkretnie chodzi o &lt;a href=&#34;http://www.tp-link.com.pl/products/details/Archer-T1U.html&#34;&gt;kartę Archer
T1U&lt;/a&gt;. Jest ona bardzo podobna do
&lt;a href=&#34;https://morfikov.github.io
/post/recenzja-karta-wifi-tp-link-tl-wn725n/&#34;&gt;TL-WN725N&lt;/a&gt;, przynajmniej pod
względem wizualnym. To co odróżnia od siebie te dwa adaptery, to pasmo, w którym mogą pracować oraz
oczywiście prędkość transferu. Archer T1U działa w 5 GHz (standard AC) i teoretycznie może pochwalić
się prędkością do 433 mbit/s. Zobaczmy zatem jak on spisze się w przypadku linux&#39;ów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sterowniki dla karty WiFi Archer T1U (mt7610u_sta)</title>
      <link>https://morfikov.github.io/post/sterowniki-karta-wifi-archer-t1u-mt7610u_sta/</link>
      <pubDate>Thu, 18 Aug 2016 14:35:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sterowniki-karta-wifi-archer-t1u-mt7610u_sta/</guid>
      <description>&lt;p&gt;Dziś postanowiłem się wziąć za ostatnią kartę WiFi, którą podesłał mi TP-LINK. Jest to nano adapter
Archer T1U V1 na &lt;a href=&#34;https://wikidevi.com/wiki/TP-LINK_TL-WDN5200&#34;&gt;czipie MediaTek MT7610U&lt;/a&gt;
identyfikowany w systemie jako &lt;code&gt;idVendor=2357&lt;/code&gt; , &lt;code&gt;idProduct=0105&lt;/code&gt; . Na opakowaniu pisało, że ta
karta działa na linux&#39;ach ale oczywiście w przypadku mojego Debiana, ten adapter nie został w ogóle
wykryty. Winą są zbyt stare sterowniki, które nie zostały zaktualizowane przez MediaTek od 2013
roku. TP-Link może i ma u siebie na stronie &lt;a href=&#34;http://www.tp-link.com/en/download/Archer-T1U.html#Driver&#34;&gt;nieco nowszą wersję
sterowników&lt;/a&gt;, bo z 2015 roku ale nie
udało mi się za ich sprawą zbudować poprawnie modułu &lt;code&gt;mt7610u_sta&lt;/code&gt; na kernelu 4.6 . Na szczęście
mamy jedną alternatywę, która pomoże nam jako tako wybrnąć z tej sytuacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Karta WiFi TP-LINK TL-WN823N</title>
      <link>https://morfikov.github.io/post/recenzja-karta-wifi-tp-link-tl-wn823n/</link>
      <pubDate>Wed, 17 Aug 2016 19:16:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-karta-wifi-tp-link-tl-wn823n/</guid>
      <description>&lt;p&gt;Jako mobilny osobnik wiem jak ważne są niewielkie rozmiary sprzętu, na którym przyjdzie mi operować
gdzieś poza miejscem mojego zamieszkania. Wielkość urządzeń ma zatem dla mnie ogromne znaczenie.
Nikogo raczej nie trzeba przekonywać, że wraz z miniaturyzacją sprzętu, maleje również jego
funkcjonalność. Idealne urządzenie to takie, które ma na tyle małe wymiary, by za ich sprawą nie
ucierpiały wszystkie te niezbędne nam dobrodziejstwa oferowane przez nowe technologie. Bez internetu
w obecnych czasach ani rusz, zatem potrzebne nam są różnego rodzaju adaptery i karty WiFi
umożliwiające naszym komputerom bezprzewodowe połączenie sieciowe. Jest cała masa urządzeń, które
moglibyśmy podłączyć do naszych laptopów ale nie wszystkie z nich mają na tyle małe wymiary, by ich
zastosowanie było dla nas iście komfortowe. TP-LINK dysponuje w swojej ofercie kilkoma
bezprzewodowymi kartami sieciowymi w standardzie micro/mini. W tym wpisie zobaczymy jak na linux&#39;ie
będzie sprawował się &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WN823N.html&#34;&gt;mini adapter
TL-WN823N&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zresetować hasło root do bazy danych MySQL</title>
      <link>https://morfikov.github.io/post/reset-hasla-bazy-danych-mysql/</link>
      <pubDate>Tue, 16 Aug 2016 18:36:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/reset-hasla-bazy-danych-mysql/</guid>
      <description>&lt;p&gt;Dziś podczas przenoszenia jednej z baz danych przytrafiła mi się bardzo dziwna sytuacja. Niby
wszystkie kroki zostały przeprowadzone poprawnie i nic bazie nie dolega ale jest jeden problem.
Okazuje się, że po wszystkim nie sposób do tej bazy uzyskać dostęp. Tak to się już czasem zdarza, że
człowiek ustawi hasło administratora bazy i po chwili je zapomni. Generalnie rzecz biorąc, to
komputery za mnie mają pamiętać hasła do różnych aplikacji, w tym też i do baz danych. Ja tylko
ograniczam się zawsze do kilku fraz, które odblokowują keyring. Niemniej jednak, jakimś dziwnym
trafem, w tym keyring&#39;u zabrakło hasła do tej nieszczęsnej bazy danych. Jak zatem odzyskać to
zagubione hasło do bazy MySQL? Odpowiedź jest nawet bardzo prosta, o ile się posiada dostęp do
użytkownika root na serwerze i na szczęście takowy posiadałem, więc w sumie nikt nic nie zauważył.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Jak zwiększyć ilość elementów w chmurze tagów</title>
      <link>https://morfikov.github.io/post/wordpress-jak-zwiekszyc-ilosc-elementow-w-chmurze-tagow/</link>
      <pubDate>Tue, 16 Aug 2016 09:21:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-jak-zwiekszyc-ilosc-elementow-w-chmurze-tagow/</guid>
      <description>&lt;p&gt;Po drobnym dostosowaniu tego bloga, zmieniła się też nieco jego stopka. Problem w tym, że z początku
widżety ulokowane na samym dole strony niezbyt współgrały ze sobą wizualnie. Generalnie rzecz
biorąc, w stopce mam trzy widżety: ostatnie recenzje, archiwum i chmurę tagów. Można co prawda
zmieniać ich kolejność ale z racji że są tylko trzy widżety, to nie idzie ich dobrać tak, by były
przyzwoicie wyrównane. Winne są tutaj same tagi, które WordPress domyślnie wyświetla w liczbie 45.
By te widżety wyglądały przyzwoicie, trzeba by tych tagów dodać kilka, np. tak ze 20 sztuk ale jak
to zrobić? Możemy skorzystać z funkcji &lt;code&gt;wp_tag_cloud()&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Jak usunąć alias &#34;login&#34; dla wp-login.php</title>
      <link>https://morfikov.github.io/post/wordpress-jak-usunac-alias-wp-login-php/</link>
      <pubDate>Sun, 14 Aug 2016 20:05:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-jak-usunac-alias-wp-login-php/</guid>
      <description>&lt;p&gt;Przeglądając sobie ostatnio logi mojego serwera Apache2, zauważyłem tam dziwną aktywność. Jakieś
boty czy też inne ustrojstwa próbują od czasu do czasu uzyskać dostęp do formularza logowania tego
bloga. Jako, że tutaj mamy do czynienia z WordPress&#39;em oraz &lt;a href=&#34;https://morfikov.github.io
/post/certyfikat-chroniacy-wp-login-php-wp-admin/&#34;&gt;ochroną pliku wp-login.php oraz
katalogu wp-admin/ za pomocą
certyfikatów&lt;/a&gt;, to taki bot
nigdy nie uzyska dostępu do tych zasobów. Niemniej jednak, te automaty generują zapytania do serwera
o zasób &lt;code&gt;login&lt;/code&gt; , który z kolei przekierowuje je pod &lt;code&gt;wp-login.php&lt;/code&gt; za pomocą kodu 301 lub 302.
Moglibyśmy uniknąć tego typu przekierowań zwracając im kod 404 i przy tym odciążając nieco serwer
www. W tym krótkim artykule zobaczymy jak tego typu zabieg przeprowadzić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Power Bank TL-PB10400 od TP-LINK</title>
      <link>https://morfikov.github.io/post/recenzja-power-bank-tl-pb10400-tp-link/</link>
      <pubDate>Sun, 14 Aug 2016 08:12:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-power-bank-tl-pb10400-tp-link/</guid>
      <description>&lt;p&gt;Technologie mobilne rozwijają się bardzo szybko. Dziś już praktycznie każdy z nas ma jakiś smartfon,
tablet czy mp3player. Wszystkie te urządzenia wymagają do pracy energii, którą zwykliśmy pozyskiwać
z sieci energetycznej. Niemniej jednak, mobilność oznacza również ograniczony dostęp do źródeł
zasilania. Przebywając gdzieś w dziczy poza obszarem cywilizacji trzeba mieć na względzie
alternatywne źródło energii, której tak bardzo potrzebują nasze urządzenia. Niekoniecznie musimy
znajdować się w położeniu Mad Max&#39;a ale zasada działania jest bardzo podobna, tj. dorwać się do
źródła energii, zgromadzić jej jak najwięcej i korzystać z niej w przypadku &amp;quot;trudnych czasów&amp;quot;.
Zapasy energii możemy gromadzić w akumulatorach konkretnych urządzeń, choć te są zwykle niewielkiej
pojemności, przez co nie wystarczą nam na długo. Alternatywą są zaś power banki, które potrafią
przechować znaczne ilości energii. W tym wpisie obadamy sobie bank energii od TP-LINK&#39;a, a
konkretnie będzie to &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-PB10400.html&#34;&gt;model TL-PB10400 o pojemności 10400
mAh&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sterowniki do karty TP-LINK TL-WN823N (8192eu)</title>
      <link>https://morfikov.github.io/post/sterowniki-tp-link-tl-wn823n-8192eu/</link>
      <pubDate>Fri, 12 Aug 2016 20:50:39 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sterowniki-tp-link-tl-wn823n-8192eu/</guid>
      <description>&lt;p&gt;Systemy operacyjne nie są w stanie wejść w interakcję ze sprzętem, do którego nie posiadają
sterowników. Linux już od dość dawna żyje sobie wśród nas i coraz bardziej pcha się na desktopy.
Niemniej jednak producenci tych wszystkich urządzeń niechętnie wypuszczają sterowniki dla
alternatywnych systemów. Ostatnio próbowałem uruchomić &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WN823N.html&#34;&gt;adapter TL-WN823N
V2&lt;/a&gt; od firmy TP-LINK. Na opakowaniu
widnieje napis sugerujący, że ta karta działa pod linux&#39;em. Rzeczywistość jednak okazała się
zupełnie inna. Mianowicie, mój Debian w ogóle nie rozpoznał tej karty. Jedyne informacje jakie mi
zwrócił to nazwę producenta czipu, którym okazał się być &lt;code&gt;Realtek&lt;/code&gt; , oraz &lt;code&gt;idVendor=2357&lt;/code&gt; i
&lt;code&gt;idProduct=0109&lt;/code&gt; . &lt;a href=&#34;http://www.tp-link.com/en/download/TL-WN823N.html#Driver&#34;&gt;Sterowników dostępnych na stronie
TP-LINK&#39;a&lt;/a&gt; nie szło zbudować na obecnym
kernelu 4.6 . Trzeba było zatem poszukać innej alternatywy. Na szczęście udało się znaleźć moduł
8192eu (rtl8192eu), który się skompilował i zainstalował bez problemu. Karta TL-WN823N V2 została
wykryta i działa. W tym wpisie zostanie pokazany proces kompilacji tego modułu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: Karta WiFi TP-LINK TL-WN725N (r8188eu)</title>
      <link>https://morfikov.github.io/post/recenzja-karta-wifi-tp-link-tl-wn725n/</link>
      <pubDate>Thu, 11 Aug 2016 21:00:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-karta-wifi-tp-link-tl-wn725n/</guid>
      <description>&lt;p&gt;Świat ciągle idzie do przodu i oferuje nam coraz to nowsze rozwiązania, które są w większym stopniu
dostosowane do naszych potrzeb. Mobilność w obecnych czasach to podstawa. Niekoniecznie jednak
musimy upychać naszą wirtualną rzeczywistość w urządzeniu wielkości smartfona. Może takie
rozwiązanie idealnie nadaje się dla osób podróżujących ale też nic nie stoi na przeszkodzie, by
zabrać ze sobą nieco większy komputer w postaci laptopa. Niemniej jednak, w terenie ciężko o
przewód, którym moglibyśmy się podpiąć do sieci. Dlatego też technologia WiFi jest nam zwykle
niezbędna. Na rynku jest wiele kart i adapterów, które mogą nam umożliwić połączenie bezprzewodowe,
choć nie wszystkie z nich są na tyle poręczne, abyśmy rozważali ich zakup i użytkowanie. Potrzebne
jest nam raczej urządzenie na tyle minimalistyczne, że na pierwszy rzut oka nie zauważymy żadnej
różnicy po jego podłączeniu do komputera. Firma TP-LINK oferuje kilka rozwiązań tego typu i w tym
wpisie przyjrzymy się nieco bliżej &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WN725N.html&#34;&gt;nano adapterowi WiFi
TL-WN725N&lt;/a&gt; i przetestujemy jego
kompatybilność z linux&#39;ami.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Debian: Bezpieczne pobieranie aktualizacji (apt-transport-https)</title>
      <link>https://morfikov.github.io/post/debian-bezpieczne-pobieranie-aktualizacji-apt-transport-https/</link>
      <pubDate>Tue, 09 Aug 2016 16:04:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/debian-bezpieczne-pobieranie-aktualizacji-apt-transport-https/</guid>
      <description>&lt;p&gt;Posiadanie aktualnego systemu za sprawą regularnych aktualizacji może znacząco przyczynić się do
poprawy bezpieczeństwa naszego linux&#39;a. Niemniej jednak, niezabezpieczony proces aktualizacji może
zdradzić pewne informacje, które mogą się okazać przydatne dla potencjalnego atakującego. Dlatego
też menadżer pakietów &lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;aptitude&lt;/code&gt; w Debianie wyposażony jest w dodatkowe transporty
umożliwiające komunikację z serwerem repozytorium w oparciu o różne protokoły. Standardowy
protokół, którym posługują się maszyny mające na pokładzie dystrybucję Debian, to HTTP
(ewentualnie FTP). Oba z nich ślą wszelkie informacje w postaci czystego tekstu, który nadaje się do
analizy przez człowieka. Możemy jednak skorzystać z protokołu SSL/TLS i zaszyfrować proces
pobierania aktualizacji za sprawą pakietu &lt;code&gt;apt-transport-https&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Jak edytować plik robots.txt</title>
      <link>https://morfikov.github.io/post/wordpress-jak-edytowac-plik-robots-txt/</link>
      <pubDate>Mon, 08 Aug 2016 09:44:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-jak-edytowac-plik-robots-txt/</guid>
      <description>&lt;p&gt;Co jakiś czas zaglądam sobie do &lt;a href=&#34;https://www.google.com/webmasters/tools/&#34;&gt;panelu Google Search
Console&lt;/a&gt; w poszukiwaniu błędów na tym blogu. Do tej pory
trafiały mi się pojedyncze przypadki błędnego przekierowania adresu URL. Nic wielkiego, bo wystarczy
odszukać dany post i poprawić w nim konkretny link. Niemniej jednak, Google zaczyna mnie drażnić
&amp;quot;błędami&amp;quot; odnośnie plików &lt;code&gt;xmlrpc.php&lt;/code&gt; oraz &lt;code&gt;wp-includes/wlwmanifest.xml&lt;/code&gt; . Oba te pliki są
zablokowane na poziomie serwera Apache2 z powodu &lt;a href=&#34;https://niebezpiecznik.pl/post/trwaja-ataki-ddos-wykorzystujace-wordpressa-sprawdz-czy-twoj-blog-zostal-uzyty-w-ataku/&#34;&gt;zagrożeń jakie niesie protokół
XML-RPC&lt;/a&gt;.
Dlaczego zatem mechanizmy Google zwracają błędy? Winna jest tutaj błędna konfiguracja instrukcji dla
wyszukiwarek, tj. plik &lt;code&gt;robots.txt&lt;/code&gt; . Jakby tego było mało, to w przypadku WordPress&#39;a ten plik jest
generowany w locie i fizycznie nie istnieje na serwerze. Jak zatem poddać go edycji? Na to pytanie
postaramy się znaleźć odpowiedź w tym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wybrać optymalny mirror repozytorium Debiana</title>
      <link>https://morfikov.github.io/post/jak-wybrac-optymalny-mirror-repozytorium-debiana/</link>
      <pubDate>Sun, 07 Aug 2016 15:15:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wybrac-optymalny-mirror-repozytorium-debiana/</guid>
      <description>&lt;p&gt;Debian to dość stara i rozbudowana dystrybucja linux&#39;a, którą można spotkać praktycznie w każdym
zakątku naszego globu. Dziesiątki tysięcy pakietów dostępne w oficjalnych repozytoriach tylko
czekają aż je pobierzemy i zainstalujemy w swoim systemie. Problem zaczyna się jednak w momencie,
gdy wielu użytkowników w tym samym czasie zaczyna pobierać pakiety i to z tego samego serwera. Wtedy
aktualizacja Debiana może trwać dłużej niż zazwyczaj. By zaadresować ten problem, developerzy tej
dystrybucji stawiają serwery lustrzane (mirror) w różnych częściach świata i rozładowują w ten
sposób ruch, który by powędrował do głównego serwera. Spora część krajów ma kilka własnych
mirror&#39;ów ale ich jakość może czasami zostawić wiele do życzenia. Co w przypadku, gdy taki mirror,
z którego my korzystamy, ulegnie awarii? Trzeba będzie poddać edycji plik &lt;code&gt;/etc/apt/sources.list&lt;/code&gt; i
zmienić adres repozytorium przez dostosowanie w nim części odpowiedzialnej za lokalizację, np.
&lt;code&gt;ftp.pl&lt;/code&gt; czy &lt;code&gt;ftp.us&lt;/code&gt; . Istnieje jednak sposób, który dostosuje lokalizację serwera lustrzanego
automatycznie, a my już nie będziemy musieli sobie głowy zawracać edycją wspomnianego wyżej pliku.&lt;/p&gt;
&lt;p&gt;Projekt, o którym traktuje poniższy wpis, nie jest już rozwijany przez Debiana. Więcej info
&lt;a href=&#34;https://wiki.debian.org/DebianGeoMirror&#34;&gt;tutaj&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Debian: Anonimowe pobieranie aktualizacji (apt-transport-tor)</title>
      <link>https://morfikov.github.io/post/debian-anonimowe-pobieranie-aktualizacji-apt-transport-tor/</link>
      <pubDate>Sun, 07 Aug 2016 13:06:03 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/debian-anonimowe-pobieranie-aktualizacji-apt-transport-tor/</guid>
      <description>&lt;p&gt;Dystrybucja linux&#39;a Debian oferuje możliwość pobierania pakietów &lt;code&gt;.deb&lt;/code&gt; za pomocą sieci TOR. W ten
sposób jesteśmy w stanie ukryć nieco informacji na temat zainstalowanego w naszym systemie
oprogramowania. Jakby nie patrzeć, aplikacje mają pełno dziur i nie wszystkie z tych programików są
łatane natychmiast po opublikowaniu podatności. Z chwilą dokonywania aktualizacji systemu,
potencjalny atakujący może dowiedzieć się zatem z jakich programów korzystamy, wliczając w to ich
wersje. Znając te dane, można ocenić czy system posiada jakieś błędy. By zaimplementować w
menadżerze pakietów &lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;aptitude&lt;/code&gt; możliwość korzystania z &lt;a href=&#34;https://www.torproject.org/&#34;&gt;sieci
TOR&lt;/a&gt;, musimy posiadać w systemie skonfigurowanego klienta TOR oraz
zainstalować pakiet &lt;code&gt;apt-transport-tor&lt;/code&gt; . W tym artykule postaramy się skonfigurować ten cały
mechanizm TOR&#39;owych aktualizacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Apache2: Konfiguracja OCSP Stapling</title>
      <link>https://morfikov.github.io/post/apache2-konfiguracja-ocsp-stapling/</link>
      <pubDate>Sat, 06 Aug 2016 19:16:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/apache2-konfiguracja-ocsp-stapling/</guid>
      <description>&lt;p&gt;Serwery udostępniające nam różnego rodzaju strony www na protokole SSL/TLS posiadają certyfikaty,
które są ważne przez pewien okres czasu. Z reguły jest to rok albo, jak w przypadku
&lt;a href=&#34;https://morfikov.github.io
/post/certyfikat-letsencrypt-dla-bloga-certbot/&#34;&gt;letsencrypt&lt;/a&gt;, są to 3 miesiące.
Taki certyfikat może zostać unieważniony z różnych przyczyn ale informacja o tym fakcie musi trafić
do wszystkich klientów odwiedzających taki serwis www. Do tego celu mogą posłużyć dwa mechanizmy.
Pierwszym z nich są listy &lt;a href=&#34;https://pl.wikipedia.org/wiki/Lista_uniewa%C5%BCnionych_certyfikat%C3%B3w&#34;&gt;Certificate Revocation
Lists&lt;/a&gt; (CRL). Drugim zaś
jest &lt;a href=&#34;https://pl.wikipedia.org/wiki/Online_Certificate_Status_Protocol&#34;&gt;Online Certificate Status
Protocol&lt;/a&gt; (OCSP). W tym wpisie
postaramy się zaimplementować to drugie rozwiązanie na serwerze Apache2.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Apache2: Moduł evasive, ipset i iptables (anty DOS/DDOS)</title>
      <link>https://morfikov.github.io/post/apache2-modul-evasive-ipset-iptables/</link>
      <pubDate>Sat, 06 Aug 2016 09:13:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/apache2-modul-evasive-ipset-iptables/</guid>
      <description>&lt;p&gt;Apache2 ma kilka ciekawych modułów, które mogą uchronić nasz serwer www przed atakami DOS i DDOS.
Jednym z nich jest moduł &lt;code&gt;evasive&lt;/code&gt; . Nie jest on jednak oficjalnym modułem i brak o nim
jakiejkolwiek wzmianki w oficjalnej dokumentacji na stronie Apache2. Niemniej jednak, jest to bardzo
prosty moduł składający się dosłownie z kilku dyrektyw, które są w stanie zablokować zapytania o
zasoby serwera w przypadku, gdy zostanie przekroczony pewien ustalony przez nas limit. Dodatkowo,
ten moduł może współgrać z filtrem &lt;code&gt;iptables&lt;/code&gt; oraz &lt;code&gt;ipset&lt;/code&gt; , dając nam możliwość wygodnego
blokowania uporczywych klientów na poziomie pakietów sieciowych.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problemy z dyrektywą SSLOpenSSLConfCmd w Apache2</title>
      <link>https://morfikov.github.io/post/problemy-z-dyrektywa-sslopensslconfcmd-w-apache2/</link>
      <pubDate>Fri, 05 Aug 2016 15:52:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problemy-z-dyrektywa-sslopensslconfcmd-w-apache2/</guid>
      <description>&lt;p&gt;W stabilnej dystrybucji linux&#39;a debian niewiele rzeczy ulega zmianie w przeciągu roku czy dwóch lat.
Dlatego też ta gałąź jest wykorzystywana głównie w przypadku serwerów, min. na tym VPS. Na co dzień
jednak korzystam z debiana SID, czyli gałęzi niestabilnej, która jest nieco bardziej aktualna i
przystosowana do otaczającej nas tej wirtualnej rzeczywistości. Chodzi generalnie o nowsze
oprogramowanie implementujące całą masę ficzerów, których starsze wersje nie posiadają. W tym
przypadku problem dotyczy serwera Apache2, który ostatnimi czasy wypracował szereg mechanizmów
obronnych adresujących ataki na protokół SSL/TLS. Jedną z podatności jest słaba liczba pierwsza
wykorzystywana w &lt;a href=&#34;https://pl.wikipedia.org/wiki/Protok%C3%B3%C5%82_Diffiego-Hellmana&#34;&gt;protokole
Diffie-Hellman&#39;a&lt;/a&gt;. Ten problem
można stosunkowo łatwo poprawić w nowszej wersji Apache2 wykorzystując dyrektywę &lt;code&gt;SSLOpenSSLConfCmd&lt;/code&gt;
. W starszych wersjach ona niestety nie działa. Niemniej jednak, w dalszym ciągu możemy użyć
własnych parametrów dla protokołu Diffie-Hellman&#39;a, z tym, że trzeba to zrobić nieco inaczej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Apache2: Jak odchudzić nieco plik access.log</title>
      <link>https://morfikov.github.io/post/apache2-jak-odchudzic-nieco-plik-access-log/</link>
      <pubDate>Thu, 04 Aug 2016 11:10:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/apache2-jak-odchudzic-nieco-plik-access-log/</guid>
      <description>&lt;p&gt;Mając serwer www oparty o oprogramowanie Apache2, w pewnym momencie zacznie nas nieco przytłaczać
kwestia logowania do pliku &lt;code&gt;/var/log/apache2/access.log&lt;/code&gt; wszystkiego co się nawinie. Jak nazwa pliku
sugeruje, znajdują się w nim komunikaty, które serwer generuje ilekroć tylko ktoś odwiedzi nasz
serwis. Każdy zasób przesłany do klienta, np. style CSS czy obrazki, zostanie zalogowany w powyższym
pliku. Generalnie rzecz ujmując, nie musimy logować wszystkich tych informacji, chyba, że ich
faktycznie potrzebujemy. Trzeba jednak wziąć pod uwagę fakt, że w przypadku obciążonych serwerów,
ilość operacji I/O dysku może być znaczna. Dodatkowo, miejsce na dysku za sprawą takiego obszernego
logu może bardzo szybko się wyczerpać. W tym artykule postaramy się nieco ograniczyć apetyt serwera
Apache2 na logi i oduczymy go logować większość zbędnych komunikatów za sprawą dyrektywy
&lt;code&gt;SetEnvIf&lt;/code&gt;/&lt;code&gt;SetEnvIFNoCase&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>packet_write_wait: Connection to IP port 22: Broken pipe</title>
      <link>https://morfikov.github.io/post/packet_write_wait-connection-to-ip-port-22-broken-pipe/</link>
      <pubDate>Wed, 03 Aug 2016 13:41:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/packet_write_wait-connection-to-ip-port-22-broken-pipe/</guid>
      <description>&lt;p&gt;Operowanie na VPS nie jest jakoś specjalnie trudne, zwłaszcza w przypadku, gdy mamy dostęp root i
możemy logować się na serwer z wykorzystaniem protokołu SSH. Dalej to już zwykła linux&#39;owa
mechanika, która może być nieco inna, w zależności od tego, jaki dokładnie system operacyjny na tym
VPS stoi. Czasami jednak, w pewnym momencie podczas połączenia możemy zostać rozłączeni z
niewiadomych nam przyczyn. Niemniej jednak, zawsze, gdy ten problem występuje, w terminalu można
zobaczyć komunikat: &lt;code&gt;packet_write_wait: Connection to 1.2.3.4 port 22: Broken pipe&lt;/code&gt; . Przydałoby się
zatem coś na ten stan rzeczy poradzić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cache-Control, Last-Modified, ETag i Expires w Apache2</title>
      <link>https://morfikov.github.io/post/cache-control-last-modified-etag-i-expires-w-apache2/</link>
      <pubDate>Mon, 01 Aug 2016 18:50:48 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/cache-control-last-modified-etag-i-expires-w-apache2/</guid>
      <description>&lt;p&gt;Każda przeglądarka internetowa potrafi buforować dane w swoim cache w celach optymalizacji
przeglądanych stron www. Dzięki temu, szereg elementów odwiedzonych już witryn nie musi być
ponownie pobieranych z serwera. Zyskuje na tym nie tylko serwer ale również i sam klient, któremu
strona ładuje się parokrotnie szybciej. Pod ten mechanizm podpadają nie tylko pliki graficzne ale
również style CSS, skrypty JS, a nawet pliki &lt;code&gt;.html&lt;/code&gt; . Generalnie rzecz ujmując, wszystko co serwer
www jest w stanie przesłać przeglądarce. Problemem może jednak się okazać zbyt krótki/długi okres
ważności cache. Jeśli ten czas jest za krótki, to elementy strony będą niepotrzebnie utylizować
łącze, nie tylko nasze ale również i serwera www. Z kolei, jeśli okres ważności będzie za długi,
to będziemy odwiedzać nieaktualną stronę. Optymalnym rozwiązaniem byłaby taka konfiguracja serwera
www, gdzie dla konkretnych elementów strony sami moglibyśmy ustalić czas ważności cache. Apache2
daje nam taką możliwość przez ustawienie nagłówków HTTP &lt;code&gt;Cache-Control&lt;/code&gt; , &lt;code&gt;Expires&lt;/code&gt; , &lt;code&gt;ETag&lt;/code&gt; oraz
&lt;code&gt;Last-Modified&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>&#34;Internal dummy connection&#34; w logu Apache2 (mpm_prefork)</title>
      <link>https://morfikov.github.io/post/internal-dummy-connection-apache2-mpm_prefork/</link>
      <pubDate>Sat, 30 Jul 2016 20:00:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/internal-dummy-connection-apache2-mpm_prefork/</guid>
      <description>&lt;p&gt;Od czasu do czasu przeglądam sobie logi Apache2 w poszukiwaniu pewnych nieprawidłowości. Na dobrą
sprawę, to nie ma tutaj zbytnio dużo roboty, przynajmniej póki co. Niemniej jednak, w pliku
&lt;code&gt;/var/log/apache2/access.log&lt;/code&gt; co jakiś czas pojawiają się komunikaty zawierające &amp;quot;internal dummy
connection&amp;quot;. Za co one odpowiadają i czy można je w zupełności zignorować bez stwarzania zagrożenia
bezpieczeństwa dla serwera www?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Wersja plików .css/.js na blogu</title>
      <link>https://morfikov.github.io/post/wordpress-wersja-plikow-css-js-na-blogu/</link>
      <pubDate>Fri, 29 Jul 2016 13:08:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-wersja-plikow-css-js-na-blogu/</guid>
      <description>&lt;p&gt;Gdy odwiedzamy jakiś blog WordPress&#39;a po raz pierwszy, szereg jego elementów jest buforowanych w
cache przeglądarki. W ten sposób pewne pliki, np. &lt;code&gt;.css&lt;/code&gt;, &lt;code&gt;.js&lt;/code&gt; czy też obrazki, nie są pobierane
bezpośrednio z serwera www, bo mamy je lokalnie u siebie na dysku. Takie rozwiązanie zapewnia
szybsze załadowanie się strony przez minimalizowanie ruchu sieciowego. Niemniej jednak, jako, że te
pliki siedzą w cache, to muszą mieć ustawiony pewien czas ważności. Może on być różny, a my możemy
go sobie dostosować dla poszczególnych elementów ustawiając im &lt;a href=&#34;https://morfikov.github.io
/post/cache-control-last-modified-etag-i-expires-w-apache2/&#34;&gt;nagłówek Cache-Control, Expires,
Last-Modified, czy
ETag&lt;/a&gt;. Gdy w takim
nagłówku określimy wysoką wartość &lt;code&gt;max-age&lt;/code&gt; , przeglądarka klienta może przez bardzo długi czas nie
być świadoma faktu, że któreś elementy strony uległy zmianie. W efekcie może i pojawiła się nowa
wersja pliku &lt;code&gt;.css&lt;/code&gt; ale klienci odwiedzający nasz serwis i tak nie zaobserwują żadnej różnicy do
momentu wygaśnięcia cache lub też odświeżenia strony z przytrzymanym klawiszem Shift . Możemy jednak
dodać numer wersji do określonych plików i uzależnić go od czasu modyfikacji danego zasobu na
serwerze. Jeśli zmianie ulegnie plik, klient automatycznie pobierze zmodyfikowany zasób.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zdalny backup przy pomocy rsync, ssh i sudo</title>
      <link>https://morfikov.github.io/post/zdalny-backup-przy-pomocy-rsync-ssh-sudo/</link>
      <pubDate>Thu, 28 Jul 2016 23:15:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zdalny-backup-przy-pomocy-rsync-ssh-sudo/</guid>
      <description>&lt;p&gt;Mój VPS, jako, że jest dość tani, nie zawiera całej masy wynalazków. Jedną z tych bardziej
użytecznych rzeczy jest backup danych na dysku VPS&#39;a. OVH liczy sobie trochę grosza za usługę
snapshot&#39;ów. Dlatego też byłem zmuszony poszukać innego rozwiązania, które sprawiłoby, że kopia
wszystkich ważnych plików byłaby zawsze poza granicami tego VPS. Najlepiej, gdyby te pliki były
umieszczany na moim własnym komputerze, czy jakiejś stacji roboczej, która ma robić za taki
backup&#39;owy serwer. Problem w tym, że ciężko jest zsynchronizować sobie poprawnie katalogi na
odległość, choć jest to możliwe przy pomocy &lt;code&gt;ssh&lt;/code&gt; , &lt;code&gt;rsync&lt;/code&gt; oraz &lt;code&gt;sudo&lt;/code&gt; . Z tym, że mamy tutaj
szereg problemów związanych z uprawnieniami do plików. No i oczywiście trzeba także uwzględnić inny
port SSH. Trochę było z tym zamieszania ale ostatecznie udało się to zadanie rozwiązać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Jak przetłumaczyć motyw/wtyczkę</title>
      <link>https://morfikov.github.io/post/wordpress-jak-przetlumaczyc-motyw-wtyczke/</link>
      <pubDate>Wed, 27 Jul 2016 20:00:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-jak-przetlumaczyc-motyw-wtyczke/</guid>
      <description>&lt;p&gt;WordPress został przetłumaczony na dość sporo języków, w tym też i na język polski. Niemniej jednak,
pliki bazowe to nie to samo co pliki różnych dodatków. Dlatego też czasem po zmianie języka na
polski, nie wszystkie elementy naszego bloga są przetłumaczone. Nie ma przy tym znaczenia czy
&lt;a href=&#34;https://morfikov.github.io
/post/wordpress-domyslny-jezyk-instalacji/&#34;&gt;ustawialiśmy język podczas instalacji
WordPress&#39;a&lt;/a&gt;, czy też później z poziomu
panela administracyjnego. Taki stan rzeczy nie wygląda zbyt estetycznie i przydałoby się coś z tym
zrobić. Jeśli zajrzymy do katalogu wtyczek czy motywów, to zwykle znajdziemy tam pliki &lt;code&gt;.mo&lt;/code&gt; oraz
&lt;code&gt;.po&lt;/code&gt; , które są używane przy tłumaczeniu tekstu z wykorzystaniem
&lt;a href=&#34;https://www.gnu.org/software/gettext/&#34;&gt;gettext&lt;/a&gt;. Jako, że motyw, który jest wykorzystywany na tym
blogu nie jest przetłumaczony, to postanowiłem go przetłumaczyć i przy okazji opisać ten niezbyt
skomplikowany proces.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Certyfikat Let&#39;s Encrypt dla bloga WordPress (certbot)</title>
      <link>https://morfikov.github.io/post/certyfikat-letsencrypt-dla-bloga-certbot/</link>
      <pubDate>Sat, 23 Jul 2016 12:00:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/certyfikat-letsencrypt-dla-bloga-certbot/</guid>
      <description>&lt;p&gt;Jeszcze nie tak dawno temu, rzadko który serwis internetowy wykorzystywał certyfikaty SSL/TLS do
zabezpieczenia komunikacji między serwerem, a łączącymi się do niego klientami. W dalszym ciągu
jednak notuje się strony bez &amp;quot;zielonej kłódki&amp;quot; ale na szczęście jest ich coraz mniej w naszym
otoczeniu. Liczbę tych stron można by z powodzeniem ograniczyć jeszcze bardziej, gdyby takie
certyfikaty były za free, łatwe do zaimplementowania i dostępne praktycznie dla każdego od tak. No i
na dobrą sprawę są, tylko ludzie jeszcze nie zdają sobie z tego sprawy. Istnieje bowiem &lt;a href=&#34;https://letsencrypt.org/&#34;&gt;projekt
Let&#39;s Encrypt&lt;/a&gt;, który umożliwia stosunkowo bardzo proste wdrożenie
certyfikatu na serwerze www opartym, np. o oprogramowanie Apache2. W tym wpisie zobaczymy jak ta
cała procedura implementacji certyfikatu SSL/TLS przebiega.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Kilku użytkowników bazy danych</title>
      <link>https://morfikov.github.io/post/wordpress-kilku-uzytkownikow-bazy-danych/</link>
      <pubDate>Wed, 20 Jul 2016 20:15:44 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-kilku-uzytkownikow-bazy-danych/</guid>
      <description>&lt;p&gt;Za wysokie uprawnienia zawsze prowadzą do problemów, zwłaszcza, gdy w grę wchodzą komputery i
serwisy www. Wszyscy wiemy, że WordPress nie należy do bezpiecznych rozwiązań, mimo, że cała masa
stron na necie opiera się właśnie o tego CMS&#39;a. Można jednak wypracować sobie bezpieczny setup, pod
warunkiem, że będziemy się zawsze kierować jedna prostą zasadą. Mianowicie chodzi o ograniczenie
uprawnień. Standardowo WordPress ma zdefiniowanego jednego użytkownika w pliku &lt;code&gt;wp-config.php&lt;/code&gt; ,
którym skrypt się posługuje. Zwykle też ten użytkownik ma wszystkie możliwe prawa do wszystkich
tabel w bazie danych naszego bloga czy serwisu. Nie musi tak być, a my możemy wykorzystać kilku
użytkowników i nadać im inne uprawnienia w zależności od tego jakie operacje na bazie danych będą
oni przeprowadzać. W tym wpisie zobaczymy jak zaprzęgnąć wielu użytkowników do pracy z bazą danych
Wordpress&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zablokować hotlink&#39;i w Apache2</title>
      <link>https://morfikov.github.io/post/zablokowac-hotlink-apache2/</link>
      <pubDate>Wed, 20 Jul 2016 18:55:21 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zablokowac-hotlink-apache2/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Hotlink&#34;&gt;Hotlink lub hotlinking&lt;/a&gt; to proceder wykorzystywania zasobów
(plików) jednej strony www przez inny serwis internetowy. Chodzi generalnie o to, że materiały,
które pojawiają się w obcych serwisach, fizycznie w dalszym ciągu są hostowane, np. na naszym
serwerze. W taki sposób osoba, która linkuje do naszych plików &lt;code&gt;.jpg&lt;/code&gt; , &lt;code&gt;.png&lt;/code&gt; , &lt;code&gt;.mp3&lt;/code&gt; czy nawet
&lt;code&gt;.css&lt;/code&gt; i tworzy swój serwis w oparciu o nie, nie ponosi przy tym praktycznie żadnego obciążenia ze
swojej strony. Cały ten ciężar jest spychany na nasz serwer, co zjada nam transfer i zapychając
łącze. W tym krótkim wpisie postaramy się zablokować możliwość hotlink&#39;owania przez inne serwisy
www w Apache2.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HTTP Strict Transport Security (HSTS) w Apache2</title>
      <link>https://morfikov.github.io/post/http-strict-transport-security-hsts-apache2/</link>
      <pubDate>Tue, 19 Jul 2016 19:08:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/http-strict-transport-security-hsts-apache2/</guid>
      <description>&lt;p&gt;Ostatnio na niebezpieczniku czytałem &lt;a href=&#34;https://niebezpiecznik.pl/post/podroze-kosztuja/&#34;&gt;taki oto
post&lt;/a&gt;. Historia jak historia, nieco długa ale
mniej więcej w połowie pojawiła się informacja na temat nagłówków HSTS (&lt;a href=&#34;https://en.wikipedia.org/wiki/HTTP_Strict_Transport_Security&#34;&gt;HTTP Strict Transport
Security&lt;/a&gt;), który jest przesyłany w
zapytaniach HTTP/HTTPS. Postanowiłem nieco się zainteresować tym tematem i zbadać czym są te
nagłówki HSTS i w jaki sposób są one w stanie poprawić bezpieczeństwo protokołów SSL/TLS
wykorzystywanych podczas szyfrowania zawartości stron internetowych.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Certyfikat chroniący wp-login.php i wp-admin/</title>
      <link>https://morfikov.github.io/post/certyfikat-chroniacy-wp-login-php-wp-admin/</link>
      <pubDate>Tue, 19 Jul 2016 14:07:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/certyfikat-chroniacy-wp-login-php-wp-admin/</guid>
      <description>&lt;p&gt;Jednym z bardziej wyrafinowanych sposobów ochrony zasobów (katalogów) na serwerze www opartym o
oprogramowanie Apache2 jest wykorzystanie certyfikatów klienckich. Tego typu zabezpieczenie można
jednak zastosować tylko i wyłącznie w przypadku stron, które korzystają z szyfrowania SSL/TLS. Dla
przykładu weźmy sobie blog WordPress&#39;a, gdzie mamy katalog &lt;code&gt;wp-admin/&lt;/code&gt; i plik &lt;code&gt;wp-login.php&lt;/code&gt; .
Formularz logowania oraz panel admina zwykle są szyfrowane. Zatem każdy taki blog powinien robić już
użytek z tunelu SSL/TLS w mniejszym lub większym stopniu. Jeśli teraz mamy dość niestandardową
instalację WordPress&#39;a, to przy pomocy certyfikatów możemy weryfikować użytkowników, którzy chcą
uzyskać dostęp do tych w/w lokalizacji. Jest to nieco inne podejście w stosunku do tego, które
zostało opisane w artykule o &lt;a href=&#34;https://morfikov.github.io
/post/wordpress-ukrycie-wp-login-php-oraz-wp-admin/&#34;&gt;ukrywaniu wp-login.php oraz
wp-admin&lt;/a&gt;, gdzie był
wykorzystywany moduł &lt;code&gt;mod_rewrite&lt;/code&gt; oraz dyrektywy &lt;code&gt;Files&lt;/code&gt; i &lt;code&gt;MatchFiles&lt;/code&gt; . Takie certyfikaty
klienckie dają nam jednak większe pole manewru, bo identyfikują konkretnego użytkownika chcącego
uzyskać dostęp do zasobów serwera. Ten wpis ma na celu pokazanie w jaki sposób zaimplementować
obsługę certyfikatów klienckich w Apache2.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Baza danych pozwoleń w Firefox&#39;ie (permissions.sqlite)</title>
      <link>https://morfikov.github.io/post/baza-danych-pozwolen-firefox-permissions-sqlite/</link>
      <pubDate>Sun, 17 Jul 2016 21:43:14 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/baza-danych-pozwolen-firefox-permissions-sqlite/</guid>
      <description>&lt;p&gt;Praktycznie każda przeglądarka, w tym też i Firefox, oferuje możliwość nadania określonym domenom
praw dostępu do zasobów systemowych. Chodzi generalnie o wykorzystywanie wtyczek, np. flash, które
są aktywowane na danej stronie internetowej jeśli ta ich potrzebuje. Po części też sprawa dotyczy
korzystania z urządzeń takich jak wbudowane w laptop kamera i mikrofon oraz szeregu dodatkowych
rzeczy, np. ciasteczka, pop-up&#39;y i inne takie. Obecnie Firefox standardowo blokuje dostęp do
pluginów, a gdy zachodzi potrzeba skorzystania z któregoś z nich, to zostaje nam zaprezentowane
okienko, w którym możemy zdecydować co zrobić. Gdy często odwiedzamy daną witrynę, to naturalnie
prosimy naszą przeglądarkę, by ta zapisała ustawienia dla tej strony. Firefox robi to przez dodanie
wyjątku w pliku &lt;code&gt;permissions.sqlite&lt;/code&gt; . W sporej części przypadków będziemy mogli cofnąć pozwolenia w
dość prosty sposób. Niemniej jednak, nie we wszystkich z nich da się to tak łatwo zrobić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nf_conntrack: automatic helper assignment is deprecated</title>
      <link>https://morfikov.github.io/post/nf_conntrack-automatic-helper-assignment-deprecated/</link>
      <pubDate>Sat, 16 Jul 2016 18:59:19 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/nf_conntrack-automatic-helper-assignment-deprecated/</guid>
      <description>&lt;p&gt;Jeśli ktoś uważnie śledzi logi systemowe, to od czasu do czasu można w nich znaleźć komunikat,
którzy brzmi mniej więcej tak: &lt;code&gt;nf_conntrack: automatic helper assignment is deprecated and it will be removed soon. Use the iptables CT target to attach helpers instead&lt;/code&gt; . Ta wiadomość odnosi się do
jednego z modułów linux&#39;owego filtra pakietów &lt;code&gt;iptables&lt;/code&gt; . Moduł, o którym mowa to &lt;code&gt;nf_conntrack&lt;/code&gt; ,
który odpowiada za śledzenie połączeń nawiązywanych przez system. Sam komunikat zaś dotyczy
mechanizmów pomocniczych, których sposób aktywacji jest już nieco przestarzały i zostanie wkrótce
usunięty. Co to oznacza dla przeciętnego użytkownika linux&#39;a i czym są w istocie te mechanizmy
pomocnicze, które znajdują zastosowane na zaporze sieciowej?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zweryfikować status poleceń w pipe</title>
      <link>https://morfikov.github.io/post/zweryfikowac-status-polecen-pipe/</link>
      <pubDate>Sun, 10 Jul 2016 19:14:31 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zweryfikowac-status-polecen-pipe/</guid>
      <description>&lt;p&gt;Ja zbytnio się nie nadaję na programistę ale czasem jakieś trzeciorzędne skrypty nawet potrafię
napisać. Problem ze skryptami jest taki, że mogą one nie do końca działać jak należy. Zwykle w
takich przypadkach, skrypt zwraca jakiś kod wyjścia. Z reguły też jest on inny od 0, który z kolei
oznacza, że skrypt został wykonany prawidłowo. Załóżmy teraz, że wywołujemy szereg poleceń. Każde z
nich przekierowuje swoje wyjście na wejście innego polecenia przy pomocy znaku &lt;code&gt;|&lt;/code&gt; (pipe) . Jak w
takim przypadku ustalić czy wszystkie z tych poleceń w łańcuchu wykonały się poprawnie? W tym wpisie
postaramy się odpowiedzieć na to pytanie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kształtowanie ruchu z qos-scripts w OpenWRT</title>
      <link>https://morfikov.github.io/post/ksztaltowanie-ruchu-qos-scripts-openwrt/</link>
      <pubDate>Fri, 08 Jul 2016 18:00:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ksztaltowanie-ruchu-qos-scripts-openwrt/</guid>
      <description>&lt;p&gt;Każdy bardziej zaawansowany administrator sieci prędzej czy później będzie chciał wdrożyć na swoim
routerze wyposażonym w firmware OpenWRT pewien mechanizm QoS umożliwiający kształtowanie ruchu
sieciowego. Ci, którzy się za ten temat zabierali, wiedzą, że nie jest on prosty w realizacji.
Zwłaszcza, gdy chce się cały ten system zarządzania pakietami skonfigurować od podstaw przy pomocy
narzędzi takich jak &lt;code&gt;iptables&lt;/code&gt; , &lt;code&gt;tc&lt;/code&gt; oraz &lt;code&gt;ip&lt;/code&gt; . Z tego też względu OpenWRT umożliwia nam nieco
prostszą w konfiguracji alternatywę polegającą na zainstalowaniu narzędzi zawartych w pakietach
&lt;code&gt;wshaper&lt;/code&gt; , &lt;code&gt;qos-scripts&lt;/code&gt; lub &lt;code&gt;sqm-scripts&lt;/code&gt; . Trzeba przy tym pamiętać, że mechanizm, który zostanie
stworzony z wykorzystaniem jednego z tych w/w pakietów nie będzie tak elastyczny jak przy ręcznej
konfiguracji od podstaw. Niemniej jednak, w tym artykule postaramy się ogarnąć kształtowanie ruchu
przy pomocy tych pakietów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Różne adresy LAN i WLAN w OpenWRT (Routed AP)</title>
      <link>https://morfikov.github.io/post/rozne-adresy-lan-wlan-openwrt-routed-ap/</link>
      <pubDate>Thu, 07 Jul 2016 16:20:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/rozne-adresy-lan-wlan-openwrt-routed-ap/</guid>
      <description>&lt;p&gt;W standardowej konfiguracji OpenWRT, hosty łączące się za pomocą sieci bezprzewodowej jak i tej
przewodowej są spięte razem za pomocą mostka (bridge) i tworzą jedną sieć lokalną. Nie ma w tym nic
dziwnego, bo przecie chcemy, aby komunikacja między wszystkimi hostami w sieci LAN odbywała się bez
większych przeszkód. Przynajmniej takie jest standardowe podejście przy konfiguracji sieci domowej.
Niemniej jednak, w pewnych przypadkach istnieje potrzeba oddzielenia maszyn, które nawiązują
połączenie za pomocą sieci WiFi od tych, które łączą się przewodowo. Generalnie chodzi o różne
adresy, które zostaną przypisane sieciom LAN i WLAN. Rozwiązanie, które zostanie opisane w tym
artykule jest podobne do tworzenia &lt;a href=&#34;https://morfikov.github.io
/post/bezprzewodowa-siec-goscinna-guest-wlan/&#34;&gt;bezprzewodowej sieci
gościnnej&lt;/a&gt; (guest WLAN), z tą
różnicą, że w tym przypadku będziemy mieli do czynienia tylko z jedną siecią WiFi (tzw. &lt;a href=&#34;https://wiki.openwrt.org/doc/recipes/routedap&#34;&gt;Routed
AP&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bezprzewodowa sieć gościnna (guest WLAN)</title>
      <link>https://morfikov.github.io/post/bezprzewodowa-siec-goscinna-guest-wlan/</link>
      <pubDate>Wed, 06 Jul 2016 21:00:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/bezprzewodowa-siec-goscinna-guest-wlan/</guid>
      <description>&lt;p&gt;Routery WiFi zwykle oferują jedną sieć bezprzewodową, do której użytkownicy mogą się łączyć po
podaniu nazwy ESSID oraz hasła. W przypadku znanych nam osób chcących korzystać z udostępnianego
przez nas AP, taka sieć powinna nam w pełni wystarczyć. Problem jednak zaczyna się w przypadku tych
użytkowników, którym chcemy zezwolić na dostęp do naszej sieci WiFi ale nie darzymy ich zbytnio
wysokim kredytem zaufania. By ten problem rozwiązać, w OpenWRT możemy skonfigurować &lt;a href=&#34;https://wiki.openwrt.org/doc/recipes/guest-wlan&#34;&gt;mechanizm zwany
&amp;quot;guest WLAN&amp;quot;&lt;/a&gt;, czyli bezprzewodowa sieć gościnna. W
tym artykule zobaczymy jak odseparować od siebie hosty w sieci LAN od tych w sieci gościnnej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja DMZ w OpenWRT</title>
      <link>https://morfikov.github.io/post/konfiguracja-dmz-openwrt/</link>
      <pubDate>Tue, 05 Jul 2016 18:05:31 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-dmz-openwrt/</guid>
      <description>&lt;p&gt;Strefa zdemilitaryzowana (&lt;a href=&#34;https://pl.wikipedia.org/wiki/Strefa_zdemilitaryzowana_(informatyka)&#34;&gt;DMZ, demilitarized
zone&lt;/a&gt;) to taki mechanizm,
który ma na celu poprawę bezpieczeństwa usług w sieci lokalnej. Generalnie chodzi o podział sieci
na kilka mniejszych podsieci i oddzielenie ich od siebie fizycznie lub logicznie. &lt;a href=&#34;https://wiki.openwrt.org/doc/howto/dmz&#34;&gt;W OpenWRT możemy
wydzielić taką strefę DMZ przy pomocy VLAN&#39;ów&lt;/a&gt;. Z kolei
odpowiednio skonfigurowany firewall odseparuje nam tę strefę od pozostałych maszyn pracujących w
sieci LAN. W taki sposób nawet w przypadku włamania mającego miejsce w strefie DMZ, maszyny w
pozostałych segmentach sieci będą bezpieczne. W tym wpisie postaramy się skonfigurować strefę
zdemilitaryzowaną na routerze wyposażonym w firmware OpenWRT.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja kluczy GPG na github&#39;ie</title>
      <link>https://morfikov.github.io/post/implementacja-kluczy-gpg-githubie/</link>
      <pubDate>Sun, 03 Jul 2016 15:30:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-kluczy-gpg-githubie/</guid>
      <description>&lt;p&gt;Github to serwis, w którym użytkownicy mogą pracować wspólnie nad różnymi projektami utrzymywanymi w
systemie kontroli wersji GIT. Konto w w/w serwisie może być łakomym kąskiem dla przestępców,
zwłaszcza gdy uczestniczymy w dość rozbudowanych projektach i przyczyniamy się do ich tworzenia w
dużym stopniu. Z tego powodu github implementuje rozwiązania, które mają na celu poprawić
bezpieczeństwo naszej pracy. Mamy już uwierzytelnianie dwuetapowe, &lt;a href=&#34;https://morfikov.github.io
/post/github-z-obsluga-kluczy-ssh/&#34;&gt;obsługę kluczy
SSH&lt;/a&gt; ale nadal brakowało odpornego systemu,
który by uwierzytelnił osoby współdziałające z nami. Chodzi o to, że wszelkie zmiany w repozytorium
GIT muszą być przez kogoś poczynione. Każdy commit ma zatem swojego właściciela ale my nigdy nie
mamy pewności co do tego, kto tak naprawdę tej zmiany dokonał. Dlatego też &lt;a href=&#34;https://github.com/blog/2144-gpg-signature-verification&#34;&gt;github umożliwił
ostatnio podpisywanie tagów i commit&#39;ów przy pomocy kluczy
GPG&lt;/a&gt;. To właśnie temu tematowi będzie
poświęcony niniejszy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Unexpected Inconsistency: Inode has corrupt extent header</title>
      <link>https://morfikov.github.io/post/unexpected-inconsistency-inode-corrupt-extent-header/</link>
      <pubDate>Fri, 01 Jul 2016 14:27:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/unexpected-inconsistency-inode-corrupt-extent-header/</guid>
      <description>&lt;p&gt;Dzisiaj system plików jednej z partycji mojego głównego dysku uległ awarii z niewiadomych przyczyn.
Dałbym sobie nawet głowę uciąć, że wszystkie partycje zostały poprawnie odmontowane podczas
wyłączania maszyny. Niemniej jednak, z jakiegoś powodu podczas startu systemu, ten wyrzuca szereg
komunikatów dotyczących głównego systemu plików, tj. &lt;code&gt;/&lt;/code&gt; . Sam komunikat brzmi mniej więcej tak:
&lt;code&gt;UNEXPECTED INCONSISTENCY; RUN fsck MANUALLY&lt;/code&gt; . Oznacza to, że błędy w systemie plików nie są łatwe
do naprawy i wymagana jest nasza ingerencja w ten proces. Przy sprawdzaniu systemu plików w
poszukiwaniu błędów przy pomocy &lt;code&gt;fsck.ext4&lt;/code&gt; można było dostrzec min. taką wiadomość: &lt;code&gt;Inode 556975 has corrupt extent header&lt;/code&gt; . Co ona tak naprawdę oznacza i czy damy radę wybrnąć z tej sytuacji bez
szwanku?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sieciowy system plików w OpenWRT (NFS)</title>
      <link>https://morfikov.github.io/post/sieciowy-system-plikow-openwrt-nfs/</link>
      <pubDate>Sun, 26 Jun 2016 19:15:01 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sieciowy-system-plikow-openwrt-nfs/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Network_File_System_(protok%C3%B3%C5%82)&#34;&gt;Network File System&lt;/a&gt; to
sieciowy system plików, za pomocą którego maszyny mające na pokładzie system operacyjny linux, w tym
tez OpenWRT, są w stanie udostępniać pliki w sieci. Zatem NFS to głównie domena linux&#39;ów. W
przypadku windowsów można korzystać z protokołu SMB
(&lt;a href=&#34;https://pl.wikipedia.org/wiki/Samba_(program)&#34;&gt;samba&lt;/a&gt;). Sposób udostępniania zasobów przy pomocy
tego sieciowego systemu plików jest bardzo podobny do tego, który jest realizowany w przypadku
protokołu SSHFS. Zasadniczą różnicą między NFS i SSHFS jest brak szyfrowania komunikacji. W
warunkach domowej sieci, ta cecha raczej nie stanowi większego problemu. Poza tym, trzeba też brać
pod uwagę fakt, że szyfrowanie znacznie obciążyłoby router, co przełożyłoby się na spadek prędkości
transferu. W tym wpisie zobaczymy jak na routerze z OpenWRT zaimplementować protokół NFS i
udostępnić za jego pomocą zasoby w sieci lokalnej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Serwer FTP na routerze z OpenWRT (vsftpd)</title>
      <link>https://morfikov.github.io/post/serwer-ftp-routerze-openwrt-vsftpd/</link>
      <pubDate>Thu, 23 Jun 2016 14:30:39 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/serwer-ftp-routerze-openwrt-vsftpd/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/File_Transfer_Protocol&#34;&gt;Usługa FTP&lt;/a&gt; jest w miarę wygodnym
rozwiązaniem w przypadku, gdy chcemy korzystać z zasobów udostępnianych przez router zarówno na
linux&#39;ach jak i na windowsach. Jedyne czego potrzebujemy to kawałek przeglądarki albo jakiegoś
klienta FTP. W tym protokole nie ma też znaczenia system plików, w którym znajdują się udostępniane
pliki. Jedyne co nas interesuje, to postawienie serwera na routerze i podanie klientom namiarów na
niego. W OpenWRT możemy do tego celu zaprzęgnąć &lt;code&gt;vsftpd&lt;/code&gt; . W tym wpisie pokażę jedynie jak tego typu
usługę uruchomić na domowym routerze WiFi i jak ją wstępnie skonfigurować. Wszelkie kwestie
techniczne związane z działaniem samego serwera FTP jak i jego wszystkich parametrów już opisywałem
przy okazji &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-vsftpd-w-debianie/&#34;&gt;wdrażania vsftpd w dystrybucji
debian&lt;/a&gt;. Zachęcam zatem do zapoznania się
również z tym podlinkowanym wpisem.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Stałe nazwy urządzeń w OpenWRT (hotplug, udev)</title>
      <link>https://morfikov.github.io/post/stale-nazwy-urzadzen-openwrt-hotplug-udev/</link>
      <pubDate>Mon, 20 Jun 2016 16:46:48 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/stale-nazwy-urzadzen-openwrt-hotplug-udev/</guid>
      <description>&lt;p&gt;Bezprzewodowy router WiFi to w miarę proste urządzenie, które w zasadzie realizuje kilka
podstawowych aspektów pracy sieci domowej. Wielu użytkownikom jednak jest nieustannie potrzebna
jakaś nowa funkcjonalność, której oryginalny firmware producenta nie oferuje. Dlatego też mamy do
dyspozycji OpenWRT będący minimalistyczną formą bardziej rozbudowanej dystrybucji linux&#39;a. Może i
OpenWRT daje nam możliwość zaawansowanej konfiguracji naszej sieci ale tego typu opcja powoduje też
szereg problemów. Chodzi o to, że kernel dynamicznie tworzy nazwy dla wszystkich podłączanych
urządzeń do routera. W dużych dystrybucjach linux&#39;a do ogarnięcia tych nazw wykorzystywany jest
UDEV. W przypadku OpenWRT też możemy skorzystać tego mechanizmu. Jeśli jednak mamy niewiele miejsca
na pamięci flash routera, to możemy też skorzystać ze zdarzeń hotplug. W tym wpisie postaramy się
przepisać nazwy pendrive/dysków twardych oraz modemów USB (LTE), tak by ich kolejność podłączania do
routera nie stwarzała problemów w konfiguracji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Most bezprzewodowy w OpenWRT (tryb WDS)</title>
      <link>https://morfikov.github.io/post/most-bezprzewodowy-openwrt-tryb-wds/</link>
      <pubDate>Sun, 19 Jun 2016 16:32:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/most-bezprzewodowy-openwrt-tryb-wds/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Wireless_Distribution_System&#34;&gt;Tryb WDS (Wireless Distribution
System)&lt;/a&gt; umożliwia stworzenie mostu
bezprzewodowego, w którym to nadrzędny AP (Access Point) przekazuje pakiety do klientów WDS. Ci z
kolei przesyłają te pakiety dalej do podrzędnych AP. Z reguły routery posiadają funkcję WDS i po jej
aktywowaniu, ten drugi AP będzie wzmacniał i rozsyłał otrzymany sygnał dalej w granicach swojego
zasięgu. Tryb WDS nie jest jednak standardem i producenci firmware oraz sterowników implementują go
inaczej, co przekłada się na problemy z kompatybilnością. Jeśli chcemy korzystać z opcji WDS w
OpenWRT, to najlepiej posiadać kilka takich samych urządzeń i dobrze jest mieć na nich wgrane to
samo oprogramowanie. W tym wpisie zaprojektujemy sobie taki most bezprzewodowy w oparciu o dwa
routery firmy TP-LINK: &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WDR3600.html&#34;&gt;TL-WDR3600 v1&lt;/a&gt;
oraz &lt;a href=&#34;http://www.tp-link.com.pl/products/details/Archer-C7.html&#34;&gt;Archer C7 v2&lt;/a&gt;, na których jest
wgrany firmware OpenWRT Chaos Calmer 15.05.1 .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja WISP w OpenWRT (tryb STA &#43; AP)</title>
      <link>https://morfikov.github.io/post/konfiguracja-wisp-openwrt-tryb-sta-ap/</link>
      <pubDate>Sat, 18 Jun 2016 22:13:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-wisp-openwrt-tryb-sta-ap/</guid>
      <description>&lt;p&gt;Routery wyposażone w firmware OpenWRT mają tę zaletę, że ich bezprzewodowe karty sieciowe można w
miarę dowolnie sobie skonfigurować. Oryginalne oprogramowanie producenta takiego sprzętu zwykle nie
umożliwia nam przełączenia kart routera w inny tryb niż AP (Access Point). W OpenWRT możemy ustawić
praktycznie dowolny tryb, o ile pozwala na to sterownik karty WiFi. W ten sposób możemy aktywować,
np. &lt;a href=&#34;https://morfikov.github.io
/post/karta-wifi-trybie-monitor-openwrt/&#34;&gt;tryb MONITOR&lt;/a&gt;. W tym wpisie jednak
będzie nas interesował tryb STA (STATION), czyli postaramy się przełączyć karty WiFi routera w tryb
klienta. Jest to bardzo przydatna opcja w przypadku, gdy mamy do czynienia z &lt;a href=&#34;https://pl.wikipedia.org/wiki/WISP&#34;&gt;Wireless Internet
Service Provider (WISP)&lt;/a&gt;, czyli bezprzewodowymi dostawcami
internetu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Narzędzia nice, renice, ionice, taskset i trickle</title>
      <link>https://morfikov.github.io/post/nice-renice-ionice-taskset-trickle/</link>
      <pubDate>Thu, 16 Jun 2016 21:35:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/nice-renice-ionice-taskset-trickle/</guid>
      <description>&lt;p&gt;W każdym systemie operacyjnym cała masa procesów rywalizuje ze sobą o zasoby, w skład których
wchodzą min. pamięć operacyjna RAM, procesor i operacje I/O dysku twardego. Czasami zdarza się tak,
że niektóre aplikacje są w stanie zdusić inne programy, bo mają zbyt duże wymagania co do zasobów
systemowych. W takich przypadkach administrator systemu powinien zatroszczyć się o przydział zasobów
konkretnym procesom. W linux&#39;ie do tego typu prac przeznaczony jest &lt;a href=&#34;https://morfikov.github.io
/post/ograniczanie-zasobow-procesom-przez-cgroups/&#34;&gt;mechanizm
cgroups&lt;/a&gt; obecny w kernelu.
Niemniej jednak, jeśli cgroups przerasta nasze umiejętności albo też z jakiegoś powodu nie możemy z
niego korzystać, to istnieje inne rozwiązanie, które może nam pomóc ograniczyć zasoby przydzielane
procesom przez nasz system. Chodzi generalnie o narzędzia &lt;code&gt;nice&lt;/code&gt;/&lt;code&gt;renice&lt;/code&gt; (procesor) , &lt;code&gt;ionice&lt;/code&gt;
(dysku twardy) , &lt;code&gt;taskset&lt;/code&gt; (przypisanie procesu do konkretnego procesora) oraz &lt;code&gt;trickle&lt;/code&gt; (sieć). W
tym wpisie zobaczymy jak przy pomocy tych powyższych narzędzi limitować procesy systemowe.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Karta WiFi w trybie MONITOR w OpenWRT</title>
      <link>https://morfikov.github.io/post/karta-wifi-trybie-monitor-openwrt/</link>
      <pubDate>Wed, 15 Jun 2016 20:33:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/karta-wifi-trybie-monitor-openwrt/</guid>
      <description>&lt;p&gt;Routery WiFi, zwłaszcza te na podzespołach firmy Qualcomm, mają zwykle bardzo dobre wsparcie w
alternatywnym firmware OpenWRT. Te bezprzewodowe routery posiadają na pokładzie zwykle jedną lub
dwie karty WiFi, w zależności od obsługiwanego pasma (2,4 GHz i/lub 5 GHz). Karty tych routerów
działają standardowo w trybie AP (Access Point), czyli &lt;a href=&#34;https://pl.wikipedia.org/wiki/Punkt_dost%C4%99pu&#34;&gt;punktu
dostępowego&lt;/a&gt;. W taki sposób jesteśmy w stanie
bezprzewodowo połączyć szereg urządzeń w sieci domowej z internetem. Niemniej jednak, karta WiFi
może pracować w kilku innych trybach. W tym wpisie zobaczymy jak przełączyć kartę WiFi routera w
tryb MONITOR.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Router OpenWRT jako serwer i klient RADIUS</title>
      <link>https://morfikov.github.io/post/router-openwrt-jako-serwer-klient-radius/</link>
      <pubDate>Wed, 15 Jun 2016 07:17:07 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/router-openwrt-jako-serwer-klient-radius/</guid>
      <description>&lt;p&gt;Ten poniższy artykuł ma na celu pokazanie w jaki sposób stworzyć infrastrukturę WiFi w oparciu o
oprogramowanie &lt;code&gt;freeradius&lt;/code&gt; (serwer RADIUS), które zostanie zainstalowane na przykładowym routerze
&lt;a href=&#34;http://www.tp-link.com.pl/products/details/Archer-C7.html&#34;&gt;TP-Link Archer C7 v2&lt;/a&gt;. Router ma wgrany
firmware OpenWRT Chaos Calmer w wersji 15.05.1 (r49294). Zostanie tutaj opisane dokładnie jak
wdrożyć protokół WPA2 Enterprise z obsługą trzech metod uwierzytelniania: EAP-TLS, EAP-TTLS oraz
PEAP (v0) .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Skrypt dhclient&#39;a (dhclient script)</title>
      <link>https://morfikov.github.io/post/skrypt-dhclienta-dhclient-script/</link>
      <pubDate>Tue, 14 Jun 2016 16:26:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/skrypt-dhclienta-dhclient-script/</guid>
      <description>&lt;p&gt;Jak wiele osób zapewne wie, szereg dystrybucji linux&#39;a wykorzystuje &lt;code&gt;dhclient&lt;/code&gt; w celu pobrania
sieciowej konfiguracji hosta za sprawą protokółu DHCP. W zasadzie cała konfiguracja tego narzędzia
sprowadza się do określenia szeregu opcji w pliku &lt;code&gt;/etc/dhcp/dhclient.conf&lt;/code&gt; . W debianie nawet nie
musimy dotykać tego pliku, by wszystko działało nam jak trzeba. Niemniej jednak, czasem konfiguracja
interfejsów sieciowych może wymagać od nas dodatkowych zabiegów. W celu ułatwienia życia adminom
dodano obsługę skryptów shell&#39;owych
(&lt;a href=&#34;http://manpages.ubuntu.com/manpages/xenial/en/man8/dhclient-script.8.html&#34;&gt;dhclient-script&lt;/a&gt;). Taki
skrypt jesteśmy w stanie wywołać w zależności od zaistniałych zdarzeń protokołu DHCP. W tym wpisie
zostanie pokazane w jaki sposób te skrypty możemy utworzyć i wykorzystać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja interfejsów sieciowych w dhclient</title>
      <link>https://morfikov.github.io/post/konfiguracja-interfejsow-sieciowych-w-dhclient/</link>
      <pubDate>Thu, 09 Jun 2016 18:05:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-interfejsow-sieciowych-w-dhclient/</guid>
      <description>&lt;p&gt;Konfiguracja maszyn w sieci za sprawą protokołu DHCP znacznie ułatwia życie administratorom. Cały
ten proces jest nie tylko szybszy ale też eliminuje szereg błędów, które mogą pojawić się za sprawą
czynnika ludzkiego. W przypadku, gdy nasza maszyna dysponuje kilkoma interfejsami sieciowymi, to
każdy z nich możemy skonfigurować nieco inaczej. Oczywiście, nie chodzi o samą konfigurację
adresacji ale o szereg parametrów, które klient przesyła do serwera DHCP. To dzięki nim host min.
wie jak ustawić adresację na interfejsie i pod jaki adres słać zapytania DNS. Każdy interfejs może w
ten sposób posiadać własne opcje, które klient DHCP będzie przesyłał do serwera. W tym artykule
postaramy się konfigurować niezależnie dwa interfejsy sieciowe przy pomocy &lt;code&gt;dhclient&lt;/code&gt; , czyli
domyślnego klienta DHCP w linux&#39;ie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak odszukać pliki utworzone godzinę temu (find)</title>
      <link>https://morfikov.github.io/post/jak-odszukac-pliki-utworzone-godzine-temu-find/</link>
      <pubDate>Thu, 09 Jun 2016 12:44:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-odszukac-pliki-utworzone-godzine-temu-find/</guid>
      <description>&lt;p&gt;W linux&#39;ie wszystko może być reprezentowane za pomocą pliku. Te pliki są tworzone, zmieniane i
usuwane praktycznie non stop podczas pracy systemu operacyjnego. Zwykle też nie zwracamy uwagi na
metadane opisujące pliki w systemie plików, bo przecie bardziej interesuje nas ich zawartość.
Niemniej jednak, w pewnych sytuacjach te metadane mogą się okazać bardzo użyteczne. Weźmy sobie
przykład partycji &lt;code&gt;/home/&lt;/code&gt; . Prawie zawsze po odpaleniu aplikacji są tworzone na niej nowe pliki lub
zmieniane te już istniejące. Jako, że nie zawsze wiemy na jakich plikach operuje dany program, to
moglibyśmy przeszukać pliki w katalogu domowym użytkownika i poddać analizie ich czas modyfikacji.
Taką operacje możemy przeprowadzić przy pomocy polecenia &lt;code&gt;find&lt;/code&gt; i w tym wpisie zobaczymy jak tego
dokonać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uruchamianie zadań cron co 15 minut lub 6 godzin</title>
      <link>https://morfikov.github.io/post/zadania-cron-co-15-minut-lub-6-godzin/</link>
      <pubDate>Tue, 07 Jun 2016 18:56:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zadania-cron-co-15-minut-lub-6-godzin/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Cron&#34;&gt;cron&lt;/a&gt; to takie linux&#39;owe narzędzie, które cyklicznie, co pewien
ustalony interwał czasu, wykonuje jakieś zaplanowane zadania. Minimalna wartość tego interwału to
jedna minuta. Niemniej jednak, bardzo wielu użytkowników linux&#39;a zastanawia się w jaki sposób
wywołać określone zadanie, np. co 5, 10, 15, 30 minut, czy nawet co 2, 6 albo 12 godzin. Dlatego
właśnie powstał ten wpis, by nieco przybliżyć mechanikę samego cron&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Data i czas utworzenia pliku w linux&#39;ie (crtime)</title>
      <link>https://morfikov.github.io/post/data-czas-utworzenia-pliku-w-linuxie-crtime/</link>
      <pubDate>Tue, 07 Jun 2016 17:07:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/data-czas-utworzenia-pliku-w-linuxie-crtime/</guid>
      <description>&lt;p&gt;Systemy plików, które wykorzystujemy na partycjach swoich dysków, zawierają metadane opisujące
pliki. Domyślnym systemem plików w większości linux&#39;ów (do nich zalicza się też debian) jest EXT4.
Gdy listujemy pliki przy pomocy narzędzia &lt;code&gt;ls&lt;/code&gt; , jesteśmy w stanie uzyskać szereg informacji
opisujących konkretny plik. Mamy tam min. czas ostatniej modyfikacji i-węzła (i-node), czyli tzw.
&lt;code&gt;ctime&lt;/code&gt; . Narzędzia takie jak &lt;code&gt;stat&lt;/code&gt; są w stanie podać również inne czasy, tj. &lt;code&gt;atime&lt;/code&gt; (ostatni czas
dostępu do pliku) oraz &lt;code&gt;mtime&lt;/code&gt; (ostatni czas modyfikacji pliku). Jednak żaden z tych powyższych nie
przekłada się na czas utworzenia pliku. Co prawda, po stworzeniu pliku, wszystkie te czasy są ze
sobą zsynchronizowane ale po przeprowadzeniu szeregu różnych operacji na tym pliku, problematyczne
może być ustalenie pierwotnej daty jego utworzenia. Celem tego artykułu jest pokazanie, jak przy
pomocy &lt;code&gt;debugfs&lt;/code&gt; uzyskać czas utworzenia dowolnie wskazanego pliku w systemie plików EXT4.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>FZF (fuzzy finder) dla tmux&#39;a</title>
      <link>https://morfikov.github.io/post/fzf-fuzzy-finder-dla-tmuxa/</link>
      <pubDate>Mon, 06 Jun 2016 10:47:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/fzf-fuzzy-finder-dla-tmuxa/</guid>
      <description>&lt;p&gt;Jakiś czas temu pisałem o &lt;a href=&#34;https://morfikov.github.io
/post/implementacja-multipleksera-tmux/&#34;&gt;implementacji tmux&#39;a na
debianie&lt;/a&gt;. Dla tych, którzy nie za bardzo
wiedzą &lt;a href=&#34;https://tmux.github.io/&#34;&gt;czym tmux jest&lt;/a&gt;, to wyjaśniam, że jest to narzędzie, które min.
potrafi dzielić okno terminala na kilka mniejszych okienek. W ten sposób możemy korzystać ze swojego
ulubionego terminala i cieszyć się funkcjonalnością znaną choćby z terminatora. Ta umiejętność
dzielenia okien w tmux idealnie współgra z &lt;a href=&#34;https://github.com/junegunn/fzf&#34;&gt;FZF (fuzzy finder)&lt;/a&gt;.
Jest to narzędzie, które pomaga min. przeszukiwać historię poleceń shell&#39;a. BASH czy ZSH są, jakby
nie patrzeć, dość ograniczone pod tym względem. Może i ZSH nieco lepiej radzi sobie z odnajdywaniem
poleceń w historii od BASH ale i tak jego umiejętności pozostają daleko w tyle za FZF. Dlatego też w
tym artykule spróbujemy sobie zainstalować ten cały &amp;quot;fuzzy finder&amp;quot;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Losowy adres MAC dla WAN w OpenWRT</title>
      <link>https://morfikov.github.io/post/losowy-adres-mac-dla-wan-w-openwrt/</link>
      <pubDate>Sun, 05 Jun 2016 18:28:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/losowy-adres-mac-dla-wan-w-openwrt/</guid>
      <description>&lt;p&gt;Na dużych dystrybucjach linux&#39;a adres MAC można zmienić bez problemu. Podobnie sprawa ma się w
przypadku &lt;a href=&#34;https://morfikov.github.io
/post/jak-przypisac-losowy-adres-mac-interfejsu/&#34;&gt;automatycznego generowania takiego adresu
MAC&lt;/a&gt; za każdym razem, gdy chcemy
nawiązać połączenie z internetem. W OpenWRT rozwiązanie tego zadania nie jest tak oczywiste jak, np.
na debianie, ale też znowu nie jest niemożliwe. W repozytorium OpenWRT mamy dostępny pakiet
&lt;code&gt;macchanger&lt;/code&gt; . Niemniej jednak, w przypadku routerów o małych pamięciach flash, instalowanie
dodatkowych pakietów może nie być dobrym pomysłem. Przydałoby się zatem zaprojektować mechanizm
generowania i zmiany adresu MAC interfejsu WAN za każdym razem, gdy będziemy resetować router i to
zadanie postaramy się zrealizować w tym artykule.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wyczyścić tablicę conntrack&#39;a w debianie</title>
      <link>https://morfikov.github.io/post/jak-wyczyscic-tablice-conntrack-w-debianie/</link>
      <pubDate>Sun, 05 Jun 2016 12:34:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wyczyscic-tablice-conntrack-w-debianie/</guid>
      <description>&lt;p&gt;Sporo użytkowników lunux&#39;a, zwłaszcza dystrybucji debian, korzysta z własnych skryptów firewall&#39;a
aplikujących reguły &lt;code&gt;iptables&lt;/code&gt; . Tego typu rozwiązanie ma jednak swoje wady i zalety. Niewątpliwie
do zalet można zaliczyć brak dodatkowego oprogramowania obsługującego zaporę sieciową. Jeśli chodzi
zaś o wady, to niestety cały skrypt trzeba sobie dobrze przemyśleć przed zaaplikowaniem. Ludzie
często zapominają tutaj o śledzeniu połączeń przez kernel. To właśnie na podstawie wpisów w
&lt;code&gt;/proc/net/ip_conntrack&lt;/code&gt; lub &lt;code&gt;/proc/net/nf_conntrack&lt;/code&gt; system wie, które pakiety należy na zaporze
przepuścić, a które zablokować. Jeśli teraz dodajemy reguły do filtra &lt;code&gt;iptables&lt;/code&gt; , to nowa polityka
zapory nie będzie odnosić się do tych nawiązanych już połączeń, które są określone w tablicy
conntrack&#39;a. By się upewnić, że tego typu scenariusz nigdy nas nie spotka, musimy tę tablicę
opróżnić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja trybu AP kart WiFi na debianie</title>
      <link>https://morfikov.github.io/post/konfiguracja-trybu-ap-kart-wifi-na-debianie/</link>
      <pubDate>Sat, 04 Jun 2016 15:26:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-trybu-ap-kart-wifi-na-debianie/</guid>
      <description>&lt;p&gt;Jakiś czas temu dokonałem zakupu adaptera WiFi &lt;a href=&#34;https://morfikov.github.io
/post/recenzja-karta-wifi-tp-link-tl-wn722n/&#34;&gt;TP-Link
TL-WN722n&lt;/a&gt;, a to z tego względu, że
potrzebowałem zewnętrznej karty sieciowej do mojego laptopa. Chodziło generalnie o to, że ten
wbudowany w niego broadcom nie był w stanie robić kilku użytecznych rzeczy, min. testów
penetracyjnych mojej bezprzewodowej sieci domowej. Jak się później okazało, ten zakupiony adapter
posiada też dodatkowy ficzer, którym jest tryb AP (Access Point). Wprawdzie ta karta nie może się
równać z routerami WiFi, bo te zwykle mają więcej anten, z których każda jest lepszej jakości ale
jesteśmy w stanie połączyć ze sobą bezprzewodowo kilka stacji roboczych. Trzeba jednak wziąć po
uwagę, że zasięg jak i transfer będą w dużej mierze ograniczone. W tym wpisie postaramy się
przerobić zwykłą maszynę, na której jest zainstalowany debian, na punkt dostępowy sieci WiFi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sparse files (rozrzedzone pliki)</title>
      <link>https://morfikov.github.io/post/sparse-files-rozrzedzone-pliki/</link>
      <pubDate>Thu, 02 Jun 2016 16:42:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sparse-files-rozrzedzone-pliki/</guid>
      <description>&lt;p&gt;Każdy system plików opiera się na blokach danych. Standardowo taki blok w systemie plików EXT4 ma 4
KiB (8 x 512 bajtów). Za każdym razem, gdy tworzymy jakiś plik na dysku, alokowana jest pewna część
bloków, na których ten plik ma zostać zapisany. Te większe pliki rezerwują więcej bloków, choć nie
zawsze są to bloki ciągłe. W taki sposób, plik o rozmiarze 10 GiB okupowałby dokładnie tyle miejsca
na dysku ile sam waży. Niemniej jednak są pewne pliki, które może i ważą te 10 GiB ale system plików
postrzega je tak jakby miały 100 MiB czy 200 MiB, w zależności od tego ile &amp;quot;faktycznie&amp;quot; taki plik
zajmuje miejsca. Jak to możliwe? Pliki, o których mowa, to tzw. &amp;quot;rozrzedzone pliki&amp;quot; (&lt;a href=&#34;https://en.wikipedia.org/wiki/Sparse_file&#34;&gt;Sparse
files&lt;/a&gt;). Taki plik składa się z szeregu bloków pustych
(mających same zera), których nie trzeba zapisywać na dysk. Zamiast tego, można jedynie zapisać
metadane w strykturze systemu plików, które będą opisywać te puste bloki. Poniższy artykuł ma na
celu pokazać do czego takie pliki sparse mogą nam się przydać i jak z nich korzystać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: karta WiFi TP-LINK Archer T4U</title>
      <link>https://morfikov.github.io/post/recenzja-karta-wifi-tp-link-archer-t4u/</link>
      <pubDate>Wed, 01 Jun 2016 17:14:59 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-karta-wifi-tp-link-archer-t4u/</guid>
      <description>&lt;p&gt;Ilość punktów dostępowych w paśmie 2,4 GHz rośnie bardzo szybko. Obecnie spora część użytkowników
laptopów czy smartfonów zdolnych łączyć się bezprzewodowo korzysta z ruterów WiFi w swoim domowym
zaciszu. W przypadku zatłoczonych blokowisk i innych większych skupisk ludzkich, transfer w paśmie
2,4 GHz może nie być za duży. By rozwiązać ten problem, wprowadzono urządzenia nadające w paśmie 5
GHz. Są one nieco droższe, bo i technologia jest nieco nowsza. Niemnie jednak, pasmo 5 GHz idealnie
nadaje się do zastosowań miejskich. Chodzi generalnie o mniejszy zasięg punktu dostępowego, a co z
tym się wiąże, mniejszą ilością zakłóceń, które osłabiają transfer w sieci bezprzewodowej. Sporo
routerów WiFi ma już zaimplementowane dwa radia, po jednym dla każdego z w/w pasm i przydałoby się
powoli postarać o zakup karty/adaptera pracującego w standardzie AC. Tak się składa, że mam na
składzie dwuzakresowy adapter Archer T4U (czip Realtek RTL8812AU), który został mi sprezentowany
przez firmę TP-LINK. Postaram go zatem opisać w tym artykule.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: karta WiFi TP-LINK TL-WN722N</title>
      <link>https://morfikov.github.io/post/recenzja-karta-wifi-tp-link-tl-wn722n/</link>
      <pubDate>Tue, 31 May 2016 17:22:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-karta-wifi-tp-link-tl-wn722n/</guid>
      <description>&lt;p&gt;Karty WiFi implementowane w różnego rodzaju laptopach zwykle są dość przyzwoite. Przynajmniej do
czasu aż użytkownik zapragnie korzystać z alternatywnego systemu operacyjnego z rodziny linux. W
takim przypadku często okazuje się, że większość kart bezprzewodowych pracuje na układach, których
sterowniki nie są wolne i nie ma ich dostępnych w linux&#39;owym kernelu. Czasem takie karty można
zmusić do pracy ale uzyskana w ten sposób prędkość transferu zbytnio nie zachwyca. Jedynym
przyzwoitym rozwiązaniem jest zakup zewnętrznego adaptera WiFi, który pracuje na czipie wspieranym
przez kernel. Zwykle są to karty na układach od firmy &lt;a href=&#34;https://en.wikipedia.org/wiki/Qualcomm_Atheros&#34;&gt;QUALCOMM
ATHEROS&lt;/a&gt;. W tym artykule weźmiemy sobie pod lupę
adapter &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WN722N.html&#34;&gt;TL-WN722N&lt;/a&gt; od firmy TP-LINK,
który działa w standardzie N (pasmo 2,4 GHz, transfer do 150 mbit/s).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: router TP-LINK TL-WR1043ND v2</title>
      <link>https://morfikov.github.io/post/recenzja-sprzetu-router-tp-link-tl-wr1043nd-v2/</link>
      <pubDate>Tue, 31 May 2016 15:14:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-sprzetu-router-tp-link-tl-wr1043nd-v2/</guid>
      <description>&lt;p&gt;Jednym z popularniejszych routerów bezprzewodowych firmy TP-LINK jest model &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WR1043ND.html&#34;&gt;TL-WR1043ND
v2&lt;/a&gt; . Dlaczego ten router jest tak
rozchwytywany? Wytłumaczenie tkwi w alternatywnym firmware OpenWRT, który daje znaczne możliwości
rozbudowania funkcjonalności tego urządzenia. Jest to chyba jeden z najlepiej wpieranych przez
OpenWRT modeli, co zapewnia bezproblemowe użytkowanie. Niewątpliwą zaletą TL-WR1043ND v2 jest dość
silne WiFi, choć mamy do dyspozycji tylko pamso 2,4 GHz. Standardowo na wyposażeniu mamy także
gigabitowy switch 5-cio portowy oraz tylko jeden port USB 2.0. Przy czym, ten jeden port USB nie
powinien nam zbytnio przeszkadzać, zwłaszcza jeśli dysponujemy aktywnym hubem USB. W tym wpisie
przyjrzymy się nieco bliżej temu routerowi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recenzja: router TP-LINK Archer C7 v2</title>
      <link>https://morfikov.github.io/post/recenzja-router-tp-link-archer-c7-v2/</link>
      <pubDate>Mon, 30 May 2016 22:23:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/recenzja-router-tp-link-archer-c7-v2/</guid>
      <description>&lt;p&gt;Routery bezprzewodowe to bardzo użyteczne urządzenia i na dobrą sprawę każdy dom powinien posiadać
jeden taki wynalazek. Na rynku jest cała masa sprzętu WiFi, który w większości przypadków zaspokoi
gust kupujących ale też trzeba wziąć pod uwagę fakt, że nie wszystkie routery posiadają pożądane
przez nas ficzery. Część routerów ma tylko jedno radio, zwykle o zakresie 2,4 GHz. Te droższe modele
mają także radio 5GHz. Routery różnią się także ilością portów w switch&#39;u, ilością pamięci RAM,
częstotliwością pracy procesora, no i rozmiarem pamięci flash. Wszystkie te cechy trzeba wziąć pod
uwagę przy próbie ewentualnego zakupu routera bezprzewodowego. Oczywiście spora część z tych
gabarytów będzie miała znaczenie tylko w przypadku zainstalowania alternatywnego firmware, np.
OpenWRT. Niemniej jednak, dobrze zdawać sobie sprawę z tego co dany router ma pod obudową. W tym
wpisie zostanie przedstawiony router &lt;a href=&#34;http://www.tp-link.com.pl/products/details/Archer-C7.html&#34;&gt;TP-LINK Archer C7
v2&lt;/a&gt;, obsługujący pasma 2.4 GHz i 5 GHz,
mający 128 MiB pamięci RAM, 16 MiB flash, gigabitowy switch 5-cio portowy i dwa porty USB 2.0 .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ukryć user-agent w nagłówku email</title>
      <link>https://morfikov.github.io/post/jak-ukryc-user-agent-w-naglowku-email/</link>
      <pubDate>Sun, 29 May 2016 12:05:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ukryc-user-agent-w-naglowku-email/</guid>
      <description>&lt;p&gt;Na każdym kroku można natknąć się na przecieki informacyjne, które zagrażają naszej prywatności.
Widzieliśmy to choćby i na przykładzie &lt;a href=&#34;https://morfikov.github.io
/post/jak-ukryc-prywatny-adres-ip-w-naglowku-email/&#34;&gt;prywatnego adresu IP widocznego w nagłówku w wiadomości
email&lt;/a&gt;. Przeglądając ten
podlinkowany wpis mogliśmy z grubsza zobaczyć jak wygląda taki nagłówek wiadomości. Bardziej uważni
czytelnicy zwrócili uwagę na jego zawartość. Poza polem zawierającym adres IP, można było też
zobaczyć pole odpowiadające za &lt;a href=&#34;https://pl.wikipedia.org/wiki/User_agent&#34;&gt;user-agent&lt;/a&gt;. Ciąg zawarty
w tym polu zdradza informacje na temat wykorzystywanego klienta pocztowego oraz systemu
operacyjnego. Ten komunikat możemy jednak ukryć i w tym wpisie zostanie to pokazane na przykładzie
&lt;a href=&#34;https://www.mozilla.org/pl/thunderbird/&#34;&gt;Thunderbird&#39;a&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ukryć prywatny adres IP w nagłówku email</title>
      <link>https://morfikov.github.io/post/jak-ukryc-prywatny-adres-ip-w-naglowku-email/</link>
      <pubDate>Sat, 28 May 2016 18:29:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ukryc-prywatny-adres-ip-w-naglowku-email/</guid>
      <description>&lt;p&gt;Korzystając z różnego rodzaju klientów email udostępniamy serwerom mailowym nieco więcej informacji
niż gdybyśmy to robili z panelu webowego serwera pocztowego. Chodzi generalnie o adres IP hosta,
który przesłał wiadomość na serwer. Tradycyjnie w nagłówku email&#39;a znajdzie się nasz adres
zewnętrzny, ten przypisany przez ISP. Niemniej jednak, w części przypadków będzie załączony również
adres IP z przestrzeni prywatnej, np. 10.0.0.0/8 lub 192.168.0.0/16 . O ile nie damy rady zataić
publicznego IP naszego ISP, to jesteśmy w stanie ukryć ten prywatny adres i tym samym nieco poprawić
naszą prywatność. W tym wpisie zostanie pokazane, to jak ten adres prywatny ukryć w nagłówku
wiadomości email w kliencie &lt;a href=&#34;https://www.mozilla.org/pl/thunderbird/&#34;&gt;Thunderbird&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ukryć hostname w protokole DHCP</title>
      <link>https://morfikov.github.io/post/jak-ukryc-hostname-w-protokole-dhcp/</link>
      <pubDate>Tue, 24 May 2016 20:07:14 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ukryc-hostname-w-protokole-dhcp/</guid>
      <description>&lt;p&gt;Darmowe hotspoty sieci WiFi są dostępne w każdym mieście. Dzięki nim możemy uzyskać połączenie z
internetem praktycznie za free. Niemniej jednak, takie połączenie nie jest do końca bezpieczne i
może zagrażać naszej prywatności. Wiele osób stara się temu przeciwdziałać &lt;a href=&#34;https://morfikov.github.io
/post/jak-przypisac-losowy-adres-mac-interfejsu/&#34;&gt;generując losowy adres
MAC&lt;/a&gt;. No i to jest jakieś
wyjście, o ile ten adres jest generowany z głową. Niemniej jednak, w takich sieciach WiFi, host ma
przydzielaną adresację za pomocą &lt;a href=&#34;https://pl.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol&#34;&gt;protokołu
DHCP&lt;/a&gt;. Ci, którzy wiedza, jak
odbywa się konfiguracja za pomocą tego protokołu, wiedzą też, że nasz komputer przesyła pewne dane
do serwera DHCP. Jakie dane? To zwykle zależy od konfiguracji klienta DHCP. Na linux&#39;ach domyślnym
klientem DHCP jest &lt;code&gt;dhclinet&lt;/code&gt; i on standardowo przesyła nazwę hosta (hostname) w zapytaniu o
adresację. Co nam zatem po losowym adresie MAC, gdy można nas zidentyfikować po nazwie hosta? W tym
artykule postaramy się ukryć lub też losowo wygenerować hostname danej maszyny w sieci.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja DDNS dla OpenDNS</title>
      <link>https://morfikov.github.io/post/konfiguracja-ddns-dla-opendns/</link>
      <pubDate>Mon, 23 May 2016 20:09:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-ddns-dla-opendns/</guid>
      <description>&lt;p&gt;Ludzkość w dalszym ciągu siedzi na przestarzałym już od prawie 20 lat protokole IPv4. Nie widać, też
by w najbliższym czasie coś miało się w tej kwestii zmienić. Można, co prawda, wykupić sobie stały
adres IP ale to kosztuje, no i płacimy za coś co powinniśmy mieć w standardzie, gdyby ludzie w końcu
zaczęli korzystać z IPv6. Niemniej jednak, by te wszystkie nasze maszyny podłączyć jakoś do sieci,
potrzebne nam są prywatne adresy IP + NAT lub też dynamicznie zmieniające się adresy publiczne.
Bywają też przypadki, że mamy przydzielane dynamicznie adresy z puli prywatnej, np. w wyniku dbania
o prywatność w sieciach WiFi przez &lt;a href=&#34;https://morfikov.github.io
/post/jak-przypisac-losowy-adres-mac-interfejsu/&#34;&gt;generowanie sobie przy każdym połączeniu losowego adresu
MAC&lt;/a&gt;. Zwykle w takiej sytuacji
zmienia nam się adres zewnętrzny (publiczny), który wskazuje na jeden z adresów naszego ISP. Taki
zmieniający się adres powoduje problemy przy konfiguracji poszczególnych usług sieciowych, np. gdy w
grę wchodzi konfiguracja filtra DNS, który jest zapewniany przez OpenDNS. By tego typu niedogodności
rozwiązać, możemy posłużyć się &lt;a href=&#34;https://pl.wikipedia.org/wiki/DDNS&#34;&gt;DDNS (dynamic DNS)&lt;/a&gt;. Za każdym
razem, gdy adres IP ulega zmianie, klient DDNS informuje o tym fakcie skonfigurowane usługi. W tym
artykule przyjrzymy się nieco bliżej temu mechanizmowi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Równoważenie ruchu łącz kilku ISP (load balancing)</title>
      <link>https://morfikov.github.io/post/rownowazenie-ruchu-lacz-kilku-isp-load-balancing/</link>
      <pubDate>Sun, 22 May 2016 13:40:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/rownowazenie-ruchu-lacz-kilku-isp-load-balancing/</guid>
      <description>&lt;p&gt;Podłączenie pojedynczego komputera do sieci raczej nie stanowi żadnego problemu dla przeciętnego
użytkownika linux&#39;a. Wystarczy jedynie skonfigurować kilka parametrów i możemy oglądać swoje
ulubione serwisy www. Co jednak w przypadku, gdy mamy do dyspozycji kilka łącz internetowych? Jedną
z opcji jest używanie łącza tego ISP, które jest lepsze gabarytowo, a pozostałe łącza trzymać na
wypadek awarii tego pierwszego. Nie jest to zbytnio satysfakcjonujące rozwiązanie, zwłaszcza w
przypadku, gdy tym providerom płacimy za świadczone nam usługi. W taki sposób płacimy, np. za dwa
łącza, a korzystamy z jednego w danej chwili. W linux&#39;ie obsługa wielu łącz różnych ISP jest dość
skomplikowana. By taki mechanizm zaimplementować sobie, trzeba stworzyć kilka tablic routingu.
Następnie ruch sieciowy musi zostać oznaczony w &lt;code&gt;iptables&lt;/code&gt; i przekierowany do tych tablic przez
kernel. Przy odrobienie wysiłku jesteśmy jednak w stanie zaprojektować sobie load balancer, który
będzie równoważył obciążenie łącza między kilku ISP. Dodatkowo, jeśli jedno z łączy nam nawali, to
automatycznie zostaniemy przełączeni na drugie łącze (failover). W tym artykule postaramy się
zaprojektować taki właśnie mechanizm.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Statystyki routera w OpenWRT (collectd, rrdtool)</title>
      <link>https://morfikov.github.io/post/statystyki-openwrt-collectd-rrdtool/</link>
      <pubDate>Thu, 19 May 2016 21:38:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/statystyki-openwrt-collectd-rrdtool/</guid>
      <description>&lt;p&gt;Domowe routery WiFi chodzą zwykle 24 godziny na dobę. Ich moc obliczeniowa, choć zwykle niewielka,
czasem się marnuje. Mając router z OpenWRT, możemy przerobić go tak, by zbierał różnego rodzaju dane
dla statystyki. Te dane mogą pochodzić z różnych źródeł i nie koniecznie muszą one dotyczyć samego
routera. Tego typu funkcjonalność mogą zapewnić nam narzędzia &lt;code&gt;collectd&lt;/code&gt; oraz &lt;code&gt;rrdtool&lt;/code&gt; . W tym
artykule spróbujemy zaprogramować router, by zbierał pewne dane dotyczące połączenia sieciowego. Na
podstawie tych informacji będą rysowane wykresy, które nastepnie będą udostępniane przez serwer
&lt;code&gt;uhttpd&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Quality of Service (QoS) w OpenWRT</title>
      <link>https://morfikov.github.io/post/quality-service-qos-w-openwrt/</link>
      <pubDate>Thu, 19 May 2016 15:07:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/quality-service-qos-w-openwrt/</guid>
      <description>&lt;p&gt;Wszyscy spotkaliśmy się z sytuacją, w której z bliżej nieokreślonego powodu nie mogliśmy przeglądać
stron w internecie. Niby połączenie jest, mamy też dobrej klasy ISP ale net nam muli. W olbrzymiej
części przypadków winą można obarczyć sieć &lt;a href=&#34;https://pl.wikipedia.org/wiki/Peer-to-peer&#34;&gt;Peer to Peer
(P2P)&lt;/a&gt;. Przy nieodpowiedniej konfiguracji klientów tej
sieci może dojść do nawiązywania całej masy połączeń w ułamku chwili. W ten sposób nawet jeśli nic
aktualnie nie wysyłamy lub nie pobieramy, to i tak te połączenia same w sobie zapychają łącze, no bo
przecież nawet puste pakiety w protokołach TCP/UDP zawierają nagłówki, a te już swoje ważą. Gdy sami
korzystamy z łącza, to taka sytuacja nie stanowi większego problemu, bo wystarczy odpalić klienta
torrent&#39;a w wolnym czasie. Natomiast w przypadku, gdy zachodzi potrzeba wejścia na jakiś serwis www,
to możemy zwyczajnie tego klienta wyłączyć. Nie jest to jednak wygodne. Jak zatem wyeliminować
problemy związane z siecią P2P? Jeśli na routerze mamy wgrany firmware OpenWRT, to możemy
zaimplementować na nim &lt;a href=&#34;https://pl.wikipedia.org/wiki/Quality_of_service&#34;&gt;mechanizm QoS (Qality of
Service)&lt;/a&gt;. W ten sposób możemy nadać usługom
priorytety. W niniejszym wpisie postaramy się wdrożyć takie rozwiązanie w oparciu o narzędzia
&lt;code&gt;iptables&lt;/code&gt; oraz &lt;code&gt;tc&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Target MARK w iptables (sumowanie oznaczeń)</title>
      <link>https://morfikov.github.io/post/target-mark-w-iptables/</link>
      <pubDate>Wed, 18 May 2016 15:17:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/target-mark-w-iptables/</guid>
      <description>&lt;p&gt;Pakiety i połączenia można oznaczać w &lt;code&gt;iptables&lt;/code&gt; za pomocą target &lt;code&gt;MARK&lt;/code&gt; oraz &lt;code&gt;CONNMARK&lt;/code&gt; . Ta
właściwość tego filtra jest znana chyba większość użytkowników linux&#39;a. Z reguły nie interesujemy
się zbytnio szczegółami oznaczania pakietów/połączeń, bo zwykle jest ono przeprowadzane prawidłowo.
Niemniej jednak, są przypadki, w których markery nie będą ustawiane poprawnie. Chodzi o sytuacje,
gdzie mamy do czynienia z kilkoma mechanizmami oznaczającymi pakiety. Dla przykładu weźmy sobie
kształtowanie ruchu za pomocą narzędzia &lt;code&gt;tc&lt;/code&gt; oraz failover czy load balancing łącza w oparciu o
różne tablice routingu. W obu tych mechanizmach zwykle używa się markowania pakietów w &lt;code&gt;iptables&lt;/code&gt;
. Co się jednak dzieje z takim pakietem, gdy przechodzi przez reguły zarówno pierwszego jak i
drugiego mechanizmu? To właśnie spróbujemy ustalić w tym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Failover i load balancing w OpenWRT (mwan3)</title>
      <link>https://morfikov.github.io/post/failover-load-balancing-openwrt-mwan3/</link>
      <pubDate>Sun, 15 May 2016 13:37:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/failover-load-balancing-openwrt-mwan3/</guid>
      <description>&lt;p&gt;Może się zdarzyć tak, że będziemy mieli kiedyś dostęp do łącz kilku różnych providerów
internetowych. Jeśli chcielibyśmy skorzystać z internetu w takiej sytuacji, to trzeba by się
zdecydować na jednego z tych dostępnych ISP. Natomiast łącze pozostałych ISP będzie niewykorzystane
w tym danym momencie, a przecie nie za to im płacimy. Jeśli mamy router z OpenWRT i
&lt;a href=&#34;https://morfikov.github.io
/post/podzial-switcha-na-kilka-vlan-w-openwrt/&#34;&gt;skonfigurowaliśmy przy tym switch tak, by mieć kilka portów
WAN&lt;/a&gt;, to możemy korzystać z usług
wielu ISP w tym samym czasie. Oczywiście, ten mechanizm działa również w przypadku, gdy ISP świadczy
nam usługi za pomocą technologi LTE. Trzeba tylko odpowiednio &lt;a href=&#34;https://morfikov.github.io
/post/modem-lte-pod-openwrt/&#34;&gt;skonfigurować modem USB do pracy na
routerze&lt;/a&gt;. W tym artykule zostanie opisane &lt;a href=&#34;https://wiki.openwrt.org/doc/howto/mwan3&#34;&gt;narzędzie
mwan3&lt;/a&gt;, za pomocą którego zaprojektujemy sobie prosty
failover (łącze awaryjne) lub load balancing (równoważenie ruchu) mając do wykorzystania dwóch
różnych ISP.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>CUPS, czyli konfiguracja drukarki pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/cups-konfiguracja-drukarki-pod-linuxem/</link>
      <pubDate>Wed, 11 May 2016 21:45:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/cups-konfiguracja-drukarki-pod-linuxem/</guid>
      <description>&lt;p&gt;Ja jestem tym szczęśliwcem, który posiada takie fajne urządzenie zwane drukarką. Bardzo umila ono
życie pod warunkiem, że działa jak należy, a z tym różnie bywa, zwłaszcza pod linux&#39;em. W debianie
do obsługi drukarek używa się &lt;a href=&#34;https://en.wikipedia.org/wiki/CUPS&#34;&gt;CUPS (Common Unix Printing
System)&lt;/a&gt; i można powiedzieć, że radzi on sobie z tym zadaniem
całkiem nieźle, przynajmniej w przypadku mojej drukarki. Drukarka, o której mowa, to dość stary
model, konkretnie jest to EPSON Stylus Color 760. Potrzebne są jej odpowiednie sterowniki, które są
dostępne w repozytorium debiana. Jedyne czego potrzeba do szczęścia, to skonfigurowanie demona
&lt;code&gt;cupsd&lt;/code&gt; , który będzie zarządzał tą drukarką. W tym artykule postaramy się skonfigurować to powyższe
urządzenie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wake On LAN z etherwake pod OpenWRT</title>
      <link>https://morfikov.github.io/post/wake-lan-z-etherwake-pod-openwrt/</link>
      <pubDate>Wed, 11 May 2016 21:39:37 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wake-lan-z-etherwake-pod-openwrt/</guid>
      <description>&lt;p&gt;Router wyposażony w firmware OpenWRT potrafi wybudzać maszyny w sieci lokalnej. &lt;a href=&#34;https://pl.wikipedia.org/wiki/Wake_on_LAN&#34;&gt;Wake On LAN
(WOL)&lt;/a&gt; nie działa przez internet, a jedynie, jak sama
nazwa sugeruje, w sieci LAN. W tym mechanizmie wykorzystywany jest
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Broadcast&#34;&gt;broadcast&lt;/a&gt;, a routery nie forward&#39;ują pakietów
rozgłoszeniowych. Oczywiście, nic nie stoi na przeszkodzie, by zalogować się na router via SSH od
strony WAN i wybudzić jakąś maszynę z poziomu routera. Komputery, które chcemy budzić muszą mieć
odpowiednią płytę główną. Prawdopodobnie wszystkie nowsze płyty już taką właściwość posiadają.
Dodatkowo, trzeba w BIOS&#39;ie ustawić odpowiednie opcje. Ważną rzeczą jest, by nie wyłączać PC
przyciskiem w obudowie (lub na zasilaczu), bo wtedy nie będzie możliwe wybudzenie maszyny, nawet po
dostarczeniu jej zasilania. Wyłączenia maszyny musimy dokonać z poziomu systemu operacyjnego, tylko
wtedy WOL zadziała. W tym wpisie pokażemy jak przy pomocy &lt;code&gt;etherwake&lt;/code&gt; wybudzić określonego hosta w
sieci LAN.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Drukarka sieciowa w OpenWRT (serwer wydruku)</title>
      <link>https://morfikov.github.io/post/drukarka-sieciowa-w-openwrt-serwer-wydruku/</link>
      <pubDate>Wed, 11 May 2016 19:32:50 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/drukarka-sieciowa-w-openwrt-serwer-wydruku/</guid>
      <description>&lt;p&gt;OpenWRT daje możliwość doinstalowania całej masy aplikacji, które są w stanie realizować pewne dość
wyrafinowane zadania. Jednym z takich zadań jest serwer wydruku, czyli możliwość obsługi różnego
rodzaju drukarek. Jeśli nasz router posiada port USB, to taką drukarkę jesteśmy w stanie do niego
podłączyć. Nawet jeśli router dysponuje tylko jednym portem USB i do tego zajętym już, to nic nie
stoi na przeszkodzie, by dokupić HUB&#39;a i rozgałęzić sobie ten pojedynczy port. Serwer wydruku ma tę
zaletę, że drukarka jest udostępniana przez router w sieci domowej. W efekcie odpada nam
utrzymywanie dedykowanego komputera, który zajmowałby się tylko obsługą takiej drukarki. Możemy
zatem oszczędzić nieco na rachunku za prąd. W tym wpisie skonfigurujemy sobie właśnie taki serwer
wydruku w oparciu o drukarkę EPSON Stylus Color 760 i oprogramowanie &lt;code&gt;p910nd&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Debugowanie reguł iptables via target TRACE</title>
      <link>https://morfikov.github.io/post/debugowanie-regul-iptables-target-trace/</link>
      <pubDate>Wed, 11 May 2016 13:20:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/debugowanie-regul-iptables-target-trace/</guid>
      <description>&lt;p&gt;Linux&#39;owy firewall w postaci &lt;code&gt;iptables&lt;/code&gt; może czasami mieć zdefiniowanych sporo reguł. W takim
gąszczu jest czasem ciężko się odnaleźć. Bywa zwykle tak, że dodając kolejną regułę chcemy
przyblokować szereg pakietów, a mimo to przechodzą one przez zaporę jak gdyby nigdy nic. W takim
przypadku zaczyna się mozolne przeszukiwanie reguł w &lt;code&gt;iptables&lt;/code&gt; i próba ustalenia, którą z nich
zaakceptowała interesujący nas pakiet. Nie musimy jednak głowić się aż tak, by w miarę szybko dociec
jak te reguły przez filtr przechodzą i jak są przetwarzane. Możemy skorzystać z mechanizmu śledzenia
reguł, który jest wbudowany bezpośrednio w &lt;code&gt;iptables&lt;/code&gt; . Mowa oczywiście o target &lt;code&gt;TRACE&lt;/code&gt; . W tym
artykule zobaczymy jak przy pomocy &lt;code&gt;TRACE&lt;/code&gt; ustalić, przez które reguły i łańcuchy przechodzi pakiet.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zablokować Facebook i YouTube w OpenWRT</title>
      <link>https://morfikov.github.io/post/jak-zablokowac-facebook-youtube-openwrt/</link>
      <pubDate>Tue, 10 May 2016 22:17:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zablokowac-facebook-youtube-openwrt/</guid>
      <description>&lt;p&gt;Serwisy społecznościowe takie jak Facebook, Twitter czy YouTube coraz bardziej dają się we znaki
przedsiębiorcom, który muszą cały czas pilnować, by ich pracownicy nie siedzieli ciągle w
internecie, przynajmniej w czasie pracy. Problem nagminnego przebywania w tych w/w portalach można
bardzo łatwo rozwiązać przez... porozmawianie z pracownikami. No może nie zawsze ale co nam szkodzi
spróbować? W przypadku, gdy upomnienia nie są w stanie zmusić ludzi w naszej firmie do pracy, a nie
możemy przy tym ich zwolnić, to możemy pójść o krok dalej i spróbować im założyć blokadę na te
powyższe serwisy. Oczywiście blokada szeregu adresów IP nie wchodzi w rachubę. Korporacje typu
Facebook czy Google mają wiele adresów IP na których świadczą swoje usługi. Nie wszystkie z nich są
uwzględniane na różnego rodzaju listach. Niemniej jednak, tak na dobrą sprawę to nie musimy nawet
znać tych adresów. Jedyne czego nam potrzeba to nazwa domeny oraz kilka pakietów standardowo
dostępnych w repozytorium OpenWRT. Mowa o &lt;code&gt;iptables&lt;/code&gt; , &lt;code&gt;dnsmasq&lt;/code&gt; oraz &lt;code&gt;ipset&lt;/code&gt; . W OpenWRT, przy
pomocy tych narzędzi możemy zaprojektować filtr, który może zablokować ludziom z naszej sieci dostęp
do praktycznie każdego serwisu www. W tym artykule zobaczymy jak taki filtr skonstruować.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Filtr pakietów sieciowych w OpenWRT (firewall)</title>
      <link>https://morfikov.github.io/post/filtr-pakietow-sieciowych-w-openwrt-firewall/</link>
      <pubDate>Mon, 09 May 2016 23:26:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/filtr-pakietow-sieciowych-w-openwrt-firewall/</guid>
      <description>&lt;p&gt;Router wyposażony w firmware OpenWRT posiada wbudowany firewall, który ma za zadnie stać na straży
bezpieczeństwa naszej sieci domowej. Standardowo ta zapora przepuszcza cały ruch sieciowy z obszaru
LAN do WAN, czyli z sieci lokalnej do sieci naszego ISP. W ten sposób komputery znajdujące się w
naszej sieci mają dostęp do internetu i mogą z niego korzystać bez przeszkód. Niemniej jednak, ten
mechanizm nie działa tak samo w drugą stronę, czyli z WAN do LAN. Tutaj są już blokowane wszystkie
próby nawiązania nowych połączeń (&lt;a href=&#34;https://morfikov.github.io
/post/kompromitacja-firewalla-openwrt-za-sprawa-ping/&#34;&gt;za wyjątkiem żądań
ping&lt;/a&gt;) ale nic nie stoi na
przeszkodzie, by zastosować przekierowanie portów. Dzięki takiemu rozwiązaniu możemy przekierować
ruch, który jest kierowany na dany port w routerze, do określonego hosta w sieci lokalnej. Wszystkie
te zadania realizowane są przez &lt;code&gt;iptables&lt;/code&gt; i w tym wpisie postaramy się ogarnąć to narzędzie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NAT Reflection oraz NAT Loopback w OpenWRT</title>
      <link>https://morfikov.github.io/post/nat-reflection-oraz-nat-loopback-w-openwrt/</link>
      <pubDate>Mon, 09 May 2016 22:09:47 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/nat-reflection-oraz-nat-loopback-w-openwrt/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Network_address_translation#NAT_loopback&#34;&gt;Mechanizm NAT Loopback&lt;/a&gt;
nazywany też NAT Reflection lub NAT Hairpinning często jest pomijany przy omawianiu tematyki
firewall&#39;a. Chodzi generalnie o możliwość uzyskiwania dostępu do zasobów w sieci lokalnej po
adresie, który jest na zewnętrznym interfejsie sieciowym routera. W taki sposób mając dwa hosty w
sieci lokalnej, jeden z nich jest w stanie uzyskać dostęp do usług znajdujących się na drugim hoście
przez wykorzystanie zewnętrznego często też publicznego adresu IP. W tym wpisie przybliżymy sobie
zasadę działania tego mechanizmu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kompromitacja firewall&#39;a OpenWRT za sprawą ping</title>
      <link>https://morfikov.github.io/post/kompromitacja-firewalla-openwrt-za-sprawa-ping/</link>
      <pubDate>Mon, 09 May 2016 15:40:47 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kompromitacja-firewalla-openwrt-za-sprawa-ping/</guid>
      <description>&lt;p&gt;Ten standardowy firewall, który oferuje OpenWRT, ma w zamiarze blokować wszystkie nowe próby
połączeń od strony WAN. Faktycznie tak jest w istocie. Niemniej jednak, mamy tam jedną regułę,
która zezwala na wysyłanie żądań &lt;code&gt;ping&lt;/code&gt; . Niby te żądania wydają się być niepozorne ale przy takiej
konfiguracji &lt;code&gt;iptables&lt;/code&gt; jaką oferuje OpenWRT istnieje ryzyko, że ktoś z zewnątrz może utworzyć sporo
sesji bez jakiegokolwiek nadzoru. Każda z tych sesji musi być śledzona przez kernel w tablicy
conntrack&#39;a. Nie mając kontroli nad tym ile takich sesji może zostać utworzonych, łatwo może dojść
do zapełnienia tej tablicy. Jeśli do tego dojdzie, to router przestanie nawiązywać nowe połączenia.
Przydałoby się zatem jakoś ten cały &lt;code&gt;ping&lt;/code&gt; ogarnąć i to niekoniecznie blokując go po stronie WAN. W
tym wpisie zaimplementujemy sobie mechanizm ochrony przez tego typu zagrożeniem.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SMStools i smsd, czyli automat do wysyłania SMS</title>
      <link>https://morfikov.github.io/post/smstools-smsd-automat-wysylania-sms/</link>
      <pubDate>Fri, 06 May 2016 20:33:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/smstools-smsd-automat-wysylania-sms/</guid>
      <description>&lt;p&gt;Pod linux&#39;em jest całe mnóstwo oprogramowania, które może realizować zadanie odbierania i wysyłania
wiadomości SMS. Są również narzędzia, dzięki którym cały proces związany z przetwarzaniem SMS&#39;ów
można zautomatyzować. Jakiś czas temu opisywałem tego typu funkcjonalność na przykładzie
&lt;a href=&#34;https://morfikov.github.io
/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/&#34;&gt;gammu-smsd&lt;/a&gt;. Nadal uważam, że
jest to przyzwoite narzędzie ale jakby nie patrzeć wymaga ono wielu zależności. Właśnie przez nie
&lt;code&gt;gammu-smsd&lt;/code&gt; nie nadaje się do zastosowań, gdzie ma się do dyspozycji niewiele miejsca. Niemniej
jednak, w przypadku OpenWRT mamy tam możliwość zainstalowania pakietu &lt;code&gt;smstool3&lt;/code&gt; , w którym jest
dostępny demon &lt;code&gt;smsd&lt;/code&gt; . Tak się też składa, że debian również ma swoich repozytoriach to narzędzie
posiada, z tym, że w pakiecie &lt;a href=&#34;http://smstools3.kekekasvi.com/index.php?p=blacklist&#34;&gt;smstools&lt;/a&gt;. W
tym wpisie skonfigurujemy sobie działającą bramkę SMS, która będzie automatycznie odbierać
wiadomości SMS i podejmować stosowne działanie w zależności od numeru czy treści otrzymanego
komunikatu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WPS, czyli WiFi Protected Setup w OpenWRT</title>
      <link>https://morfikov.github.io/post/wps-czyli-wifi-protected-setup-w-openwrt/</link>
      <pubDate>Thu, 05 May 2016 18:04:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wps-czyli-wifi-protected-setup-w-openwrt/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Wi-Fi_Protected_Setup&#34;&gt;Wi-Fi Protected Setup (WPS)&lt;/a&gt; powstał w celu
ułatwienia konfiguracji urządzeń w sieci WiFi. Przy WPS nie musimy ustawiać wszystkich parametrów
połączenia ręcznie. Nie musimy także pamiętać nazwy sieci czy samego hasła, które może mieć nawet 64
znaki. Zamiast tego, cała konfiguracja sprowadza się to wciśnięcia dwóch przycisków: jednego na
karcie WiFi, drugiego na obudowie routera. Niemniej jednak, wszędzie gdzie nie spojrzeć, ludzie
rozpisują się na temat tego jakim to niebezpieczeństwem jest włączenie w routerach WiFi opcji WPS. O
tych zagrożeniach, jeśli kogoś interesują, można poczytać, np.
&lt;a href=&#34;https://dankaminsky.com/2012/01/26/wps2/&#34;&gt;tutaj&lt;/a&gt;. W tym wpisie rozprawimy się raz na zawsze z
mitami dotyczącymi WPS, który jest implementowany w routerach WiFi. Postaramy się skonfigurować ten
mechanizm pod OpenWRT i zobaczymy czy cokolwiek z tego co ludzie piszą na necie ma zastosowanie w
praktyce.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatyczna blokada internetu LTE w OpenWRT</title>
      <link>https://morfikov.github.io/post/automatyczna-blokada-internetu-lte-w-openwrt/</link>
      <pubDate>Thu, 05 May 2016 15:20:14 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/automatyczna-blokada-internetu-lte-w-openwrt/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/darmowy-internet-lte-od-rbmplay/&#34;&gt;darmowy internet LTE w
RBM/PLAY&lt;/a&gt;. Jego niewątpliwą zaletą jest
fakt, że jest za free, o ile posiadamy odpowiedni modem. Niemniej jednak, ta usługa jest na 30 dni,
po upływie których trzeba ją aktywować na nowo. Jeśli z jakichś przyczyn się tego nie zrobi, to
wtedy korzystanie z internetu może nas słono kosztować. Niby można zaprzęgnąć do pomocy &lt;a href=&#34;https://morfikov.github.io
/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/&#34;&gt;gammu-smsd,
który będzie nas powiadamiał
SMS&#39;em&lt;/a&gt;, że usługa została
wyłączona lub włączona. Niemniej jednak, w dalszym ciągu pozostaje do ogarnięcia kwestia czasu,
przez który czekamy na włączenie usługi. Najlepszym wyjściem jest całkowita blokada internetu na
routerze, tak by przez ten moment nie nawiązać żadnego połączenia. Jeśli nie nawiążemy połączenia,
to dane z pakietu danych nie będą nam uciekać. W momencie, gdy usługa zostanie aktywowana, to
blokada będzie zdejmowana. Tego typu rozwiązanie można zaimplementować w OpenWRT za sprawą
&lt;a href=&#34;http://smstools3.kekekasvi.com/&#34;&gt;oprogramowania smstools&lt;/a&gt; dostępnego w pakiecie &lt;code&gt;smstools3&lt;/code&gt; . W tym
wpisie postaramy się zaprojektować swojego rodzaju automatyczne blokowanie internet w zależności od
otrzymywanych komunikatów od operatora GSM.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sieć bezprzewodowa WiFi w OpenWRT (WLAN)</title>
      <link>https://morfikov.github.io/post/siec-bezprzewodowa-wifi-w-openwrt-wlan/</link>
      <pubDate>Wed, 04 May 2016 20:26:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/siec-bezprzewodowa-wifi-w-openwrt-wlan/</guid>
      <description>&lt;p&gt;Sieć bezprzewodowa w dzisiejszych czasach to podstawa. Z reguły routery posiadają jedno radio
operujące na częstotliwości 2,4 GHz. Te nieco nowsze (i droższe) modele mają do dyspozycji dwa
radia: 2,4 GHz oraz 5 GHz. OpenWRT zapewnia wsparcie zarówno dla sieci pracującej w paśmie 2.4 GHz
jak i tej nadającej w 5 GHz. Konfiguracja tych pasm w OpenWRT różni się nieco. Weźmy dla przykładu
obsługę kanału 12 i 13, którą dotyczy tylko sieci pasma 2.4 GHz. Podobnie sprawa ma się z
szerokością kanałów, która jest inna w przypadku obu tych pasm. Niemniej jednak, większość opcji
pozostaje taka sama i w tym artykule rzucimy okiem na zagadnienie konfiguracji sieci WiFi w OpenWRT.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Podział switch&#39;a na kilka VLAN&#39;ów w OpenWRT</title>
      <link>https://morfikov.github.io/post/podzial-switcha-na-kilka-vlan-w-openwrt/</link>
      <pubDate>Tue, 03 May 2016 20:49:50 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/podzial-switcha-na-kilka-vlan-w-openwrt/</guid>
      <description>&lt;p&gt;Każdy router ma w swoim wyposażeniu
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Prze%C5%82%C4%85cznik_sieciowy&#34;&gt;switch&lt;/a&gt;, czyli przełącznik
umożliwiający rozdzielenie sygnału na kilka portów. W ten sposób przy pomocy przewodu możemy
podłączyć więcej komputerów niż by to miało miejsce w przypadku posiadania tylko jednego gniazda
&lt;a href=&#34;https://pl.wikipedia.org/wiki/RJ-45&#34;&gt;RJ-45&lt;/a&gt;. Na oryginalnym firmware zwykle nie mamy możliwości
dodatkowej konfiguracji switch&#39;a. Z kolei ta co jest, oferuje nam jedynie jeden port WAN i kilka
portów dla podłączenia komputerów w sieci lokalnej. Jeśli jednak pokusilibyśmy się o wgranie OpenWRT
na nasz router, to będziemy mieli możliwość zarządzania konfiguracją switch&#39;a. W ten sposób będziemy
mogli tworzyć dowolne konfiguracje portów (VLAN), wliczając w to utworzenie, np. kilku portów WAN.
Tego typu rozwiązanie może się przydać do bardziej zaawansowanych konfiguracji sieciowych, np.
&lt;a href=&#34;https://en.wikipedia.org/wiki/Failover&#34;&gt;failover łącza&lt;/a&gt; czy &lt;a href=&#34;https://pl.wikipedia.org/wiki/R%C3%B3wnowa%C5%BCenie_obci%C4%85%C5%BCenia&#34;&gt;load
balancing&lt;/a&gt; w przypadku,
gdy posiadamy kilku ISP i chcemy wykorzystać w pełni łącze oferowane przez te podmioty.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja interfejsów sieciowych w OpenWRT</title>
      <link>https://morfikov.github.io/post/konfiguracja-interfejsow-sieciowych-w-openwrt/</link>
      <pubDate>Tue, 03 May 2016 02:08:31 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-interfejsow-sieciowych-w-openwrt/</guid>
      <description>&lt;p&gt;Routery, które posiadamy w naszych domach, znane są z tego, że mają szereg interfejsów sieciowych.
Taki przeciętny router jest wyposażony w
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Prze%C5%82%C4%85cznik_sieciowy&#34;&gt;switch&lt;/a&gt; z 5 portami
&lt;a href=&#34;https://pl.wikipedia.org/wiki/RJ-45&#34;&gt;RJ-45&lt;/a&gt;. Zwykle jest on też &lt;a href=&#34;https://pl.wikipedia.org/wiki/Wirtualna_sie%C4%87_lokalna&#34;&gt;wirtualnie podzielony
(VLAN)&lt;/a&gt; na kilka interfejsów, standardowo
LAN i WAN. Do tego z reguły dochodzą jeszcze interfejsy bezprzewodowe WLAN na pasmo 2.5GHz i 5GHz.
Jakby tego było mało, to mamy jeszcze wirtualny interfejs mostka, który spina ze sobą lokalne
interfejsy switch&#39;a z interfejsami bezprzewodowymi tworząc w ten sposób jeden interfejs, przez który
pakiety wydostają się z naszej sieci i lecą dalej w świat przez interfejs WAN. Jest to trochę
skomplikowane, dlatego też w tym wpisie przyjrzymy się całej tej konfiguracji interfejsów sieciowych
w OpenWRT.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak sklonować adres MAC w OpenWRT</title>
      <link>https://morfikov.github.io/post/jak-sklonowac-adres-mac-w-openwrt/</link>
      <pubDate>Mon, 02 May 2016 17:25:31 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-sklonowac-adres-mac-w-openwrt/</guid>
      <description>&lt;p&gt;Każde urządzenie sieciowe ma inny &lt;a href=&#34;https://pl.wikipedia.org/wiki/Adres_MAC&#34;&gt;adres MAC&lt;/a&gt;. Jest to
numer, który identyfikuje je w strukturze sieci. Gdy zachodzi potrzeba rozbudowania sieci domowej,
możemy napotkać problemy z naszym obecnym ISP. Załóżmy, że posiadaliśmy do tej pory jeden komputer,
który był wpięty bezpośrednio do łącza ISP. Jeśli dokupiliśmy router i podłączymy go w miejsce
komputera, to urządzenie, które widzi nasz provider, ulega zmianie. Konkretnie, to nie ma znaczenia
samo urządzenie. Liczy się jedynie adres MAC. Providerzy internetowi mają powiązane adresy MAC z
adresami IP i nowo wpięty router nie otrzyma adresu IP, bo ma nieautoryzowany MAC. W takiej sytuacji
zwykle wystarczy telefon do ISP z prośbą przepisanie adresu. Niemniej jednak, czasami ISP każą sobie
dodatkowo płacić za tę czynność. Jeśli jesteśmy postawieni w takiej sytuacji, to możemy sklonować
sobie adres MAC tej maszyny, którą wcześniej widział nasz provider internetowy. Z jego perspektywy
nic się nie zmieni, a my będziemy mogli sobie rozdzielić sygnał na tyle komputerów, ile tylko
chcemy. W tym wpisie zobaczymy jak pod OpenWRT przeprowadzić klonowanie adresu MAC.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DHCP i DNS, czyli konfiguracja sieci w OpenWRT</title>
      <link>https://morfikov.github.io/post/dhcp-dns-czyli-konfiguracja-sieci-w-openwrt/</link>
      <pubDate>Mon, 02 May 2016 16:21:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dhcp-dns-czyli-konfiguracja-sieci-w-openwrt/</guid>
      <description>&lt;p&gt;Rutery WiFi są w stanie zorganizować przewodową i/lub bezprzewodową sieć w naszych domach. By taka
sieć działała bez zarzutu, potrzebna jest odpowiednia adresacja wszystkich komputerów wewnątrz niej.
W obecnych czasach już praktycznie nie stosuje się statycznej konfiguracji, bo to zadanie zostało
zrzucone na barki serwera DHCP. W OpenWRT do tego celu oddelegowane jest &lt;a href=&#34;http://www.thekelleys.org.uk/dnsmasq/doc.html&#34;&gt;oprogramowanie
dnsmasq&lt;/a&gt;. Zapewnia ono nie tylko wspomniany wyżej
serwer DHCP ale także serwer cache&#39;ujący zapytania DNS. Ten drugi z kolei jest niezastąpiony w
przypadku przekazywania zapytań o nazwy domen do upstream&#39;owego serwera DNS, który zajmuje się
rozwiązywaniem tych nazw na odpowiadające im adresy IP. Bez &lt;code&gt;dnsmasq&lt;/code&gt; ogarnięcie naszej sieci
przerodziłoby się w istne piekło. Dlatego też w tym artykule przybliżymy sobie nieco konfigurację
tego narzędzia.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja przycisków w OpenWRT</title>
      <link>https://morfikov.github.io/post/konfiguracja-przyciskow-w-openwrt/</link>
      <pubDate>Sat, 30 Apr 2016 20:00:19 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-przyciskow-w-openwrt/</guid>
      <description>&lt;p&gt;Każdy router w standardzie ma na swojej obudowie kilka przycisków. Zwykle są to przyciski zasilania,
restartu i przełącznik sieci bezprzewodowej. Różnie są one oznaczane i można się spotkać z QSS, WPS,
reset czy WiFi. O ile z przyciskiem zasilania nic więcej się nie da zrobić, bo po naciśnięciu go
router jest odcinany od źródła zasilania ale w przypadku pozostałych przycisków mamy zwykle pełną
swobodę w ich konfiguracji i można je sobie odpowiednio zaprogramować. Oczywiście trzeba widzieć jak
tego dokonać i dlatego właśnie powstał ten artykuł.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja diod w routerze pod OpenWRT (LED)</title>
      <link>https://morfikov.github.io/post/konfiguracja-diod-w-routerze-pod-openwrt-led/</link>
      <pubDate>Sat, 30 Apr 2016 17:11:47 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-diod-w-routerze-pod-openwrt-led/</guid>
      <description>&lt;p&gt;Praktycznie każdy router posiada szereg diod LED, które wizualizują stan pracy takiego urządzenia. W
taki sposób jesteśmy w stanie stwierdzić czy sieć WiFi jest aktualnie włączona albo czy odbywa się
wymiana danych za jej pomocą. Podobnie możemy ocenić aktywność mechanizmu WPS oraz czy połączenie
przewodowe zostało ustanowione. Routery TP-LINK&#39;a mają także w standardzie diodę &lt;code&gt;system&lt;/code&gt; , która
informuje nas czy router działa prawidłowo i nie uległ powieszeniu. W OpenWRT wszystkie te wyżej
opisane właściwości można skonfigurować, tak by dioda LED reagowała w określony sposób na pewne
zaistniałe zdarzenie. W tym wpisie przyjrzymy się bliżej konfiguracji diod routera.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przypisać losowy adres MAC do interfejsu</title>
      <link>https://morfikov.github.io/post/jak-przypisac-losowy-adres-mac-interfejsu/</link>
      <pubDate>Fri, 29 Apr 2016 16:42:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przypisac-losowy-adres-mac-interfejsu/</guid>
      <description>&lt;p&gt;Interfejsy kart sieciowych, które są instalowane w komputerach, posiadają adres MAC (&lt;a href=&#34;https://en.wikipedia.org/wiki/MAC_address&#34;&gt;Media Access
Control&lt;/a&gt;). Jest to unikalny identyfikator, który wyróżnia
nasz komputer spośród tłumu. Na podstawie tego adresu można nie tylko określić markę sprzętu, którą
się posługujemy ale także można sklasyfikować cały nasz ruch sieciowy. W ten sposób bardzo prosto
możemy zostać zidentyfikowani wymieniając dane przez darmowe hotspoty sieci bezprzewodowych WiFi.
Niemniej jednak, jesteśmy się w stanie obronić przed tego typu inwigilacją zmieniając adres MAC
naszego komputera. Nie jest to zbytnio trudne ale trzeba uważać, by znowu nie przesadzić w drugą
stronę i czasem nie zostać zidentyfikowanym przez naszą &amp;quot;odmienność&amp;quot;. W tym wpisie postaramy się
wypracować taki mechanizm, który zmieni nam adres MAC przy każdym podłączeniu do sieci i przy
zachowaniu zdroworozsądkowych zasad.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Szyfrowanie logów w OpenWRT (syslog-ng)</title>
      <link>https://morfikov.github.io/post/szyfrowanie-logow-w-openwrt-syslog-ng/</link>
      <pubDate>Fri, 29 Apr 2016 02:36:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/szyfrowanie-logow-w-openwrt-syslog-ng/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/logread-czyli-system-logowania-w-openwrt/&#34;&gt;We wpisie dotyczącym logread&lt;/a&gt;
została podniesiona kwestia przesłania logów przez sieć. OpenWRT jest w stanie tego typu zadanie
realizować po określeniu kilku dodatkowych opcji w pliku &lt;code&gt;/etc/config/system&lt;/code&gt; . Trzeba jednak zdawać
sobie sprawę, że tak przesyłane komunikaty nie będą w żaden sposób zabezpieczone. W sieci domowej
raczej nie musimy sobie zawracać głowy tym mankamentem. Niemniej jednak, gdy w grę wchodzi
przesyłanie logów do zdalnego serwera zlokalizowanego gdzieś w internecie, to taką komunikację
należy zabezpieczyć przed podsłuchem. Niestety OpenWRT standardowo nie wspiera takich udziwnień ale
dysponuje on pakietami, które mogą nam zapewnić taką funkcjonalność. Szyfrowanie logów możemy w
łatwy sposób wdrożyć za pomocą pakietu &lt;code&gt;syslog-ng3&lt;/code&gt; . W nim znajduje się demon &lt;code&gt;syslog-ng&lt;/code&gt; , który
jest kompatybilny w pełni z innymi linux&#39;owymi demonami logowania. Nie powinno zatem być problemów
ze skonfigurowaniem tego całego mechanizmu.&lt;/p&gt;
&lt;p&gt;W OpenWRT w wersji Chaos Calmer nie ma pakietu &lt;code&gt;syslog-ng3&lt;/code&gt; . W efekcie szyfrowanie logów routera
nie jest obecnie możliwe. Ten wpis dotyczy jedynie wydania Barrier Breaker i zostanie zaktualizowany
jak tylko wspomniany pakiet trafi do repozytorium.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Logread, czyli system logowania w OpenWRT</title>
      <link>https://morfikov.github.io/post/logread-czyli-system-logowania-w-openwrt/</link>
      <pubDate>Thu, 28 Apr 2016 21:04:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/logread-czyli-system-logowania-w-openwrt/</guid>
      <description>&lt;p&gt;Każdy szanujący się system, nawet ten najmniejszy na bazie OpenWRT, musi posiadać mechanizm
logowania komunikatów. Logi routera to bardzo ważna rzecz. Jeśli coś dolega naszemu małemu
przyjacielowi, to jest niemal pewne, że właśnie wśród tych wiadomości znajdziemy przyczynę
problemów. Każda usługa systemowa działająca na routerze przesyła logi, które są zbierane przez
demon logowania. W Chaos Calmer odpowiadają za to &lt;code&gt;logd&lt;/code&gt; oraz &lt;code&gt;logread&lt;/code&gt; . Standardowa konfiguracja
logów w OpenWRT nie jest raczej skomplikowana ale niewiele osób wie, że logi routera można zapisywać
w pliku lub przesłać je przez sieć do innego hosta. W tym wpisie postaramy się właśnie zrealizować
te dwa zadania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Strefa czasowa (timezone) w OpenWRT</title>
      <link>https://morfikov.github.io/post/strefa-czasowa-timezone-w-openwrt/</link>
      <pubDate>Thu, 28 Apr 2016 00:58:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/strefa-czasowa-timezone-w-openwrt/</guid>
      <description>&lt;p&gt;Tanie routery WiFi przeznaczone do użytku domowego nie zawierają w sobie &lt;a href=&#34;https://pl.wikipedia.org/wiki/Zegar_czasu_rzeczywistego&#34;&gt;zegara czasu
rzeczywistego&lt;/a&gt; (RTC, Real Time Clock). Taki
zegar jest implementowany w standardowych komputerach PC czy laptopach ale większość routerów go nie
posiada. Niesie to za sobą pewne komplikacje. Skąd niby router ma wiedzieć jaki mamy aktualnie czas,
skoro nie ma żadnego punktu odniesienia? Komputer bez precyzyjnie ustawionego czasu może mieć
problemy z certyfikatami SSL/TLS. Niewłaściwy czas może także utrudnić analizę pewnych zdarzeń typu
nieautoryzowane próby dostępu do sieci. Ważne jest zatem, by czas na routerze wyposażonym w firmware
OpenWRT był zawsze aktualny i w tym wpisie postaramy się zadbać o to, by strefa czasowa była
odpowiednia, oraz by router uwzględniał czas letni. Przyjrzymy się także mechanizmom aktualizacji
czasu przez protokół NTP.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Hostname, czyli nazwa hosta w OpenWRT</title>
      <link>https://morfikov.github.io/post/hostname-czyli-nazwa-hosta-w-openwrt/</link>
      <pubDate>Wed, 27 Apr 2016 23:49:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/hostname-czyli-nazwa-hosta-w-openwrt/</guid>
      <description>&lt;p&gt;Po wgraniu świeżego firmware OpenWRT, mamy domyślnie skonfigurowany system, który umożliwia nam
nawiązanie połączenia sieciowego ze światem. Niemniej jednak, w przypadku posiadania w domu kilku
stacji roboczych, zapamiętanie ich adresów IP może być niemałym problemem. Niemniej jednak, każdemu
hostowi w sieci możemy przypisać nazwę, tzw. hostname. W ten sposób możemy powiązać nazwy
poszczególnych komputerów z przypisanymi in adresami IP. To rozwiązanie ma tę zaletę, że nie musimy
pamiętać już adresów IP. Możemy za to posługiwać się nazwami, które są o wiele łatwiejsze do
zapamiętania dla człowieka. Działa to mniej więcej na tej samej zasadzie co domeny internetowe. W
tym wpisie postaramy się skonfigurować domenę, w której pracuje router oraz nazwy hostów w sieci.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Skrypty startowe init w OpenWRT</title>
      <link>https://morfikov.github.io/post/skrypty-startowe-init-w-openwrt/</link>
      <pubDate>Wed, 27 Apr 2016 20:47:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/skrypty-startowe-init-w-openwrt/</guid>
      <description>&lt;p&gt;Znaczna część usług, które są dostępne w OpenWRT, jest odpalana &lt;a href=&#34;https://wiki.openwrt.org/doc/techref/process.boot#init&#34;&gt;w fazie startowej
routera&lt;/a&gt;. Te zadnia są realizowane przez
skrypty startowe, które są dołączane w konkretnych pakietach. Takie skrypty są wywoływane w
odpowiedniej kolejności. Każdy z nich można dodać lub usunąć z autostartu. W przypadku, gdy jakaś
usługa nie dostarcza swojego skryptu startowego, możemy pokusić się o napisanie jej takowego.
Oczywiście, nic też nie stoi na przeszkodzie, by utworzyć własne skrypty startowe, które
niekoniecznie odnoszą się do określonych usług. Mogą one np. realizować pewne określone zadanie. W
tym wpisie przybliżymy sobie trochę budowę skryptów startowych w OpenWRT tak, by być w stanie je
tworzyć i edytować jeśli zajdzie taka potrzeba.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru katalogu /tmp/ pod OpenWRT</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-katalogu-tmp-pod-openwrt/</link>
      <pubDate>Wed, 27 Apr 2016 18:24:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-katalogu-tmp-pod-openwrt/</guid>
      <description>&lt;p&gt;OpenWRT ma w swoich repozytoriach całe mnóstwo pakietów. By móc je zainstalować, potrzebne jest nam
miejsce na flash&#39;u routera. Ten z kolei nie jest zbyt duży, często nie przekracza 16 MiB. Podczas
pracy, system operacyjny routera przeprowadza cały szereg operacji. Część z nich generuje jakieś
dane, np. tworzone są pliki konfiguracyjne, generowane statystyki czy pobierane z internetu pliki w
celu dalszego ich przetworzenia. Zwykle są to pliki, które wędrują do katalogu &lt;code&gt;/tmp/&lt;/code&gt; . Gdybyśmy
chcieli zapisać wszystkie te informacje na flash&#39;u routera, to zabrakłoby nam zwyczajnie miejsca.
Inną kwestią są problemy związane z zapisem samego flash&#39;a, który ulega zużyciu. Dlatego też, szereg
operacji zapisu został przeniesiony do pamięci operacyjnej RAM. W ten sposób mamy do wykorzystania
nieco więcej miejsca ale standardowo nie więcej niż 50% wielkości pamięci operacyjnej. Wielkość tego
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Ramdysk&#34;&gt;RAMdysku&lt;/a&gt; można dostosować i w tym wpisie zobaczymy jak to
zrobić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dysk, pendrive i inne nośniki pod OpenWRT</title>
      <link>https://morfikov.github.io/post/dysk-pendrive-inne-nosniki-pod-openwrt/</link>
      <pubDate>Wed, 27 Apr 2016 00:32:19 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dysk-pendrive-inne-nosniki-pod-openwrt/</guid>
      <description>&lt;p&gt;Czym by był router bez portów USB? Obecnie chyba wszystkie routery posiadają przy najmniej jeden
taki port. Umożliwia to podłączenie pendrive, dysku USB, drukarki i innych urządzeń posiadających
interfejs USB. W przypadku, gdy posiadamy jeden port USB i chcemy podłączyć dwa (lub więcej)
urządzenia, musimy skorzystać z hubów USB. Ja w przypadku swojego routera &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WR1043ND.html&#34;&gt;TP-LINK TL-WR1043N/ND
v2&lt;/a&gt; mam zastosowane właśnie takie
rozwiązanie. Niby potrzebuję trzy porty USB, a ten router ma tylko jeden. Co prawda, pojawia się
problem z zapotrzebowaniem na energię ale aktywne huby USB wyposażone w zasilacze niwelują tę
dolegliwość. Ten wpis ma na celu przedstawić zarządzanie tymi wszystkimi nośnikami pod OpenWRT.
Zostanie tutaj pokazane jak stworzyć i zamontować partycje o systemie plików EXT4, NTFS, FAT.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Extroot i whole_root (fullroot) pod OpenWRT</title>
      <link>https://morfikov.github.io/post/extroot-whole_root-fullroot-pod-openwrt/</link>
      <pubDate>Tue, 26 Apr 2016 16:08:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/extroot-whole_root-fullroot-pod-openwrt/</guid>
      <description>&lt;p&gt;Domowe routery WiFi zwykle nie dysponują flash&#39;em o dużej pojemności. W ogromnej części przypadków
pamięć flash w takich urządzeniach nie przekracza 16 MiB. W zasadzie jest to wystarczająca ilość
miejsca ale tylko w przypadku korzystania z oryginalnego firmware producenta routera. Gdy w grę
wchodzi OpenWRT, to przy tak niewielkiej przestrzeni jest duże prawdopodobieństwo, że przy
instalowaniu dodatkowych pakietów zwyczajnie zabraknie nam miejsca. Jeśli nasz router dysponuje
chociaż jednym portem USB, to możemy rozszerzyć system plików routera do rozmiarów partycji
pendrive, który zostanie podłączony. W ten sposób z tych 16 MiB może nam się zrobić, np. 1-2 GiB, a
to już w zupełności wystarczy na instalację dowolnych pakietów z repozytorium OpenWRT. Cały ten
zabieg nosi nazwę &lt;code&gt;extroot&lt;/code&gt; (&lt;a href=&#34;https://wiki.openwrt.org/doc/howto/extroot&#34;&gt;external root&lt;/a&gt;) lub
&lt;code&gt;whole_root&lt;/code&gt; (fullroot) i w tym wpisie prześledzimy procedurę tworzenia tego mechanizmu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przeciek DNS (DNS leak) w VPN (resolvconf)</title>
      <link>https://morfikov.github.io/post/przeciek-dns-dns-leak-w-vpn-resolvconf/</link>
      <pubDate>Mon, 25 Apr 2016 14:37:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przeciek-dns-dns-leak-w-vpn-resolvconf/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://dnsleaktest.com/what-is-a-dns-leak.html&#34;&gt;Przeciek DNS (dns leak)&lt;/a&gt; to nic innego jak wyciek
poufnej informacji, za sprawą nieprawidłowej konfiguracji resolver&#39;a DNS. Może niekoniecznie jest
winne tutaj samo oprogramowanie, które realizuje zapytania DNS, czy też serwer domen jakiejś
organizacji. Chodzi głównie o tematykę &lt;a href=&#34;https://pl.wikipedia.org/wiki/Virtual_Private_Network&#34;&gt;VPN&lt;/a&gt;,
gdzie cały ruch sieciowy powinien być wrzucany do tunelu SSL/TLS i szyfrowany. W pewnych sytuacjach,
zapytania DNS mogą zostać wysyłane pod zewnętrzny resolver, często w formie niezaszyfrowanej i do
tego poza połączeniem VPN. Ten ruch można podsłuchać, przechwycić i poddać analizie. Celem tego
artykułu jest tak skonfigurowanie linux&#39;a (w tym przypadku dystrybucja Debian), by te przecieki
wyeliminować. Jest to możliwe za sprawą narzędzia &lt;code&gt;resolvconf&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja dnscrypt-proxy w OpenWRT</title>
      <link>https://morfikov.github.io/post/konfiguracja-dnscrypt-proxy-w-openwrt/</link>
      <pubDate>Sun, 24 Apr 2016 20:10:01 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-dnscrypt-proxy-w-openwrt/</guid>
      <description>&lt;p&gt;Realizowanie zapytań DNS jest kluczowe do poprawnego działania min. stron internetowych. Router z
OpenWRT na pokładzie bez problemu potrafi rozwiązywać domeny na adresy IP. Jest to realizowane przez
oprogramowanie &lt;code&gt;dnsmasq&lt;/code&gt; . Problem w tym, że zwykle resolver, który będzie uwzględniany w
konfiguracji routera, wskazuje na serwery DNS naszego ISP, czy też jakiejś większej korporacji. W
ten sposób, wszystkie dane z przeglądania stron internetowych podajemy tym organizacjom za free.
Przy pomocy &lt;a href=&#34;https://dnscrypt.org/&#34;&gt;narzędzia dnscrypt-proxy&lt;/a&gt; jesteśmy w stanie zabezpieczyć naszą
sieć przed tego typu zabiegami zbierania danych. Po części też możemy uchronić się przed cenzurą,
którą może nam zafundować lokalny provider internetowy. W tym artykule zaimplementujemy obsługę
szyfrowanego resolver&#39;a DNS na naszym domowym routerze.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OPKG, czyli menadżer pakietów w OpenWRT</title>
      <link>https://morfikov.github.io/post/opkg-czyli-menadzer-pakietow-w-openwrt/</link>
      <pubDate>Sun, 24 Apr 2016 17:49:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/opkg-czyli-menadzer-pakietow-w-openwrt/</guid>
      <description>&lt;p&gt;W OpenWRT do zarządzania pakietami wykorzystywany jest menadżer pakietów
&lt;a href=&#34;https://wiki.openwrt.org/doc/techref/opkg&#34;&gt;opkg&lt;/a&gt;. To przy jego pomocy instalujemy i usuwamy
pakiety. Niemniej jednak, to narzędzie nie ogranicza się jedynie do tych dwóch powyższych czynności.
Przy pomocy &lt;code&gt;opkg&lt;/code&gt; jesteśmy w stanie przeprowadzić szereg innych operacji dotyczących zarządzania
pakietami w systemie operacyjnym naszego domowego routera. W tym wpisie prześledzimy sobie
poszczególne opcje jakie ten menadżer pakietów nam oferuje.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klucze szyfrujące RSA w OpenWRT (ssh)</title>
      <link>https://morfikov.github.io/post/klucze-szyfrujace-rsa-w-openwrt-ssh/</link>
      <pubDate>Sun, 24 Apr 2016 01:14:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/klucze-szyfrujace-rsa-w-openwrt-ssh/</guid>
      <description>&lt;p&gt;Klucze RSA w protokole SSH mogą być wykorzystane jako sposób identyfikacji danej osoby przy
logowaniu się do zdalnego serwera. Te klucze zawsze występują w parach. Jeden prywatny, drugi
publiczny. Pierwszy z nich jest znany tylko nam i powinien być trzymany w sekrecie i pilnie
strzeżony. Klucz publiczny z kolei zaś jest przesyłany na każdy serwer SSH, z którym chcemy się
połączyć. Gdy serwer jest w posiadaniu naszego klucza publicznego i widzi przy tym, że próbujemy
nawiązać połączenie, używa on tego klucza, by wysłać do nas zapytanie (challange). Jest ono
zakodowane i musi na nie zostać udzielona prawidłowa odpowiedź. Tej z kolei może udzielić ktoś, kto
jest w posiadaniu klucza prywatnego. Nie ma innej opcji, by rozkodować wiadomość. Dlatego też nikt
inny nie może udzielić na nią prawidłowej odpowiedzi. To rozwiązanie eliminuje wrażliwość na różne
formy podsłuchu. Ten kto nasłuchuje nie będzie w stanie przechwycić pakietów zawierających hasło, bo
ono nie jest nigdy transmitowane prze sieć. No i oczywiście jeśli chodzi o samo hasło, to odpadają
nam ataki bruteforce pod kątem jego złamania. W tym wpisie postaramy się zaimplementować na routerze
z OpenWrt system logowania oparty o klucze RSA.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dostęp do routera OpenWRT (telnet, ssh, sshfs)</title>
      <link>https://morfikov.github.io/post/dostep-routera-openwrt-telnet-ssh-sshfs/</link>
      <pubDate>Sun, 24 Apr 2016 00:00:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dostep-routera-openwrt-telnet-ssh-sshfs/</guid>
      <description>&lt;p&gt;Standardowa instalacja OpenWRT nie zawiera w sobie żadnego trybu graficznego czy też panelu www.
Wszelkie operacje trzeba przeprowadzać przy pomocy terminala. Mimo to, OpenWRT daje nam kilka
możliwości na uzyskanie dostępu do routera. Ten firmware ma zaimplementowaną
obsługę &lt;a href=&#34;https://pl.wikipedia.org/wiki/Telnet&#34;&gt;protokołu telnet&lt;/a&gt;, który swoją drogą nie należy do
bezpiecznych. Oprócz niego, mamy możliwość logowania się za
pomocą &lt;a href=&#34;https://pl.wikipedia.org/wiki/Secure_Shell&#34;&gt;protokołu SSH&lt;/a&gt;. Tutaj sprawa bezpieczeństwa ma
się o wiele lepiej. Poza tym, można bardzo łatwo zaimplementować klucze SSH eliminując tym samym
dostęp oparty o wprowadzanie hasła przy logowaniu. Czy takie zabezpieczenia nam są potrzebne w
domowych warunkach? Tę kwestię niech sobie każdy użytkownik rozważy sam. Dodatkowo, jeśli już
wspomnieliśmy o protokole SSH, to warto poruszyć
kwestię &lt;a href=&#34;https://pl.wikipedia.org/wiki/SSHFS&#34;&gt;protokołu SSHFS&lt;/a&gt;, czyli możliwości zamontowania
systemu plików routera lokalnie na komputerze. Daje nam to możliwość przeglądania takiego systemu
plików jak zwykłego katalogu. No i mamy też uproszczoną edycję plików, która może odbywać się w
trybie graficznym przy pomocy narzędzi, z których zwykle korzystamy na swoim PC. W tym wpisie
rzucimy okiem na te poszczególne metody i przy pomocy każdej z nich spróbujemy uzyskać dostęp do
routera.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tryb ratunkowy (failsafe) w OpenWRT</title>
      <link>https://morfikov.github.io/post/tryb-ratunkowy-failsafe-w-openwrt/</link>
      <pubDate>Sat, 23 Apr 2016 18:50:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/tryb-ratunkowy-failsafe-w-openwrt/</guid>
      <description>&lt;p&gt;Obrazy OpenWRT mają wbudowany &lt;a href=&#34;https://wiki.openwrt.org/doc/howto/generic.failsafe&#34;&gt;tryb failsafe&lt;/a&gt;
obchodzący całą konfigurację, która została zapisana na &lt;a href=&#34;https://pl.wikipedia.org/wiki/JFFS2&#34;&gt;partycji
JFFS2&lt;/a&gt;. To jest ta części pamięci flash routera, w której
możemy dokonywać własnych zmian w konfiguracji tego firmware. Jak to zwykle bywa, czasem coś
uszkodzimy przez przypadek i masz router nie chce zbytnio działać tak jak byśmy od niego oczekiwali.
Tryb &lt;code&gt;failsafe&lt;/code&gt; nie jest tym samym co &lt;code&gt;firstboot&lt;/code&gt;, który resetuje ustawienia do fabrycznych. W
przypadku &lt;code&gt;failsafe&lt;/code&gt; , wszelkie zmiany jakich dokonaliśmy w procesie konfiguracji zostają i nic nie
tracimy. Jedynie co, to nie jest montowana partycja, na której ten zmiany figurują. Dodatkowo, ilość
odpalonych usług jest ograniczona do minimum. Nie mamy, np. dostępu do internetu, nie działa WiFi,
resolver DNS i nie mamy możliwości uzyskania adresu za pomocą protokołu DHCP. W tym wpisie
przyjrzymy się nieco bliżej temu mechanizmowi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Reset ustawień w OpenWRT (firstboot)</title>
      <link>https://morfikov.github.io/post/reset-ustawien-w-openwrt-firstboot/</link>
      <pubDate>Sat, 23 Apr 2016 17:30:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/reset-ustawien-w-openwrt-firstboot/</guid>
      <description>&lt;p&gt;Routery zwykle nie posiadają monitorów, klawiatur czy myszy. Gdy z takim urządzeniem zaczynają się
dziać problemy, mamy bardzo niewielkie pole manewru. Nie dość, że nie mamy jak zarządzać takim
routerem, to jeszcze rozebranie go zwykle nic nam nie da. Nie są to przecie dekstop&#39;y, z których
można wymontować dysk czy podpiąć do nich pendrive live i odratować znajdujący się na nich system
operacyjny. Czasem wystarczy drobny błąd konfiguracyjny, by router nie chciał się nam odpalić lub
nie będziemy w stanie się z nim połączyć. Z powodu tak ograniczonego dostępu do systemu routerów w
przypadku awarii, ich &lt;a href=&#34;http://www.tp-link.com/en/faq-140.html&#34;&gt;firmware zwykle jest wyposażony w mechanizm resetowania
konfiguracji&lt;/a&gt; do ustawień fabrycznych. Podobnie sprawa ma
się w przypadku firmware OpenWRT. Cały mechanizm resetowania ustawień nosi nazwę &lt;code&gt;firstboot&lt;/code&gt; lub
&lt;code&gt;factory defaults&lt;/code&gt; albo też &lt;code&gt;factory reset&lt;/code&gt; . W tym wpisie postaramy się zresetować ustawienia
routera na kilka sposobów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Obsługa SMS i kodów USSD w OpenWRT</title>
      <link>https://morfikov.github.io/post/obsluga-sms-kodow-ussd-w-openwrt/</link>
      <pubDate>Sat, 23 Apr 2016 15:16:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/obsluga-sms-kodow-ussd-w-openwrt/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/monitor-polaczenia-3glte-w-openwrt-3ginfo/&#34;&gt;W artykule poświęconym 3ginfo&lt;/a&gt;
omawialiśmy monitorowanie połączenia 3G/LTE pod OpenWRT. Zabrakło tam jednak pewnej funkcjonalności,
która ucieszyłaby chyba każdego użytkownika tego firmware. Chodzi oczywiście o wysyłanie i
odbieranie SMS oraz przesyłanie kodów USSD. Okazuje się, że &lt;code&gt;3ginfo&lt;/code&gt; potrafi nam tę funkcjonalność
zapewnić, tylko wymagane jest doinstalowanie kilku pakietów i odpowiednie skonfigurowanie systemu. W
tym wpisie spróbujemy sobie ten mechanizm wysyłania SMS i kodów USSD skonfigurować.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Monitor połączenia 3G/LTE W OpenWRT (3ginfo)</title>
      <link>https://morfikov.github.io/post/monitor-polaczenia-3glte-w-openwrt-3ginfo/</link>
      <pubDate>Fri, 22 Apr 2016 19:53:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/monitor-polaczenia-3glte-w-openwrt-3ginfo/</guid>
      <description>&lt;p&gt;W pewnych sytuacjach lub też ze zwykłej ciekawości możemy chcieć sprawdzić jak sprawuje się
połączenie LTE, którego obsługę zaimplementowaliśmy na naszym routerze mającym na pokładzie
firmware OpenWRT. Nie będę tutaj opisywał samej konfiguracji takiego połączenia, bo to zostało
zrobione we wpisie poświęconym &lt;a href=&#34;https://morfikov.github.io
/post/modem-lte-pod-openwrt/&#34;&gt;konfiguracji modemu Huawei E3372 pod
OpenWRT&lt;/a&gt;, jak i przy okazji &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-polaczenia-aero2-na-openwrt/&#34;&gt;konfiguracji połączenia
Aero2&lt;/a&gt;. W tym wpisie zaś skupimy
się na monitorowaniu za pomocą &lt;code&gt;3ginfo&lt;/code&gt; już działającego połączenia, które jest realizowane za
pomocą modemu LTE podłączonego do portu USB routera.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja połączenia Aero2 na OpenWRT</title>
      <link>https://morfikov.github.io/post/konfiguracja-polaczenia-aero2-na-openwrt/</link>
      <pubDate>Fri, 22 Apr 2016 16:19:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-polaczenia-aero2-na-openwrt/</guid>
      <description>&lt;p&gt;Darmowy internet oferowany przez Aero2 nie grzeszy zbytnio osiągami, bo mamy do dyspozycji jedynie
512 kbit/s. Niemniej jednak, taka prędkość w zupełności wystarcza do przeglądania stron
internetowych. Gorzej z oglądaniem materiałów video w serwisach takich jak YouTube. To jednak nie ma
raczej większego znaczenia, bo przecie usługa jest za free, a poza tym, możemy dokupić szereg
pakietów aktywujących pełną prędkość w technologi LTE. Problem w tym, że od Aero2 możemy otrzymać
tylko jedną kartę SIM na użytkownika. Może i mamy możliwość dostania kilku kart na jeden adres
zamieszkania ale i tak trzeba by dla każdego SIM załatwić osobny modem LTE. Zwykle takie rozwiązanie
nie wchodzi w grę, zwłaszcza, gdy z internetu korzystamy raczej sporadycznie. Mając jednak router z
alternatywnym firmware OpenWRT, możemy do jednego z jego portów USB doczepić taki modem i udostępnić
połączenie internetowe wszystkim urządzeniom w naszej sieci domowej. W tym artykule postaramy się to
zadanie zrealizować.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wgrać firmware OpenWRT na router TP-LINK</title>
      <link>https://morfikov.github.io/post/jak-wgrac-firmware-openwrt-na-router-tp-link/</link>
      <pubDate>Fri, 22 Apr 2016 12:34:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wgrac-firmware-openwrt-na-router-tp-link/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://openwrt.org/&#34;&gt;OpenWRT&lt;/a&gt; to alternatywny firmware dla routerów oparty o linux&#39;a. Może on
okazać się dość złożonym systemem i to pomimo faktu, że zajmuje raczej niewiele miejsca, bo rozmiary
obrazów nie przekraczają 8-16 MiB, oczywiście wliczając w to wolne miejsce. Niemniej jednak, by
komfortowo operować na dostarczonym oprogramowaniu, trzeba dysponować określoną wiedzą. OpenWRT w
dużej mierze przypomina linux&#39;a i szereg poleceń jest w tych dwóch systemach taki sam. Jedynie co,
to z powodu dość ograniczonego miejsca, większość programów została okrojona dość solidnie,
zostawiając przy tym tylko niezbędną funkcjonalność. Mamy, co prawda, szereg nakładek z interfejsem
webowym (min. &lt;a href=&#34;https://www.gargoyle-router.com/&#34;&gt;Gargoyle&lt;/a&gt; i
&lt;a href=&#34;https://github.com/openwrt/luci/wiki&#34;&gt;LuCi&lt;/a&gt;), które upraszczają operowanie na tym firmware ale my w
tym artykule położymy nacisk na przejście na czyste OpenWRT, z którym będziemy się komunikować za
pomocą poleceń tekstowych wydawanych w terminalu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak powrócić z firmware OpenWRT do TP-LINK&#39;a</title>
      <link>https://morfikov.github.io/post/jak-powrocic-z-firmware-openwrt-tp-linka/</link>
      <pubDate>Thu, 21 Apr 2016 19:41:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-powrocic-z-firmware-openwrt-tp-linka/</guid>
      <description>&lt;p&gt;Zmiana oryginalnego firmware na alternatywne na bazie OpenWRT nie jest procesem tylko i wyłączenie w
jedną stronę. W przypadku, gdy OpenWRT z jakichś powodów nie spełnia naszych oczekiwań, to zawsze
możemy powrócić do oprogramowania oferowanego przez producenta routera. W tym wpisie prześledzimy
sobie proces powrotu do oryginalnego firmware na przykładzie routera &lt;a href=&#34;http://www.tp-link.com.pl/products/details/TL-WR1043ND.html&#34;&gt;TP-LINK TL-WR1043ND
v2&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sysupgrade, czyli aktualizacja firmware OpenWRT</title>
      <link>https://morfikov.github.io/post/sysupgrade-czyli-aktualizacja-firmware-openwrt/</link>
      <pubDate>Thu, 21 Apr 2016 16:30:44 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sysupgrade-czyli-aktualizacja-firmware-openwrt/</guid>
      <description>&lt;p&gt;Alternatywne oprogramowanie OpenWRT dla routerów trzeba regularnie aktualizować. Nie chodzi tutaj
tylko o znane podatności w oprogramowaniu ale też o wyeliminowanie błędów wynikłych z niepoprawnego
działania sterownika czy jakiegoś modułu samego kernela. Proces aktualizacji firmware nie jest
niczym trudnym, choć przeprowadzany niewłaściwie może zakończyć się uwaleniem routera. Poniższy wpis
ma na celu zaprezentowanie jak krok po kroku dokonać aktualizacji oprogramowania za pomocą narzędzia
&lt;code&gt;sysupgrade&lt;/code&gt; . Postaramy się to zrobić w oparciu o najnowszą dostępną wersję OpenWRT, w tym
przypadku będzie to Chaos Calmer 15.05.1 (r49172).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Obsługa kodów USSD w modemach LTE</title>
      <link>https://morfikov.github.io/post/obsluga-kodow-ussd-w-modemach-lte/</link>
      <pubDate>Wed, 20 Apr 2016 15:31:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/obsluga-kodow-ussd-w-modemach-lte/</guid>
      <description>&lt;p&gt;Każdy, kto ma lub miał prepaid&#39;a, prędzej czy później musiał nauczyć się obsługi &lt;a href=&#34;https://pl.wikipedia.org/wiki/Unstructured_Supplementary_Service_Data&#34;&gt;kodów
USSD&lt;/a&gt;. To za ich pomocą
jesteśmy w stanie sprawdzić stan konta czy też aktywować poszczególne usługi. Co się jednak stanie,
gdy taki prepaid zostanie umieszczony w modemie LTE? Teoretycznie modem powinien nam zapewnić
połączenie LTE ale to jest nieco inna technologia niż GSM czy UMTS, a to za ich pomocą mogą być
przesyłane zarówno kody USSD i SMS. Niby modemy LTE potrafią operować również na UMTS i GSM ale pod
linux&#39;em przesyłanie kodów USSD może być nieco problematyczne. Jedynym oprogramowaniem będącym w
stanie operować na tych kodach był &lt;code&gt;modem-manager-gui&lt;/code&gt; . Problem w tym, że zajmuje on praktycznie
cały modem dla siebie, co w pewnych sytuacjach może nie być pożądane. Zatem jakie alternatywy nam
pozostają? W jaki sposób operować na tych kodach USSD pod linux&#39;em?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tworzenie repozytorium git na github&#39;ie</title>
      <link>https://morfikov.github.io/post/tworzenie-repozytorium-git-na-githubie/</link>
      <pubDate>Tue, 19 Apr 2016 17:08:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/tworzenie-repozytorium-git-na-githubie/</guid>
      <description>&lt;p&gt;Po eksperymentah z repozytorium git na github&#39;ie postanowiłem zrobić drobną ściągawkę na temat
obsługi tego mechanizmu z poziomu linii poleceń. Oczywiście, tutaj będą przedstawione jedynie
podstawy, tj. jak zacząć tworzyć takie repozytorium. Bardziej zaawansowane rzeczy, np.
&lt;a href=&#34;https://morfikov.github.io
/post/github-z-obsluga-kluczy-ssh/&#34;&gt;implementacja kluczy SSH na github&#39;ie&lt;/a&gt;, czy
też &lt;a href=&#34;https://morfikov.github.io
/post/implementacja-kluczy-gpg-repozytorium-git/&#34;&gt;podpisywanie swojej pracy przy pomocy kluczy
GPG&lt;/a&gt; zostały opisane w osobnych
wpisach, bo lekko wykraczają poza tematykę tego artykułu. Oczywiście te dwie rzeczy nie są wymagane
do pracy z git&#39;em ale trzeba rozważyć ich wdrożenie jeśli faktycznie zamierzamy zacząć korzystać z
tego VCS&#39;a. W każdym razie, tutaj zajmę się podstawowymi operacjami, które człowiek zwykle
przeprowadza, gdy przychodzi mu korzystać z git&#39;a. Zdaję sobie sprawę, że są różne nakładki
graficzne na narzędzie &lt;code&gt;git&lt;/code&gt; ale, jak się okaże po przeczytaniu tego wpisu, operowanie na tekstowym
&lt;code&gt;git&lt;/code&gt; nie jest takie straszne, choć sama dokumentacja może przerazić, bo jest tego dość sporo i
raczej wszystkiego od razu nie ogarniemy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wvdial i PPP, czyli modem LTE w trybie RAS</title>
      <link>https://morfikov.github.io/post/wvdial-ppp-czyli-modem-lte-w-trybie-ras/</link>
      <pubDate>Thu, 14 Apr 2016 19:01:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wvdial-ppp-czyli-modem-lte-w-trybie-ras/</guid>
      <description>&lt;p&gt;Jak wielu użytkowników linux&#39;a zapewne wie, modem GSM/UMTS/LTE może pracować w kilku trybach.
Najpopularniejszym z nich jest tryb RAS wykorzystujący interfejsy udostępniane przez to urządzenie
w katalogu &lt;code&gt;/dev/&lt;/code&gt; , zwykle &lt;code&gt;ttyUSB0&lt;/code&gt; , &lt;code&gt;ttyUSB1&lt;/code&gt; , etc. By taki modem mógł nawiązać połączenie z
siecią, potrzebny jest demon &lt;a href=&#34;https://pl.wikipedia.org/wiki/Point_to_Point_Protocol&#34;&gt;PPP&lt;/a&gt;. O trybie
RAS wspominałem już parokrotnie, min. we wpisach dotyczących &lt;a href=&#34;https://morfikov.github.io
/post/darmowy-internet-lte-od-rbmplay/&#34;&gt;konfiguracji połączenia LTE w
RBM/Play&lt;/a&gt; jak i przy omawianiu &lt;a href=&#34;https://morfikov.github.io
/post/aero2-w-polaczeniu-z-dnsmasq-dnscrypt-proxy/&#34;&gt;problemów
z resolver&#39;em DNS w przypadku
Aero2&lt;/a&gt;. Generalnie ten tryb
różni się trochę od &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-modemu-lte-w-trybie-ndis-ncm/&#34;&gt;trybu
NDIS(NCM)&lt;/a&gt; głównie tym, że tutaj
nie uzyskamy większych prędkości niż 20-30 mbit/s. Niemniej jednak, jeśli nie mamy dobrej jakości
połączenia LTE, lub nasz modem z jakiegoś powodu pod linux&#39;em nie potrafi pracować w trybie NDIS,
to możemy skonfigurować połączenie w trybie RAS wykorzystując do tego celu &lt;code&gt;wvdial&lt;/code&gt; oraz demona PPP.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wysyłanie i odbieranie SMS w wammu</title>
      <link>https://morfikov.github.io/post/wysylanie-odbieranie-sms-w-wammu/</link>
      <pubDate>Mon, 11 Apr 2016 20:19:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wysylanie-odbieranie-sms-w-wammu/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://wammu.eu/&#34;&gt;Wammu&lt;/a&gt; to aplikacja, przy pomocy której jesteśmy w stanie zarządzać swoim
telefonem komórkowym. Można ją także wykorzystać do zarządzania modemami USB, tymi samymi, które są
w stanie nam dostarczyć połączenie LTE. Przy pomocy &lt;code&gt;wammu&lt;/code&gt; nie damy rady jednak nawiązać połączenia
internetowego ale jest kilka rzeczy, do których ten soft może nam się przydać. Karta SIM obecna w
takim modemie może mieć zapisane kontakty, które możemy edytować, usuwać i ewentualnie dodawać nowe.
Ważniejszym ficzerem, który oferuje &lt;code&gt;wammu&lt;/code&gt; , jest możliwość wysyłania i odbierania wiadomości SMS.
Wcześniej opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/&#34;&gt;wysyłanie i odbieranie SMS za pomocą
gammu-smsd&lt;/a&gt;, niemniej jednak, w
przypadku &lt;code&gt;wammu&lt;/code&gt; nie będziemy uruchamiać żadnej usługi systemowej. Same wiadomości SMS odbiera i
wysyła się na podobnej zasadzie co w telefonie komórkowym. Przyjrzymy się zatem bliżej temu
kawałkowi oprogramowania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gammu-smsd, czyli wysyłanie i odbieranie SMS</title>
      <link>https://morfikov.github.io/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/</link>
      <pubDate>Sat, 09 Apr 2016 18:53:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/</guid>
      <description>&lt;p&gt;Eksperymentując ostatnio z modemem Huawei E3372s-153 w wersji NON-HiLink, pomyślałem, że przydałoby
się zaprojektować jakiś prosty system do odbioru i wysyłania SMS. Nie chodzi tutaj o zaprzęgnięcie
do pracy oprogramowania takiego jak &lt;a href=&#34;https://linuxonly.ru/cms/page.php?7&#34;&gt;modem-manager-gui&lt;/a&gt; czy też
&lt;a href=&#34;https://wammu.eu/wammu/&#34;&gt;wammu&lt;/a&gt; ale bardziej o przekazywanie tych wiadomości SMS, które trafiają na
modem, na inny numer telefonu komórkowego. Czyli stworzenie takiego telefonicznego proxy, które te
SMS będzie przekazywał dalej. Tego typu funkcjonalność można zaimplementować praktycznie w każdym
linux&#39;ie, tylko wymagane jest posiadanie odpowiednich narzędzi. W tym przypadku rozchodzi się o
&lt;code&gt;gammu-smsd&lt;/code&gt; i to o nim będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana nazwy interfejsu modemu ttyUSB0</title>
      <link>https://morfikov.github.io/post/zmiana-nazwy-interfejsu-modemu-ttyusb0/</link>
      <pubDate>Sat, 09 Apr 2016 18:50:19 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-nazwy-interfejsu-modemu-ttyusb0/</guid>
      <description>&lt;p&gt;Spora część osób posiada różnego rodzaju urządzenia do komunikacji GSM/UMTS/LTE. Mogą to być
smartfony, czy też modemy USB. Zwykle po podpięciu takiego urządzenia do portu USB, system wykrywa
je i oddaje nam do dyspozycji kilka interfejsów w katalogu &lt;code&gt;/dev/&lt;/code&gt; . W przypadku modemu Huawei
E3372s-153 w wersji NON-HiLink, standardowo są dwa interfejsy: &lt;code&gt;ttyUSB0&lt;/code&gt; oraz &lt;code&gt;ttyUSB1&lt;/code&gt; . Gdy
podłączamy tylko jedno urządzenie, to nie mamy problemy z tymi nazwami. Co się jednak stanie w
przypadku, gdzie tych urządzeń będzie więcej i podepniemy je w losowej kolejności? Nawet jeśli
będziemy wiedzieć które interfejsy są od jakich urządzeń, to i tak trzeba będzie przepisywać pliki
konfiguracyjne różnych aplikacji pod kątem dostosowania tych nazw. Możemy jednak stworzyć unikalne
nazwy interfejsów w oparciu o &lt;a href=&#34;https://en.wikipedia.org/wiki/Udev&#34;&gt;reguły udev&#39;a&lt;/a&gt; i tym zajmiemy się
w niniejszym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Modem LTE HUAWEI E3372 bez usb-modeswitch</title>
      <link>https://morfikov.github.io/post/modem-lte-huawei-e3372-bez-usb-modeswitch/</link>
      <pubDate>Wed, 06 Apr 2016 18:51:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modem-lte-huawei-e3372-bez-usb-modeswitch/</guid>
      <description>&lt;p&gt;Ten artykuł, podobnie jak kilka poprzednich, powstał w oparciu o moje badania przeprowadzane nad
modemem LTE HUAWEI E3372s-153 w wersji NON-HiLink. Niby rozwiązań dotyczących konfiguracji modemów
pod linux&#39;em jest pełno w sieci ale zasadniczą różnicą niżej opisanego sposobu jest kompletne
pozbycie się pakietu &lt;code&gt;usb-modeswitch&lt;/code&gt; . Dla przypomnienia, ten pakiet odpowiada za przełączanie
trybu modemu. Zwykle są dostępne dwa tryby. Pierwszy z nich jest w stanie dostarczyć sterowniki (pod
windows), po instalacji których modem przechodzi w drugi tryb, już ten właściwy. Na linux&#39;ach to
przełączanie jest realizowane via &lt;code&gt;usb-modeswitch&lt;/code&gt; . I tu się nasuwa pytanie, czy ten modem
faktycznie trzeba przełączać? A może istnieje sposób, który by automatycznie ustawił modem na taki
tryb, który linux&#39;y lubią najbardziej? Okazało się, że istnieje i w tym wpisie zostanie on
przestawiony.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja modemu LTE w trybie NDIS (NCM)</title>
      <link>https://morfikov.github.io/post/konfiguracja-modemu-lte-w-trybie-ndis-ncm/</link>
      <pubDate>Tue, 05 Apr 2016 15:45:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-modemu-lte-w-trybie-ndis-ncm/</guid>
      <description>&lt;p&gt;Sporo modemów LTE potrafi pracować w kilku trybach. Weźmy na przykład modem Huawei E3372s-153 w
wersji NON-HiLink. Standardowo obsługuje on tryb RAS (&lt;a href=&#34;https://en.wikipedia.org/wiki/Remote_Access_Service&#34;&gt;Remote Access
Services&lt;/a&gt;) jak i NDIS (&lt;a href=&#34;https://en.wikipedia.org/wiki/Network_Driver_Interface_Specification&#34;&gt;Network Driver
Interface Specification&lt;/a&gt;).
Domyślnie też włączony jest NDIS ale, by móc z tego trybu korzystać na debianie, musimy nieco
inaczej skonfigurować sobie połączenie sieciowe. Gdy w grę wchodzą modemy LTE, to użytkownicy zwykli
korzystać z narzędzia &lt;code&gt;wvdial&lt;/code&gt; , który zaprzęga do pracy demona PPP i w ten sposób modem zaczyna
pracować w trybie RAS, a nie NDIS. W tym wpisie skonfigurujemy sobie połączenie sieciowe na debianie
w taki sposób, by wykorzystywało ono potencjał trybu NDIS.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Modem LTE pod OpenWRT (Huawei E3372s-153)</title>
      <link>https://morfikov.github.io/post/modem-lte-pod-openwrt/</link>
      <pubDate>Mon, 04 Apr 2016 19:44:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modem-lte-pod-openwrt/</guid>
      <description>&lt;p&gt;Modem LTE jest zwykle przeznaczony dla jednej stacji roboczej. Podpina się go do portu USB i zwykle
po chwili można zestawić połączenie z siecią. W przypadku, gdy mamy kilka komputerów i na każdym z
nich chcemy mieć internet, to mamy z grubsza trzy wyjścia. Pierwszym z nich jest dokupienie
kolejnych modemów LTE, co zwykle nie wchodzi w grę. Drugą opcją jest zakup routera LTE. Różni się on
od zwykłego routera WiFi tym, że ma już wbudowany modem LTE. Jeśli jednak dysponujemy własnym
routerem WiFi, to niekoniecznie musimy się go pozbywać, zwłaszcza w przypadku, gdy już zakupiliśmy
osobno modem LTE. Jeśli na tym routerze WiFi jesteśmy w stanie zainstalować firmware OpenWRT, to
istnieje duża szansa na to, że damy radę ten router przerobić na router LTE. W tym wpisie postaramy
się ten zabieg przeprowadzić z wykorzystaniem routera &lt;a href=&#34;http://www.tp-link.com.pl/products/details/cat-9_Archer-C7.html&#34;&gt;TP-LINK Archer C7
v2&lt;/a&gt; oraz modemu LTE Huawei
E3372s-153 w wersji NON-HiLink.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Darmowy internet LTE od RBM (Play)</title>
      <link>https://morfikov.github.io/post/darmowy-internet-lte-od-rbmplay/</link>
      <pubDate>Sun, 03 Apr 2016 14:57:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/darmowy-internet-lte-od-rbmplay/</guid>
      <description>&lt;p&gt;We wpisie dotyczącym &lt;a href=&#34;https://morfikov.github.io
/post/aero2-w-polaczeniu-z-dnsmasq-dnscrypt-proxy/&#34;&gt;konfiguracji serwerów DNS na potrzeby
Aero2&lt;/a&gt; wspomniałem, że ten
operator daje możliwość korzystania z internetu LTE praktycznie za darmo. Trzeba tam, co prawda,
złożyć wniosek i zapłacić jakieś grosze za przysłanie karty SIM ale opłat jako takich za
połączenie internetowe nie ma żadnych. Uporczywy może być jedynie kod CAPTCHA, który trzeba
wpisywać co 60 minut. Szukając na necie informacji na temat darmowego internetu LTE &lt;a href=&#34;http://jdtech.pl/2015/09/darmowy-internet-lte-w-redbullmobile-porady-2015.html&#34;&gt;doszukałem się
tego oto wpisu&lt;/a&gt;.
Jest tam przedstawiony sposób na włączenie bezpłatnej usługi internetu LTE u operatora RBM (Play). Z
początku wydawało mi się to niezbyt wiarygodne, by tego typu oferta była w ogóle dostępna ale
okazało się jednak, że nie ma tutaj żadnego haczyka i ten internet LTE faktycznie można włączyć i
korzystać z niego za free. W tym wpisie postaramy się skonfigurować Debiana właśnie na potrzeby tej
usługi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aero2 w połączeniu z dnsmasq i dnscrypt-proxy</title>
      <link>https://morfikov.github.io/post/aero2-w-polaczeniu-z-dnsmasq-dnscrypt-proxy/</link>
      <pubDate>Sat, 02 Apr 2016 18:47:47 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aero2-w-polaczeniu-z-dnsmasq-dnscrypt-proxy/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aero2.pl/&#34;&gt;Aero2&lt;/a&gt; już od dość dawna oferuje darmowy dostęp do internetu w technologi LTE
ale jakoś wcześniej nie byłem tym tematem zainteresowany. Parę dni temu złożyłem jednak wniosek o
kartę SIM, tak by posiadać zapasowe łącze na wypadek, gdyby mój obecny ISP z jakiegoś powodu padł.
Aero2 oferuje wersję komercyjną jak i tę za free i każda z nich ma swoje wady i zalety. Jako, że to
łącze ma robić jedynie za zapas, to korzystam z wersji FREE, a jest ono dość poważne ograniczenie,
tj. występuje tutaj &lt;a href=&#34;https://pl.wikipedia.org/wiki/CAPTCHA&#34;&gt;kod CAPTCHA&lt;/a&gt;, który trzeba wpisywać tak
co godzinę, po czym należy resetować modem. Ten kod może zostać zaserwowany jedynie w przypadku
korzystania z DNS Aero2 i pozornie odpada możliwość używania własnego systemu DNS opartego o
&lt;a href=&#34;http://www.thekelleys.org.uk/dnsmasq/doc.html&#34;&gt;dnsmasq&lt;/a&gt; i &lt;a href=&#34;https://dnscrypt.org/&#34;&gt;dnscrypt-proxy&lt;/a&gt;.
Po kilku dniach eksperymentów udało mi się wypracować przyzwoitą konfigurację, która potrafi obejść
to ograniczenie, poprawiając tym samym prywatność i bezpieczeństwo w internecie korzystając z
darmowego LTE za sprawą Aero2. W tym wpisie postaramy się zaimplementować ten mechanizm na debianie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rkhunter jako ochrona przed rootkit&#39;ami</title>
      <link>https://morfikov.github.io/post/rkhunter-jako-ochrona-przed-rootkitami/</link>
      <pubDate>Tue, 08 Mar 2016 15:42:59 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/rkhunter-jako-ochrona-przed-rootkitami/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Rootkit&#34;&gt;Rootkit&lt;/a&gt; to takie ustrojstwo, które jest w stanie przebywać
niepostrzeżenie w naszym systemie przez bardzo długi czas. Dzieje się tak ze względu na uśpioną
czujność administratora. Teoretycznie wszystko jest w należytym porządku, nie widać żadnych
złowrogich procesów, a szereg narzędzi, które mają przeciwdziałać rootkit&#39;om, nie zwraca żadnych
ostrzeżeń o ewentualnych próbach naruszenia bezpieczeństwa systemu operacyjnego. Taki rootkit jest w
stanie całkowicie przejąc kontrolę nad linux&#39;em i np. może decydować o tym jakie procesy zostaną nam
pokazane, a jakie ukryte. W świetle takiego zagrożenia, linux&#39;y wypracowały sobie pewne mechanizmy
obronne. W tym wpisie przebadamy sobie jeden z projektów, tj.
&lt;a href=&#34;http://rkhunter.sourceforge.net/&#34;&gt;rkhunter&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Systemowy klient TOR w TorBrowser</title>
      <link>https://morfikov.github.io/post/systemowy-klient-tor-w-torbrowser/</link>
      <pubDate>Wed, 02 Mar 2016 15:14:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/systemowy-klient-tor-w-torbrowser/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.torproject.org/projects/torbrowser.html.en&#34;&gt;TorBrowser&lt;/a&gt; to projekt, który ma na celu
zabezpieczenie użytkownika przed przeciekiem informacji. Jest to połączenie klienta sieci TOR oraz
przeglądarki Firefox (plus kilka dodatków). Ten mechanizm jest tak skonfigurowany, by możliwie jak w
największym stopniu dbał o naszą prywatność podczas przeglądania stron internetowych. Kilka lat
wstecz, użytkownicy Firefox&#39;a mogli się zaopatrzyć w addon TorButton. Niemniej jednak, obecnie &lt;a href=&#34;https://www.torproject.org/docs/torbutton/index.html.en&#34;&gt;ten
dodatek nie jest już rozwijany&lt;/a&gt;,
przynajmniej nie jako osobny projekt. Cały ten TorButton został zintegrowany z TorBrowser i nie ma
obecnie sposobu na to, by przeznaczyć jeden profil Firefox&#39;a pod bezpieczne przeglądanie internetu.
Jeśli chcemy mieć taką możliwość, to musimy korzystać z TorBrowser. Nie stanowi to oczywiście
problemu ale jako, że ma on w sobie wbudowanego klienta TOR&#39;a, to uruchamia też pewne procesy, które
mogą okazać się zbędne, zwłaszcza, gdy na swoim linux&#39;ie mamy już systemową instancję TOR&#39;a. W takim
przypadku, przydałoby się wyłączyć tego klienta TOR w TorBrowser, a ruch z przeglądarki przekierować
do systemowego TOR&#39;a i przez ten proces postaramy się przebrnąć w tym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja tunelu 6in4 w OpenWRT (IPv6)</title>
      <link>https://morfikov.github.io/post/konfiguracja-tunelu-6in4-w-openwrt-ipv6/</link>
      <pubDate>Tue, 01 Mar 2016 15:28:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-tunelu-6in4-w-openwrt-ipv6/</guid>
      <description>&lt;p&gt;Ludzie z IETF prawie 20 lat temu opracowali protokół IPv6. Niemniej jednak, w dalszym ciągu ogromna
część providerów internetowych nie ma zamiaru zaimplementować u siebie jego obsługi. &lt;a href=&#34;http://www.google.com/intl/pl/ipv6/statistics.html&#34;&gt;Ilość
użytkowników, którzy mają natywne wsparcie dla protokołu
IPv6&lt;/a&gt; oscyluje w granicach 10% . Jeśli jednak
mamy do dyspozycji router z firmware OpenWRT na pokładzie, to możemy pokusić się o skonfigurowanie
tunelu 6in4. Jedynym warunkiem jest posiadanie zewnętrznego adresu IP. Tunel 6in4 jest bardzo
podobny do tego &lt;a href=&#34;https://morfikov.github.io
/post/implementacja-protokolu-ipv6-za-pomoca-tunelu-6to4/&#34;&gt;6to4, który był opisywany na przykładzie
debiana&lt;/a&gt;. Tutaj jednak
ten tunel zostanie ustawiony na routerze i w ten sposób cała wewnętrzna sieć będzie miała
przydzieloną określoną przestrzeń adresową z puli IPv6.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zdiagnozować kernel OOPS</title>
      <link>https://morfikov.github.io/post/jak-zdiagnozowac-kernel-oops/</link>
      <pubDate>Mon, 22 Feb 2016 18:41:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zdiagnozowac-kernel-oops/</guid>
      <description>&lt;p&gt;Kernel linux&#39;a, jak każdy inny program, podczas swojego działania może napotkać nieprzewidzianą
przez programistów sytuację. W przypadku zwykłych aplikacji, pewne błędy krytyczne mogą doprowadzić
do &amp;quot;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Naruszenie_ochrony_pami%C4%99ci&#34;&gt;naruszenia ochrony pamięci&lt;/a&gt;&amp;quot;, co
szerzej jest znane jako segfault. W przypadku wystąpienia tego błędu, proces zwykle jest
unicestwiany. Co jednak w przypadku kernela? Odpowiedź jest prosta: &lt;a href=&#34;https://pl.wikipedia.org/wiki/Kernel_panic&#34;&gt;kernel
panic&lt;/a&gt;, czyli panika kernela, która pozostawia system w
stanie braku jakichkolwiek oznak życia. Są jednak pewne błędy, z którymi kernel jest w stanie sobie
poradzić i odzyskać sprawność w mniejszym lub większym stopniu. Te błędy są nazywane &lt;a href=&#34;http://slacksite.com/slackware/oops.html&#34;&gt;kernel
OOPS&lt;/a&gt;. W tym wpisie postaramy się przeanalizować
przykładowy OOPS i zobaczymy czy uda nam się ustalić przyczynę zaistniałego problemu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Zmiana serwera i nazwy bloga</title>
      <link>https://morfikov.github.io/post/wordpress-zmiana-serwera-nazwy-bloga/</link>
      <pubDate>Mon, 15 Feb 2016 15:17:56 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-zmiana-serwera-nazwy-bloga/</guid>
      <description>&lt;p&gt;Prędzej czy później przyjdzie taki czas, że będziemy musieli porzucić stary hosting, na którym
trzymamy swój blog WordPress&#39;a. O ile samo przeniesienie całego kontentu nie powinno sprawić
trudności, bo to przecież zwykłe kopiowanie plików, to zmiana struktury strony, np. katalogu
głównego lub też nazwy bloga (domeny), &lt;a href=&#34;https://codex.wordpress.org/Moving_WordPress&#34;&gt;pociąga już za sobą pewne
komplikacje&lt;/a&gt;. W tych bardziej zaawansowanych
przypadkach, zwłaszcza jeśli posiadamy niestandardową konfigurację, będzie potrzebna edycja
niektórych plików WordPress&#39;a oraz trzeba będzie zmienić szereg wpisów w bazie danych. W tym
artykule zostanie opisany proces przenoszenia instalacji WordPress&#39;a na nowy serwer wliczając w to
zmianę nazwy serwisu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja protokołu SSL/TLS w vsftpd</title>
      <link>https://morfikov.github.io/post/implementacja-protokolu-ssltls-w-vsftpd/</link>
      <pubDate>Sat, 13 Feb 2016 22:30:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-protokolu-ssltls-w-vsftpd/</guid>
      <description>&lt;p&gt;Kwestię &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-vsftpd-w-debianie/&#34;&gt;konfiguracji serwera FTP na debianie w oparciu o
vsftpd&lt;/a&gt; już przerabialiśmy. Została nam
jeszcze do omówienia implementacja protokołu SSL/TLS. FTP nie jest bezpiecznym protokołem i wszelkie
dane logowania są przesyłane przez sieć otwartym tekstem. W przypadku, gdy stawiamy lokalny serwer
FTP w zaufanej sieci lub też będziemy korzystać jedynie z dostępu anonimowego, to raczej nie
potrzebujemy szyfrować danych. Trzeba pamiętać, że każde szyfrowanie dość mocno obciąża procesor,
który może stanowić wąskie gardło przy przesyle danych. W tym wpisie założenie jest takie, że
bezpieczeństwo danych, które będziemy przesyłać za pomocą protokołu FTP, jest rzeczą najważniejszą i
dlatego wdrożyć szyfrowanie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja vsftpd w Debianie</title>
      <link>https://morfikov.github.io/post/konfiguracja-vsftpd-w-debianie/</link>
      <pubDate>Fri, 12 Feb 2016 02:39:29 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-vsftpd-w-debianie/</guid>
      <description>&lt;p&gt;Serwery FTP umożliwiają przesyłanie plików przez sieć za pomocą protokołu TCP. Raczej wszyscy
mieliśmy z nimi już do czynienia. Może niekoniecznie zarządzaliśmy takimi serwerami ale na pewno
zdarzyło nam się pobierać pliki za ich pomocą. W tym wpisie jednak postaramy się skonfigurować taki
serwer FTP w oparciu o oprogramowanie &lt;a href=&#34;https://security.appspot.com/vsftpd.html&#34;&gt;vsftpd&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aktualizacja Firefox&#39;a i Thunderbird&#39;a w debianie</title>
      <link>https://morfikov.github.io/post/aktualizacja-firefoxa-thunderbirda-w-debianie/</link>
      <pubDate>Tue, 09 Feb 2016 03:04:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aktualizacja-firefoxa-thunderbirda-w-debianie/</guid>
      <description>&lt;p&gt;W 2006 roku, Mozilla przyczepiła się do debiana o to, że ten &lt;a href=&#34;https://en.wikipedia.org/wiki/Mozilla_Corporation_software_rebranded_by_the_Debian_project&#34;&gt;wykorzystuje ich znaki
towarowe&lt;/a&gt;.
Chodziło głównie o to, że debian wprowadzał swoje poprawki, które nie były zatwierdzone przez zespół
Mozilli. W efekcie czego, debian pozmieniał nazwy szeregu produktów Mozilli i tak zamiast normalnego
Firefox&#39;a mamy Iceweasel, podobnie z Thunderbird&#39;em i Icedove. Obecnie nie ma możliwości wgrania
aplikacji Mozilli wykorzystując repozytorium debiana. Trzeba się trochę wysilić i paczki pobierać
ręcznie z serwerów Mozilli. Takie rozwiązanie nie jest zbytnio praktyczne, bo przecie w linux&#39;ie
aplikacji nie aktualizuje się za pomocą ich interfejsów graficznych. Jeśli tak by było, to
musielibyśmy uruchamiać przeglądarkę z uprawnieniami root w trybie graficznym, czego raczej nikt
rozsądny nie próbowałby robić. Można, co prawda, napisać skrypt i całą operację aktualizacji nieco
zautomatyzować. Problem w tym, że zarówno Firefox jak i Thunderbird ważą tak około 50 MiB każdy i
taka aktualizacja polegająca na pobraniu całej aplikacji i zainstalowaniu jej na nowo zjadłaby
trochę transferu. Istnieje jednak rozwiązanie, które zakłada wykorzystanie &lt;a href=&#34;https://wiki.mozilla.org/Software_Update:Manually_Installing_a_MAR_file&#34;&gt;plików
MAR&lt;/a&gt;. Ważą one zaledwie
kilka MiB, bo zawierają jedynie aktualizację danej aplikacji. W tym wpisie spróbujemy się przyjrzeć
procesowi aktualizacji z wykorzystaniem tych właśnie plików.&lt;/p&gt;
&lt;p&gt;Zgodnie z &lt;a href=&#34;https://glandium.org/blog/?p=3622&#34;&gt;informacją na tym blogu&lt;/a&gt;, Firefox wraca do debiana i
zastępuje tym samym Iceweasel. Od tego momentu można już instalować pakiet &lt;code&gt;firefox&lt;/code&gt; i cieszyć się
normalnym produktem Mozilli. Niniejszy artykuł w dalszym ciągu znajduje zastosowanie ale nie można
mieszać opisanego niżej sposobu aktualizacji Firefox&#39;a z tym dostarczanym w ramach menadżera
pakietów &lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;aptitude&lt;/code&gt; . Zatem albo instalujemy Firefox&#39;a bezpośrednio z repozytorium debiana,
albo ściągamy pakiet z serwerów Mozilli.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Backup dysku przez sieć przy pomocy dd i netcat</title>
      <link>https://morfikov.github.io/post/backup-dysku-przez-siec-przy-pomocy-dd-netcat/</link>
      <pubDate>Mon, 08 Feb 2016 00:45:07 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/backup-dysku-przez-siec-przy-pomocy-dd-netcat/</guid>
      <description>&lt;p&gt;Dyski talerzowe mają to do siebie, że zawierają elementy mechaniczne, np. ramię głowicy czy też sam
napęd dysku. Te ruchome elementy się zużywają podczas eksploatacji dysku i trzeba mieć na uwadze, że
prędzej czy później taki dysk ulegnie awarii. Statystycznie rzecz biorąc, około 5% dysków rocznie
zdycha. Oczywiście to tylko statystyka i w sporej części przypadków dyski twarde ulegają awarii
znacznie wcześniej. Niekoniecznie musimy mieć tutaj do czynienia z &lt;a href=&#34;https://pl.wikipedia.org/wiki/Planowane_starzenie&#34;&gt;planowanym postarzaniem
sprzętu&lt;/a&gt; i zwyczajnie możemy trafić na trefny
model, którego wada fabryczna wyjdzie po 2-3 miesiącach użytkowania. Poza tym, producenci dysków
implementują w nich te energooszczędne rozwiązania, które znacznie skracają żywotność nośników.
Można o tym przekonać się analizując &lt;a href=&#34;https://morfikov.github.io
/post/parkowanie-glowicy-w-dyskach-wstern-digital/&#34;&gt;193 parametr SMART (Load/Unload Cycle) odpowiadający za
parkowanie głowicy&lt;/a&gt; w dyskach
firmy Western Digital. Także na dobrą sprawę nie możemy być pewni kiedy nam ten dysk zwyczajnie
odmówi posłuszeństwa. Dlatego też powinniśmy się zabezpieczyć na taką ewentualność robiąc kopię
bezpieczeństwa (backup) danych zawartych na dysku. W tym wpisie postaramy się zrobić kompletny obraz
dysku laptopa przy pomocy narzędzi &lt;code&gt;dd&lt;/code&gt; i &lt;code&gt;nc&lt;/code&gt; (netcat). Nie będziemy przy tym rozkręcać urządzenia
czy też podłączać do portu USB zewnętrznego nośnika. Dane prześlemy zwyczajnie przez sieć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mechanizm inhibitor lock w systemd</title>
      <link>https://morfikov.github.io/post/mechanizm-inhibitor-lock-w-systemd/</link>
      <pubDate>Thu, 04 Feb 2016 23:36:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mechanizm-inhibitor-lock-w-systemd/</guid>
      <description>&lt;p&gt;Hibernacja w przypadku komputerów, zwłaszcza laptopów, to bardzo użyteczny wynalazek. Na linux&#39;ach
wymaga ona czasem lekkiej konfiguracji ale generalnie można powiedzieć, że działa OOTB. Po migracji
szeregu dystrybucji na systemd, proces hibernacji zdaje się przebiegać nieco inaczej niż to miało
miejsce w przeszłości. Bardzo często możemy się spotkać z sytuacjami, gdzie przy próbie
zahibernowania czy wyłączenia systemu, ten zwyczajnie ignoruje nasze żądanie i pracuje dalej jak
gdyby nigdy nic. W tym przypadku nie mamy do czynienia z bug&#39;iem ale ficzerem. Okazuje się bowiem,
że systemd dysponuje mechanizmem zwanym &lt;a href=&#34;https://www.freedesktop.org/wiki/Software/systemd/inhibit/&#34;&gt;inhibitor
lock&lt;/a&gt;, który ma na celu powstrzymanie
systemu od dokonania hibernacji, uśpienia lub wyłączenia w pewnych określonych sytuacjach. W tym
wpisie przyjrzymy się nieco bliżej temu mechanizmowi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja protokołu IPv6 za pomocą tunelu 6to4</title>
      <link>https://morfikov.github.io/post/implementacja-protokolu-ipv6-za-pomoca-tunelu-6to4/</link>
      <pubDate>Thu, 04 Feb 2016 16:57:37 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-protokolu-ipv6-za-pomoca-tunelu-6to4/</guid>
      <description>&lt;p&gt;Ogromna cześć lokalnych ISP zdaje się nie nadążać za ciągle zmieniającą się rzeczywistością. Problem
dotyczy implementacji protokołu IPv6, który jest już z nami od bardzo wielu lat. W przypadku mojego
obecnego ISP raczej nie mam co liczyć na to, by w bliżej nieokreślonej przyszłości dodał on obsługę
tego protokołu. Istnieje jednak mechanizm zwany &lt;a href=&#34;https://pl.wikipedia.org/wiki/6to4&#34;&gt;tunelowaniem pakietów protokołu IPv6 wewnątrz
pakietów protokołu IPv4&lt;/a&gt; (w skrócie 6to4), którym warto się
zainteresować. W ogromnym skrócie, część puli adresowej IPv6 jest zarezerwowana i zmapowana na
adresy protokołu IPv4. Dzięki takiemu podejściu, każdy kto posiada stały zewnętrzny adres IPv4 ma
również adres w puli IPv6. Mając zatem zarezerwowany adres, możemy pokusić się o utworzenie tunelu
6to4, co aktywuje w naszej infrastrukturze ten nowszy protokół obchodząc jednocześnie ograniczenia
ISP. Trzeba jednak mieć na względzie, że nie jest to natywne wsparcie dla protokołu IPv6 i jest
niemal pewne, że wystąpią mniejsze lub większe problemy z wydajnością.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak dodać nowy dysk do LVM</title>
      <link>https://morfikov.github.io/post/jak-dodac-nowy-dysk-lvm/</link>
      <pubDate>Tue, 02 Feb 2016 16:21:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-dodac-nowy-dysk-lvm/</guid>
      <description>&lt;p&gt;Rozmiary obecnych dysków twardych zwykliśmy już liczyć w TiB. Jest to dość sporo ale ciągle zdarzają
się sytuacje, gdzie zaczyna nam brakować miejsca na pliki. W takich przypadkach myślimy raczej o
zmianie rozmiaru istniejących już partycji czy też dokupieniu nowego dysku. Pierwsza z powyższych
opcji nie zawsze może wchodzić w grę, no chyba, że zaimplementowaliśmy sobie
&lt;a href=&#34;https://pl.wikipedia.org/wiki/LVM&#34;&gt;LVM&lt;/a&gt;. Jeśli tak, to możemy bez większego problemu &lt;a href=&#34;https://morfikov.github.io
/post/zmiana-rozmiaru-lvm/&#34;&gt;zmieniać
rozmiar każdego z tych voluminów LVM&lt;/a&gt;. Niemniej jednak,
nawet jeśli już dostosujemy sobie te wirtualne dyski, to miejsce wciąż może nam się skończyć i
raczej można przyjąć za pewne, że tak się stanie w bliżej nieokreślonej przyszłości. Gdy to nastąpi,
czeka nas druga opcja wymieniona wyżej, tj. zaopatrzenie się w dodatkowy nośnik danych. Przy pomocy
LVM jesteśmy w stanie ten nowy dysk dodać do istniejącej grupy voluminów i zwiększyć tym wirtualnym
partycjom rozmiar bez potrzeby przerywania pracy systemu, czy też wykonywania dodatkowych czynności
związanych z formatowaniem i instalowaniem systemu na nowo. W tym wpisie postaramy się przebrnąć
przez ten proces.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Streaming obrazu za sprawą ffmpeg i netcat</title>
      <link>https://morfikov.github.io/post/streaming-obrazu-za-sprawa-ffmpeg-netcat/</link>
      <pubDate>Sat, 30 Jan 2016 20:37:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/streaming-obrazu-za-sprawa-ffmpeg-netcat/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=28188&#34;&gt;Na forum DUG&#39;a pojawił się ciekawy post&lt;/a&gt;, w którym
autor wątku chciał wykonać coś co określił jako &amp;quot;display mirroring&amp;quot;. Poszukałem trochę informacji na
temat tego zagadnienia i okazało się, że to nic innego jak tylko wyświetlenie tej samej zawartości,
np. na dwóch monitorach. Nie jest to nic zaawansowanego, bo przecie Xserver jest w stanie tego typu
zadanie zrealizować. Niemniej jednak, oba monitory muszą być podłączone do tego samego komputera. W
tym przypadku mamy dwie maszyny i dwa osobne monitory. Celem jest przesłanie obrazu z jednej maszyny
na drugą za pomocą sieci. W tym podlinkowanym wątku została poruszona kwestia przechwycenia obrazu
przy pomocy &lt;code&gt;ffmpeg&lt;/code&gt; i przesłania go przez sieć za pomocą &lt;code&gt;nc&lt;/code&gt; (netcat). Tak bardzo zainteresowało
mnie to rozwiązanie, że postanowiłem zobaczyć jak wygląda ono w praktyce.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana identyfikatora UUID</title>
      <link>https://morfikov.github.io/post/zmiana-identyfikatora-uuid/</link>
      <pubDate>Sat, 30 Jan 2016 16:52:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-identyfikatora-uuid/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=28210&#34;&gt;Na forum DUG&#39;a po raz kolejny pojawił się post&lt;/a&gt;
dotyczący unikalnych identyfikatorów, które są nadawane partycjom dysków twardych. Nie wiem jak
sprawa ma się w przypadku windowsów ale linux na podstawie tych numerów
&lt;a href=&#34;https://en.wikipedia.org/wiki/Universally_unique_identifier&#34;&gt;UUID&lt;/a&gt;
(&lt;a href=&#34;https://pl.wikipedia.org/wiki/Globally_Unique_Identifier&#34;&gt;GUID&lt;/a&gt;) jest w stanie identyfikować
konkretne urządzenia. Czasem się zdarza tak, że dwa dyski czy partycje mają taki sam identyfikator,
co prowadzi zwykle do problemów. Kolizja numerów identyfikacyjnych może być wynikiem pozostałości po
procesie produkcyjnym ale może także powstać za sprawą klonowania nośnika za pomocą narzędzia &lt;code&gt;dd&lt;/code&gt; .
Tak czy inaczej, przydałoby się wiedzieć jak ustalić, poprawnie wygenerować czy też zmienić UUID
wszędzie tam, gdzie jest on wykorzystywany i o tym będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja multipleksera tmux</title>
      <link>https://morfikov.github.io/post/implementacja-multipleksera-tmux/</link>
      <pubDate>Sat, 30 Jan 2016 03:30:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-multipleksera-tmux/</guid>
      <description>&lt;p&gt;Wszystko zaczęło się od pewnego posta na &lt;a href=&#34;https://forum.dug.net.pl/&#34;&gt;forum DUGa&lt;/a&gt;, w którym to jeden
użytkownik polecał innemu, aby ten zainteresował się programem o nazwie &lt;code&gt;tmux&lt;/code&gt; . Nie wiem czy tamta
osoba to zrobiła ale ja postanowiłem się przyjrzeć temu wynalazkowi zwanemu &lt;a href=&#34;https://en.wikipedia.org/wiki/Terminal_multiplexer&#34;&gt;terminal
multiplekser&lt;/a&gt;. Po niezbyt wnikliwym przejrzeniu
&lt;a href=&#34;https://tmux.github.io/&#34;&gt;strony projektu&lt;/a&gt; rzuciło mi się w oczy dzielenie okna jednego terminala na
szereg mniejszych. Ten ficzer znany był mi min. z &lt;a href=&#34;https://gnometerminator.blogspot.fr/p/introduction.html&#34;&gt;terminala
terminator&lt;/a&gt;. Zasadniczą różnicą tych dwóch
aplikacji jest to, że &lt;code&gt;tmux&lt;/code&gt; może być uruchomiony również pod TTY, efektywnie dzieląc obszar jednej
konsoli. Nie to bym ciągle siedział w trybie tekstowym ale skoro &lt;code&gt;tmux&lt;/code&gt; potrafi to samo co
&lt;code&gt;terminator&lt;/code&gt; oraz działa zarówno w trybie graficznym jak i tekstowym przy zaznaczeniu, że zjada
także mniej pamięci RAM, to czemu nie zaimplementować sobie jego obsługi? W trakcie użytkowania
tmux&#39;a okazało, że potrafi on sporo więcej i dlatego właśnie powstał ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wyłączyć systemowy &#34;beep&#34;</title>
      <link>https://morfikov.github.io/post/jak-wylaczyc-glosnik-sprzetowy-w-komputerze/</link>
      <pubDate>Mon, 25 Jan 2016 21:56:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wylaczyc-glosnik-sprzetowy-w-komputerze/</guid>
      <description>&lt;p&gt;Zgodnie z tym co można wyczytać na &lt;a href=&#34;https://wiki.archlinux.org/index.php/Disable_PC_speaker_beep&#34;&gt;wiki
Archlinux&#39;a&lt;/a&gt;, mamy kilka źródeł
generowania dźwięków, które trafiają do wbudowanego głośnika naszego komputera (case speaker). Te
dźwięki określane mianem &amp;quot;beep&amp;quot; mogą powstać za sprawą BIOS&#39;u płyty głównej, systemu operacyjnego,
środowiska graficznego lub też różnych programów użytkowych. Najbardziej uporczywe są dźwięki
generowane przez BIOS. Na dobrą sprawę, jeśli w BIOS&#39;ie nie ma żadnych opcji dotyczących
konfiguracji tego głośnika, to raczej niewiele jesteśmy w stanie zrobić w tej kwestii. Możemy zawsze
ten głośnik odłączyć fizycznie. Choć nie jest to zalecane, bo na podstawie wydawanych przez niego
dźwięków, jesteśmy w stanie określić czy z naszym komputerem jest wszystko w porządku. Niemniej
jednak, w tych pozostałych trzech w/w punkach mamy większe pole manewru, gdzie możemy dostosować
sobie szereg parametrów i o tym właśnie będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Odpowiedni DPI (PPI) dla monitora</title>
      <link>https://morfikov.github.io/post/odpowiedni-dpi-dla-monitora-pod-xserverem/</link>
      <pubDate>Sun, 24 Jan 2016 22:22:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/odpowiedni-dpi-dla-monitora-pod-xserverem/</guid>
      <description>&lt;p&gt;Monitory posiadają różne wymiary fizyczne i co za tym idzie mają też inne rozdzielczości. Te
informacje nie są jakoś zbytnio tajne i każdy klient przed zakupem konkretnego modelu monitora jest
w stanie się zapoznać z tymi parametrami. To co zwykle sprzedawcy starają się ukryć przed nami, to
współczynnik &lt;a href=&#34;https://pl.wikipedia.org/wiki/Ppi&#34;&gt;PPI (pixels per inch)&lt;/a&gt;. Zwykle też można spotkać
się z terminem &lt;a href=&#34;https://pl.wikipedia.org/wiki/Dpi&#34;&gt;DPI (dots per inch)&lt;/a&gt;. Nie są one równoznaczne,
bo w monitorach LCD jeden piksel składa się z trzech podpikseli. Sprzedawcy wykorzystują ten fakt i
chwalą się, że dany model monitora ma 300 DPI. W skrajnych przypadkach można nawet usłyszeć i 300
PPI. Osoby, które nie rozróżniają tych dwóch pojęć mogą bardzo łatwo zostać oszukane podczas zakupu.
Problem potęguje fakt, że gdy monitor jest sporych rozmiarów i patrzymy na niego z większej
odległości, to nawet nie dostrzeżemy, że nas oszukano. Na wszelki wypadek lepiej założyć, że
sprzedawca ma co innego na myśli niż my i podaną wartość podzielić przez 3, a następnie
skontrastować tak otrzymaną liczbę z PPI większości monitorów (100). Niemniej jednak, dobrze jest
przed zakupem monitora sprawdzić jaki współczynnik PPI ma dany model i nie sugerować się tym co
sprzedawca napisał w ofercie. Dlatego też w tym wpisie postaramy się ustalić faktyczną wartość PPI
dla naszego obecnego lub przyszłego monitora.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja terminala urxvt</title>
      <link>https://morfikov.github.io/post/konfiguracja-terminala-urxvt/</link>
      <pubDate>Sat, 23 Jan 2016 19:13:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-terminala-urxvt/</guid>
      <description>&lt;p&gt;Na rynku oprogramowania linux&#39;owego mamy całą gamę różnego rodzaju pseudo terminali, które na dobrą
sprawę robią za konsolę w środowiskach graficznych. Jako, że takie środowiska rozrosły się dość
mocno ostatnimi czasy, to instalacja niektórych terminali może pociągać za sobą wiele zależności. To
z kolei przyczynia się do wgrania zbędnego oprogramowania. Inną kwestią są zasoby systemowe, bo
niektóre z terminali potrafią zjeść naprawdę sporo pamięci operacyjnej. Są oczywiście lżejsze
alternatywy i w tym wpisie omówimy sobie konfigurację terminala urxvt.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ukrywanie informacji w plikach (steganografia)</title>
      <link>https://morfikov.github.io/post/ukrywanie-informacji-w-plikach-steganografia/</link>
      <pubDate>Thu, 21 Jan 2016 21:49:23 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ukrywanie-informacji-w-plikach-steganografia/</guid>
      <description>&lt;p&gt;Jak możemy wyczytać na wikipedii, &lt;a href=&#34;https://pl.wikipedia.org/wiki/Steganografia&#34;&gt;steganografia&lt;/a&gt; to
nauka, która ma na celu ukrycie faktu prowadzenia komunikacji. Odróżnia ją to nieco od kryptografii,
gdzie wiadomość jest wprawdzie nieczytelna ale wiadome jest, że dokonywana jest wymiana informacji
między dwoma punktami. W przypadku steganografii możemy ukryć pewną informację, np. w pliku
graficznym maskując tym samym cały proces przekazywania danych. W taki sposób osoba, która nie ma
pojęcia o fakcie ukrycia informacji, zobaczymy jedynie zwykły obrazek. Poniższy wpis ma na celu
sprawdzenie jak skuteczna jest ta metoda i czy nadaje się do zastosowania dla przeciętnego zjadacza
chleba.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Metadane plików graficznych (EXIF)</title>
      <link>https://morfikov.github.io/post/metadane-plikow-graficznych-exif/</link>
      <pubDate>Thu, 21 Jan 2016 16:58:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/metadane-plikow-graficznych-exif/</guid>
      <description>&lt;p&gt;Każdy plik posiada szereg opisujących go atrybutów. Możemy się o tym przekonać wykorzystując
narzędzia &lt;code&gt;ls&lt;/code&gt; lub &lt;code&gt;stat&lt;/code&gt; . W ich przypadku zostaną nam zwrócone takie informacje jak rozmiar
pliku, data modyfikacji czy też prawa dostępu. To właśnie są metadane opisujące pliki w obszarze
systemu plików i są one wymagane, by system operacyjny działał prawidłowo. To jednak nie jedyne
metadane, z którymi spotykamy się na co dzień. Najlepszym przykładem są zdjęcia czy filmy robione
smartfonami czy też aparatami lub kamerami cyfrowymi. Każdy plik stworzony za pomocą tych urządzeń
zawiera w sobie bardzo rozbudowane informacje, które nie zawsze chcielibyśmy udostępniać. W tym
wpisie skupimy się głównie na &lt;a href=&#34;https://pl.wikipedia.org/wiki/Exchangeable_Image_File_Format&#34;&gt;danych
EXIF&lt;/a&gt; zawartych w plikach graficznych,
które postaramy się wydobyć, zmienić i usunąć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Quake II pod linux&#39;em bez Wine</title>
      <link>https://morfikov.github.io/post/quake-ii-pod-linuxem-bez-wine/</link>
      <pubDate>Tue, 19 Jan 2016 16:59:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/quake-ii-pod-linuxem-bez-wine/</guid>
      <description>&lt;p&gt;Linux nie nadaje się za bardzo na konsolę do gier i do tego stwierdzenia raczej nikogo nie trzeba
przekonywać. Wszyscy znamy projekt WineHQ, który umożliwia odpalanie szeregu aplikacji z windowsa, w
tym też i gier, ale zwykle też trzeba się nieco napracować, by daną grę uruchomić pod Wine. Nawet
jeśli się nam to uda, to i tak zawsze będziemy mieć problemy czy to z wydajnością, czy też jakimiś
mniej lub bardziej dającymi się we znaki błędami. Bardzo rzadko zdarza mi się grać w cokolwiek ale
jest kilka kultowych gierek z lat &#39;90, które można odpalić na linux&#39;ie bez zaciągania do tego Wine.
Jedyne czego nam potrzeba to posiadać nośnik z plikami do danej gry. W tym wpisie postaramy się
odpalić Quake II na 64 bitowym debianie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Emulacja rolek myszy (scroll)</title>
      <link>https://morfikov.github.io/post/emulacja-rolek-myszy-scroll/</link>
      <pubDate>Sun, 17 Jan 2016 17:14:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/emulacja-rolek-myszy-scroll/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?pid=295709&#34;&gt;Na forum DUG&lt;/a&gt; pojawił się ciekawy temat
dotyczący emulacji rolek myszy (scroll) w urządzeniach, które ich nie posiadają. W tym przypadku
chodziło o bliżej nieokreślony model &lt;a href=&#34;https://pl.wikipedia.org/wiki/Trackball&#34;&gt;trackball&#39;a&lt;/a&gt;.
Niemniej jednak, są też myszy, które może i rolki mają, ale użytkownikom tych urządzeń zwyczajnie
nie chce się wysilać, by tymi kółkami kręcić non stop. Jako, że ja się zaliczam do tej grupy osób,
pomyślałem, by zaimplementować sobie ficzer, który sprawi, że moja bardzo wypasiona mysz będzie
miała pod prawym przyciskiem również emulację scroll&#39;a. Oczywiście dalej będzie można klikać prawym
przyciskiem, by uzyskać dostęp do menu kontekstowego i pod tym względem nic się nie zmieni. W tym
wpisie sprawdzimy jak taka emulacja rolek wygląda w praktyce.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Nagłówek kontenera LUKS trzymany na pendrive</title>
      <link>https://morfikov.github.io/post/naglowek-kontenera-luks-trzymany-na-pendrive/</link>
      <pubDate>Fri, 15 Jan 2016 20:28:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/naglowek-kontenera-luks-trzymany-na-pendrive/</guid>
      <description>&lt;p&gt;Jeśli kiedyś rozważaliśmy &lt;a href=&#34;https://morfikov.github.io
/post/keyfile-trzymany-w-glebokim-ukryciu/&#34;&gt;umieszczenie pliku klucza (keyfile) do zaszyfrowanego kontenera LUKS na
pendrive&lt;/a&gt;, to ciekawszą alternatywą
może okazać się umieszczenie całego nagłówka takiego kontenera na zewnętrznym nośniku. Ma to tę
przewagę nad keyfile, że wszystkie informacje zapewniające dostęp do kontenera, wliczając w to klucz
główny, są oddzielone od zaszyfrowanych danych. W ten sposób nawet jeśli kontener wpadnie w
niepowołane ręce, to nie ma żadnego sposobu na to, by ten ktoś te dane odzyskał, no bo przecie nie
ma klucza szyfrującego. Przechwycenie hasła również nic to nie zmieni, no chyba, że ten ktoś
zdobędzie również pendrive z nagłówkiem kontenera. Z ludzkiego punktu widzenia, to na takim dysku
będą znajdować się jedynie losowymi dane i do tego w formie kompletnie nieczytelnej dla człowieka
(brak systemu plików). Niemniej jednak, jest kilka rzeczy, o których warto pamiętać, gdy w grę
wchodzi nagłówek LUKS i to o nich porozmawiamy sobie w tym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klucz główny kontenera LUKS i jego odzyskanie</title>
      <link>https://morfikov.github.io/post/odzyskanie-klucza-glownego-w-kontenerze-luks/</link>
      <pubDate>Fri, 15 Jan 2016 16:25:39 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/odzyskanie-klucza-glownego-w-kontenerze-luks/</guid>
      <description>&lt;p&gt;Kontenery LUKS to takie wynalazki, za których pomocą jesteśmy w stanie zaszyfrować całe dyski
twarde, a właściwie to znajdujące się na nich dane. Taki kontener składa się głównie z nagłówka,
który jest umieszczany na początku partycji. By być w stanie dokonać szyfrowania i deszyfrowania
informacji w locie, system musi posiadać klucz główny (master key). Ten klucz jest przechowywany w
nagłówku i by go wydobyć, musimy wprowadzić jedno z haseł do kontenera. Później klucz wędruje do
pamięci, a hasło jest z niej usuwane. W ten sposób system ma dostęp do klucza głównego przez cały
czas począwszy od chwili otwarcia kontenera, aż do momentu jego zamknięcia. &lt;a href=&#34;https://gitlab.com/cryptsetup/cryptsetup/wikis/FrequentlyAskedQuestions&#34;&gt;Ten klucz jesteśmy w
stanie bez większego problemu
wydobyć&lt;/a&gt;, co może być
bardzo przydatne na wypadek zapomnienia hasła, czy też uszkodzenia samego nagłówka. W tym wpisie
postaramy się odzyskać klucz główny zaszyfrowanego kontenera LUKS.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Backup systemu przy pomocy LVM snapshot</title>
      <link>https://morfikov.github.io/post/backup-przy-pomocy-lvm-snapshot/</link>
      <pubDate>Fri, 15 Jan 2016 14:09:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/backup-przy-pomocy-lvm-snapshot/</guid>
      <description>&lt;p&gt;W dzisiejszych czasach systemy operacyjne są bardziej odporne na błędy niż to miało miejsce kilka
czy kilkanaście lat temu. Bardzo ciężko jest się zatem odnaleźć w sytuacji, gdzie nasz linux odmawia
współpracy i nie chce się w ogóle uruchomić. Niemniej jednak, jeśli chodzi o samą kwestię
naprawiania szkód po ewentualnej awarii systemu, to, jakby nie patrzeć, zajmuje ona nasz cenny czas.
Oczywiście takie błędy sprawiają, że mamy szansę nieco zgłębić strukturę używanego systemu
operacyjnego ale też pojawiają się w najmniej oczekiwanym momencie. W takiej sytuacji nie ma mowy
byśmy siedzieli paręnaście minut i zastanawiali się nad tym dlaczego coś nie działa jak należy.
Jest kilka mechanizmów bezpieczeństwa, które mogą nam nieco czasu zaoszczędzić. W tym wpisie omówimy
sobie zagadnienia związane z &lt;a href=&#34;http://www.tldp.org/HOWTO/html_single/LVM-HOWTO/#snapshotintro&#34;&gt;LVM
snapshot&lt;/a&gt;, czyli migawką systemu,
którą możemy wykonać praktycznie natychmiast i w razie problemów przywrócić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Domyślne aplikacje w oparciu o typy plików (MIME)</title>
      <link>https://morfikov.github.io/post/domyslne-aplikacje-w-oparciu-o-typy-plikow-mime/</link>
      <pubDate>Tue, 12 Jan 2016 20:18:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/domyslne-aplikacje-w-oparciu-o-typy-plikow-mime/</guid>
      <description>&lt;p&gt;Pełne środowiska graficzne zwykle oferują odpowiednie narzędzia, które mogą posłużyć skonfigurowaniu
domyślnych aplikacji. Jesteśmy zatem w stanie bardzo prosto przypisać szereg &lt;a href=&#34;https://pl.wikipedia.org/wiki/Typ_MIME&#34;&gt;typów
MIME&lt;/a&gt; do odpowiednich programów. Wobec takiego stanu rzeczy,
przy próbie uruchomienia jakiegoś pliku, ten zostanie odpalony przez konkretną aplikację. Niemniej
jednak, jeśli chodzi o środowiska graficzne oparte o menadżery okien, np. Openbox, to na dobrą
sprawę mamy bardzo małe pole manewru. Niezależnie czy korzystamy z GNOME, KDE, XFCE, MATE czy też
Openbox&#39;a, wszystkie z nich wykorzystują dokładnie ten sam mechanizm wiązania aplikacji z typami
plików. Możemy zatem ominąć te wszystkie graficzne nakładki i ręcznie skonfigurować sobie typy MIME,
tak by działały niezależnie od wykorzystywanego środowiska graficznego. W tym wpisie spróbujemy
przyjrzeć się nieco bliżej konfiguracji tego całego mechanizmu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja serwera dźwięku PulseAudio</title>
      <link>https://morfikov.github.io/post/konfiguracja-serwera-dzwieku-pulseaudio/</link>
      <pubDate>Mon, 11 Jan 2016 21:49:37 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-serwera-dzwieku-pulseaudio/</guid>
      <description>&lt;p&gt;Wielu użytkowników linux&#39;a nie przepada zbytnio za PulseAudio, bo ten z jakiegoś powodu sprawia u
nich same kłopoty. U mnie ten serwer dźwięku działa przyzwoicie i zwykle nie ma z nim żadnych
problemów. Obecnie ten projekt jest już na tyle dojrzały, że te większe środowiska graficzne
zwyczajnie polegają na nim w zależnościach. Jeśli jednak &lt;a href=&#34;https://morfikov.github.io
/post/instalacja-debiana-z-wykorzystaniem-debootstrap/&#34;&gt;instalowaliśmy debiana za pomocą narzędzia
debootstrap&lt;/a&gt; i
&lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-xservera-na-debianie-xorg/&#34;&gt;konfigurowaliśmy osobno graficzną sesję
Xserver&#39;a&lt;/a&gt;, &lt;a href=&#34;https://morfikov.github.io
/post/menadzer-logowania-lightdm/&#34;&gt;menadżer logowania
LightDM&lt;/a&gt; czy też &lt;a href=&#34;https://morfikov.github.io
/post/menadzer-okien-openbox/&#34;&gt;menadżer okien
Openbox&lt;/a&gt;, to raczej zależy nam na minimalnym
środowisku, które może się zwyczajnie obejść bez PulseAudio. Niemniej jednak, PulseAudio ma kilka
ciekawych bajerów, których ALSA nie posiada. By się nie rozpisywać zbytnio, mogę wspomnieć choćby o
możliwości&lt;a href=&#34;https://morfikov.github.io
/post/pulseaudio-i-przesylanie-dzwieku-przez-siec/&#34;&gt;przesyłania dźwięku przez
sieć&lt;/a&gt;, czy też o takim
ficzerze jak &lt;a href=&#34;https://morfikov.github.io
/post/normalizacja-glosnosci-w-pulseaudio/&#34;&gt;normalizacja głośności&lt;/a&gt;.
Są to głównie zabawki dla nieco bardziej zaawansowanych użytkowników i gdy ich nie potrzebujemy, to
serwer dźwięku nam się raczej do niczego nie przyda. Warto jednak się zaznajomić z tym nieco
bardziej zaawansowanym kawałkiem oprogramowania i w tym wpisie postaramy się nieco omówić instalację
i konfigurację tego serwera dźwięku.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Menadżer okien Openbox</title>
      <link>https://morfikov.github.io/post/menadzer-okien-openbox/</link>
      <pubDate>Sun, 10 Jan 2016 21:31:47 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/menadzer-okien-openbox/</guid>
      <description>&lt;p&gt;Spora większość środowisk graficznych rozrosła się obecnie nieco i ich instalacja na maszynach
wyposażonych w niewiele pamięci RAM może nie wchodzić w grę. Nie jesteśmy też skazani na życie w
konsoli, ani na kupno nowego sprzętu. Możemy nieco odchudzić instalację pozbywając się zbędnych
usług, których tak naprawdę nie potrzebujemy. Poza tym, praktycznie każde z graficznych narzędzi,
przy pomocy których chcemy konfigurować linux&#39;a, ma tekstowe zamienniki, lub też o wiele lżejsze
alternatywy. Jednak w przypadku, gdy korzystamy z takich rozbudowanych środowisk jak GNOME, to nie
koniecznie da się usunąć szereg tych zasobożernych komponentów. Pozostaje nam zwykle jedna opcja,
którą jest usunięcie całego środowiska graficznego i zainstalowanie potrzebnych nam komponentów
osobno. Jako, że mamy już opisany&lt;a href=&#34;https://morfikov.github.io
/post/instalacja-debiana-z-wykorzystaniem-debootstrap/&#34;&gt;proces instalacji debiana przy pomocy
debootstrap&lt;/a&gt;, &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-xservera-na-debianie-xorg/&#34;&gt;instalację i
konfigurację Xserver&#39;a&lt;/a&gt;, jak i
również &lt;a href=&#34;https://morfikov.github.io
/post/menadzer-logowania-lightdm/&#34;&gt;menadżera okien LightDM&lt;/a&gt;, to przyszedł
czas na omówienie niezbędnego w sesji graficznej &lt;a href=&#34;https://pl.wikipedia.org/wiki/Mened%C5%BCer_okien&#34;&gt;menadżera
okien&lt;/a&gt;. W tym wpisie skupimy się głównie na
instalacji i konfiguracji Openbox&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Menadżer logowania LightDM</title>
      <link>https://morfikov.github.io/post/menadzer-logowania-lightdm/</link>
      <pubDate>Fri, 08 Jan 2016 20:12:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/menadzer-logowania-lightdm/</guid>
      <description>&lt;p&gt;Istnieje kilka sposobów na to, by uruchomić sesję graficzną Xserver&#39;a. W przypadku, gdy nie
wykorzystujemy zaawansowanych środowisk graficznych, zwykle korzystamy z polecenia &lt;code&gt;startx&lt;/code&gt;
wydawanego zaraz po zalogowaniu się na konsolę TTY. Niemniej jednak, nawet w tych najprostszych
środowiskach graficznych możemy pokusić się o instalację lekkiego menadżera okien, tak by nie
musieć konfigurować samodzielnie szeregu opcji sesji. Menadżery logowania (display managers) mają
na celu zrobienie dokładnie tego samego co pliki &lt;code&gt;~/.xinitrc&lt;/code&gt; i &lt;code&gt;~/.xserverrc&lt;/code&gt; , z tym, że w nieco
bardziej przyjaznej dla użytkownika formie. W tym wpisie przyjrzymy się nieco dokładniej
&lt;a href=&#34;https://www.freedesktop.org/wiki/Software/LightDM/&#34;&gt;menadżerowi LightDM&lt;/a&gt;. Zostanie także omówiony
sposób blokowania aktywnej sesji Xserver&#39;a bez potrzeby jej zamykania przy pomocy narzędzia
&lt;a href=&#34;https://github.com/the-cavalry/light-locker&#34;&gt;light-locker&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja Xserver&#39;a na debianie (Xorg)</title>
      <link>https://morfikov.github.io/post/konfiguracja-xservera-na-debianie-xorg/</link>
      <pubDate>Fri, 08 Jan 2016 17:53:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-xservera-na-debianie-xorg/</guid>
      <description>&lt;p&gt;Dzięki takiemu wynalazkowi jak Xserver (Xorg) mamy możliwość odpalania aplikacji graficznych. Bez
niego wszystko musielibyśmy robić w czarnej konsoli, przez co funkcjonalność naszej maszyny w dość
znacznym stopniu ucierpiałaby. Oczywiście tryb graficzny ma też swoje wady. Niemniej jednak, Xserver
leży póki co u podstaw każdego środowiska graficznego i jeśli chcemy mieć możliwość odpalania, np.
Firefox&#39;a, czy oglądania filmów w VLC, to nie ma innego wyjścia jak skonfigurować sobie Xserver. W
tym wpisie się zajmiemy tym zagadnieniem, przy czym, chcę uprzedzić, że nie będziemy korzystać z
żadnych automatów, które można znaleźć w tych wszystkich zaawansowanych środowiskach graficznych. A
to z tego względu, że ustawienia tych środowisk zwykle nadpisują ustawienia samego Xserver&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mysz i jej konfiguracja na linux&#39;ie</title>
      <link>https://morfikov.github.io/post/mysz-i-jej-konfiguracja-na-linuxie/</link>
      <pubDate>Fri, 08 Jan 2016 15:09:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mysz-i-jej-konfiguracja-na-linuxie/</guid>
      <description>&lt;p&gt;Mysz, zaraz obok klawiatury, to jedno z tych narzędzi, z których korzystamy praktycznie bez przerwy
ilekroć tylko siadamy przed komputerem. Z reguły działa ona prawidłowo, nawet pod linux&#39;em, z tym,
że dla jednych użytkowników standardowe ustawienia nie są zbyt zadowalające. Nawet jeśli wszystkie
przyciski zostaną rozpoznane poprawnie, to zawsze pozostaje, np. kwestia dostosowania szybkości
przemieszczania się kursora po ekranie. Oczywiście, istnieje także szereg innych aspektów, które
możemy sobie dostosować i tym właśnie się zajmiemy w niniejszym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja jasności ekranu w laptopie (backlight)</title>
      <link>https://morfikov.github.io/post/konfiguracja-jasnosci-ekranu-w-laptopie-backlight/</link>
      <pubDate>Tue, 05 Jan 2016 21:52:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-jasnosci-ekranu-w-laptopie-backlight/</guid>
      <description>&lt;p&gt;Linux nigdy nie był popularnym systemem operacyjnym na stacjach klienckich. Może i cieszy się sporym
wzięciem wśród środowisk serwerowych ale jego niezbyt prosta obsługa nie przemawia do przeciętnego
użytkownika komputera. Wraz z rozwojem technologi, zmienił się też rodzaj urządzeń na jakich
obecnie pracujemy. W dzisiejszych czasach liczy się przede wszystkim mobilność i praktycznie każdy z
nas miał już prawdopodobnie do czynienia z laptopami. Producenci tych urządzeń lubią nam wciskać
windowsa z dopiskiem, że ten laptop bez niego nie będzie w ogóle nam działał. Już od dość dawna
szereg laptopów jest w stanie pracować pod linux&#39;em ale, jakby nie patrzeć, sporo rzeczy w nich nie
działa OOTB i trzeba poświęcić trochę czasu, by tę maszynę doprowadzić do porządku. W tym wpisie
zajmiemy się zagadnieniem podświetlania matrycy (backlight), tak by system był w stanie bez problemu
zapisać ustawienia jasności ekranu przy wyłączaniu komputera oraz, by potrafił je także wczytać
podczas fazy rozruchu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Monitor i jego konfiguracja pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/monitor-i-jego-konfiguracja-pod-linuxem/</link>
      <pubDate>Mon, 04 Jan 2016 18:02:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/monitor-i-jego-konfiguracja-pod-linuxem/</guid>
      <description>&lt;p&gt;Obecnie w linux&#39;ach spora cześć sprzętu jest rozpoznawana prawidłowo, a my nie musimy poświęcać
czasu na dodatkową konfigurację. Domyślne ustawienia sprawdzają się praktycznie za każdym razem, gdy
w grę nie wchodzi nic bardziej zaawansowanego. W tym wpisie rzucimy okiem na konfigurację Xserver&#39;a,
która dotyczyć będzie wyświetlanego obrazu na monitorze. Pośrednio też będziemy musieli
skonfigurować sobie kartę graficzną, bo to ona jest odpowiedzialna w dużej mierze za to, co jest
odbierane przez nasz monitor.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja touchpad&#39;a w laptopie pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/konfiguracja-touchpada-w-laptopie-pod-linuxem/</link>
      <pubDate>Sun, 03 Jan 2016 20:48:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-touchpada-w-laptopie-pod-linuxem/</guid>
      <description>&lt;p&gt;Laptopy zwykle mają niewielkie rozmiary i są możliwie okrojone, tak by zapewnić jak największą
mobilność. Oczywiście nikt tych maszyn nie pozbawił klawiatury, bo to czyniłoby je mało użytecznymi.
Możemy oczywiście spotkać całą masę modeli, które nie mają wydzielonej klawiatury numerycznej, czy
też brak określonych przycisków. Niemniej jednak, nie jest to aż taka niedogodność jak brak myszy. W
laptopach zamiast myszki mamy zaimplementowany &lt;a href=&#34;https://pl.wikipedia.org/wiki/Touchpad&#34;&gt;touchpad&lt;/a&gt;.
Korzystanie z niego wymaga znacznej wprawy ale i tak wątpię, że ktoś byłby w stanie używać go do gry
w CS&#39;a. Tak czy inaczej, każde urządzenie w linux&#39;ie idzie w mniejszym czy większym stopniu sobie
skonfigurować. Taki laptopowy touchpad nie jest żadnym wyjątkiem i w tym wpisie postaramy się go
nieco ogarnąć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Temperatura dysku twardego (hddtemp)</title>
      <link>https://morfikov.github.io/post/temperatura-dysku-twardego-hddtemp/</link>
      <pubDate>Sun, 03 Jan 2016 16:24:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/temperatura-dysku-twardego-hddtemp/</guid>
      <description>&lt;p&gt;Obecnie dyski twarde nie są potrzebne do prawidłowego działania komputera. Mając sporo pamięci
operacyjnej oraz &lt;a href=&#34;https://pl.wikipedia.org/wiki/Live_CD&#34;&gt;system live&lt;/a&gt;, możemy bez problemu korzystać
z takiego sprzętu. Niemniej jednak, systemy live są nieco ograniczone. Najdotkliwszą ich wadą jest
brak zapisywania wprowadzanych zmian. W pewnych przypadkach ta cecha może być bardzo pożądana ale
jeśli chodzi o przeciętnego użytkownika, to chciałby on raczej mieć możliwość zapisu swojej pracy.
Dlatego też zewnętrzny magazyn danych w postaci dysku twardego nie prędko wyjdzie z użytku. Te
urządzenia, jak i większość tych, które podłączamy do naszego komputera, wydzielają ciepło.
Temperatura jest wrogiem numer 1 w przypadku maszyn i musi stale być monitorowana, tak by czasem nie
doszło do przegrzania sprzętu. &lt;a href=&#34;https://pl.wikipedia.org/wiki/Dysk_twardy&#34;&gt;Dyski HDD&lt;/a&gt; mają ten
problem, że im wyższa jest temperatura, tym obszar magnetyczny się bardziej rozszerza, a to powoduje
błędy odczytu i zapisu. Podobnie jest ze zbyt niską temperaturą, gdzie ścieżki i sektory ulegają
skurczeniu. Taki dysk musi pracować w odpowiednich warunkach termalnych. W tym wpisie postaramy się
ustalić aktualną temperaturę dysku oraz spróbujemy ją monitorować, tak by wiedzieć czy czynnik
temperaturowy nie zagraża czasem dyskom podpiętym do naszego PC.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować bonding w Debian linux (eth0&#43;wlan0)</title>
      <link>https://morfikov.github.io/post/konfiguracja-interfejsow-bond-bonding/</link>
      <pubDate>Sat, 02 Jan 2016 15:07:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-interfejsow-bond-bonding/</guid>
      <description>&lt;p&gt;W artykule poświęconym &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-polaczenia-wifi-pod-debianem/&#34;&gt;konfiguracji sieci WiFi na Debianie z wykorzystaniem narzędzia
wpa_supplicant&lt;/a&gt; wspomniałem parę słów na temat &lt;a href=&#34;https://www.kernel.org/pub/linux/kernel/people/marcelo/linux-2.4/Documentation/networking/bonding.txt&#34;&gt;interfejsu bond&lt;/a&gt;. Bonding na linux
wykorzystywany jest w zasadzie do spięcia kilku interfejsów sieciowych, w tym przewodowych
( &lt;code&gt;eth0&lt;/code&gt; ) i bezprzewodowych ( &lt;code&gt;wlan0&lt;/code&gt; ) w jeden (zwykle &lt;code&gt;bond0&lt;/code&gt; ). Takie rozwiązanie sprawia, że
w przypadku awarii któregoś z podpiętych interfejsów, my nie tracimy połączenia z siecią i nie
musimy nic nigdzie przełączać, by to połączenie przywrócić. To rozwiązanie jest o tyle użyteczne,
że w przypadku, gdy podepniemy przewód do gniazda RJ-45 w naszym laptopie, to komunikacja będzie
odbywać się po kablu. Natomiast jeśli przewód zostanie odłączony, to system automatycznie przejdzie
na komunikację bezprzewodową. W tym wpisie spróbujemy zaprojektować sobie właśnie tego typu
mechanizm zarówno za sprawą pakietu &lt;code&gt;ifupdown&lt;/code&gt; , gdzie konfiguracja interfejsów sieciowych jest
zarządzana przez plik &lt;code&gt;/etc/network/interfaces&lt;/code&gt; , jak i przy pomocy natywnego rozwiązania jakie
oferuje systemd/networkd.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instalacja debiana z wykorzystaniem debootstrap</title>
      <link>https://morfikov.github.io/post/instalacja-debiana-z-wykorzystaniem-debootstrap/</link>
      <pubDate>Sat, 02 Jan 2016 03:52:49 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/instalacja-debiana-z-wykorzystaniem-debootstrap/</guid>
      <description>&lt;p&gt;Instalowanie debiana z wykorzystaniem &lt;code&gt;debootstrap&lt;/code&gt; trochę się różni od instalacji z wykorzystaniem
instalatora. Chodzi generalnie o to, że wszystkie kroki instalacyjne trzeba przeprowadzać ręcznie.
Poza tym, cała konfiguracja będzie wymagać manualnego dostosowania. Plus tego rozwiązania jest
oczywisty, albowiem mamy całkowitą władzę nad tym co się w systemie znajdzie oraz jak będzie on
skonfigurowany. By mieć możliwość przeprowadzenia tego typu instalacji potrzebny będzie nam
działający system. Może to być płytka lub pendrive live z &lt;a href=&#34;https://www.debian.org/CD/live/index.pl.html&#34;&gt;Debianem&lt;/a&gt; czy &lt;a href=&#34;https://www.ubuntu.com/download/desktop/try-ubuntu-before-you-install&#34;&gt;Ubuntu&lt;/a&gt;. Można też
wykorzystać już zainstalowany system operacyjny. Ważne jest tylko to, aby była możliwość
zainstalowania w takim systemie pakietu &lt;code&gt;debootstrap&lt;/code&gt; , no i oczywiście wymagany jest dostęp do
internetu. W przeciwieństwie do instalatora debiana, mamy dostęp do graficznego środowiska, a w nim
do przeglądarki i w przypadku utknięcia gdzieś po drodze podczas instalacji, możemy sobie wygooglać
napotkane problemy nie przerywając przy tym prac instalacyjnych.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instalacja i konfiguracja bootloader&#39;a extlinux</title>
      <link>https://morfikov.github.io/post/instalacja-i-konfiguracja-bootloadera-extlinux/</link>
      <pubDate>Sat, 02 Jan 2016 01:47:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/instalacja-i-konfiguracja-bootloadera-extlinux/</guid>
      <description>&lt;p&gt;W debianie mamy do dyspozycji kilka
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Program_rozruchowy&#34;&gt;bootloader&#39;ów&lt;/a&gt;. Z tych częściej używanych to
będą syslinux, extlinux oraz grub2. Jeśli potrzebujemy automatyzacji oraz szeregu zaawansowanych
ficzerów, to dobrym wyjściem jest grub2. Jeśli natomiast korzystamy ze standardowej konfiguracji,
którą można by określić mianem BIOS-MBR i do tego chcemy mieć pełną kontrolę na bootloader&#39;em, to
najlepiej wybrać extlinux&#39;a lub syslinux&#39;a. Syslinux jest wykorzystywany głównie w przypadku
partycji FAT, która znajduje zastosowanie w różnego rodzaju systemach live. Natomiast jeśli w grę
wchodzi system plików EXT4, który jest domyślny na sporej części linux&#39;ów, to pozostaje nam do
wyboru jedynie extlinux. W tym wpisie postaramy się przebrnąć przez proces instalacji i konfiguracji
tego bootloader&#39;a. Nie będziemy przy tym korzystać z żadnych automatów i wszystko postaramy się
dostosować ręcznie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Odszyfrowanie kontenerów LUKS w systemd</title>
      <link>https://morfikov.github.io/post/odszyfrowanie-kontenerow-luks-w-systemd/</link>
      <pubDate>Fri, 01 Jan 2016 17:18:03 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/odszyfrowanie-kontenerow-luks-w-systemd/</guid>
      <description>&lt;p&gt;Osoby, które wykorzystują pełne szyfrowanie dysku, wiedzą, że nie zawsze da radę tak skonfigurować
swój system, by upchnąć go na jednej partycji. Nawet jeśli korzystamy z LVM wewnątrz kontenera LUKS,
to i tak zwykle możemy posiadać inne zaszyfrowane partycje, które są odrębną całością i montowane
osobno przy starcie systemu. W takim przypadku zwykle jesteśmy zmuszeni do podawania hasła do
każdego z tych dysków z osobna, co zajmuje czas. Ten problem opisałem po części przy okazji
&lt;a href=&#34;https://morfikov.github.io
/post/dropbox-i-kontener-luks/&#34;&gt;implementacji kontenera LUKS na potrzeby
Dropbox&#39;a&lt;/a&gt;, jak i we wpisie poświęconym &lt;a href=&#34;https://morfikov.github.io
/post/przejscie-z-truecrypt-na-luks/&#34;&gt;przejściu
z kontenerów TrueCrypt&#39;a na te linux&#39;owe, które są wspierane natywnie przez sam
kernel&lt;/a&gt;. Niemniej jednak, tamto rozwiązanie
było oparte głównie o starszy init (sysvinit), co wymagało dodatkowej konfiguracji, tak by system
otworzył się po podaniu tylko jednego hasła. W tym wpisie postaramy się wdrożyć mechanizm, który
jest oferowany przez systemd.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kopia struktury dysku twardego</title>
      <link>https://morfikov.github.io/post/kopia-struktury-dysku-twardego/</link>
      <pubDate>Fri, 18 Dec 2015 17:01:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kopia-struktury-dysku-twardego/</guid>
      <description>&lt;p&gt;Wszyscy wiedzą, że zabawa z dyskiem zwykle kończy się tragicznie dla zawartych na nim danych. W tym
wpisie spróbujemy się przyjrzeć sytuacjom, które nie jednego użytkownika linux&#39;a potrafią przyprawić
o zawał serca. Chodzi generalnie o uszkodzenie struktury dysku, oczywiście tylko tej programowej. Na
błędy fizyczne nie możemy zbytnio nic poradzić. Natomiast jeśli chodzi o sferę logiczną, to mamy
tutaj dość duże pole do popisu i jesteśmy w stanie się zabezpieczyć przed wieloma krytycznymi
sytuacjami. Postaramy się tutaj omówić to jak wykonać kopię dysku. Taka kopia będzie miała tylko
kilka (ew. kilkanaście) MiB, w skład której wchodzić będzie superblok systemu plików, nagłówki
zaszyfrowanych partycji LUKS, struktura LVM i tablica partycji. Uszkodzenie każdego z tych
powyższych uniemożliwia nam dostęp do danych zgromadzonych na dysku.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru dysków w strukturze LVM</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-lvm/</link>
      <pubDate>Thu, 17 Dec 2015 20:15:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-lvm/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/LVM&#34;&gt;Logical Volume Manager (LVM)&lt;/a&gt;, czyli menadżer voluminów
logicznych w systemach linux, to mechanizm, który jest w stanie podzielić jedną partycję fizyczną na
szereg dysków logicznych. Każdy z tych dysków może być programowo dostosowany bez potrzeby edycji
czy zmiany tablicy partycji fizycznego dysku. Dzięki LVM jesteśmy w stanie obejść kilka ograniczeń
płynących z wykorzystywania tablicy partycji MS-DOS. Głównie chodzi tutaj o 4 partycje podstawowe,
które mieszczą się w &lt;a href=&#34;https://pl.wikipedia.org/wiki/Master_Boot_Record&#34;&gt;MBR&lt;/a&gt;. Jeśli zdecydowaliśmy
się na wykorzystywanie LVM, to w pewnym momencie może okazać się, że niektóre voluminy mają zbyt
duże lub też zbyt małe rozmiary. Trzeba będzie je zatem dostosować i w tym wpisie postaramy się ten
proces zasymulować.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru kontenera LUKS</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-zaszyfrowanego-kontenera-luks/</link>
      <pubDate>Thu, 17 Dec 2015 18:38:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-zaszyfrowanego-kontenera-luks/</guid>
      <description>&lt;p&gt;Ci z nas, którzy zabezpieczają swoje systemy przy pomocy technik kryptograficznych wiedzą, że taki
system trzeba traktować nieco inaczej niż ten, który nie jest w żaden sposób zaszyfrowany. Gdy mamy
na swoim dysku kilka &lt;a href=&#34;https://pl.wikipedia.org/wiki/Linux_Unified_Key_Setup&#34;&gt;kontenerów LUKS&lt;/a&gt; (czy
też TrueCrypt), problematyczna może się okazać zmiana rozmiaru tego typu partycji. Praktycznie żadne
narzędzia graficzne, ewentualnie inne automaty, nie są w stanie nas przez ten proces bezstresowo
przeprowadzić. Musimy zatem skorzystać z niskopoziomowych aplikacji, takich jak &lt;code&gt;fdisk&lt;/code&gt; czy
&lt;code&gt;cryptsetup&lt;/code&gt; , by ten rozmiar sobie dostosować. Problem w tym, że nieumiejętne operowanie na tych
narzędziach może skończyć się tragicznie dla zgromadzonych na dysku danych. W tym wpisie postaram
się opisać cały proces zmiany rozmiaru zaszyfrowanego kontenera LUKS wliczając w to również
dostosowanie partycji i jej systemu plików.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru partycji FAT32 pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-partycji-fat32/</link>
      <pubDate>Thu, 17 Dec 2015 16:05:23 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-partycji-fat32/</guid>
      <description>&lt;p&gt;Partycje mające system plików FAT32 są głównie wykorzystywane w przypadku pendrive i innych pamięci
flash, gdzie nie mamy do czynienia ze sporą ilością danych czy też dużymi plikami. Czasem się zdarza
tak, że układ partycji, który chcieliśmy zrobić, nie wyszedł nam tak jak powinien i musimy tego
pendrive jeszcze raz przeformatować. Pół biedy, gdy na nim nie ma żadnych danych lub mamy możliwość
zgrania ich na osobny dysk. Natomiast w przypadku, gdy nie możemy z jakiegoś powodu skorzystać z w/w
opcji, to musimy liczyć się z utratą danych. Oczywiście, możemy także spróbować zmienić rozmiar
takiej partycji i nic nie powinno się stać znajdującym się na niej danym. W tym wpisie postaramy się
przejść przez proces zmiany rozmiaru partycji mającej system plików FAT32 i zobaczymy czy nasz linux
poradzi sobie z tym zdaniem bez większego problemu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru partycji EXT4</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-partycji-ext4/</link>
      <pubDate>Wed, 16 Dec 2015 19:06:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-partycji-ext4/</guid>
      <description>&lt;p&gt;Jeśli jeszcze nie dokonaliśmy &lt;a href=&#34;https://morfikov.github.io
/post/migracja-systemu-plikow-ext2-i-ext3-na-ext4/&#34;&gt;migracji systemu plików z EXT2/3 na
EXT4&lt;/a&gt;, to powinniśmy rozważyć
tę kwestię z przyczyn czysto praktycznych. W tym wpisie nie będziemy sobie głowy zawracać migracją
między poszczególnymi wersjami systemu plików z rodziny EXT, a raczej skupimy się na tym jak zmienić
rozmiar partycji, której systemem plików jest właśnie EXT4. Bawienie się rozmiarem partycji w tym
przypadku niczym zbytnio się nie różni w stosunku do omawianego wcześniej &lt;a href=&#34;https://morfikov.github.io
/post/zmiana-rozmiaru-partycji-ntfs-pod-linuxem/&#34;&gt;systemu plików
NTFS&lt;/a&gt;. Będziemy wykorzystywać
tylko nieco inne narzędzia.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru partycji NTFS pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-partycji-ntfs-pod-linuxem/</link>
      <pubDate>Wed, 16 Dec 2015 18:03:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-partycji-ntfs-pod-linuxem/</guid>
      <description>&lt;p&gt;Zmiana rozmiaru partycji, nie tylko tej zawierającej system plików NTFS, nie sprawia w dzisiejszych
czasach praktycznie żadnych problemów. Mamy przecie do dyspozycji takie narzędzia jak
&lt;a href=&#34;http://gparted.org/&#34;&gt;gparted&lt;/a&gt;, które w dużej mierze automatyzują cały proces tworzenia i usuwania
partycji, czy też zmiany ich rozmiaru. W tym wpisie przyjrzymy się temu procesowi z bliska, z tym,
że nie będziemy korzystać z żadnych graficznych nakładek. Wszystkie kroki postaramy się
zreprodukować ręcznie z poziomu konsoli przy pomocy takich narzędzi jak &lt;code&gt;fdisk&lt;/code&gt; czy &lt;code&gt;ntfsresize&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja interfejsów IFB w linux&#39;ie</title>
      <link>https://morfikov.github.io/post/konfiguracja-interfejsow-ifb-w-linuxie/</link>
      <pubDate>Wed, 16 Dec 2015 14:46:50 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-interfejsow-ifb-w-linuxie/</guid>
      <description>&lt;p&gt;Ten wpis również będzie poświęcony tematyce
&lt;a href=&#34;http://linux-ip.net/articles/Traffic-Control-HOWTO/index.html&#34;&gt;kontroli&lt;/a&gt; i
&lt;a href=&#34;https://lukasz.bromirski.net/docs/translations/lartc-pl.html&#34;&gt;kształtowania&lt;/a&gt; ruchu sieciowego w
linux&#39;ie, z tym, że ograniczymy się tutaj do konfiguracji interfejsów IFB. Działają one na podobnej
zasadzie co &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-interfejsow-imq-w-linuxie/&#34;&gt;interfejsy IMQ&lt;/a&gt;.
Niewątpliwą zaletą interfejsów IFB jest fakt, że są one natywnie wspierane przez kernel linux&#39;a,
przez co ich obsługa jest dziecinnie prosta. Wadą jest z kolei to, że nie do końca damy radę
kształtować ruch przychodzący do naszej maszyny. Tak czy inaczej, postaramy się skonfigurować te
interfejsy i zobaczymy co z nich idzie wycisnąć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kształtowanie ruchu sieciowego (Traffic Control)</title>
      <link>https://morfikov.github.io/post/ksztaltowanie-ruchu-sieciowego-traffic-control/</link>
      <pubDate>Tue, 15 Dec 2015 20:40:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ksztaltowanie-ruchu-sieciowego-traffic-control/</guid>
      <description>&lt;p&gt;Każdy z nas chciałby, aby jego sieć działała możliwie szybko i bezproblemowo. W przypadku, gdy łącze
nie jest zbytnio obciążone, a my jesteśmy jedynym użytkownikiem internetu, to nie doświadczymy
raczej żadnych problemów z połączeniem. Rzecz w tym, że im więcej użytkowników ma nasza sieć, tym
większe prawdopodobieństwo, że zostanie ona przeciążona, tj. będziemy chcieli przesyłać więcej
danych niż sieć jest w stanie obsłużyć. W ten sposób zaczną pojawiać się kolejki pakietów na
interfejsach, których obsługa zajmuje trochę czasu. Rosą zatem opóźnienia, które są bardzo
odczuwalne w momencie, gdy ktoś lubi sobie pograć w różnego rodzaju gry online. Innym problemem może
być sieć P2P, gdzie pojedynczy host z naszej sieci może nawiązywać dziesiątki czy nawet setki
połączeń i tym samym zapychać łącze nie dając szansy innym użytkownikom na komfortowe korzystanie
z internetu. W obu przypadkach może nam pomóc &lt;a href=&#34;http://lartc.org/lartc.html&#34;&gt;kształtowanie ruchu
sieciowego&lt;/a&gt; (Traffic Control), która jest w stanie nadać pakietom
odpowiedni priorytet, tak by część z nich nie musiała czekać zbyt długo w kolejce. W tym wpisie
przyjrzymy się bliżej temu mechanizmowi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja interfejsów IMQ w linux&#39;ie</title>
      <link>https://morfikov.github.io/post/konfiguracja-interfejsow-imq-w-linuxie/</link>
      <pubDate>Tue, 15 Dec 2015 14:38:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-interfejsow-imq-w-linuxie/</guid>
      <description>&lt;p&gt;W linux&#39;ie, kształtowanie przychodzącego ruchu sieciowego stwarza dość poważne problemy. Na dobrą
sprawę, obecnie w kernelu nie ma żadnego mechanizmu, który byłby w stanie to zadanie realizować.
Istnieją, co prawda, &lt;a href=&#34;https://wiki.linuxfoundation.org/networking/ifb&#34;&gt;interfejsy IFB&lt;/a&gt; ale za ich
pomocą jesteśmy w stanie z powodzeniem kształtować jedynie ruch wychodzący. W przypadku pakietów
napływających, możemy jedynie ograniczyć im przepustowość. W tym powyższym linku jest wzmianka, że
te interfejsy IFB są następcą &lt;a href=&#34;https://github.com/imq/linuximq/wiki/WhatIs&#34;&gt;interfejsów IMQ&lt;/a&gt;.
Niemniej jednak, ten drugi projekt zdaje się działać, choć nie jest obecnie wspierany przez kernel
linux&#39;a. W tym wpisie postaramy się skonfigurować działające interfejsy IMQ, tak, by za ich pomocą
skutecznie kształtować ruch przychodzący.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ograniczanie zasobów procesom przez cgroups</title>
      <link>https://morfikov.github.io/post/ograniczanie-zasobow-procesom-przez-cgroups/</link>
      <pubDate>Tue, 08 Dec 2015 21:21:53 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ograniczanie-zasobow-procesom-przez-cgroups/</guid>
      <description>&lt;p&gt;Nasze komputery obecnie mają dość pokaźne zasoby obliczeniowe. Jeszcze nie tak dawno temu
wyposażenie maszyny w 32 GiB pamięci RAM, czy też 8 rdzeni było czystą abstrakcją. Wydawałoby się,
że te powyższe parametry zaspokoją każdego. Niemniej jednak, nie ważne jak szybki i rozbudowany
będzie nasz PC, to nam zawsze będzie mało. Mamy dwa rdzenie, to chcemy cztery. Mamy cztery, to
chcemy osiem, itd. Poza tym, szereg aplikacji realizuje co raz więcej zadań i staje się bardziej
wymagająca z każdym mijającym rokiem. Jeśli nie przeprowadzamy modernizacji sprzętu, to może się
okazać, że w niedługim czasie zabraknie nam pamięci albo pewne operacje będą wykonywane bardzo
wolno. W sporej części przypadków nie obędzie się bez wymiany podzespołów ale nawet w przypadku, gdy
mamy spory zapas zasobów systemowych, to poszczególne procesy rywalizują o nie ze sobą. Często bywa
tak, że chcielibyśmy, aby konkretny proces wykonał się szybciej, a to pociąga za sobą, np. zmianę
priorytetów w dostępie do rdzeni procesora. W linux&#39;ie jest mechanizm zwany
&lt;a href=&#34;https://en.wikipedia.org/wiki/Cgroups&#34;&gt;cgroups&lt;/a&gt;, który potrafi ograniczyć zasoby całym aplikacjom
bez względu na to ile ona by miała procesów. W tym wpisie postaramy się przebrnąć przez proces
konfiguracji tego mechanizmu i spróbujemy wyprofilować sobie nasz system.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Poradnik maintainer&#39;a, czyli jak zrobić pakiet deb</title>
      <link>https://morfikov.github.io/post/poradnik-maintainera-czyli-jak-zrobic-pakiet-deb/</link>
      <pubDate>Mon, 07 Dec 2015 20:26:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/poradnik-maintainera-czyli-jak-zrobic-pakiet-deb/</guid>
      <description>&lt;p&gt;Debian posiada bardzo rozbudowany system robienia pakietów. Generalnie rzecz biorąc, to wszystkie z
nich musiały przejść przez ten proces zanim trafiły do głównego repozytorium dystrybucji. Dzięki
takiemu stanu rzeczy, nie musimy ręcznie powielać pracy szeregu innych osób i odpada nam
własnoręczna kompilacja pakietów, a wszyscy wiemy, że zajmuje ona cenny czas i zasoby. Paczki
&lt;code&gt;.deb&lt;/code&gt; są tworzone ze źródeł i instalowane przy pomocy menadżera pakietów &lt;code&gt;aptitude&lt;/code&gt;/&lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;dpkg&lt;/code&gt; .
Nic jednak nie stoi na przeszkodzie by daną aplikację skompilować sobie ręcznie i zainstalować ją
przy pomocy &lt;code&gt;make install&lt;/code&gt; . Problem w tym, że w taki sposób robi się śmietnik w naszym systemie i
śledzenie wszystkich zainstalowanych w ten sposób pakietów w pewnym momencie stanie się wręcz
niemożliwe. Dlatego też przydałby nam się mechanizm, który ułatwiłby nam nieco to zadanie. Debian
udostępnia szereg narzędzi, które są w stanie w pełni zautomatyzować cały ten proces budowy
pakietów. Ten poradnik zaś ma na celu zebranie wszystkich istotniejszych informacji związanych z
obsługą narzędzi takich jak &lt;code&gt;dh_make&lt;/code&gt; , &lt;code&gt;dpkg-buildpackage&lt;/code&gt; , &lt;code&gt;pbuilder&lt;/code&gt; , &lt;code&gt;quilt&lt;/code&gt; czy &lt;code&gt;lintian&lt;/code&gt; ,
tak by tworzyć pakiety w prosty sposób i przy tym równając do najwyższych standardów debiana.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wymusić sprawdzenie systemu plików w systemd</title>
      <link>https://morfikov.github.io/post/jak-wymusic-sprawdzenie-systemu-plikow-w-systemd/</link>
      <pubDate>Fri, 04 Dec 2015 20:11:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wymusic-sprawdzenie-systemu-plikow-w-systemd/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem jak w systemach linux&#39;owych przeprowadzić &lt;a href=&#34;https://morfikov.github.io
/post/sprawdzanie-bledow-systemu-plikow-ext4/&#34;&gt;sprawdzenie systemu plików pod
kątem ewentualnych błędów&lt;/a&gt;. Był tam
poświęcony kawałek na temat ręcznego wymuszenia takiego skanowania. Ten sposób, który został opisany
w tamtym wpisie działa wyśmienicie w przypadku sysvinit. Natomiast przy systemd mogą pojawić się
pewne problemy, w efekcie czego nie będziemy w stanie wymusić skanowania pewnych partycji.
Generalnie to rozchodzi się o tę główną, na której znajduje się system plików &lt;code&gt;/&lt;/code&gt; . Postanowiłem się
przyjrzeć nieco temu mechanizmowi i sprawdzić czy faktycznie nic nie da się zrobić i czy musimy
czekać pełną ilość cykli startu systemu, by ten system plików został przez niego przeskanowany
automatycznie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zwiększyć prędkość zapisu w urządzeniach USB</title>
      <link>https://morfikov.github.io/post/jak-zwiekszyc-predkosc-zapisu-w-urzadzeniach-usb/</link>
      <pubDate>Wed, 02 Dec 2015 17:06:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zwiekszyc-predkosc-zapisu-w-urzadzeniach-usb/</guid>
      <description>&lt;p&gt;Przeglądając sobie &lt;a href=&#34;http://www.linux-usb.org/FAQ.html&#34;&gt;FAQ dotyczący urządzeń USB&lt;/a&gt; natknąłem się na
punkt, który opisywał parametr &lt;code&gt;max_sectors&lt;/code&gt; . Niby nic wielkiego, w linux&#39;ie jest przecie pełno
przeróżnych opcji, przy pomocy których jesteśmy w stanie zmienić szereg aspektów pracy naszego
systemu operacyjnego. Rzecz w tym, że parametr &lt;code&gt;max_sectors&lt;/code&gt; potrafi nawet dość znacznie poprawić
wydajność urządzeń USB, w tym tych wszystkich pendrive&#39;ach, w których prędkość zapisu pozostawia
wiele do życzenia. W tym wpisie postaramy się nieco dostosować ten parametr, tak by przyśpieszyć
transfer kopiowanych plików.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Profil AppArmor&#39;a i jego dokładna budowa</title>
      <link>https://morfikov.github.io/post/profil-apparmora-i-jego-dokladna-budowa/</link>
      <pubDate>Tue, 01 Dec 2015 17:57:39 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/profil-apparmora-i-jego-dokladna-budowa/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/apparmor-profilowanie-aplikacji/&#34;&gt;Budowanie samych profili dla AppArmor&#39;a&lt;/a&gt;
nie jest jakoś szczególnie trudne, zwłaszcza, gdy do tego celu wykorzystujemy narzędzia dostępne w
pakiecie &lt;code&gt;apparmor-utils&lt;/code&gt; . Dobrze jest jednak prześledzić sobie
&lt;a href=&#34;http://manpages.ubuntu.com/manpages/xenial/en/man5/apparmor.d.5.html&#34;&gt;manual&lt;/a&gt;
&lt;a href=&#34;http://manpages.ubuntu.com/manpages/xenial/en/man7/apparmor.7.html&#34;&gt;AppArmor&#39;a&lt;/a&gt; oraz to, co twórcy
piszą na swojej stronie w &lt;a href=&#34;http://wiki.apparmor.net/index.php/Documentation&#34;&gt;oficjalnej
dokumentacji&lt;/a&gt; projektu. Poniższy wpis powstał w
celu zrozumienia składni profili AppArmor&#39;a, tak by jeszcze bardziej uprościć proces ich budowania.&lt;/p&gt;
&lt;p&gt;Opis składni znajdujący się poniżej został zaczerpnięty z
&lt;a href=&#34;http://wiki.apparmor.net/index.php/QuickProfileLanguage&#34;&gt;wiki&lt;/a&gt;
&lt;a href=&#34;http://wiki.apparmor.net/index.php/AppArmor_Core_Policy_Reference&#34;&gt;AppArmor&#39;a&lt;/a&gt;. Część z poniższych
informacji może nie mieć zastosowania w przypadku starszych wersji samego AppArmor&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak odzyskać usunięte z dysku pliki</title>
      <link>https://morfikov.github.io/post/jak-odzyskac-usuniete-z-dysku-pliki/</link>
      <pubDate>Mon, 30 Nov 2015 19:03:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-odzyskac-usuniete-z-dysku-pliki/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/usuwanie-plikow-przy-pomocy-shred/&#34;&gt;Całkowite usuwanie plików (shred)&lt;/a&gt; jak i
&lt;a href=&#34;https://morfikov.github.io
/post/programowe-sprzetowe-zerowanie-dysku/&#34;&gt;zerowanie całych nośników&lt;/a&gt; ma na celu
nieodwracalne zniszczenie danych. W tych podlinkowanych artykułach próbowaliśmy zatrzeć ślady po
skasowanych plikach. W tym wpisie zaś prześledzimy sobie co tak naprawdę się dzieje po utworzeniu i
skasowaniu pliku, a także spróbujemy odzyskać te z nich, które już nie istnieją w naszym systemie.
Ten artykuł będzie dotyczył jedynie systemu plików z rodziny &lt;code&gt;ext&lt;/code&gt; , głównie &lt;code&gt;ext4&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kodowanie nazw plików i jego zmiana</title>
      <link>https://morfikov.github.io/post/kodowanie-nazw-plikow-i-jego-zmiana/</link>
      <pubDate>Fri, 27 Nov 2015 15:15:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kodowanie-nazw-plikow-i-jego-zmiana/</guid>
      <description>&lt;p&gt;Chciałem dziś wypakować sobie kilka plików, które były zebrane w paczkę &lt;code&gt;.zip&lt;/code&gt; . Problem w tym, że
ta osoba, co te pliki pakowała, najwyraźniej robiła to na widnowsie no i nie użyła standardowego
kodowania, które jest wykorzystywane na każdym innym systemie, tj. UTF-8. Wobec tego, wszystkie
pliki mają w swoich nazwach znaczek &lt;code&gt;�&lt;/code&gt; w miejscu polskich liter. Jako, że tych plików jest dość
dużo, to odpada ręczna edycja nazw i trzeba pomyśleć nad jakimś innym rozwiązaniem. Zmiana
kodowania nazw plików, to nie jest to samo co &lt;a href=&#34;https://morfikov.github.io
/post/zmiana-kodowania-znakow-w-plikach-na-utf-8/&#34;&gt;zmiana kodowania zawartości tych
plików&lt;/a&gt;. Na szczęście w
linux&#39;ie mamy do dyspozycji narzędzie &lt;code&gt;convmv&lt;/code&gt; , które jest w stanie, jak sama nazwa mówi, przepisać
nazwy plików ustawiając przy tym odpowiednie kodowanie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana hasła konta administratora root</title>
      <link>https://morfikov.github.io/post/zmiana-hasla-konta-administratora-root/</link>
      <pubDate>Wed, 25 Nov 2015 13:55:44 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-hasla-konta-administratora-root/</guid>
      <description>&lt;p&gt;W pewnych skrajnych przypadkach może się nam zdarzyć tak, że zapomnimy hasła do konta administratora
systemu. Jak wiadomo bez użytkownika root w naszych linux&#39;ach nie da się zbytnio nic zrobić. Na
pewno nie da się przeprowadzić żądnych prac administracyjnych. Zwykle w takim przypadku moglibyśmy
przeinstalować system i ustawić nowe hasło ale to wydaje się lekką przesadą. Poza tym, co w
przypadku gdy nie możemy zwyczajnie zainstalować na nowo systemu lub nie mamy akurat pod ręką płytki
czy pendrive live? Czy w linux&#39;ie jest w ogóle możliwość odzyskania hasła użytkownika root bez
rozkręcania komputera biorąc pod uwagę te wszystkie mechanizmy bezpieczeństwa, które czynią ten
system tak bezpiecznym? Oczywiście zmiana hasła do konta administratora jest możliwa i nawet nie
trzeba się przy tym zbytnio wysilać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Programowe i sprzętowe zerowanie dysku</title>
      <link>https://morfikov.github.io/post/programowe-sprzetowe-zerowanie-dysku/</link>
      <pubDate>Tue, 24 Nov 2015 17:54:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/programowe-sprzetowe-zerowanie-dysku/</guid>
      <description>&lt;p&gt;Zerowanie dysku twardego ma na celu usunięcie wszystkich znajdujących się na nim danych. Generalnie
chodzi o zapisanie całej powierzchni danego nośnika samymi zerami. Ten proces różni się znacząco of
formatowania dysku, czyli utworzenia nowego systemu plików, gdzie praktycznie wszystkie dane można
bez większego problemu odzyskać. Zerowanie dysku (czy też pendrive) może w pewnych przypadkach
&lt;a href=&#34;https://morfikov.github.io
/post/uszkodzony-sektor-na-dysku-i-jego-realokoacja/&#34;&gt;naprawić logiczne błędy
sektorów&lt;/a&gt; na dysku. Niemniej
jednak, nie usuniemy za jego pomocą fizycznych bad&#39;ów. Generalnie rzecz biorąc, mamy do wyboru dwie
techniki zerowania. Jedna jest dokonywana na poziomie programowym, np. przy pomocy &lt;code&gt;dd&lt;/code&gt; , druga zaś
na poziomie sprzętowym, np. w &lt;code&gt;hdparm&lt;/code&gt; . W tym wpisie postaramy się wyzerować przykładowy dysk.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Całkowite usuwanie plików przy pomocy shred</title>
      <link>https://morfikov.github.io/post/usuwanie-plikow-przy-pomocy-shred/</link>
      <pubDate>Tue, 24 Nov 2015 15:11:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/usuwanie-plikow-przy-pomocy-shred/</guid>
      <description>&lt;p&gt;W przypadku, gdy musimy pozbyć się jakiegoś pliku, który znajduje się na dysku, to nie jest zalecane
korzystanie z narzędzia &lt;code&gt;rm&lt;/code&gt; . Usuwa ono jedynie odnośnik do pliku, który go identyfikuje w
strukturze systemu plików, tzw. &lt;a href=&#34;https://pl.wikipedia.org/wiki/I-w%C4%99ze%C5%82&#34;&gt;i-węzeł&lt;/a&gt; (i-node).
To co uzyskujemy za pomocą takich narzędzi jak &lt;code&gt;rm&lt;/code&gt; , to jedynie oznaczenie pewnych bloków (tych od
pliku) jako wolne, w których system operacyjny będzie w stanie dokonać zapisu danych późniejszym
czasie. Podczas tej operacji nie są usuwane żadne informacje z dysku, a mając na uwadze ten fakt,
możemy bez problemu tak &amp;quot;usunięty&amp;quot; plik odzyskać. By mieć pewność, że plik zostanie trwale
zniszczony, trzeba go ponownie napisać, np. przy pomocy
&lt;a href=&#34;http://manpages.ubuntu.com/manpages/wily/en/man1/shred.1.html&#34;&gt;shred&lt;/a&gt;, który standardowo jest
dostępny w każdej dystrybucji linux&#39;a i to jemu będzie poświęcony ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Integralność plików passwd, group, shadow, gshadow</title>
      <link>https://morfikov.github.io/post/integralnosc-plikow-passwd-group-shadow-gshadow/</link>
      <pubDate>Tue, 24 Nov 2015 12:30:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/integralnosc-plikow-passwd-group-shadow-gshadow/</guid>
      <description>&lt;p&gt;W pliku &lt;code&gt;/etc/passwd&lt;/code&gt; jest przechowywana baza danych kont użytkowników w systemie linux. Z kolei w
&lt;code&gt;/etc/group&lt;/code&gt; mamy wypisane wszystkie grupy oraz powiązanych z nimi użytkowników. Generalnie rzecz
biorąc, to te dwa pliki odpowiadają za konfigurację kont. Problem jednak zaczyna się w momencie gdy
w grę wchodzą hasła, zarówno do kont jak i do grup. Gdyby były one trzymane w tych plikach, nie
byłyby one w żaden sposób szyfrowane. Dlatego też powstał inny mechanizm, który ma na celu
przeniesienie zahashowanych haseł do plików &lt;code&gt;/etc/shadow&lt;/code&gt; i &lt;code&gt;/etc/gshadow&lt;/code&gt; . W debianie
użytkownikami i grupami możemy zarządzać przy pomocy odpowiednich narzędzi, które automatycznie
dostosują wszystkie powyższe pliki. Nic jednak nie stoi na przeszkodzie aby edytować każdy z nich
ręcznie. Problemy mogą się pojawić w momencie, gdy te pliki będą zawierać różne wpisy, np. w pliku
&lt;code&gt;passwd&lt;/code&gt; będzie określony użytkownik, który jednocześnie nie będzie istniał w pliku &lt;code&gt;shadow&lt;/code&gt; ,
podobnie z grupami. W tym wpisie postaramy się sprawdzić te pliki i upewnimy się czy aby na pewno
jest z nimi wszystko w porządku.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przewidywalne nazwy interfejsów sieciowych</title>
      <link>https://morfikov.github.io/post/przewidywalne-nazwy-interfejsow-sieciowych/</link>
      <pubDate>Sun, 22 Nov 2015 21:44:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przewidywalne-nazwy-interfejsow-sieciowych/</guid>
      <description>&lt;p&gt;Podczas jednej z aktualizacji systemu został mi zwrócony pewien komunikat. Oświadczał on bowiem, że
od jakiegoś czasu nazewnictwo interfejsów sieciowych w systemie uległo zmianie, oraz, że w wersji 10
debiana, ten obecny system nazw nie będzie już wspierany. Rozchodzi się o coś co nazywa się
&lt;a href=&#34;https://www.freedesktop.org/wiki/Software/systemd/PredictableNetworkInterfaceNames/&#34;&gt;Predictable Network Interface
Names&lt;/a&gt;, czyli
przewidywalne nazwy interfejsów sieciowych. Jako, że aktualne wydanie stabilnego debiana ma numerek
8 i w niedalekiej przyszłości zostanie wydana 9, to przydałoby się już zacząć migrować na ten nowy
system nazw. W tym wpisie dokonamy takiej migracji i zobaczymy jakie zmiany musimy poczynić, by nie
doświadczyć problemów związanych z tą migracją nazw.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czy zmiana nazwy użytkownika root ma sens?</title>
      <link>https://morfikov.github.io/post/czy-zmiana-nazwy-uzytkownika-root-ma-sens/</link>
      <pubDate>Sat, 21 Nov 2015 19:52:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czy-zmiana-nazwy-uzytkownika-root-ma-sens/</guid>
      <description>&lt;p&gt;Wielu ludzi potrafi się rozpisywać na temat bezpieczeństwa systemu linux jednocześnie nie zauważając
jednego bardzo poważnego problemu. Wszyscy wiemy, że linux&#39;y są bezpieczne min. przez fakt
rozgraniczenia konta administratora od konta zwykłego użytkownika i nadaniu im różnych praw dostępu
do poszczególnych części systemu operacyjnego. O ile konta użytkowników mają różne nazwy, o tyle
administrator w praktycznie każdym linux&#39;ie kryje się pod nazwą &lt;code&gt;root&lt;/code&gt; . Znając nazwę konta, można
próbować złamać hasło. To trochę dziwne, że nie można sobie arbitralnie ustalić nazwy dla tego konta
tak by uniknąć wszelkich ataków, które związane są z logowaniem się na określonego użytkownika w
systemie. W tym wpisie postaramy się prześledzić całą procedurę zmiany nazwy konta &lt;code&gt;root&lt;/code&gt; na jakąś
dowolną i zobaczymy czy wpłynie to w jakimś stopniu na pracę naszego systemu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wypakować każde archiwum</title>
      <link>https://morfikov.github.io/post/jak-wypakowac-kazde-archiwum/</link>
      <pubDate>Fri, 20 Nov 2015 15:15:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wypakowac-kazde-archiwum/</guid>
      <description>&lt;p&gt;Archiwum &lt;code&gt;.tar.gz&lt;/code&gt; czy też każde inne, np. &lt;code&gt;.zip&lt;/code&gt; lub &lt;code&gt;.rar&lt;/code&gt; , jest bardzo użyteczne przy
przesyłaniu przez sieć plików między wieloma maszynami. Nie dość, że zaoszczędzają nam sporo
transferu, to jeszcze do tego operujemy na jednym pliku. Problem z tymi wszystkimi rodzajami
archiwów jest taki, że do każdego z nich mamy inne narzędzia. Zwykle też każde z tych narzędzi ma
inne opcje, które taką paczkę potrafią wypakować. Przydałby się zatem sposób, który ogarnąłby
wypakowanie różnych archiwów i sprowadzałby się do wydania w terminalu tylko jednego polecenia, bez
potrzeby pamiętania nazw narzędzi i ich opcji. W tym wpisie postaramy się coś takiego
zaimplementować na swoich linux&#39;ach.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja cache DNS w Firefox&#39;ie</title>
      <link>https://morfikov.github.io/post/konfiguracja-cache-dns-w-firefoxie/</link>
      <pubDate>Fri, 20 Nov 2015 14:01:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-cache-dns-w-firefoxie/</guid>
      <description>&lt;p&gt;We wpisie poświęconym &lt;a href=&#34;https://morfikov.github.io
/post/cache-dns-buforowania-zapytan/&#34;&gt;systemowemu cache DNS w
linux&#39;ie&lt;/a&gt; mieliśmy okazję zobaczyć jak
wzrasta wydajność po zaimplementowaniu tego mechanizmu. W skrócie, to ponad drugie tyle zapytań było
rozwiązywanych lokalnie bez potrzeby odwoływania się do zdalnego serwera DNS, co zajmuje sporo czasu
(20-40ms). Przeglądarki internetowe, np. Firefox, mają swoje wynalazki, które potrafią wyeliminować
opóźnienia związane z surfowaniem po stronach www. Do nich zalicza się również cache DNS, z tym, że
w tym przypadku zaimplementowany jest on na poziomie przeglądarki, a nie globalnie w systemie.
Dzięki temu rozwiązaniu, nawet bez &lt;code&gt;dnsmasq&lt;/code&gt; , Firefox jest nam w stanie zaoszczędzić sporo czasu
przy przeglądaniu internetu. Zajrzyjmy zatem Firefox&#39;owi pod maskę i sprawdźmy, które parametry
dotyczące cache DNS wymagają dostosowania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Nagrywanie strumienia audio radia internetowego</title>
      <link>https://morfikov.github.io/post/nagrywanie-strumienia-audio-radia-internetowego/</link>
      <pubDate>Thu, 19 Nov 2015 17:49:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/nagrywanie-strumienia-audio-radia-internetowego/</guid>
      <description>&lt;p&gt;Człowiek raczej nigdy nie przywyknie do absolutnej ciszy. Dlatego nawet jeśli pracujemy nad czymś
ważnym, to chcemy mieć w tle jakiś dźwięk, który zagłuszy ciszę. Zwykle jest to nasza ulubiona
muzyka odtwarzana na jednym z player&#39;ów audio, który mamy zainstalowany w swoim linux&#39;ie. Muzyka
może nam się szybko znudzić, zwłaszcza gdy w kółko odsłuchujemy te same kawałki. Te bardziej
wymagające osobniki preferują informacje zamiast muzyki, a to wiąże się w dużej mierze z wszelkiej
maści podcastami czy też radiami internetowymi. W sporej części przypadków, musimy być obecni przy
kompie podczas nadawania audycji. Może nie koniecznie jest to wymagane przy podcastach, bo pliki
&lt;code&gt;.mp3&lt;/code&gt; możemy sobie ściągnąć w późniejszym czasie ale sporo stacji radiowych nie dostarczy
słuchaczom audycji w trybie offline. Poza tym, w przypadku podcastów, mamy także część audycji,
która jest nienagrywana i nie jest uwzględniona w pliku &lt;code&gt;.mp3&lt;/code&gt; . Tak czy inaczej, przydałoby się
mieć możliwość nagrania strumienia audio, który jest przesyłany przez sieć. Czy istnieje jakiś
prosty sposób, który nam to umożliwi?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Statystyki transferu danych w sieci (vnstat)</title>
      <link>https://morfikov.github.io/post/statystyki-transferu-danych-w-sieci-vnstat/</link>
      <pubDate>Thu, 19 Nov 2015 16:16:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/statystyki-transferu-danych-w-sieci-vnstat/</guid>
      <description>&lt;p&gt;W prehistorycznych czasach, internet był bardzo limitowany. Nie chodzi tutaj o prędkość, która
obecnie sięga 100+ mbit/s, a o transfer danych. Świat poszedł już trochę do przodu od tamtego czasu
i chyba żaden ISP, który obecnie dostarcza internet stacjonarny, nie narzuca swoim klientom ile
danych mogą pobrać i/lub wysłać w konkretnym miesiącu. Problem pojawia się w przypadku internetu
mobilnego, który w niedługim czasie prawdopodobnie zapanuje nad światem. Mowa oczywiście o
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Long_Term_Evolution&#34;&gt;LTE&lt;/a&gt;, czyli szerokopasmowym internecie
bezprzewodowym. Chodzi generalnie o to, że spora cześć providerów (jak nie wszyscy) limitują
transfer danych w tej usłudze. Jest to około 100GB na miesiąc. Może to wydawać się dużo ale trzeba
mieć na względzie, że dotyczy to zarówno download&#39;u jak i upload&#39;u. No i oczywiście, dziś wszystko
mamy w HD i rzadko kto korzysta z internetu sam. Nawet przeciętna strona www waży już kilka MiB.
Przydałoby się zatem wiedzieć ile danych transmitujemy przez sieć każdego dnia, tak by czasem nie
doświadczyć problemów związanych z przekroczeniem transferu. W tym wpisie postaramy się pozyskać te
informacje i wygenerujemy sobie przyzwoite statystyki transferu przy pomocy narzędzia &lt;code&gt;vnstat&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Montowanie obrazów ISO (urządzenia loop)</title>
      <link>https://morfikov.github.io/post/montowanie-obrazow-iso-urzadzenia-loop/</link>
      <pubDate>Thu, 19 Nov 2015 14:17:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/montowanie-obrazow-iso-urzadzenia-loop/</guid>
      <description>&lt;p&gt;Użytkownicy Debiana (i innych dystrybucji linux&#39;a) mają czasem poważne problemy z zamontowaniem
&lt;a href=&#34;https://pl.wikipedia.org/wiki/ISO_%28obraz%29&#34;&gt;obrazu ISO&lt;/a&gt; pozyskanego czy to z internetu, czy też
od swoich znajomych. Na windowsach zwykliśmy korzystać z takich rozwiązań jak Daemon Tools, Alcohol
120%, czy też &lt;a href=&#34;http://wincdemu.sysprogs.org/&#34;&gt;WinCDEmu&lt;/a&gt;. Na linux&#39;ach z narzędzi, które mają GUI,
można chyba wyróżnić &lt;a href=&#34;https://launchpad.net/furiusisomount&#34;&gt;furiusisomount&lt;/a&gt; oraz
&lt;a href=&#34;http://sourceforge.net/projects/acetoneiso/&#34;&gt;acetoneiso&lt;/a&gt; ale nie będziemy się nimi zajmować w tym
wpisie. Na dobrą sprawę, to nie potrzebujemy żadnego zewnętrznego oprogramowania, by sprawnie i
szybko zamontować dowolny obraz ISO w swoim systemie. W tym wpisie zostanie przedstawiony sposób
montownia tychże obrazów, który zakłada wykorzystanie urządzeń &lt;code&gt;loop&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cache DNS, czyli włączenie buforowania zapytań</title>
      <link>https://morfikov.github.io/post/cache-dns-buforowania-zapytan/</link>
      <pubDate>Mon, 16 Nov 2015 20:13:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/cache-dns-buforowania-zapytan/</guid>
      <description>&lt;p&gt;Większość z nas wie, że standardowe instalacje systemu linux nie buforują żadnych zapytań do
serwerów DNS. Dzieje się tak dlatego, że te systemy domyślnie nie mają zainstalowanego żadnego
oprogramowania, które by im to umożliwiało. Niesie to ze sobą zwiększenie opóźnień transakcji
krótkoterminowych, np. tych w protokole http czy https. Za każdym razem gdy odwiedzamy jakiś serwis
www, musimy wykonać szereg zapytań DNS, by rozwiązać nazwy domen na adresy IP. W przypadku gdybyśmy
mieli cache DNS, to te nazwy nie musiałyby być za każdym każdym razem rozwiązywane na nowo,
przynajmniej nie przez odpytywanie zdalnego serwera DNS, do którego RTT wynosi jakieś 20-40ms.
Przydałoby się zatem nieco poprawić wydajność stron www i w tym wpisie postaramy się zaimplementować
prosty cache DNS z wykorzystaniem &lt;a href=&#34;http://www.thekelleys.org.uk/dnsmasq/doc.html&#34;&gt;narzędzia
dnsmasq&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uprawnienia do plików systemowych w linux&#39;ie</title>
      <link>https://morfikov.github.io/post/uprawnienia-do-plikow-systemowych-w-linuxie/</link>
      <pubDate>Mon, 16 Nov 2015 12:34:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uprawnienia-do-plikow-systemowych-w-linuxie/</guid>
      <description>&lt;p&gt;Każdy z nas popełnia błędy. Niektóre z nich są błahe i w sporej części łatwe do poprawienia. Zwykle
też nie niosą one ze sobą większych konsekwencji. Natomiast błędy, które popełniamy podczas pracy w
systemie operacyjnym wykonując różne prace administracyjne mogą nas czasem słono kosztować. W
linux&#39;ach ogromną rolę odgrywają prawa do plików. O ile root ma dostęp do wszystkich plików, to w
przypadku zwykłych użytkowników (czy tez usług systemowych) już tak nie jest. Przypadkowa zmiana
tych uprawnień może zaowocować problemami związanymi z bezpieczeństwem takiego systemu, a w
niektórych przypadkach może nawet uniemożliwić jego start. Na necie kilka razy obił mi się o oczy
temat, gdzie ludzie przez przypadek (lub też &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=27876&#34;&gt;całkiem
świadomie&lt;/a&gt;) zmienili masowo uprawnienia w takich
katalogach jak &lt;code&gt;/usr/&lt;/code&gt; czy &lt;code&gt;/etc/&lt;/code&gt; . Powiem nawet więcej, mi się raz taka sytuacja kiedyś
przytrafiła. Co w takim przypadku można zrobić? Czy jedyną opcją, jaka nam pozostaje, to ponowna
instalacja sytemu? Na szczęście nie, bo uprawnienia do plików możemy sobie zwyczajnie spisać i
odtworzyć je w późniejszym czasie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana kodowania znaków w plikach na UTF-8</title>
      <link>https://morfikov.github.io/post/zmiana-kodowania-znakow-w-plikach-na-utf-8/</link>
      <pubDate>Fri, 13 Nov 2015 16:18:56 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-kodowania-znakow-w-plikach-na-utf-8/</guid>
      <description>&lt;p&gt;Pliki tekstowe w linux&#39;ie są zakodowane w &lt;a href=&#34;https://www.cl.cam.ac.uk/~mgk25/unicode.html&#34;&gt;formacie
UTF-8&lt;/a&gt;. Ta cyfra &lt;code&gt;8&lt;/code&gt; może być jednak myląca, bo ilość
bajtów potrzebnych do zakodowania pojedynczego znaku może się różnić i wynosi od 1 do 4. Tak czy
inaczej, środowiska linux&#39;owe już dawno zaimplementowały obsługę tego systemu kodowania i uczyniły
go sobie domyślnym. Są jednak takie systemy operacyjne, które nie wykorzystują domyślnie UTF-8 do
kodowania tekstu. Wobec czego, gdy spróbujemy otworzyć w edytorze taki plik, to w pewnych miejscach
będziemy mieli krzaczki, zwykle tam gdzie są polskie znaki. To zjawisko jest bardzo
charakterystyczne dla napisów w filmach. Niemniej jednak, zarówno edytory tekstu jak i player&#39;y
video są w stanie dokonać automatycznego doboru systemu kodowania i zwrócić nam czytelny plik. Nie
zawsze jednak tak robią. Zamiast bawić się w tego typu automatyczne wynalazki, dużo lepszym
rozwiązaniem jest zmiana kodowania plików, tak by przekonwertować je do formatu UTF-8 i w tym
wpisie postaramy się to zrobić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kiedy uruchomiony proces wymaga restartu</title>
      <link>https://morfikov.github.io/post/kiedy-uruchomiony-proces-wymaga-restartu/</link>
      <pubDate>Fri, 13 Nov 2015 14:22:21 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kiedy-uruchomiony-proces-wymaga-restartu/</guid>
      <description>&lt;p&gt;Linux słynie z tego, że nie są wymagane w nim częste restarty całego systemu operacyjnego. Nie ma
przy tym znaczenia czy aktualizujemy jakieś oprogramowanie, czy też wgrywamy nową wersję kernela.
Jeśli by to przenieść na środowisko windowsa, to tam system jest w stanie się automatycznie
zresetować kilka razy tylko podczas samego procesu aktualizacji. Można zatem kwestionować zasadność
twierdzenia, że linux nie wymaga restartu. Może nie koniecznie jesteśmy zmuszeni do dokonania
restartu w danej chwili, tak jak to ma miejsce w przypadku windowsa, ale czy aby na pewno po
instalacji jakichś pakietów w systemie, każdy proces powinien w dalszym ciągu działać bez restartu?
Na to pytanie postaramy się odpowiedzieć w tym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dzielenie i łączenie pliku mp3</title>
      <link>https://morfikov.github.io/post/dzielenie-i-laczenie-pliku-mp3/</link>
      <pubDate>Fri, 13 Nov 2015 13:03:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dzielenie-i-laczenie-pliku-mp3/</guid>
      <description>&lt;p&gt;Każdy z nas odsłuchuje czasem pliki &lt;code&gt;.mp3&lt;/code&gt; . Niekoniecznie musi to być muzyka, np. mogą być to
audycje radiowe, czy też inne materiały audio. W przypadku dłuższych nagrań problematyczne może być
odnalezienie w nich tego kawałka, który akurat chcielibyśmy ponownie odsłuchać. Podobnie sprawa ma
się w przypadku, gdy dany materiał chcemy komuś przesłać. Jeśli ślemy całe nagranie, to musimy dodać
informację od którego momentu zaczyna się coś dziać w tym utworze. Nie prościej wyciąć ten
interesujący nas kawałek i zapisać go w osobnym pliku?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migracja systemu plików ext2 i ext3 na ext4</title>
      <link>https://morfikov.github.io/post/migracja-systemu-plikow-ext2-i-ext3-na-ext4/</link>
      <pubDate>Thu, 12 Nov 2015 14:16:49 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/migracja-systemu-plikow-ext2-i-ext3-na-ext4/</guid>
      <description>&lt;p&gt;Dyski twarde są w stanie pomieścić setki gigabajtów danych. Ilość informacji, które jesteśmy w
stanie przechować na pojedynczym nośniku, rośnie w zastraszającym tempie. Rozwój technologii nie
jest jedynym polem gdzie prowadzone są prace nad nowymi rozwiązaniami poprawiającymi szereg aspektów
pracy tych urządzeń. Innym polem jest sfera programowa, która w przypadków dysków twardych w dużej
mierze dotyczy systemu plików. Albowiem każda powierzchnia, na której mają być przechowywane dane,
potrzebuje odpowiedniej struktury, którą również można usprawnić. Wobec czego, ten domyślny system
plików w linux&#39;ie, tj. &lt;code&gt;ext&lt;/code&gt; , przeszedł szereg modyfikacji i pojawiły się wersje &lt;code&gt;ext2&lt;/code&gt; , &lt;code&gt;ext3&lt;/code&gt; i
&lt;code&gt;ext4&lt;/code&gt; . Jeśli jakaś partycja dysku twardego zawiera starszą wersję systemu plików, powinniśmy
dokonać migracji na jego nowszy odpowiednik. W przypadku migracji z &lt;code&gt;ntfs&lt;/code&gt; na &lt;code&gt;ext4&lt;/code&gt; (czy też
odwrotnie), nieunikniona jest utrata danych. Czy w przypadku migracji z systemu plików &lt;code&gt;ext2&lt;/code&gt; i
&lt;code&gt;ext3&lt;/code&gt; na &lt;code&gt;ext4&lt;/code&gt; również musimy zgrywać wszystkie dane na osobny nośnik by przeformatować
odpowiednio taki dysk czy partycję? Okazuje się że nie musimy i możemy dokonać takiej migracji bez
obaw o utratę danych i w tym wpisie postaramy się ten zabieg przeprowadzić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wyłączyć monitor z linii poleceń</title>
      <link>https://morfikov.github.io/post/jak-wylaczyc-monitor-z-linii-polecen/</link>
      <pubDate>Wed, 11 Nov 2015 22:30:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wylaczyc-monitor-z-linii-polecen/</guid>
      <description>&lt;p&gt;Pewnego niezbyt pamiętnego dnia byłem zmuszony skorzystać z windowsa. Po chwili pracy na nim,
musiałem odejść od komputera na dłuższą chwilę. Chciałem zatem wyłączyć monitor bez jednoczesnego
wyłączania całego komputera, czy przełączania go w stan uśpienia. Problem na jaki się natknąłem był
taki, że kompletnie nie miałem pojęcia jak tego dokonać i ostatecznie zakończyło się to
przyciśnięciem fizycznego przycisku na obudowie monitora. Gdybym tego nie zrobił, monitor by się
wyłączył sam ale dopiero po pewnym czasie, który został określony w opcjach zarządzania energią. Nie
miałem za bardzo czasu i chęci szukać rozwiązania tego problemu ale z tego co widziałem na necie, to
ludzie rozpisywali jakieś tutorale na ten temat, co wydało mi się co najmniej dziwne. Czy w
windowsie nie nie ma żadnej opcji by wyłączyć w prosty sposób monitor? Najwyraźniej nie ma,
przynajmniej ja jej nie znalazłem. Czy my na linux&#39;ie też mamy takie problemy? W tym wpisie
postaramy się odpowiedzieć na pytanie czy jest jakiś prosty sposób by na linux&#39;ie wyłączyć monitor z
wiersza poleceń, tak by efekt był praktycznie natychmiastowy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Osadzanie urxvt na pulpicie przy pomocy openbox&#39;a</title>
      <link>https://morfikov.github.io/post/osadzanie-urxvt-na-pulpicie-przy-pomocy-openboxa/</link>
      <pubDate>Mon, 09 Nov 2015 21:27:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/osadzanie-urxvt-na-pulpicie-przy-pomocy-openboxa/</guid>
      <description>&lt;p&gt;Wszyscy wiemy, że ogromna rzesza ludzi nie patrzy w logi systemowe. Nawet jeśli części z nas zdarza
się to raz na jakiś czas, to zwykle nie wtedy, gdy coś złego się dzieje z naszym systemem. W
przypadku jakichkolwiek problemów, mamy spore prawdopodobieństwo, że szereg zdarzeń może zostać
zalogowanych w dzienniku systemowym. Dlaczego zatem nie osadzić jakiegoś terminala na pulpicie, w
którym będą zbierane logi w czasie rzeczywistym? W takim przypadku co kilka (czy kilkanaście) minut
będziemy w stanie podejrzeć wszystkie komunikaty jakie zostały zalogowane przez system. W tym wpisie
postaramy się osadzić na pulpicie terminal urxvt i posłużymy się w tym celu menadżerem okien openbox
.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kolorowanie wyjścia terminala</title>
      <link>https://morfikov.github.io/post/kolorowanie-wyjscia-terminala/</link>
      <pubDate>Mon, 09 Nov 2015 14:57:01 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kolorowanie-wyjscia-terminala/</guid>
      <description>&lt;p&gt;Każdy terminal jest w stanie wyświetlić tekst w kilku kolorach. Zwykle mamy ich do dyspozycji 8
lub 16. Niektóre terminale potrafią rozróżniać nawet 256 kolorów. Niemniej jednak, kolor całego
tekstu jaki jest wyświetlany w terminalu jest zwykle jednolity i nie ma w nim praktycznie żadnych
urozmaiceń. W taki sposób mamy czarny tekst i białe tło. Jako, że te terminale są w stanie
wyświetlić więcej kolorów, to dla większej czytelności przydałoby się skonfigurować kolorowanie
wyjścia takich narzędzi jak &lt;code&gt;ls&lt;/code&gt; , &lt;code&gt;grep&lt;/code&gt; czy &lt;code&gt;man&lt;/code&gt; . Jesteśmy w stanie pokolorować także szereg
innych rzeczy i o tym będzie ten poniższy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uzupełnianie poleceń w bash (bash completion)</title>
      <link>https://morfikov.github.io/post/uzupelnianie-polecen-w-bash/</link>
      <pubDate>Sat, 07 Nov 2015 16:56:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uzupelnianie-polecen-w-bash/</guid>
      <description>&lt;p&gt;Bash nie nadaje się dla nieco bardziej zaawansowanych użytkowników linux&#39;a. Najbardziej odczuwalnym
elementem bash&#39;a jest brak uzupełniania poleceń za pomocą klawisza Tab . Nie mówimy tutaj o
przeszukiwaniu zmiennej &lt;code&gt;$PATH&lt;/code&gt; pod kątem dopasowań pliku wykonywalnego do tego co wpisujemy
aktualnie w terminalu. Nie chodzi też o uzupełnianiu ścieżek podawanych do &lt;code&gt;cd&lt;/code&gt; ale o opcje, które
jakiś program może przyjąć jako argument. Zwykle musimy się uczyć ich na pamięć lub zaglądać do
help&#39;a czy manuala. Możliwe jest jednak skorzystanie z dodatku zwanego &lt;a href=&#34;https://en.wikipedia.org/wiki/Command-line_completion&#34;&gt;bash
completion&lt;/a&gt;, który w sporej części przypadków
potrafi dostarczyć dość zaawansowane uzupełnianie poleceń, którymi się posługujemy na co dzień. Ten
wpis ma na celu pokazanie jak włączyć ten cały mechanizm i uprościć sobie nieco życie podczas pracy
w terminalu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Plik .bashrc, czyli konfiguracja bash&#39;a</title>
      <link>https://morfikov.github.io/post/plik-bashrc-czyli-konfiguracja-basha/</link>
      <pubDate>Sat, 07 Nov 2015 15:23:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/plik-bashrc-czyli-konfiguracja-basha/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/plik-bash_history-czyli-historia-polecen-basha/&#34;&gt;konfigurację historii bash&#39;a w pliku
.bash_history&lt;/a&gt; ale
możliwości konfiguracyjne bash&#39;a nie ograniczają się jedynie do zmiany kilku parametrów czy
zmiennych dotyczących historii wpisywanych w terminalu poleceń. Ten wpis ma na celu zebranie tych
bardziej użytecznych funkcjonalności bash&#39;a, które często są wykorzystywane przez użytkowników
linux&#39;a i dopisywane w pliku &lt;code&gt;.bashrc&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czyszczenie konsoli TTY w systemd</title>
      <link>https://morfikov.github.io/post/czyszczenie-konsoli-tty-w-systemd/</link>
      <pubDate>Sat, 07 Nov 2015 11:48:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czyszczenie-konsoli-tty-w-systemd/</guid>
      <description>&lt;p&gt;Podczas uruchamiania się systemu, na ekranie zwykle widzimy szereg komunikatów. Informują nas one o
tym jakie usługi są aktywowane oraz czy wystąpiły jakieś błędy. Po tym jak faza boot dobiegnie
końca, wszystkie te informacje dalej są wyświetlane na konsoli TTY i możemy je podejrzeć po
przyciśnięciu klawiszy Ctrl-Alt-F1 . W pewnych sytuacjach może to stwarzać zagrożenie
bezpieczeństwa, bo są tam zawarte informacje o tym jakie usługi zostały uruchomione. Przydałoby się
zatem wyczyścić tę konsolę TTY po załadowaniu się systemu i o tym będzie poniższy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Skrót Ctrl-Alt-Del w systemd</title>
      <link>https://morfikov.github.io/post/skrot-ctrl-alt-del-w-systemd/</link>
      <pubDate>Sat, 07 Nov 2015 10:12:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/skrot-ctrl-alt-del-w-systemd/</guid>
      <description>&lt;p&gt;Po przesiadce z sysvinit na systemd okazało się, że system inaczej się zachowuje po przyciśnięciu
kombinacji klawiszy Ctrl-Alt-Del . Niby za wiele nie zmieniałem w konfiguracji systemu ale w żaden
sposób przy pomocy plików konfiguracyjnych nie szło zmienić zachowania tego powyższego skrótu.
Okazuje się bowiem, że w systemd, akcję pod ten skrót przypisuje się w nieco innym miejscu niż to
było robione w sysvinit. W tym wpisie postaramy się zmienić domyślne zachowanie tego skrótu, tak by
po jego przyciśnięciu wyłączyć komputer.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Plik .bash_history, czyli historia poleceń bash&#39;a</title>
      <link>https://morfikov.github.io/post/plik-bash_history-czyli-historia-polecen-basha/</link>
      <pubDate>Fri, 06 Nov 2015 01:08:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/plik-bash_history-czyli-historia-polecen-basha/</guid>
      <description>&lt;p&gt;Operowanie na linux&#39;ie wiąże się w dużej mierze z wpisywaniem poleceń do terminala. Każdy kto
spędził trochę czasu w tym systemie, wie, że do komfortowej pracy potrzebny jest przyzwoicie
skonfigurowany shell. Domyślnym shell&#39;em w debianie, jak i wielu innych linux&#39;ach, jest bash. Każdy
z nas na początku wpisywał wszystkie polecenia ręcznie i nawet nie wiedział, że istnieje coś takiego
jak uzupełnianie pewnych fraz, czy też nazw, przy pomocy klawisza Tab . Z czasem nasz stopień
poznania jakiejś dystrybucji linux&#39;a osiąga pewien dość zaawansowany poziom i wpisywanie za każdym
razem tych samych poleceń jedynie spowalnia naszą pracę. Dlatego właśnie bash, podobnie jak i inne
shell&#39;e, mają swoje pliki konfiguracyjne, w których to możemy &lt;a href=&#34;https://www.gnu.org/software/bash/manual/bash.html#Shell-Variables&#34;&gt;dostosować naprawdę sporo
rzeczy&lt;/a&gt;. W tym wpisie skupimy
się na historii poleceń, która trafia do pliku &lt;code&gt;.bash_history&lt;/code&gt; w katalogu domowym każdego
użytkownika w systemie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fwknop z obsługą kuczy GPG</title>
      <link>https://morfikov.github.io/post/fwknop-z-obsluga-kuczy-gpg/</link>
      <pubDate>Thu, 05 Nov 2015 20:52:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/fwknop-z-obsluga-kuczy-gpg/</guid>
      <description>&lt;p&gt;Ostatnio opisywałem jak zaimplementować na swoim serwerze &lt;a href=&#34;https://morfikov.github.io
/post/port-knocking-i-single-packet-authorization/&#34;&gt;mechanizm port
knocking&#39;u&lt;/a&gt; , który oparty był
o &lt;a href=&#34;http://www.cipherdyne.org/fwknop/docs/fwknop-tutorial.html&#34;&gt;Single Packet Authorization&lt;/a&gt;. Tamten
wpis dotyczył głównie wykorzystania szyfrów symetrycznych ale istnieje też możliwość skorzystania z
kluczy GPG. W ten sposób uwierzytelnianie oraz szyfrowanie pakietów odbywałoby się przy ich pomocy.
W tym wpisie postaramy się tak skonfigurować narzędzie &lt;code&gt;fwknop&lt;/code&gt; , tak by było ono w stanie
przepuszczać jedynie tych klientów, którzy posługują się kluczami GPG.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Moduł xt_recent i limitowanie połączeń w iptables</title>
      <link>https://morfikov.github.io/post/modul-xt_recent-i-limitowanie-polaczen-w-iptables/</link>
      <pubDate>Thu, 05 Nov 2015 17:17:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-xt_recent-i-limitowanie-polaczen-w-iptables/</guid>
      <description>&lt;p&gt;Kluczową rolę w filtrze iptables pełnią stany połączeń. Zwykle mamy do czynienia z trzema z nich:
NEW, RELATED i ESTABLISHED. Wszystko co nie pasuje do tych stanów, jest traktowane jako INVALID i
tak dla przykładu trafiają tam pakiety mające niemożliwe kombinacje flag, przynajmniej jeśli chodzi
o punkt widzenia poprawnej komunikacji sieciowej (ustawione flagi &lt;code&gt;SYN&lt;/code&gt; i &lt;code&gt;FIN&lt;/code&gt; jednocześnie).
Jednak istnieje szereg pakietów, które mogą potencjalnie zagrażać bezpieczeństwu maszyny i nie są
one uwzględnione w stanie INVALID. Takie pakiety są używane do skanowania portów w celu wykrycia
usług znajdujących się na serwerze. Krótko mówiąc, stan INVALID nie złapie skanów &lt;code&gt;UDP&lt;/code&gt;, &lt;code&gt;ACK&lt;/code&gt; oraz
&lt;code&gt;SYN&lt;/code&gt; . Czy jesteśmy faktycznie bezbronni i nic nie możemy zrobić? Na szczęście iptables ma do
dyspozycji &lt;a href=&#34;http://ipset.netfilter.org/iptables-extensions.man.html&#34;&gt;moduł xt_recent&lt;/a&gt;, który jest w
stanie zablokować wszystkie te powyżej wymienione formy ataków.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Port knocking na przykładzie knockd i iptables</title>
      <link>https://morfikov.github.io/post/port-knocking-na-przykladzie-knockd-i-iptables/</link>
      <pubDate>Thu, 05 Nov 2015 00:26:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/port-knocking-na-przykladzie-knockd-i-iptables/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Port_knocking&#34;&gt;Port knocking&lt;/a&gt; zezwala na zdalny dostęp do usług,
które są chronione za pomocą zapory sieciowej. Generalnie rzecz biorąc, iptables ma blokować
jakikolwiek ruch na porcie, na którym nasłuchuje jakaś demon. Oczywiście tym sposobem żaden klient
nie mógłby nawiązać połączenia z serwerem i tutaj właśnie znajduje zastosowanie &lt;code&gt;knockd&lt;/code&gt; , który
jest w stanie dodawać dynamicznie odpowiednie reguły do filtra iptables. Nawiązywanie połączenia
trwa z reguły bardzo szybko. Po tym jak klient uzyskał dostęp do serwera, te dodane wcześniej reguły
są usuwane blokując tym samym wszelkie nowe próby połączenia ale nie odcinając jednocześnie
ustanowionych już połączeń. Ten wpis ma jedynie na celu zaprezentowanie narzędzia &lt;code&gt;knockd&lt;/code&gt; .
Niemniej jednak, jest ono już przestarzałe i powinno się od niego odchodzić na rzecz &lt;a href=&#34;https://morfikov.github.io
/post/port-knocking-i-single-packet-authorization/&#34;&gt;Single Packet
Authorization, czyli alternatywnego port
knocking&#39;u&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pliki hosts.allow i hosts.deny</title>
      <link>https://morfikov.github.io/post/pliki-hosts-allow-i-hosts-deny/</link>
      <pubDate>Wed, 04 Nov 2015 22:36:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pliki-hosts-allow-i-hosts-deny/</guid>
      <description>&lt;p&gt;Obecnie najpopularniejszym rozwiązaniem pod kątem ograniczania dostępu do usług systemowych jest
zapora sieciowa. Reguły iptables są w tym przypadku wręcz niezastąpione. Jednak poleganie na samych
regułach iptables nie jest zbyt dobrym pomysłem. A to z tego względu, że jeśli &lt;a href=&#34;https://morfikov.github.io
/post/firewall-na-linuxowe-maszyny-klienckie/&#34;&gt;skrypt
firewall&#39;a&lt;/a&gt; z jakiegoś powodu nie
zostanie wywołany przy starcie systemu, to nasza maszyna pozostaje praktycznie bezbronna i będzie
akceptować wszelkie próby połączeń do wszystkich nasłuchujących w takim systemie usług. Na szczęście
nie jest znowu aż tak źle jak mogłoby się wydawać. Albowiem linux posiada dwa pliki
&lt;code&gt;/etc/hosts.allow&lt;/code&gt; i &lt;code&gt;/etc/hosts.deny&lt;/code&gt; , które są w stanie zarządzać dostępem do usług systemowych.
Poniższy wpis będzie poświęcony właśnie tym dwóm plikom.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Port knocking i Single Packet Authorization</title>
      <link>https://morfikov.github.io/post/port-knocking-i-single-packet-authorization/</link>
      <pubDate>Wed, 04 Nov 2015 21:36:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/port-knocking-i-single-packet-authorization/</guid>
      <description>&lt;p&gt;Poniższy wpis ma na celu zaprezentować jak w prosty sposób dozbroić nieco serwer, tak by znajdujące
się na nim usługi były należycie chronione. Zostanie to pokazane na przykładzie SSH, bo chyba każdy
serwer posiada zdalny dostęp przez shell&#39;a i za bardzo nie godzi się by zostawić tę usługę otwartą
na zewnętrzny świat wirtualny bez jakiegokolwiek nadzoru. Postaramy się tutaj wdrożyć &lt;a href=&#34;https://pl.wikipedia.org/wiki/Port_knocking&#34;&gt;port
knocking&lt;/a&gt;, z tym, że nie będziemy wykorzystywać do tego
celu narzędzia &lt;code&gt;knockd&lt;/code&gt; . Skorzystamy za to z
&lt;a href=&#34;http://www.cipherdyne.org/fwknop/docs/fwknop-tutorial.html&#34;&gt;fwknop&lt;/a&gt; , który eliminuje szereg wad
występujących w leciwym już &lt;code&gt;knockd&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migawka (snapshot) repozytorium debiana</title>
      <link>https://morfikov.github.io/post/migawka-snapshot-repozytorium-debiana/</link>
      <pubDate>Wed, 04 Nov 2015 18:23:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/migawka-snapshot-repozytorium-debiana/</guid>
      <description>&lt;p&gt;Aktualizacje systemu niosą ze sobą nowsze wersje pakietów. Czasami mają one błędy, które wychodzą na
jaw po jakimś czasie korzystania z danej aplikacji. W takiej sytuacji zwykle zachodzi potrzeba
cofnięcia wersji kilku pakietów. Jest jednak wielce prawdopodobne, że akurat tej wersji pakietu,
której potrzebujemy, nie znajdziemy z repozytorium debiana. Pobieranie pojedynczych pakietów z
internetu przez klikanie w pierwszy lepszy link, który zostanie nam zwrócony przez wyszukiwarkę, nie
jest dobrym pomysłem. Na szczęście w przypadku debiana nie musimy się aż tak narażać. A to z tego
względu, że &lt;a href=&#34;http://snapshot.debian.org/archive/debian/&#34;&gt;debian robi migawki (shapshots) swoich
repozytoriów&lt;/a&gt; 4 razy dziennie (co 6 godzin). W ten
sposób mamy dostęp do różnych stanów repozytoriów, w tym też tych, które zawierają pakiety
aktualnie niedostępne w repozytoriach. W tym wpisie postaramy się pobrać i zainstalować
nieistniejące pakiety z takich snapshot&#39;ów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ostatnio używane pliki (recently-used.xbel)</title>
      <link>https://morfikov.github.io/post/ostatnio-uzywane-pliki-recently-used-xbel/</link>
      <pubDate>Mon, 02 Nov 2015 23:54:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ostatnio-uzywane-pliki-recently-used-xbel/</guid>
      <description>&lt;p&gt;Wielu ludzi nie lubi gdy maszyny monitorują każdy ich krok. W tym przypadku chodzi o pliki, które
otwieramy czy zmieniamy podczas codziennej pracy na komputerze. Nasz system domyślnie tworzy listę i
skrupulatnie dodaje do niej nowe pozycje. Ta lista jest przechowywana w pliku &lt;code&gt;recently-used.xbel&lt;/code&gt; ,
który znajduje się w katalogu &lt;code&gt;~/.local/share/&lt;/code&gt; . Gdy popatrzymy na tę funkcjonalność trochę pod
inny kątem, możemy zauważyć, że w pewnych sytuacjach zagraża ona naszej prywatności. Skasowanie tego
pliku nie rozwiązuje problemu, bo jest on tworzony na nowo, a nadawanie atrybutu odporności (
&lt;code&gt;chattr +i&lt;/code&gt; ) nie jest żadnym rozwiązaniem. Na szczęście jest sposób na to by ten mechanizm
dezaktywować i o tym będzie poniższy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zrzut ekranu konsoli TTY (fbcat)</title>
      <link>https://morfikov.github.io/post/zrzut-ekranu-konsoli-tty-fbcat/</link>
      <pubDate>Mon, 02 Nov 2015 21:14:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zrzut-ekranu-konsoli-tty-fbcat/</guid>
      <description>&lt;p&gt;W przypadku, gdy dzieją się dziwne rzeczy z naszym linux&#39;em i ten zaczyna sypać niezrozumiałymi dla
nas błędami, to zawsze możemy takie zachowanie uwiecznić na zrzucie ekranu. Co jednak w przypadku,
gdy nawali nam środowisko graficzne i nie będziemy mieli jak zrobić zrzutu? Przecie takie aplikacje
jak &lt;code&gt;scrot&lt;/code&gt; czy też &lt;code&gt;shutter&lt;/code&gt; działają w oparciu o Xserver i bez niego nie zrobią fotki naszego
desktop&#39;a. Zwykle gdy zmuszeni jesteśmy ratować nasz system, robimy to w konsoli TTY. No chyba, że
sprawa jest poważniejsza, wtedy sięgamy po &lt;a href=&#34;https://morfikov.github.io
/post/wlasny-system-live-i-tworzenie-go-od-podstaw/&#34;&gt;system
live&lt;/a&gt; . Logi systemowe czy też
aplikacji mogą okazać się pomocne ale przecie &amp;quot;fotka jest warta więcej niż tysiąc słów&amp;quot;. Jak zatem
zrobić zrzut ekranu mając do dyspozycji jedynie tekstową konsolę TTY? Czy jest to w ogóle możliwe?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja multiarch w dystrybucji Debian</title>
      <link>https://morfikov.github.io/post/konfiguracja-multiarch-na-debianie/</link>
      <pubDate>Mon, 02 Nov 2015 20:20:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-multiarch-na-debianie/</guid>
      <description>&lt;p&gt;Posiadając nowszej klasy procesor, jesteśmy w stanie korzystać z 64 bitowego systemu operacyjnego. W
przypadku windowsów uruchamianie aplikacji 32 czy 64 bitowych nie stanowi większego problemu. W na
debianie sprawa wygląda nieco inaczej. Gdy mamy wgranego 64 bitowego debiana, aplikacje 32 bitowe
nie będą chciały się nam odpalić. Wszystkiemu winne są biblioteki 32 bitowe, które są wykorzystywane
przez dany program, a bez nich on zwyczajnie nie może działać. Jednym z rozwiązań tego problemu może
być &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-kontenerow-lxc/&#34;&gt;kontener LXC&lt;/a&gt;, gdzie jesteśmy w stanie
zainstalować 32 bitowy system wewnątrz środowiska 64 bitowego i to z tego systemu możemy uruchamiać
32 bitowe aplikacje. Skonfigurowanie takiego kontenera może być nieco skomplikowane, dlatego też
dużo lepszym rozwiązaniem jest przerobienie naszego 64 bitowego systemu na
&lt;a href=&#34;https://wiki.debian.org/Multiarch&#34;&gt;muliarch&lt;/a&gt;, czyli taki, który jest w stanie obsługiwać wiele
architektur (multiarch).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Manualna weryfikacja pakietu deb w debianie</title>
      <link>https://morfikov.github.io/post/manualna-weryfikacja-pakietu-deb-w-debianie/</link>
      <pubDate>Mon, 02 Nov 2015 00:16:03 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/manualna-weryfikacja-pakietu-deb-w-debianie/</guid>
      <description>&lt;p&gt;W dobie całego tego świata informatycznego zwykliśmy polegać na osobach, których nigdy w życiu na
oczy nie wiedzieliśmy, nie wspominając o jakimkolwiek kontakcie fizycznym. Zaufanie to obecnie chyba
najbardziej krytyczna luka bezpieczeństwa jeśli chodzi o oprogramowanie, z którego korzystamy na co
dzień. My, którzy używamy debiana w swojej pracy, polegamy na mechanizmach jakie oferuje nam &lt;code&gt;apt&lt;/code&gt;
czy &lt;code&gt;aptitude&lt;/code&gt; przy &lt;a href=&#34;https://wiki.debian.org/SecureApt&#34;&gt;weryfikacji pakietów przed ich instalacją&lt;/a&gt; w
systemie. Co się jednak by stało gdyby w tych menadżerach pojawił się błąd, który by uniemożliwiał
poprawną weryfikację pakietów? Skąd wiemy czy te mechanizmy zabezpieczające w ogóle działają? Może
one nam dają jedynie fałszywe poczucie bezpieczeństwa, a tak naprawdę przez niczym nas nie chronią?
W tym wpisie postaramy się odpowiedzieć na te powyższe pytania i sprawdzimy czy manualna weryfikacja
pakietu jest w ogóle możliwa&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klucze do repozytoriów debiana (trusted.gpg)</title>
      <link>https://morfikov.github.io/post/klucze-do-repozytoriow-debiana-trusted-gpg/</link>
      <pubDate>Sun, 01 Nov 2015 19:14:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/klucze-do-repozytoriow-debiana-trusted-gpg/</guid>
      <description>&lt;p&gt;Obecnie systemy operacyjne stają się nieco bardziej stabilne i czasy, w których reinstalacja
takiego systemu, czy też nawet format dysku, odchodzą powoli w niebyt. &lt;a href=&#34;https://morfikov.github.io
/post/dokladna-data-instalacji-systemu-linux/&#34;&gt;Data instalacji mojego
linux&#39;a&lt;/a&gt; wskazuje na prawie 2 lata wstecz. Jakby nie patrzeć jest to szmat czasu, w czasie
którego przez mojego Debiana przetoczyła się ogromna ilość oprogramowania. Nie zawsze były to
pakiety, które pochodziły z głównych repozytoriów tej dystrybucji. Niemniej jednak, każde
repozytorium z pakietami jest podpisane i by móc z nich bezpiecznie korzystać, trzeba pozyskać
&lt;a href=&#34;https://pl.wikipedia.org/wiki/GNU_Privacy_Guard&#34;&gt;klucz GPG&lt;/a&gt; i dokonać jego weryfikacji. Prędzej czy później przyjdzie czas, gdy takie klucze GPG
przestaną być ważne lub też zmianie ulegną źródła pakietów. W ten sposób baza danych kluczy
zawierać będzie szereg zbędnych pozycji. Może wielu ludziom nie przeszkadza ten fakt ale raz na
jakiś czas przydałoby się oczyścić keyring ze śmieci, które są już nam do niczego niepotrzebne.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Szyfrowanie dźwięku przesyłanego przez sieć</title>
      <link>https://morfikov.github.io/post/szyfrowanie-dzwieku-przesylanego-przez-siec/</link>
      <pubDate>Sun, 01 Nov 2015 00:31:48 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/szyfrowanie-dzwieku-przesylanego-przez-siec/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.freedesktop.org/wiki/Software/PulseAudio/&#34;&gt;PulseAudio to serwer dźwięku&lt;/a&gt;, który jest w
stanie otrzymywać zapytania ze zdalnych lokalizacji. Wobec czego, możemy realizować &lt;a href=&#34;https://morfikov.github.io
/post/pulseaudio-i-przesylanie-dzwieku-przez-siec/&#34;&gt;przesyłanie
dźwięku przez sieć&lt;/a&gt; i usłyszeć
go tam, gdzie go sobie życzymy. Problem w tym, że taki dźwięk jest przesyłany przez sieć w formie
niezaszyfrowanej. Dlatego też jesteśmy narażeni na podsłuchanie wszystkiego co mówimy do mikrofonu
lub też tego co pojawia się w naszych głośnikach. Możemy jednak zabezpieczyć komunikację między
klientem i serwerem dźwięku wykorzystując do tego połączenie SSH. W ten sposób cały sygnał
dźwiękowy, jaki jest generowany przez danego hosta w sieci, zostanie wrzucony w szyfrowany kanał
TLS i nikt nie będzie w stanie go zinterpretować. Ten wpis ma na celu przedstawienie sposobu na
zaszyfrowanie dźwięku, bez którego większość z nas nie wyobraża sobie pacy przy komputerze.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PulseAudio i przesyłanie dźwięku przez sieć</title>
      <link>https://morfikov.github.io/post/pulseaudio-i-przesylanie-dzwieku-przez-siec/</link>
      <pubDate>Sat, 31 Oct 2015 22:53:43 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pulseaudio-i-przesylanie-dzwieku-przez-siec/</guid>
      <description>&lt;p&gt;Bardzo wielu ludzi nie uświadamia sobie faktu, że w przypadku komputerów praktycznie wszystkie dane,
z którymi mamy styczność, są zapisane za pomocą dwóch znaków, tj. 0 i 1. Mając to na względzie, nie
ma chyba informacji, której by nie można było przesłać przez sieć. Serwer dźwięku, jak sama nazwa
wskazuje, jest w stanie odbierać dane zawierają informacje dźwiękowe. Dlatego też jeśli jakiś
komputer nie posiada karty muzycznej lub/i nie jest fizycznie podłączony do głośników, to nie
stanowi to większego problemu by był on w stanie odtwarzać dźwięk, przynajmniej w tym sensie jakim
my to rozumiemy. W tym wpisie sþróbujemy zrealizować przesyłanie dźwięku przez sieć wykorzystując do
tego &lt;a href=&#34;https://www.freedesktop.org/wiki/Software/PulseAudio/&#34;&gt;PulseAudio&lt;/a&gt; i zobaczymy czy sprawi nam
to jakieś problemy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Szyfrowanie ruchu do Xserver&#39;a przy pomocy SSH</title>
      <link>https://morfikov.github.io/post/szyfrowanie-ruchu-do-xservera-przy-pomocy-ssh/</link>
      <pubDate>Sat, 31 Oct 2015 16:47:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/szyfrowanie-ruchu-do-xservera-przy-pomocy-ssh/</guid>
      <description>&lt;p&gt;W przypadku zaufanych sieci lokalnych, czy też &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-kontenerow-lxc/&#34;&gt;kontenerów
LXC&lt;/a&gt;, nie musimy zbytnio się troszczyć o
bezpieczeństwo przesyłanych danych. Nikt nam przecież nie założy tutaj podsłuchu. Dlatego też we
wpisie poświęconym konfiguracji Wine nie szyfrowaliśmy praktycznie żadnego ruchu sieciowego. Gdyby
jednak zaszła potrzeba przesłania pakietów do zdalnego Xserver&#39;a przez internet, to takie
rozwiązanie naraziłoby nas na przechwycenie wszystkich danych. By zabezpieczyć się przed tego typu
scenariuszem możemy zaszyfrować ruch do Xserver&#39;a &lt;a href=&#34;https://help.ubuntu.com/community/SSH/OpenSSH/PortForwarding&#34;&gt;forward&#39;ując wszystkie zapytania przy pomocy
szyfrowanego tunelu TLS&lt;/a&gt;. Możemy to
zrobić przy pomocy SSH i w tym wpisie postaramy się skonfigurować ten mechanizm.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Xauth i xhost na straży bezpieczeństwa Xserver&#39;a</title>
      <link>https://morfikov.github.io/post/xauth-i-xhost-na-strazy-bezpieczenstwa-xservera/</link>
      <pubDate>Fri, 30 Oct 2015 23:45:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/xauth-i-xhost-na-strazy-bezpieczenstwa-xservera/</guid>
      <description>&lt;p&gt;Na debianie Xserver domyślnie ma wyłączoną możliwość nasłuchiwania połączeń zdalnych. Chodzi
oczywiście o kwestie bezpieczeństwa, bo przecie nie od dziś wiadomo, że akurat to oprogramowanie
jest dziurawe jak sito i nikt rozsądny nie chciałby instalować go na swoim serwerze. Należałoby
jednak rozgraniczyć wykorzystywanie podatności jakiegoś oprogramowania od możliwości wejścia z nim w
interakcję. Jakby nie patrzeć, sam Xserver posiada co najmniej trzy mechanizmy ochrony, a do tego
dochodzą jeszcze reguły &lt;code&gt;iptables&lt;/code&gt; , czy też pliki &lt;code&gt;/etc/hosts.allow&lt;/code&gt; i &lt;code&gt;/etc/hosts.deny&lt;/code&gt; .
Prawdopodobnie jest ich jeszcze kilka ale te najczęściej wykorzystywane mechanizmy gdy pojawia się
słowo Xserver, to &lt;code&gt;-nolisten tcp&lt;/code&gt; (domyślnie aktywowany), &lt;code&gt;xhost&lt;/code&gt; oraz &lt;code&gt;xauth&lt;/code&gt; . Pierwszy z nich
wyklucza się z pozostałymi i to tym dwóm ostatnim przyjrzymy bliżej w tym wpisie.&lt;/p&gt;
&lt;p&gt;Mechanizmy &lt;code&gt;xhost&lt;/code&gt; oraz &lt;code&gt;xauth&lt;/code&gt; w żaden sposób nie zabezpieczają informacji przesyłanych do
Xserver&#39;a. Wobec czego, całą komunikację można bez problemu podsłuchać. Stwarza to zagrożenie
przechwycenia nie tylko obrazu wyświetlanego na monitorze ale także danych dotyczących myszy i
przyciskanych klawiszy na klawiaturze.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wine w kontenerze LXC</title>
      <link>https://morfikov.github.io/post/wine-w-kontenerze-lxc/</link>
      <pubDate>Fri, 30 Oct 2015 17:13:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wine-w-kontenerze-lxc/</guid>
      <description>&lt;p&gt;Każdy kto zmienił architekturę systemu z i386 na amd64 raczej nie dostrzegł większej różnicy w
operowaniu na którejś z nich. Czasem jedynie pakiety w nazwie mają 64 zamiast 32. Jest natomiast
jedna rzecz, która drażni chyba każdego. Mowa tutaj o &lt;a href=&#34;https://www.winehq.org/&#34;&gt;projekcie Wine&lt;/a&gt;.
Wine nie umie obsługiwać natywnie serwera dźwięku PulseAudio. Do tego dochodzi jeszcze problem,
który związany jest z tymi wszystkimi pakietami 32 bitowymi, które trzeba zainstalować. I w ten
sposób nasz system staje się bardziej multiarch niż amd64. W tym wpisie postaramy się przy pomocy
kontenera LXC odizolować Wine od całej reszty systemu operacyjnego, tak by nie musieć wgrywać do
niego całej masy zbędnych bibliotek.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja kontenerów LXC</title>
      <link>https://morfikov.github.io/post/konfiguracja-kontenerow-lxc/</link>
      <pubDate>Thu, 29 Oct 2015 23:27:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-kontenerow-lxc/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://wiki.debian.org/LXC&#34;&gt;Kontenery LXC&lt;/a&gt; mają za zadanie odizolować poszczególne usługi od
pozostałej części systemu. LXC jest podobny nieco do maszyn wirtualnych, np. tych tworzonych przez
VirtualBox. Niemniej jednak, oba mechanizmy różnią się trochę. Zasadnicza różnica między nimi polega
na tym, że LXC wykorzystuje &lt;a href=&#34;https://morfikov.github.io
/post/przygotowanie-srodowiska-chroot-do-pracy/&#34;&gt;środowisko
chroot&lt;/a&gt; , w którym współdzielone
jest jądro operacyjne. Nie trzeba także z góry określać zasobów pod działanie takiego kontenera, tak
jak to ma w przypadku maszyn wirtualnych. Rzućmy zatem okiem jak wygląda konfiguracja takich
kontenerów na linux&#39;ie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Więcej niż jeden profil w Firefox&#39;ie</title>
      <link>https://morfikov.github.io/post/wiecej-niz-jeden-profil-w-firefoxie/</link>
      <pubDate>Thu, 29 Oct 2015 16:50:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wiecej-niz-jeden-profil-w-firefoxie/</guid>
      <description>&lt;p&gt;Ogromna większość ludzi korzysta z jednego profilu swojej przeglądarki internetowej. Niesie to ze
sobą spore zagrożenie bezpieczeństwa jak i może godzić w naszą prywatność. Jeśli dzielimy z kimś
komputer, to raczej wszyscy domownicy posiadają osobne konta w systemie, a co z tym się wiąże, inny
profil przeglądarki. I na tym zwykle podział się kończy ale przecie to nie wszystko. Profil, jak
sama nazwa wskazuje, jest w stanie dostosować opcje przeglądarki, np. pod kątem pewnych aktywności.
W tym wpisie postaramy się utworzyć kilka profili w Firefox&#39;ie i sprawdzimy korzystanie z nich
będzie odczuwalne w jakiś sposób dla przeciętnego użytkownika internetu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aktywacja i konfiguracja klawisza SysRq</title>
      <link>https://morfikov.github.io/post/aktywacja-i-konfiguracja-klawisza-sysrq/</link>
      <pubDate>Thu, 29 Oct 2015 01:57:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aktywacja-i-konfiguracja-klawisza-sysrq/</guid>
      <description>&lt;p&gt;SysRq (System Request) to klawisz na klawiaturze, po którego przyciśnięciu można wysłać
niskopoziomowe zapytana bezpośrednio do kernela linux&#39;a. Te komendy działają nawet w przypadku
pozornego braku kontaktu z systemem operacyjnym, tj. zacięcia dźwięku, nieruchomy kursor myszy, a
nawet w przypadku braku możliwości wpisywania znaków z klawiatury. Zwykle po opisanych wyżej
symptomach, człowiek jest skłonny przycisnąć przycisk reset na obudowie swojego komputera, no bo jak
inaczej odwiesić taki system? Problem z twardym resetem (za pomocą przycisku) jest taki, że
praktycznie zawsze po nim występuje uszkodzenie struktury systemu plików na dysku, a czasami
uszkodzeniu ulega cała partycja. To niesie ze sobą ryzyko utraty danych. Dlatego też powinniśmy
zaprzestać resetowania komputerów przy pomocy przycisków i zacząć korzystać z klawisza SysRq .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatyczny restart maszyny po kernel panic</title>
      <link>https://morfikov.github.io/post/automatyczny-restart-maszyny-po-kernel-panic/</link>
      <pubDate>Wed, 28 Oct 2015 23:56:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/automatyczny-restart-maszyny-po-kernel-panic/</guid>
      <description>&lt;p&gt;Gdy nasz linux napotka z jakiegoś powodu błąd wewnątrz swojej struktury, to istnieją sytuacje, w
których obsługa tego błędu czasem nie jest możliwa. Wobec czego, zostaje wyrzucony komunikat
systemowy oznajmiający nam, że &lt;a href=&#34;https://pl.wikipedia.org/wiki/Kernel_panic&#34;&gt;kernel spanikował (kernel
panic)&lt;/a&gt;, bo nie wie co w takim przypadku zrobić. Gdy
tego typu sytuacja się nam przytrafia, nie ma innego wyjścia jak tylko uruchomić system ponownie. Co
jednak w przypadku gdy pracujemy zdalnie i nie jesteśmy w stanie zresetować takiej maszyny
fizycznie? Na szczęście kernel ma kilka opcji, które mogą zainicjować automatyczny restart w
przypadku wystąpienia kernel panic.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja wtyczki flash na linux&#39;ie (mms.cfg)</title>
      <link>https://morfikov.github.io/post/konfiguracja-wtyczki-flash-na-linuxie-mms-cfg/</link>
      <pubDate>Wed, 28 Oct 2015 21:21:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-wtyczki-flash-na-linuxie-mms-cfg/</guid>
      <description>&lt;p&gt;W obecnych czasach powoli się odchodzi od stosowania technologi flash w przeglądarkach. Na dobra
sprawę, po tym jak google w youtube przesiadł się na html5, to korzystanie z flash player&#39;a nie ma
już większego sensu. Są jednak serwisy, które nie nadążają za zmieniającą się rzeczywistością i w
ich przypadku przejście z flash&#39;a na html5 może jeszcze zająć kilka lat. Zatem nawet jeśli nie
korzystamy z flash&#39;a na co dzień, to i tak większość z nas będzie chciała go mieć w systemie, tak na
wszelki wypadek, by nie być pozbawionym możliwości oglądania materiałów video na tych drugorzędnych
serwisach. Jako, że wtyczka flash jest bardzo dziurawa, przydałoby się ją nieco skonfigurować i w
tym wpisie zostanie przedstawionych szereg opcji, które można umieścić w pliku &lt;code&gt;mms.cfg&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Usuwanie wpisów z about:config w Firefox&#39;ie</title>
      <link>https://morfikov.github.io/post/usuwanie-wpisow-z-aboutconfig-w-firefoxie/</link>
      <pubDate>Tue, 27 Oct 2015 20:58:39 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/usuwanie-wpisow-z-aboutconfig-w-firefoxie/</guid>
      <description>&lt;p&gt;Po wpisaniu w pasku adresu Firefox&#39;a &lt;a href=&#34;http://kb.mozillazine.org/About:config&#34;&gt;about:config&lt;/a&gt; ,
zostanie nam zwrócona dość długa lista parametrów konfiguracyjnych, które możemy sobie dostosować
wedle uznania. Większość z nich ma spory wpływ na zachowanie samej przeglądarki ale są też i opcje,
które zostały dodane za sprawą różnych dodatków. Chodzi o to, że za każdym razem gdy instalujemy
nowy addon, to ten zwykle ma opcje konfiguracyjne i to właśnie one są widoczne w &lt;code&gt;about:config&lt;/code&gt; . W
przypadku gdy już nie korzystamy z tego dodatku i wyrzuciliśmy go kompletnie z Firefox&#39;a, wpisy w
konfiguracji dalej widnieją. Przydałoby się zatem nieco przeczyścić naszą przeglądarkę i usunąć te
wszystkie śmieci.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pliki .torrent i magnet linki w Firefox&#39;ie</title>
      <link>https://morfikov.github.io/post/pliki-torrent-i-magnet-linki-w-firefoxie/</link>
      <pubDate>Tue, 27 Oct 2015 20:02:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pliki-torrent-i-magnet-linki-w-firefoxie/</guid>
      <description>&lt;p&gt;Przeglądarki mają to do siebie, że każda z nich korzysta z własnych ustawień dotyczących &lt;a href=&#34;https://pl.wikipedia.org/wiki/Typ_MIME&#34;&gt;typów MIME
(mime type)&lt;/a&gt;. Do tego dochodzi jeszcze fakt, że często te
ustawienia są inne od tych, które mamy w systemie. Może to nie jest jakiś wielki problem, bo w
opcjach Firefox&#39;a możemy bez trudu szereg rzeczy poprzestawiać. Natomiast jest jeden problem,
którego w prosty sposób się obejść nie da i trzeba się trochę na nim pochylić. Chodzi o dodawanie
nowych typów MIME, które nie są pokazane na liście obsługiwanych typów w Preferences -&amp;gt;
Applications. Wiąże się z tym tak skonfigurowanie przeglądarki, by automatycznie otworzyła ona jakiś
program ilekroć dany typ pliku będzie pobierany.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mechanizm SYN cookies w protokole TCP</title>
      <link>https://morfikov.github.io/post/mechanizm-syn-cookies-w-protokole-tcp/</link>
      <pubDate>Sat, 24 Oct 2015 20:22:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mechanizm-syn-cookies-w-protokole-tcp/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/SYN_flood&#34;&gt;Atak SYN flood&lt;/a&gt; to rodzaj ataku DoS, którego celem jest
wyczerpanie zasobów serwera uniemożliwiając mu tym samym poprawne realizowanie danej usługi, do
której został oddelegowany. Jest to dość popularne zjawisko i w przypadku, gdy mamy postawioną
jakąś maszynę na publicznym adresie IP, przydałoby się nieco zainteresować tym problem, który może
wystąpić w najmniej oczekiwanym momencie. W tym wpisie rzucimy okiem na mechanizm SYN cookies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Unikanie ataków DDoS z SYNproxy</title>
      <link>https://morfikov.github.io/post/unikanie-atakow-ddos-z-synproxy/</link>
      <pubDate>Sat, 24 Oct 2015 17:39:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/unikanie-atakow-ddos-z-synproxy/</guid>
      <description>&lt;p&gt;Internet nie jest zbyt przyjaznym miejscem i jest wielce prawdopodobne, że prędzej czy później ktoś
zaatakuje jedną z naszych maszyn, która świadczy w nim jakieś usługi. Są różne typy ataków, w tym
przypadku chodzi o ataki DDoS z wykorzystaniem pakietów wchodzących w proces potrójnego witania
(three way handshake) przy nawiązywaniu połączenia w protokole TCP, tj. pakiety &lt;code&gt;SYN&lt;/code&gt; , &lt;code&gt;SYN-ACK&lt;/code&gt; i
&lt;code&gt;ACK&lt;/code&gt; . Istnieje szereg mechanizmów, które adresują problem SYN flooding&#39;u ale żaden z nich nie jest
doskonały. Jakiś czas temu, do kernela linux&#39;owego trafił patch implementujący &lt;a href=&#34;https://lwn.net/Articles/563151/&#34;&gt;mechanizm
SYNproxy&lt;/a&gt; i w tym wpisie obadamy go sobie nieco dokładniej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Moduł kernela i wartości jego parametrów</title>
      <link>https://morfikov.github.io/post/modul-kernela-i-wartosci-jego-parametrow/</link>
      <pubDate>Fri, 23 Oct 2015 19:35:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-kernela-i-wartosci-jego-parametrow/</guid>
      <description>&lt;p&gt;Raczej na pewno spotkaliśmy się już z modułami kernela w linux&#39;ie. Generalnie rzecz biorąc, taki
moduł może być ładowany dynamicznie i w sporej części przypadków niezależnie, choć z zwykle jest
pociągany przy zdarzeniach udev&#39;a. Czasem jednak, dany moduł nie działa jak należy i może to być
wynikiem, np. problemów w samym module, lub też jego niewłaściwej konfiguracji, która konfliktuje z
podzespołami naszego komputera. Ten wpis będzie dotyczył tego jak ustalić parametry modułów i ich
domyślne wartości, tak by móc je sobie zmienić w późniejszym czasie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pobieranie pakietów przy pomocy cron-apt</title>
      <link>https://morfikov.github.io/post/pobieranie-pakietow-przy-pomocy-cron-apt/</link>
      <pubDate>Fri, 23 Oct 2015 14:42:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pobieranie-pakietow-przy-pomocy-cron-apt/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem konfigurację dla menadżera pakietów &lt;code&gt;apt&lt;/code&gt; i &lt;code&gt;aptitude&lt;/code&gt; &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-apt-i-aptitude-w-pliku-apt-conf/&#34;&gt;w pliku
apt.conf&lt;/a&gt; . Ten wpis również
tyczy się konfiguracji wspomnianych menadżerów, z tym, że zostanie tutaj opisana pewna
funkcjonalność, która może nam zaoszczędzić trochę czasu przy aktualizacji systemu. Chodzi o to,
że pakiety praktycznie zawsze muszą być pobrane na dysk przed ich instalacją. Gdy nie dysponujemy
dobrym pod względem przepustowości łączem, proces pobierania pakietów jest zwykle dłuższy niż sama
ich instalacja. Przydałoby się zatem zaprogramować pobieranie plików w tle, tak by nie musieć ich
pobierać tuż przez przed procesem instalacyjnym.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Reinstalacja kernela i bootloader&#39;a</title>
      <link>https://morfikov.github.io/post/reinstalacja-kernela-bootloadera/</link>
      <pubDate>Thu, 22 Oct 2015 18:41:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/reinstalacja-kernela-bootloadera/</guid>
      <description>&lt;p&gt;Wykorzystywanie pełnego szyfrowania dysku twardego ma jedną zasadniczą wadę. O ile nasze dane są
należycie zabezpieczone, o tyle trzeba zwracać uwagę na to komu zezwalamy na dostęp do naszego
komputera. Nie chodzi tutaj o to, kto będzie używał samego systemu operacyjnego, choć to też jest
ważne, ale przede wszystkim chodzi o te osoby, które mają dostęp fizyczny do naszej maszyny. Czasem
możemy nabrać podejrzenia, że ktoś mógł nam jakąś pluskwę podłożyć. Wykrycie takiego robala, np. w
postaci sprzętowego keylogger&#39;a, nie powinno sprawić problemów. Z kolei już manipulacja boot
sektorem dysku twardego, lub też zmiany w initramfs, który znajduje się na niezaszyfrowanej partycji
&lt;code&gt;/boot/&lt;/code&gt; mogą przejść niezauważone. Jak zatem odratować system, co do którego mamy jakieś
zastrzeżenia?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Montowanie katalogu /tmp/ jako tmpfs</title>
      <link>https://morfikov.github.io/post/montowanie-katalogu-tmp-jako-tmpfs/</link>
      <pubDate>Wed, 21 Oct 2015 22:19:14 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/montowanie-katalogu-tmp-jako-tmpfs/</guid>
      <description>&lt;p&gt;Linux jest w stanie operować na wielu systemach plików, np. ext4, ntfs, fat. Większość z nich odnosi
się do dysków twardych, czy też innych urządzeń przechowujących spore ilości danych. Problem z tego
typu systemami plików jest taki, że operacje na plikach w ich obrębie, jak i same pliki, zostawiają
ślady. Dlatego też jeśli musimy tymczasowo skopiować plik zawierający tajne dane, lub też taki plik
poddać obróbce, nie powinniśmy go umieszczać bezpośrednio na dysku. No chyba, że wykorzystujemy
pełne szyfrowanie. Inną opcją (i o wiele prostszą w implementacji) jest przeznaczenie części
pamięci operacyjnej RAM pod &lt;a href=&#34;https://wiki.archlinux.org/index.php/Tmpfs&#34;&gt;system plików tmpfs&lt;/a&gt; i o
tym będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dropbox i kontener LUKS</title>
      <link>https://morfikov.github.io/post/dropbox-i-kontener-luks/</link>
      <pubDate>Wed, 21 Oct 2015 20:34:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dropbox-i-kontener-luks/</guid>
      <description>&lt;p&gt;Ogarnęliśmy już szyfrowanie plików na dropbox&#39;ie przy pomocy
&lt;a href=&#34;https://morfikov.github.io
/post/implementacja-encfs-na-dropboxie/&#34;&gt;encfs&lt;/a&gt; oraz &lt;a href=&#34;https://morfikov.github.io
/post/kontener-truecrypt-trzymany-na-dropboxie/&#34;&gt;kontenerów
TrueCrypt&lt;/a&gt;. Każda z w/w operacji
drastycznie poprawiła prywatność naszych plików, które przechowujemy w chmurze. Poniższy wpis będzie
w podobnym klimacie, tj. spróbujemy umieścić na dropbox&#39;ie &lt;a href=&#34;https://pl.wikipedia.org/wiki/Linux_Unified_Key_Setup&#34;&gt;kontener
LUKS&lt;/a&gt;, co niesie ze sobą sporo udogodnień i
czyni korzystanie z zaszyfrowanego dropbox&#39;a praktycznie transparentnym.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kontener TrueCrypt trzymany na dropbox&#39;ie</title>
      <link>https://morfikov.github.io/post/kontener-truecrypt-trzymany-na-dropboxie/</link>
      <pubDate>Tue, 20 Oct 2015 18:27:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kontener-truecrypt-trzymany-na-dropboxie/</guid>
      <description>&lt;p&gt;Żyjemy w czasach, w których mobilność jest tak samo ważna albo może i ważniejsza (dla niektórych
ludzi na pewno) jak i bezpieczeństwo i poufność danych. Użyteczność zwykle nie idzie w patrze z
bezpieczeństwem, bo im prostszy jest dla nas dostęp do danych, tym bardziej zagraża ich
bezpieczeństwu. W tym przypadku chcielibyśmy mieć możliwość dostępu do plików, np. naszego domowego
PC, z dowolnego miejsca na ziemi. Czy można w prosty i w miarę bezpieczny sposób coś takiego
osiągnąć? &lt;a href=&#34;https://morfikov.github.io
/post/implementacja-encfs-na-dropboxie/&#34;&gt;Jakiś czas temu opisywałem implementację encfs na
dropbox&#39;ie&lt;/a&gt;, w tym artykule zostanie zaś
opisane sprzęgnięcie dropbox&#39;a z kontenerem TrueCrypt.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przejście z Truecrypt na LUKS</title>
      <link>https://morfikov.github.io/post/przejscie-z-truecrypt-na-luks/</link>
      <pubDate>Tue, 20 Oct 2015 09:58:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przejscie-z-truecrypt-na-luks/</guid>
      <description>&lt;p&gt;Jakiś czas temu, można było usłyszeć, że TrueCrypt nie dba wcale o bezpieczeństwo danych
zaszyfrowanych za jego pomocą. &lt;a href=&#34;http://istruecryptauditedyet.com/&#34;&gt;Audyt bezpieczeństwa&lt;/a&gt; jednak nie
wykazał większych podatności w tym oprogramowaniu. &lt;a href=&#34;https://madiba.encs.concordia.ca/~x_decarn/truecrypt-binaries-analysis/&#34;&gt;Analiza
binarek&lt;/a&gt; dostępnych na
stronie TrueCrypt&#39;a pod kątem &lt;a href=&#34;https://wiki.debian.org/ReproducibleBuilds&#34;&gt;Reproducible Builds&lt;/a&gt;
również nie wykazała większych odchyłów w stosunku do binarek generowanych prosto z kodu
źródłowego. Problematyczne może być jednak to, że tak naprawdę nie wiadomo kto stoi za tym całym
projektem, przynajmniej gdy był jeszcze rozwijany. Cała sytuacja zamknięcia TrueCrypt&#39;a z sieci była
też co najmniej dziwna. W obliczu takich niewiadomych, powinniśmy rozważyć przejście na natywne
rozwiązania linux&#39;owe, które są jawnie rozwijane, wiadomo kto za nimi stoi i, co najważniejsze, mają
wsparcie w samym kernelu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja encfs na dropbox&#39;ie</title>
      <link>https://morfikov.github.io/post/implementacja-encfs-na-dropboxie/</link>
      <pubDate>Mon, 19 Oct 2015 23:11:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-encfs-na-dropboxie/</guid>
      <description>&lt;p&gt;Jako, że ostatnio &lt;a href=&#34;https://morfikov.github.io
/post/szyfrowanie-katalogu-home-przy-pomocy-encfs/&#34;&gt;zaszyfrowaliśmy katalog domowy przy pomocy
encfs&lt;/a&gt; , to nie sposób sobie
nie zadać pytania czy tego typu mechanizm może działać w oparciu o serwisy online takie jak, np.
&lt;a href=&#34;https://www.dropbox.com/&#34;&gt;dropbox&lt;/a&gt;. Chodzi o to, że dropbox umożliwia synchronizację plików w
czasie rzeczywistym, co może być problematyczne, gdy w grę wchodzi szyfrowanie danych. Wszelkie inne
rozwiązania na bazie &lt;a href=&#34;https://pl.wikipedia.org/wiki/Linux_Unified_Key_Setup&#34;&gt;LUKS&lt;/a&gt; są mało
praktyczne w tym przypadku. Natomiast synchronizowanie pojedynczych plików zaszyfrowanych przy
pomocy &lt;code&gt;encfs&lt;/code&gt; zapowiada się obiecująco.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zaszyfrowana przestrzeń wymiany SWAP</title>
      <link>https://morfikov.github.io/post/zaszyfrowana-przestrzen-wymiany-swap/</link>
      <pubDate>Mon, 19 Oct 2015 22:32:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zaszyfrowana-przestrzen-wymiany-swap/</guid>
      <description>&lt;p&gt;Opisując mechanizm szyfrowania katalogu domowego przy pomocy &lt;a href=&#34;https://morfikov.github.io
/post/szyfrowanie-katalogu-home-przy-pomocy-encfs/&#34;&gt;narzędzia
encfs&lt;/a&gt; , wspomniałem o
problemie jaki powstaje przy jednoczesnym braku szyfrowania przestrzeni wymiany SWAP. Oczywiście,
jeśli posiadamy w systemie dużą ilość pamięci RAM, to raczej nie potrzebna nam jest przestrzeń
wymiany. Podobnie sprawa ma się w przypadku, gdy nie korzystamy z hibernacji. Natomiast, jeśli jedna
z naszych partycji jest sformatowana jako SWAP i aktywnie z niej korzystamy, to niepełne szyfrowanie
dysku, jakie zapewnia &lt;code&gt;encfs&lt;/code&gt; może doprowadzić do skompromitowania zaszyfrowanych danych.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Szyfrowanie katalogu /home/ przy pomocy encfs</title>
      <link>https://morfikov.github.io/post/szyfrowanie-katalogu-home-przy-pomocy-encfs/</link>
      <pubDate>Mon, 19 Oct 2015 21:54:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/szyfrowanie-katalogu-home-przy-pomocy-encfs/</guid>
      <description>&lt;p&gt;Wielu ludzi uważa, że szyfrowanie całego dysku jest zbędne i pozbawione większego sensu, no bo
przecie &amp;quot;system nie zawiera żadnych wrażliwych danych, które by wymagały szyfrowania&amp;quot;. Nie będę się
tutaj spierał co do tego punktu widzenia, bo raczej wszyscy znają moje zdanie na temat &amp;quot;danych
wymagających szyfrowania&amp;quot; i skupię się tu raczej na tym jak troszeczkę podratować niepełne
szyfrowanie, które ludzie, nie wiedząc czemu, są bardziej skłonni stosować, niż cały ten full disk
encryption.&lt;/p&gt;
&lt;p&gt;Narzędzie &lt;code&gt;encfs&lt;/code&gt; nie przeszło pomyślnie &lt;a href=&#34;https://defuse.ca/audits/encfs.htm&#34;&gt;audytu bezpieczeństwa&lt;/a&gt;
, a to z takiego powodu, że projekt nie był rozwijany przez szereg lat. &lt;a href=&#34;https://github.com/vgough/encfs&#34;&gt;Obecnie jest on w rekach
społeczności&lt;/a&gt; i to od niej będzie zależeć czy te wykryte błędy
zostaną poprawione.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zabezpieczenie konta root przy pomocy pam-usb</title>
      <link>https://morfikov.github.io/post/zabezpieczenie-konta-root-przy-pomocy-pam-usb/</link>
      <pubDate>Mon, 19 Oct 2015 21:01:03 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zabezpieczenie-konta-root-przy-pomocy-pam-usb/</guid>
      <description>&lt;p&gt;Jakiś czas temu natknąłem się na moduł &lt;code&gt;pam-usb&lt;/code&gt; , który to w dość ciekawy sposób zabezpiecza dostęp
do konta użytkownika root. &lt;a href=&#34;https://wiki.debian.org/pamusb&#34;&gt;Cały mechanizm opiera się o pendrive&lt;/a&gt;,
którego to unikalne cechy są brane pod uwagę przy uwierzytelnianiu podczas logowania się na konto
super użytkownika, czyli min. gdy wydajemy polecenie &lt;code&gt;su&lt;/code&gt; albo &lt;code&gt;sudo&lt;/code&gt; . Jest to o tyle ciekawa
rzecz, że konto użytkownika root możne stać się niewrażliwe na próby złamania hasła w przypadku
połączenia sieciowego. Jak by nie patrzeć, atakujący, który łączy się zdalnie, nie jest w stanie
podłączyć do naszego komputera żadnego fizycznego urządzenia, w wyniku czego nigdy nie uzyska
dostępu do konta administratora.&lt;/p&gt;
&lt;p&gt;Pakiet &lt;code&gt;libpam-usb&lt;/code&gt; wyleciał z debiana jakiś czas temu. &lt;a href=&#34;https://tracker.debian.org/news/686153&#34;&gt;Powodem
były&lt;/a&gt; zależności, które wskazywały na przestarzały już
pakiet &lt;code&gt;udisks&lt;/code&gt; . Poza tym, nikt nie zajmował się tym pakietem. Obecnie jest on dostępny jedynie w
starszych wydaniach debiana.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konwersja napisów w kontenerze MP4</title>
      <link>https://morfikov.github.io/post/konwersja-napisow-w-kontenerze-mp4/</link>
      <pubDate>Mon, 19 Oct 2015 19:31:49 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konwersja-napisow-w-kontenerze-mp4/</guid>
      <description>&lt;p&gt;Podczas ogarniania kolekcji filmów i przerabiania jej w taki sposób by został nam tylko jeden plik,
tj. &lt;a href=&#34;https://morfikov.github.io
/post/kontener-multimedialny-mkv/&#34;&gt;kontener MKV&lt;/a&gt;, możemy czasem napotkać
problemy, które mogą nam uniemożliwić to zadanie. Może się zdarzyć tak, że będziemy mieli do
czynienia z innymi kontenerami niż MKV, np. MP4. Ten wpis będzie poświęcony właśnie tego rodzaju
kontenerom.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kontener multimedialny MKV</title>
      <link>https://morfikov.github.io/post/kontener-multimedialny-mkv/</link>
      <pubDate>Mon, 19 Oct 2015 19:29:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kontener-multimedialny-mkv/</guid>
      <description>&lt;p&gt;Wiele osób posiada pliki video i ci co uczą się angielskiego, czy innych języków, niezbyt przepadają
za słuchaniem polskiego lektora na filmach, bo zagłusza on przecie całą oryginalną ścieżkę audio.
Poza tym, jakość tłumaczenia jest na żenująco niskim poziomie. Z samego słuchu człowiek ciężko się
uczy, zwłaszcza jak zaczyna naukę nowego języka, dlatego też można sobie dociągnąć polskie napisy.
Co jednak w przypadku, gdy chcemy mieć kilka ścieżek audio czy napisów w jednym filmie? Posiadanie
wielu plików wprowadza trochę zamętu. Poniżej zostanie opisany sposób na ogarnięcie kolekcji
filmowej, tak by został nam się tylko jeden plik w przypadku każdego ulubionego przez nas filmu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja apt i aptitude w pliku apt.conf</title>
      <link>https://morfikov.github.io/post/konfiguracja-apt-i-aptitude-w-pliku-apt-conf/</link>
      <pubDate>Sun, 18 Oct 2015 20:04:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-apt-i-aptitude-w-pliku-apt-conf/</guid>
      <description>&lt;p&gt;Praktycznie każdy z nas korzysta z menadżera pakietów &lt;code&gt;apt&lt;/code&gt; lub też jego nakładki &lt;code&gt;aptitude&lt;/code&gt; .
Operowanie na debianie bez tych narzędzi raczej by nam nieco utrudniło życie. Sporo osób ogranicza
się jedynie do podstawowych poleceń, typu &lt;code&gt;update&lt;/code&gt; , &lt;code&gt;upgrade&lt;/code&gt; czy &lt;code&gt;dist-upgrade&lt;/code&gt; , pomijając przy
tym całą konfigurację w/w narzędzi. W tym wpisie zostanie zaprezentowanych szereg opcji, które można
zdefiniować na stałe w pliku konfiguracyjnym &lt;code&gt;/etc/apt/apt.conf&lt;/code&gt; , tak by nie trzeba było ich ciągle
wpisywać w terminalu ilekroć tylko korzystamy któregoś menadżera pakietów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Usuwanie środowiska graficznego</title>
      <link>https://morfikov.github.io/post/usuwanie-srodowiska-graficznego/</link>
      <pubDate>Sun, 18 Oct 2015 17:52:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/usuwanie-srodowiska-graficznego/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=27813&#34;&gt;Na forum DUG&#39;a&lt;/a&gt; znów został poruszony ciekawy
wątek, tym razem odnośnie usunięcia całego środowiska graficznego z systemu. Pozornie niby nic
nadzwyczajnego, przecie każdy z nas potrafi odinstalować szereg pakietów via &lt;code&gt;apt&lt;/code&gt; czy &lt;code&gt;aptitude&lt;/code&gt; .
Problematyczne za to mogą się okazać zależne pakiety, które nie zostaną automatycznie usunięte wraz
z konkretnym metapakietem od środowiska graficznego. Jak zatem usunąć te pozostałości?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Oczyszczanie bazy danych dconf</title>
      <link>https://morfikov.github.io/post/oczyszczanie-bazy-danych-dconf/</link>
      <pubDate>Sat, 17 Oct 2015 18:00:43 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/oczyszczanie-bazy-danych-dconf/</guid>
      <description>&lt;p&gt;Jak możemy przeczytać &lt;a href=&#34;https://wiki.gnome.org/action/show/Projects/dconf&#34;&gt;na wiki projektu GNOME&lt;/a&gt; ,
&lt;code&gt;dconf&lt;/code&gt; to swojego rodzaju baza danych, która zawiera informacje o konfiguracji systemu w postaci
klucz-wartość. Jak nie korzystam, co prawda, ze środowisk graficznych ale wykorzystuję w swoim
linux&#39;ie szereg ich elementów, które mogą działać z powodzeniem w okrojonym systemie, np.
&lt;code&gt;gnome-keyring&lt;/code&gt; . Część programów wykorzystuje tę bazę danych do przechowywania swoich ustawień,
które możemy zmieniać via &lt;code&gt;gsettings&lt;/code&gt; , &lt;code&gt;gconf&lt;/code&gt; lub też &lt;code&gt;dconf&lt;/code&gt; . Problem pojawia się po dłuższym
czasie używania systemu, gdzie cześć z ustawień jest już przestarzała, np. w wyniku zaprzestania
użytkowania jakiejś aplikacji. Przydałoby się zatem raz na jakiś czas oczyścić te bazę danych ze
zbędnych wpisów i o tym będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Serwer kluczy GPG i kwestia prywatności</title>
      <link>https://morfikov.github.io/post/serwer-kluczy-gpg-i-kwestia-prywatnosci/</link>
      <pubDate>Fri, 16 Oct 2015 18:59:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/serwer-kluczy-gpg-i-kwestia-prywatnosci/</guid>
      <description>&lt;p&gt;Czytając sobie artykuł na temat &lt;a href=&#34;https://trac.torproject.org/projects/tor/wiki/doc/TorifyHOWTO/GnuPG&#34;&gt;TORyfikacji zapytań do serwerów kluczy
GPG&lt;/a&gt;, pomyślałem, że w sumie
mógłbym zreprodukować przedstawione tam kroki dotyczące implementacji tego rozwiązania na windowsie
i wdrożyć je na linux&#39;ie. Chodzi generalnie o to, by serwer kluczy GPG nie był odpytywany
bezpośrednio przy szukaniu/przesyłaniu kluczy przez sieć, bo to może identyfikować nas, jak i grupę
ludzi, która się z nami komunikuje. Jakby nie patrzeć, klucze GPG składają się z dość newralgicznych
informacji, typu imię, nazwisko czy adres email, a serwer kluczy GPG tych danych w żaden sposób nie
zabezpiecza i są one zwykle przesyłane otwartym tekstem przez sieć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Brak dźwięku przy nieaktywnej sesji logowania</title>
      <link>https://morfikov.github.io/post/brak-dzwieku-przy-nieaktywnej-sesji-logowania/</link>
      <pubDate>Thu, 15 Oct 2015 20:52:50 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/brak-dzwieku-przy-nieaktywnej-sesji-logowania/</guid>
      <description>&lt;p&gt;Jeśli korzystamy z &lt;a href=&#34;https://www.freedesktop.org/wiki/Software/PulseAudio/&#34;&gt;serwera dźwięku
PulseAudio&lt;/a&gt; na swoim linux&#39;ie, prawdopodobnie
zdarzyła nam się już sytuacja, w której chcieliśmy zablokować lub wygasić ekran monitora mając
jednocześnie odpalony jakiś odtwarzacz muzyki. Gdy tylko ekran zostanie zablokowany, możemy
odnotować brak dźwięku, bo ten zwyczajnie natychmiast zamiera. Za to po odblokowaniu ekranu, dźwięk
wraca. Podobnie sprawa ma się przy przejściu z trybu graficznego (Xorg) na jedną z konsol TTY.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja połączenia WiFi pod debianem</title>
      <link>https://morfikov.github.io/post/konfiguracja-polaczenia-wifi-pod-debianem/</link>
      <pubDate>Thu, 15 Oct 2015 19:32:48 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-polaczenia-wifi-pod-debianem/</guid>
      <description>&lt;p&gt;Sieci bezprzewodowe w obecnych czasach to standard i nie ma chyba miejsca na ziemi gdzie nie dałoby
rady ulokować routera WiFi, do którego można by podłączyć szereg urządzeń. Każdy kto próbował
konfigurować sieć bezprzewodową na debianie, wie, że może to być bardzo upierdliwe, zwłaszcza jeśli
mamy dostęp do wielu AP, które posiadają różne konfiguracje. Wynaleziono, co prawda, automaty, które
mają pomagać w ogarnięciu tego całego bezprzewodowego zamieszania, np. &lt;code&gt;network-manager&lt;/code&gt; czy &lt;code&gt;wicd&lt;/code&gt;
ale w przypadku lekkich stacji roboczych, które nie mają wgranego pełnego środowiska graficznego, a
jedynie jakiś menadżer okien, np. Openbox, to instalacja tych powyższych narzędzi może zwyczajnie
nie wchodzić w grę.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmienna TZ w środowisku linux&#39;owym</title>
      <link>https://morfikov.github.io/post/zmienna-tz-w-srodowisku-linuxowym/</link>
      <pubDate>Thu, 15 Oct 2015 17:02:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmienna-tz-w-srodowisku-linuxowym/</guid>
      <description>&lt;p&gt;Ten wpis będzie poświęcony poprawie wydajności naszych systemów linux&#39;owych. Okazuje się bowiem, że
w pewnych aspektach ich pracy &lt;a href=&#34;http://www.brendangregg.com/blog/2014-05-11/strace-wow-much-syscall.html&#34;&gt;nie wszystko działa jak
należy&lt;/a&gt;. Rozchodzi się o
zmienną środowiskową &lt;code&gt;TZ&lt;/code&gt; , w oparciu o którą to zwracane są, np. czasy utworzenia czy modyfikacji
plików na dysku. Ten przypadek jest o tyle dziwny, że każdy z nas ma już na swojej maszynie
skonfigurowany czas systemowy, za który odpowiada pakiet &lt;code&gt;tzdata&lt;/code&gt; . Niby wyraźnie określiliśmy
strefę czasową, w tym przypadku jest to &lt;code&gt;Europe/Warsaw&lt;/code&gt; ale widać system operacyjny posiłkuje się
odwołaniami do pliku &lt;code&gt;/etc/localtime&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Baza danych użytkowników serwera freeradius</title>
      <link>https://morfikov.github.io/post/baza-danych-uzytkownikow-serwera-freeradius/</link>
      <pubDate>Tue, 13 Oct 2015 19:31:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/baza-danych-uzytkownikow-serwera-freeradius/</guid>
      <description>&lt;p&gt;Poprzedni wpis był o sieciach bezprzewodowych, a konkretnie dotyczył on &lt;a href=&#34;https://morfikov.github.io
/post/wpa2-enterprise-serwer-freeradius/&#34;&gt;konfiguracji protokołu WPA
Enterprise w oparciu o serwer
freeradius&lt;/a&gt;. Ten post będzie w podobnym
klimacie, z tym, że skupimy się tutaj na nieco innym podejściu to kwestii użytkowników, którzy mogą
się łączyć do sieci WiFi. Ich konfiguracja nie zostanie praktycznie w żaden sposób ruszona, no może
za wyjątkiem &lt;a href=&#34;http://wiki.freeradius.org/guide/SQL-HOWTO&#34;&gt;przeniesienia jej do bazy danych MySQL&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WPA/WPA2 Enterprise i serwer freeradius</title>
      <link>https://morfikov.github.io/post/wpa2-enterprise-serwer-freeradius/</link>
      <pubDate>Tue, 13 Oct 2015 18:42:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wpa2-enterprise-serwer-freeradius/</guid>
      <description>&lt;p&gt;Poniższy wpis ma na celu stworzenie infrastruktury WiFi w oparciu o oprogramowanie freeradius
zainstalowane na debianowym serwerze. Projekt zakłada wykorzystanie osobnego urządzenia NAS (AP), w
tym przypadku jest to router &lt;a href=&#34;http://wiki.openwrt.org/toh/tp-link/tl-wr1043nd&#34;&gt;TP-Link TL-WR1043N/ND
v2&lt;/a&gt;, na którym jest zainstalowane oprogramowanie
OpenWRT. W oparciu o te dwie maszyny spróbujemy skonfigurować protokół WPA2 Enterprise z obsługą
trzech metod uwierzytelniania, tj. EAP-TLS, EAP-TTLS oraz PEAP (v0) . Będziemy również potrzebować
kilku certyfikatów (w tym CA), bez których to pewne mechanizmy mogą nie działać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Generowanie certyfikatów przy pomocy easy-rsa</title>
      <link>https://morfikov.github.io/post/generowanie-certyfikatow-przy-pomocy-easy-rsa/</link>
      <pubDate>Thu, 08 Oct 2015 14:29:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/generowanie-certyfikatow-przy-pomocy-easy-rsa/</guid>
      <description>&lt;p&gt;Jakiś czas temu przedstawiłem &lt;a href=&#34;https://morfikov.github.io
/post/generowanie-certyfikatow/&#34;&gt;manualny sposób na generowanie
certyfikatów&lt;/a&gt;, które można z powodzeniem
wykorzystać przy ssl, openvpn czy freeradius. Nie było tego znowu aż tak dużo ale jakby nie patrzeć
trochę parametrów trzeba znać, a najlepiej mieć przygotowane odpowiednie linijki, by sam proces
generowania certyfikatów przebiegł dość sprawnie. Jednak wychodzi na to, że nie trzeba się znowu aż
tak wysilać, bo istnieją dedykowane narzędzia, które wygenerują nam wszystkie potrzebne pliki. Mowa
o &lt;code&gt;easy-rsa&lt;/code&gt; i to niego będzie dotyczył ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zaszyfrowane logi w rsyslog i syslog-ng</title>
      <link>https://morfikov.github.io/post/zaszyfrowane-logi-w-rsyslog-i-syslog-ng/</link>
      <pubDate>Thu, 08 Oct 2015 13:53:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zaszyfrowane-logi-w-rsyslog-i-syslog-ng/</guid>
      <description>&lt;p&gt;Jakiś czas temu, na forum DUG&#39;a wyczytałem coś o przesyłaniu logów systemowych przez sieć. W sumie,
to nigdy mi to do głowy nie przyszło ale jeśli by się nad tym głębiej zastanowić, tego typu
mechanizm może okazać się całkiem użyteczny. Na dobrą sprawę nie wiem jak to jest rozwiązane w
debianie opartym o systemd, natomiast jeśli chodzi o inne init&#39;y (openrc i sysvinit), to tego typu
funkcjonalność można zaimplementować wykorzystując narzędzie &lt;code&gt;rsyslog&lt;/code&gt; lub &lt;code&gt;syslog-ng&lt;/code&gt; . W tym
wpisie zostanie opisana konfiguracja debianowego serwera, na którym będzie nasłuchiwał daemon
&lt;code&gt;rsyslog&lt;/code&gt; . Dodatkowo, zostanie przedstawiona konfiguracja dwóch klientów, z których jeden będzie
miał zainstalowanego &lt;code&gt;syslog-ng&lt;/code&gt; , a drugi &lt;code&gt;rsyslog&lt;/code&gt; . Z klientów logi zostaną przesłane do serwera.
Dodatkowo, postaramy się &lt;a href=&#34;http://www.rsyslog.com/doc/v8-stable/tutorials/tls_cert_summary.html&#34;&gt;zaszyfrować ruch przy pomocy kanału
TLS&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aktualizacja systemu i logowanie komunikatów</title>
      <link>https://morfikov.github.io/post/aktualizacja-systemu-logowanie-komunikatow/</link>
      <pubDate>Thu, 08 Oct 2015 12:39:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aktualizacja-systemu-logowanie-komunikatow/</guid>
      <description>&lt;p&gt;Aktualizacja systemu to chyba jedna z bardziej podstawowych czynności, które przeprowadzamy niemalże
codziennie. Tak się złożyło, że chwilę po zakończeniu tego procesu musiałem wyłączyć w pośpiechu
komputer. Nie zdążyłem przy tym przeczytać uważnie informacji, które zwrócił mi terminal. Oczywiście
mógłbym zahibernować maszynę i wrócić do logu instalacji w wolnej chwili ale nie zawsze hibernacja
jest możliwa. Poza tym, na myśl przychodzą mi osoby, które często zakładają wątki na forach o tym,
że aktualizacja uwaliła ich system. Zawsze w takiej sytuacji prosi się danego człowieka o podanie
logu z aktualizacji systemu albo przynajmniej próbuje się wyciągnąć od takiego delikwenta informację
na temat tego co było aktualizowane. W większości przypadków, taki człowiek nie ma o tym kompletnie
pojęcia, a jak już, to podaje bardzo nieprecyzyjne dane. Ten post ma na celu ułatwienie znalezienia
informacji o tym co było przedmiotem aktualizacji, tak by mieć nieco jaśniejszy obraz tego co mogło
nawalić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tworzenie repozytorium przy pomocy reprepro</title>
      <link>https://morfikov.github.io/post/tworzenie-repozytorium-przy-pomocy-reprepro/</link>
      <pubDate>Wed, 07 Oct 2015 17:37:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/tworzenie-repozytorium-przy-pomocy-reprepro/</guid>
      <description>&lt;p&gt;Ten kto tworzył kiedyś paczki &lt;code&gt;.deb&lt;/code&gt; wie, że cały proces może w końcu człowieka nieco przytłoczyć.
Paczka, jak to paczka, budowana jest ze źródeł i konfigurowana przez jej opiekuna. Z reguły ludzie
instalują kompilowane programy via &lt;code&gt;make install&lt;/code&gt; . Niektórzy idą o krok dalej i używają do tego
celu narzędzi typu &lt;code&gt;checkinstall&lt;/code&gt; . I wszystko jest w miarę w porządku, przynajmniej jeśli chodzi o
utrzymywanie jednej paczki. Przeprowadzamy kompilację tylko raz, po czym instalujemy dany pakiet i
zapominamy o nim. Niemniej jednak, tego typu postępowanie może doprowadzić nasz system na skraj
niestabilności. W tym poście nie będziemy zajmować się zbytnio sposobem w jaki powinno się tworzyć
paczki &lt;code&gt;.deb&lt;/code&gt; , a jedynie tym jak je przechowywać. Do tego celu potrzebne jest nam repozytorium,
które zbudujemy w oparciu o oprogramowanie &lt;code&gt;reprepro&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Parametr readahead w dyskach twardych</title>
      <link>https://morfikov.github.io/post/parametr-readahead-w-dyskach-twardych/</link>
      <pubDate>Wed, 07 Oct 2015 15:45:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/parametr-readahead-w-dyskach-twardych/</guid>
      <description>&lt;p&gt;W celu optymalizacji swojej pracy i poprawy wydajności przy transferze danych, dyski twarde często
odczytują więcej sektorów niż było to określone w żądaniu. Chodzi o to, że odczytywany przez nas z
dysku plik jest podzielony na sektory i gdy dysk odczytuje pierwszy sektor tego pliku, to wczytuje
także kilka kolejnych sektorów zlokalizowanych za tym, którego żądanie odczytania zostało właśnie
zrealizowane. Te dodatkowe sektory trafiają do wewnętrznego cache dysku twardego, z którego mogą
zostać odczytane w późniejszym czasie, jeśli zajdzie taka potrzeba. Dostęp do danych w cache jest o
wiele szybszy w porównaniu do repozycjonownia głowicy i odczytywania fizycznych sektorów na dysku. W
efekcie czego mamy zwykle dość znaczny wzrost wydajności przy transferze danych. Ten mechanizm nosi
nazwę &lt;strong&gt;readahead&lt;/strong&gt; i w tym wpisie przyjrzymy mu się nieco bliżej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Parametr multcount w dyskach twardych</title>
      <link>https://morfikov.github.io/post/parametr-multcount-w-dyskach-twardych/</link>
      <pubDate>Tue, 06 Oct 2015 21:57:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/parametr-multcount-w-dyskach-twardych/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://manpages.ubuntu.com/manpages/xenial/pl/man8/hdparm.8.html&#34;&gt;W manualu hdparm&lt;/a&gt; możemy
przeczytać o opcji &lt;code&gt;-m&lt;/code&gt; , która szerzej jest znana jako &lt;strong&gt;multcount&lt;/strong&gt;. Obecnie praktycznie każdy
dysk w większym lub mniejszym stopniu ma zaimplementowaną jej obsługę, tj. wartość tego parametru
różni się i zwykle im większą, tym lepiej dysk powinien się sprawować. Nie wszystkie dyski mają tę
opcję włączoną standardowo. Na przykład te z rodziny WDC, jak czytamy w dokumentacji, są znane z
tego, że działają wolniej po jej ustawieniu. Jako, że mam dysk firmy Western Digital, to
postanowiłem sprawdzić jak, o ile w ogóle, zmieni się wydajność takiego urządzenia po przestawieniu
tego parametru.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Karta dźwiękowa w trybie powersave</title>
      <link>https://morfikov.github.io/post/karta-dzwiekowa-w-trybie-powersave/</link>
      <pubDate>Tue, 06 Oct 2015 10:47:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/karta-dzwiekowa-w-trybie-powersave/</guid>
      <description>&lt;p&gt;Kilka dni temu, &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?pid=291349&#34;&gt;na forum DUG&#39;a&lt;/a&gt;, jeden z
użytkowników miał problem z dźwiękiem. Udało się tę niedogodność wprawdzie poprawić ale został tam
poruszony temat trybu powersave, czyli oszczędzania energii, jaki może posiadać karta dźwiękowa. Na
dobrą sprawę, nigdy mi nawet do głowy nie przyszło, by te karty mogły przełączać sobie stan i zjadać
mniej prądu, tak jak to robią, np. karty WiFi. Oczywiście, postanowiłem zgłębić to zagadnienie i
ustalić na ile przydatna jest ta funkcja i czy da radę bez problemów słuchać muzyki lub oglądać
filmy po jej aktywowaniu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Generowanie certyfikatów</title>
      <link>https://morfikov.github.io/post/generowanie-certyfikatow/</link>
      <pubDate>Sun, 04 Oct 2015 18:11:50 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/generowanie-certyfikatow/</guid>
      <description>&lt;p&gt;Certyfikaty mogą zostać wykorzystane wszędzie tam, gdzie mamy do czynienia z protokołami
szyfrującymi ruch. Zwykle są to serwisy hostujące strony www ale też mogą to być i inne usługi, np.
OpenVPN. Można je także spotkać w sieciach bezprzewodowych gdzie wykorzystywany jest protokół
WPA2-Enterprise. Jeśli operujemy na linux&#39;ie, to prawdopodobnie spotkaliśmy się już z
oprogramowaniem, które wykorzystuje certyfikaty, np. serwer &lt;code&gt;apache2&lt;/code&gt; . Dobrze jest sobie zatem
przyswoić wiedzę na temat generowania certyfikatów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wyłączenie WOL w karcie sieciowej</title>
      <link>https://morfikov.github.io/post/wylaczenie-wol-w-karcie-sieciowej/</link>
      <pubDate>Sun, 04 Oct 2015 16:36:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wylaczenie-wol-w-karcie-sieciowej/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Wake_on_LAN&#34;&gt;WOL&lt;/a&gt; (Wake On LAN) to taki ficzer, który umożliwia
włączenie komputera przez sieć. By tego typu sytuacja miała miejsce, zarówno karta sieciowa oraz
płyta główna komputera musi wspierać WOL. Dodatkowo, BIOS maszyny musi mieć aktywowaną odpowiednią
opcję. Obecnie WOL jest implementowany praktycznie w każdej płycie głównej i karcie sieciowej, także
raczej możemy przyjąć, że nasz komputer może zostać wybudzony za pomocą kabla sieciowego. Stwarza to
oczywiście zagrożenie bezpieczeństwa ale poza tym, w grę wchodzi także większy pobór energii. Jeśli
nie korzystamy z WOL, to jest on dla nas zbędny i należałoby go wyłączyć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Normalizacja głośności w PulseAudio</title>
      <link>https://morfikov.github.io/post/normalizacja-glosnosci-w-pulseaudio/</link>
      <pubDate>Mon, 28 Sep 2015 16:13:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/normalizacja-glosnosci-w-pulseaudio/</guid>
      <description>&lt;p&gt;Każdy z nas spotkał się z sytuacją, gdzie dźwięki odtwarzane na naszych maszynach zmieniają swoje
natężenie w krótkich odstępach czasu, a my przy tym odczuwamy bardzo nieprzyjemne uczucie
dyskomfortu psychicznego. Tego typu efekt jest też bardzo często spotykany przy oglądaniu filmów,
gdzie zwykle muzyka jest sporo głośniejsza od samych dialogów, nie wspominając już o reklamach,
którymi filmy są przerywane. Innym przykładem mogą być mp3, gdzie jedna z nich jest grana zbyt
cicho, natomiast kolejna zbyt głośno. PulseAudio jest w stanie poradzić sobie z tego typu
problemami.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Użytkownik debian-sys-maint w MariaDB</title>
      <link>https://morfikov.github.io/post/uzytkownik-debian-sys-maint-w-mariadb/</link>
      <pubDate>Sun, 27 Sep 2015 15:10:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uzytkownik-debian-sys-maint-w-mariadb/</guid>
      <description>&lt;p&gt;Właśnie robiłem migrację z MySQL ma MariaDB na swoim debianie. Nie obyło się jednak bez problemów,
choć na dobrą sprawę serwer baz danych działał i na pierwszy rzut oka nic złego nie szło
zaobserwować. Dopiero po zajrzeniu w log okazało się, że są jakieś problemy z uprawnieniami, w
efekcie czego nie mogła być przeprowadzona akcja aktualizacji tabel.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Retransmisja i duplikaty pakietów w TCP</title>
      <link>https://morfikov.github.io/post/retransmisja-i-duplikaty-pakietow-w-tcp/</link>
      <pubDate>Wed, 23 Sep 2015 19:31:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/retransmisja-i-duplikaty-pakietow-w-tcp/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://pl.wikipedia.org/wiki/Retransmisja&#34;&gt;Retransmisja&lt;/a&gt; pakietu w przypadku sieci opartych na
protokołach TCP/IP nie jest niczym niezwykłym. Oczywiście, pozostaje kwestia samego realizowania
tego przedsięwzięcia ale generalnie rzecz biorąc, systemy linux&#39;owe mają szereg opcji w kernelu,
które możemy sobie dostosować konfigurując tym samym, to w jaki sposób nasz system reaguje na
zjawisko utraty pakietów podczas ich przesyłu między dwoma punktami sieciowymi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zawartość obrazu z modułami kernela (initrd)</title>
      <link>https://morfikov.github.io/post/zawartosc-obrazu-z-modulami-kernela-initrd/</link>
      <pubDate>Sun, 06 Sep 2015 12:45:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zawartosc-obrazu-z-modulami-kernela-initrd/</guid>
      <description>&lt;p&gt;Podczas instalowania jądra operacyjnego w jakiejś dystrybucji linux&#39;a, w katalogu &lt;code&gt;/boot/&lt;/code&gt; jest
tworzonych kilka plików. Mamy tam między innymi
&lt;a href=&#34;https://www.ibm.com/developerworks/linux/library/l-initrd/index.html&#34;&gt;initrd.img&lt;/a&gt; i jest to obraz
posiadający swój własny system plików, który jest ładowany do pamięci RAM w fazie boot (via
bootloader). W tym obrazie znajdują się moduły i narzędzia, przy pomocy których to główny system
plików naszego linux&#39;a może zostać zamontowany. Czasem jednak potrzebujemy zajrzeć wgłąb tego
obrazu, a to nie jest znowu taka prosta sprawa.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aplikowanie zmiennych sysctl przy pomocy udev&#39;a</title>
      <link>https://morfikov.github.io/post/aplikowanie-zmiennych-sysctl-przy-pomocy-udeva/</link>
      <pubDate>Sun, 06 Sep 2015 11:08:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aplikowanie-zmiennych-sysctl-przy-pomocy-udeva/</guid>
      <description>&lt;p&gt;Kernele linux&#39;owe mają dość sporo opcji, które możemy zmienić przy pomocy pliku &lt;code&gt;/etc/sysctl.conf&lt;/code&gt; .
Niby nic nadzwyczajnego ale co w przypadku tych zmiennych, które muszą być ustawione, z tym, że
moduł, który stworzy odpowiednie ścieżki w katalogu &lt;code&gt;/proc/sys/&lt;/code&gt; , nie został załadowany z jakichś
względów przy starcie systemu? Zmienne te nie zostaną ustawione, a w logu pojawi się komunikat
informujący nas o nieodnalezieniu określonego pliku. Okazuje się, że jesteśmy w stanie aplikować
określone ustawienia sysctl w momencie ładowania określonych modułów i temu mechanizmowi się
przyjrzymy bliżej w tym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Moduł ssl w Apache2</title>
      <link>https://morfikov.github.io/post/modul-ssl-w-apache/</link>
      <pubDate>Sat, 05 Sep 2015 18:10:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-ssl-w-apache/</guid>
      <description>&lt;p&gt;Przy okazji uszczelniania serwera Apache2, przypomniał mi się &lt;a href=&#34;https://morfikov.github.io
/post/logjam-czyli-nowa-podatnosc-w-ssltls/&#34;&gt;atak
logjam&lt;/a&gt; , przez który to było niemałe
zamieszanie. Pamiętam, że w tamtym czasie próbowałem zabezpieczyć swój serwer testowy, by był na tę
formę ataku odporny. Niemniej jednak, wersja Apache2, która w tamtym czasie była u mnie
zainstalowana, nie do końca dawała taką możliwość. Dziś podszedłem do tej kwestii jeszcze raz i w
oparciu &lt;a href=&#34;https://weakdh.org/sysadmin.html&#34;&gt;o ten link&lt;/a&gt; udało mi się poprawnie skonfigurować mój
serwer www.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migracja certyfikatów OpenSSL z SHA-1</title>
      <link>https://morfikov.github.io/post/migracja-certyfikatow-openssl-z-sha-1/</link>
      <pubDate>Sat, 05 Sep 2015 17:15:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/migracja-certyfikatow-openssl-z-sha-1/</guid>
      <description>&lt;p&gt;Szukając co by tutaj jeszcze poprawić w moim środowisku testowym, w którym działa między innymi
apache, natrafiłem na komunikat w firefoxie, który oznajmił mi, że certyfikat mojego serwera
korzysta z przestarzałego już algorytmu mieszającego (hash). W tym przypadku jest to SHA-1. &lt;a href=&#34;https://blog.mozilla.org/security/2014/09/23/phasing-out-certificates-with-sha-1-based-signature-algorithms/&#34;&gt;Jak
można przeczytać na blogu
mozilli&lt;/a&gt;,
algorytm SHA-1 wypadł z łask jakiś czas temu i obecnie nie zaleca się jego używania ze względów
bezpieczeństwa. Postanowiłem zatem poprawić tę lukę.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AppArmor i profilowanie aplikacji</title>
      <link>https://morfikov.github.io/post/apparmor-profilowanie-aplikacji/</link>
      <pubDate>Sat, 08 Aug 2015 23:33:59 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/apparmor-profilowanie-aplikacji/</guid>
      <description>&lt;p&gt;Po ostatnich doniesieniach na temat &lt;a href=&#34;https://blog.mozilla.org/security/2015/08/06/firefox-exploit-found-in-the-wild/&#34;&gt;błędu jaki został znaleziony w
Firefox&#39;ie&lt;/a&gt; ,
doszedłem do wniosku, że najwyższy czas nauczyć się obsługi narzędzia &lt;code&gt;AppArmor&lt;/code&gt; . Ma ono pomóc w
kontrolowaniu praw dostępu do zasobów systemu operacyjnego, np. plików, katalogów czy określonych
urządzeń. Jeśli weźmiemy przytoczony wyżej błąd, to przeglądarka bez takiego profilu AppArmor&#39;a była
w stanie przeszukać lokalne pliki i wysłać je gdzieś na net, co powodowałoby udostępnienie poufnych
danych, np. historia poleceń shell&#39;owych, czy klucze prywatne.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fontconfig i konfiguracja czcionek w Debianie</title>
      <link>https://morfikov.github.io/post/fontconfig-i-konfiguracja-czcionek-w-debianie/</link>
      <pubDate>Wed, 05 Aug 2015 17:10:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/fontconfig-i-konfiguracja-czcionek-w-debianie/</guid>
      <description>&lt;p&gt;Od zawsze podobały mi się czcionki windosowskie ale po przejściu na linux&#39;a okazało się, że tutaj
fonty wyglądają zupełnie inaczej i co mogło zdziwić, nie było w standardzie tych moich ulubionych,
tj. Arial, Times New Roman i Courier New. Przez szereg lat miałem obecną w systemie dość dziwną
konfigurację dla fontconfig&#39;a, która działała na takiej zasadzie, że te czcionki aplikacji były w
prządku, natomiast te pobierane z serwisów www (np. w Firefox&#39;ie) dość słabo się renderowały i bez
przeprowadzania kilku zabiegów były one zwyczajnie nieczytelne. Postanowiłem w końcu poczytać trochę
dokumentacji na temat tego jak wygląda konfiguracja czcionek w debianie i po kilku dniach udało mi
się osiągnąć dość zadowalające efekty wizualne.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Polskie znaki pod TTY</title>
      <link>https://morfikov.github.io/post/polskie-znaki-pod-tty/</link>
      <pubDate>Wed, 15 Jul 2015 18:16:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/polskie-znaki-pod-tty/</guid>
      <description>&lt;p&gt;Jeśli w środowisku graficznym mamy ustawiony &lt;a href=&#34;https://morfikov.github.io
/post/jezyk-polski-w-srodowisku-graficznym/&#34;&gt;polski
język&lt;/a&gt;, nie mamy przy tym problemów z
kodowaniem znaków w tekście i nasza klawiatura ma ustawiony odpowiedni &lt;a href=&#34;https://morfikov.github.io
/post/klawiatura-i-jej-konfiguracja-pod-debianem/&#34;&gt;układ
klawiszy&lt;/a&gt; ale jednocześnie
doświadczamy problemów jeśli chodzi o polskie znaki pod TTY, oznacza to prawdopodobnie źle
skonfigurowany wirtualny terminal. Generalnie rzecz biorąc środowisko graficzne i konsola TTY, to
tak jakby dwa różne światy i trzeba je konfigurować w pewnych aspektach osobno.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Język polski w środowisku graficznym</title>
      <link>https://morfikov.github.io/post/jezyk-polski-w-srodowisku-graficznym/</link>
      <pubDate>Wed, 15 Jul 2015 17:29:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jezyk-polski-w-srodowisku-graficznym/</guid>
      <description>&lt;p&gt;Gdy mamy do dyspozycji panel administracyjny jednego ze środowisk graficznych, np. GNOME, zmiana
języka interfejsu aplikacji w systemie nie powinna przysporzyć problemów. Natomiast jeśli chodzi o
wszelkie inne środowiska oparte jedynie o menadżery okien, np. OPENBOX, lub też i te zupełnie nie
mające graficznej sesji, to przestawienie języka jest lekko utrudnione. Przede wszystkim, musimy
rozróżnić dwie kwestie. Jedną z nich jest język interfejsu i wszelkie wiadomości, które wypisuje nam
system, np. na terminalu. A drugą są &lt;a href=&#34;https://morfikov.github.io
/post/klawiatura-i-jej-konfiguracja-pod-debianem/&#34;&gt;polskie
znaki&lt;/a&gt;, które możemy wpisywać
przy pomocy klawiatury. Te dwie rzeczy są ze sobą niepowiązane w żaden sposób, tj. można mieć polski
układ klawiszy i jednocześnie korzystać z angielskiej wersji systemu operacyjnego linux i vice
versa. Choć automaty środowisk graficznych synchronizują te dwa elementy, co wydaje się być raczej
zrozumiałe.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klawiatura i jej konfiguracja pod debianem</title>
      <link>https://morfikov.github.io/post/klawiatura-i-jej-konfiguracja-pod-debianem/</link>
      <pubDate>Wed, 15 Jul 2015 01:21:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/klawiatura-i-jej-konfiguracja-pod-debianem/</guid>
      <description>&lt;p&gt;W środowiskach graficznych, np. GNOME czy KDE, nie musimy zbytnio się zastanawiać nad tym jak
skonfigurować klawiaturę, bo wszystko możemy sobie szybko i w prosty sposób wyklikać z graficznego
panelu administracyjnego systemu. Natomiast jeśli korzystamy jedynie z odchudzonych instalacji
linux&#39;a zawierających jedynie jakiś menadżer okien, np. OPENBOX, to sami musimy zadbać o
skonfigurowanie klawiatury, tak by układ się zgadzał, by były dostępne polskie znaki, no i
oczywiście by system potrafił rozpoznać ewentualne &lt;a href=&#34;https://morfikov.github.io
/post/klawiatura-multimedialna-i-niedzialajace-klawisze/&#34;&gt;klawisze
multimedialne&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Interwał pakietów Beacon w sieciach WiFi</title>
      <link>https://morfikov.github.io/post/interwal-pakietow-beacon-w-sieciach-wifi/</link>
      <pubDate>Mon, 13 Jul 2015 18:12:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/interwal-pakietow-beacon-w-sieciach-wifi/</guid>
      <description>&lt;p&gt;Przerabiając analizę pakietów sieciowych, dotarłem w końcu do sieci bezprzewodowych, a te różnią się
nieco od tych swoich przewodowych kuzynów. Generalnie rzecz biorąc nie będę tutaj opisywał samej
analizy pakietów, które sobie przemierzają eter w pobliżu naszych urządzeń WiFi, a jedynie poruszę
kwestię pakietów Beacon, które są rozsyłane przez punkty dostępowe w pewnych odstępach czasu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kompaktowanie katalogów w systemie plików ext4</title>
      <link>https://morfikov.github.io/post/kompaktowanie-katalogow-w-systemie-plikow-ext4/</link>
      <pubDate>Sat, 11 Jul 2015 13:39:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kompaktowanie-katalogow-w-systemie-plikow-ext4/</guid>
      <description>&lt;p&gt;Jakiś czas temu pewien człowiek &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=27485&#34;&gt;miał dziwaczny
problem&lt;/a&gt;. Jak możemy wyczytać w przytoczonym linku,
system tego użytkownika lekko mówiąc nie zachowywał się tak jak powinien. Objawiało się to przez
dość ekstensywne wykorzystywanie pamięci operacyjnej RAM przy zwykłym listowaniu plików via &lt;code&gt;ls&lt;/code&gt; w
pewnych określonych katalogach. Struktura systemu plików zdaje się być porządku, bo program &lt;code&gt;fsck&lt;/code&gt;
nie zwraca żadnych błędów. Zatem w czym problem?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klawisz Backspace w Firefox&#39;ie</title>
      <link>https://morfikov.github.io/post/klawisz-backspace-w-firefoxie/</link>
      <pubDate>Sat, 11 Jul 2015 10:12:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/klawisz-backspace-w-firefoxie/</guid>
      <description>&lt;p&gt;Przez cały czas korzystania z internetu, robiłem to za pomocą przeglądarki Opera. Nawet po tym jak
przeszedłem na linuxa, to wciąż nie mogłem się z nią rozstać i to pomimo faktu, że nie była ona
przecież opensource, przez co nie była także dostępna w repozytoriach debiana. Gdy deweloperzy z
zespołu Opery przestali rozwijać tę przeglądarkę dla linuxa, musiałem poszukać sobie czegoś innego.
Wybór padł na Firefox&#39;a ale każdy kto używał tych dwóch przeglądarek wie, że różniły się one dość
znacznie parę lat temu i jedną z tych bardziej odczuwalnych różnic była inna obsługa klawisza
Backspace .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Opcja extents w systemach plików ext4</title>
      <link>https://morfikov.github.io/post/opcja-extents-w-systemach-plikow-ext4/</link>
      <pubDate>Fri, 10 Jul 2015 15:20:44 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/opcja-extents-w-systemach-plikow-ext4/</guid>
      <description>&lt;p&gt;Dziś postanowiłem sprawdzić jak wygląda struktura plików mojego dysku. Chodzi oczywiście o ich
fragmentację. Zgodnie z tym co pokazał mi &lt;code&gt;fsck&lt;/code&gt; , pofragmentowanych plików jest 350. Po
zapuszczeniu defragmentacji via &lt;code&gt;e4defrag&lt;/code&gt; ilość tych plików spadła do nieco ponad 100 i jeśli by
się przyjrzeć procesowi defragmentacji, to można było zauważyć linijki mające &lt;code&gt;extents: 100 -&amp;gt; 10&lt;/code&gt;
. Wychodzi na to, że plik dalej jest w kawałkach i nie idzie go zdefragmentować. Jak rozumieć taki
zapis?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Parkowanie głowicy w dyskach Wstern Digital</title>
      <link>https://morfikov.github.io/post/parkowanie-glowicy-w-dyskach-wstern-digital/</link>
      <pubDate>Wed, 08 Jul 2015 20:28:44 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/parkowanie-glowicy-w-dyskach-wstern-digital/</guid>
      <description>&lt;p&gt;Dyski zużywają się z różnych powodów. Jednak najczęstszą przyczyną są nowe wynalazki, które
producent w nich implementuje, bo te niezbyt dobrze działają w określonych warunkach, czy też pod
kontrolą pewnych systemów operacyjnych. Tak właśnie jest w przypadku nowszych dysków firmy Western
Digital (WD). Maja one wprowadzony ficzer parkowania głowicy w przypadku, gdy dysk &lt;a href=&#34;http://wdc.custhelp.com/app/answers/detail/a_id/5357&#34;&gt;jest
nieużywany&lt;/a&gt;. Ma to na celu zmniejszyć pobór
prądu i, co za tym idzie, temperaturę urządzenia. Jako, że parkowanie głowicy w dyskach WD nie
działa poprawnie pod moim linux&#39;em (dystrybucja Debian), to nasuwa się pytanie: jak wyłączyć
parkowanie głowicy by wydłużyć żywotność dysku twardego?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wolny start połączeń w protokole TCP</title>
      <link>https://morfikov.github.io/post/wolny-start-polaczen-w-protokole-tcp/</link>
      <pubDate>Tue, 07 Jul 2015 19:33:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wolny-start-polaczen-w-protokole-tcp/</guid>
      <description>&lt;p&gt;Wolny start jest wynikiem braku zaufania maszyny nadawczej do utworzonego kanału przesyłowego --
połączenia. Nie wie ona czy to łącze jest bowiem w stanie obsłużyć taką porcję danych, którą ma
zamiar przesłać bez czekania na pakiet &lt;code&gt;ACK&lt;/code&gt; . W przypadku bufora odbiorczego, wszystko jest proste,
bo dane dotyczące wielkości okien są zdefiniowane w nagłówku pakietów, do których ma wgląd druga ze
stron. W przypadku gdy nadawca przesyła dane, prędkość z jaką to robi zależy głównie od niego.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bufor połączeń w protokole TCP</title>
      <link>https://morfikov.github.io/post/bufor-polaczen-w-protokole-tcp/</link>
      <pubDate>Wed, 01 Jul 2015 10:20:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/bufor-polaczen-w-protokole-tcp/</guid>
      <description>&lt;p&gt;Wraz ze zwiększaniem zapotrzebowania na szybsze łącza internetowe, ograniczenia wynikające z
protokółu TCP zaczęły powoli dawać się ludziom we znaki. Problemem była bariera prędkości, którą
ciężko było pokonać mając do dyspozycji domyślną formę nagłówka protokołu TCP. Było w nim zwyczajnie
za mało miejsca, co zapoczątkowało jego rozbudowę kosztem ilości danych, które można było przesłać w
pojedynczym segmencie. W tym wpisie skupię się głównie na dwóch opcjach jakie zostały dodane do
nagłówka TCP, tj. dynamiczne skalowanie okien oraz znaczniki czasu, bo te dwa parametry nie mogą
wręcz bez siebie istnieć, zwłaszcza gdy rozmawiamy o łączach pokroju 1 czy 10 gbit/s.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SACK, czyli selektywne potwierdzenia pakietów</title>
      <link>https://morfikov.github.io/post/sack-czyli-selektywne-potwierdzenia-pakietow/</link>
      <pubDate>Wed, 01 Jul 2015 06:04:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sack-czyli-selektywne-potwierdzenia-pakietow/</guid>
      <description>&lt;p&gt;Protokół TCP jest tak zbudowany by zapewnić rzetelny transfer danych między dwoma komunikującymi się
punktami. Z początku jednak, ta cecha tego protokołu powodowała marnowanie dość sporych ilości
zasobów jeśli chodzi o przepustowość łącza. Stało się to widoczne przy większych prędkościach
połączeń, gdzie &lt;a href=&#34;https://morfikov.github.io
/post/bufor-polaczen-w-protokole-tcp/&#34;&gt;skalowany był bufor&lt;/a&gt;
(okno) TCP, co umożliwiło przesyłanie szeregu segmentów bez potrzeby czekania na ich potwierdzenie
przez odbiorcę. To zwiększyło, co prawda, transfer danych ale pojawił się problem z zagubionymi
pakietami.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TSO, czyli odciążenie segmentacji TCP</title>
      <link>https://morfikov.github.io/post/tso-czyli-odciazenie-segmentacji-tcp/</link>
      <pubDate>Tue, 30 Jun 2015 21:15:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/tso-czyli-odciazenie-segmentacji-tcp/</guid>
      <description>&lt;p&gt;Stawiając sobie środowisko testowe pod wireshark&#39;a w celu analizy pakietów sieciowych, zauważyłem,
że coś mi się nie zgadza odnośnie wielkości przesyłanych pakietów między interfejsami kontenerów
LXC. Jakby nie patrzeć, środowisko testowe ma być odwzorowaniem środowiska produkcyjnego i w tym
przypadku wszelkie zasady dotyczące, np. podziału danych na segmenty, muszą być takie same.
Generalnie rzecz biorąc rozmiar pakietu powinien wynosić 1514 bajtów, a był parokrotnie większy.
Okazało się, że jest to za sprawą odciążenia segmentacji w protokole TCP (&lt;a href=&#34;https://lwn.net/Articles/564978/&#34;&gt;TCP Segmentation
Offload&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przeszukiwanie zawartości pakietów (apt-file)</title>
      <link>https://morfikov.github.io/post/przeszukiwanie-zawartosci-pakietow-apt-file/</link>
      <pubDate>Tue, 30 Jun 2015 12:03:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przeszukiwanie-zawartosci-pakietow-apt-file/</guid>
      <description>&lt;p&gt;Podczas procesu kompilacji pakietów często zdarza się tak, że brakuje jakichś zależności, bez
których dany pakietów nie chce się nam zbudować. W większości przypadków, system powinien nam
podpowiedzieć jaki pakiet powinniśmy doinstalować. Nie zawsze jednak będzie to takie oczywiste i
jedyne co nam zostanie zwrócone, to ścieżka danego pliku lub tylko jego nazwa. Nawet jeśli nie
kompilujemy programów, to podczas zwykłego użytkowania komputera możemy potrzebować odnaleźć pakiet,
który zawiera pewien określony plik binarny czy konfiguracyjny. Jak zatem odnaleźć się w gąszczu
plików i katalogów by efektywnie ustalić pakiet, który zawiera interesujące nas pliki?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fragmentacja pakietu i zmiana wartości MTU</title>
      <link>https://morfikov.github.io/post/fragmentacja-pakietu-i-zmiana-wartosci-mtu/</link>
      <pubDate>Mon, 29 Jun 2015 21:35:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/fragmentacja-pakietu-i-zmiana-wartosci-mtu/</guid>
      <description>&lt;p&gt;MTU (Maximum Transmission Unit) to maksymalna długość pakietu jaki może zostać przesłany przez sieć.
Może ona wynosić do 64KiB ale większość punktów sieciowych, takich jak routery, wymusza o wiele
mniejsze rozmiary pakietów. Domyślna wartość MTU dla protokołu Ethernet to 1500 bajtów, oczywiście
bez nagłówka warstwy fizycznej, który ma dodatkowe 14 bajtów. Czasami te standardowe ustawienia mogą
powodować problemy w przypadku pewnych konfiguracji sieci i gdy ich doświadczamy, przydałoby się
zmienić rozmiar MTU przesyłanych pakietów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Znacznik czasu (timestamp) w protokole TCP</title>
      <link>https://morfikov.github.io/post/znacznik-czasu-timestamp-w-protokole-tcp/</link>
      <pubDate>Sun, 28 Jun 2015 17:33:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/znacznik-czasu-timestamp-w-protokole-tcp/</guid>
      <description>&lt;p&gt;O znacznikach czasu (timestamp) wspominałem już raz w ramach omawiania mechanizmu jakim jest &lt;a href=&#34;https://morfikov.github.io
/post/bufor-polaczen-w-protokole-tcp/&#34;&gt;bufor
połączenia&lt;/a&gt;, a konkretnie rozchodziło się o
skalowanie okien TCP. Generalnie rzecz biorąc, przy wyższych prędkościach, rzędu 1 gbit/s, nie ma
innej opcji jak skorzystanie z opcji znaczników czasu, które są niejako rozszerzeniem czegoś co
widnieje pod nazwą &lt;a href=&#34;https://morfikov.github.io
/post/numery-sekwencyjne-w-strumieniu-tcp/&#34;&gt;numery sekwencyjne&lt;/a&gt;
. Z jednej strony może i mamy możliwość implementacji łącz o większej przepustowości ale z drugiej
te znaczniki czasu w pakietach TCP &lt;a href=&#34;https://nfsec.pl/security/2306&#34;&gt;mogą zagrozić bezpieczeństwu&lt;/a&gt;
stacji roboczej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Numery sekwencyjne w strumieniu TCP</title>
      <link>https://morfikov.github.io/post/numery-sekwencyjne-w-strumieniu-tcp/</link>
      <pubDate>Thu, 25 Jun 2015 21:24:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/numery-sekwencyjne-w-strumieniu-tcp/</guid>
      <description>&lt;p&gt;Jeśli zastanawialiście się czym są numery sekwencyjne i potwierdzeń w strumieniach protokołu TCP, to
nie jesteście jedyni, którym to zagadnienie spędza sen z powiek. Dlatego też poniżej postanowiłem
opisać najdokładniej jak umiem proces jaki zachodzi przy przesyłaniu danych z jednego punktu
sieciowego na drugi. Bez zaprzęgnięcia sniffera sieciowego raczej nie da się zrozumieć tego tematu i
poniższy przykład zawiera szereg odwołań do programu wireshark.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Flagi TCP i przełączanie stanów połączeń</title>
      <link>https://morfikov.github.io/post/flagi-tcp-i-przelaczanie-stanow-polaczen/</link>
      <pubDate>Wed, 24 Jun 2015 21:44:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/flagi-tcp-i-przelaczanie-stanow-polaczen/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/firewall-na-linuxowe-maszyny-klienckie/&#34;&gt;jak zaprojektować swój własny
firewall&lt;/a&gt;, wobec czego postanowiłem
nieco bardziej pochylić się nad zagadnieniem stanów połączeń i je dokładniej przeanalizować. Ten
wpis dotyczy głównie protokołu TCP, bo ten UDP jest bezpołączeniowy, więc nie ma tam żadnych stanów.
Dodatkowo opiszę tutaj poszczególne flagi, które mogą zostać ustawione w pakietach zmieniając tym
samym stan połączenia.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czas życia pakietów, czyli zmiana TTL</title>
      <link>https://morfikov.github.io/post/czas-zycia-pakietow-czyli-zmiana-ttl/</link>
      <pubDate>Wed, 24 Jun 2015 17:50:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czas-zycia-pakietow-czyli-zmiana-ttl/</guid>
      <description>&lt;p&gt;Czasem niektórzy ISP z jakiegoś bliżej nieokreślonego powodu blokują dostęp do internetu hostom
zlokalizowanym za routerem czy innym komputerem udostępniającym połączenie sieciowe. ISP zwykle
stara się blokować konkretną wartość pola TTL, która jest ustawiana w każdym przesyłanym przez nasze
maszyny pakiecie. Innym sposobem zablokowania możliwości udostępniania internetu jest ograniczenie
wartości pola TTL do jednego hopa wszystkim pakietom dochodzącym do routera od strony ISP. Jeśli
mamy nieszczęście trafić na takiego providera, to warto wiedzieć, że przy pomocy iptables możemy
ustawić/podbić/zmniejszyć czas życia pakietów, które docierają do routera zarówno od strony LAN jak
i WAN i tym samym bez większego trudu możemy sobie poradzić z tą blokadą.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Udostępnianie połączenia internetowego</title>
      <link>https://morfikov.github.io/post/udostepnianie-polaczenia-internetowego/</link>
      <pubDate>Wed, 24 Jun 2015 13:57:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/udostepnianie-polaczenia-internetowego/</guid>
      <description>&lt;p&gt;Każdy z nas ma router w domu, który potrafi rozdzielić sygnał na szereg komputerów w naszej sieci
lokalnej. Jeśli z jakichś powodów nie chcemy posiadać w domu tego cuda techniki i chcielibyśmy mieć
możliwość udostępniania połączenia internetowego za pośrednictwem innego komputera, to nic nie stoi
nam na przeszkodzie by to zrobić. Taki komputer stacjonarny niczym się nie różni od routera, no może
za wyjątkiem poboru prądu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PeerGuardian w oparciu o ipset i iptables</title>
      <link>https://morfikov.github.io/post/peerguardian-w-oparciu-o-ipset-iptables/</link>
      <pubDate>Tue, 23 Jun 2015 22:50:14 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/peerguardian-w-oparciu-o-ipset-iptables/</guid>
      <description>&lt;p&gt;Wiele klientów torrenta umożliwia ładowanie zewnętrznej listy z zakresami adresów IP i ta lista ma
służyć jako swego rodzaju filtr połączeń chroniący nas przed różnego rodzaju organizacjami, które
mogą zbierać i przetwarzać informacje na temat naszego IP i tego co on porabia w sieci p2p.
Oczywiście, kwestia czy korzystać z takiego typu rozwiązania jest bardzo dyskusyjna i wiele osób
jest zdania, że to tak naprawdę w niczym nie pomoże, a wręcz nawet przyczynia się do
samounicestwienia sieci p2p. Także taki filter może czasem przynieść więcej szkody niż pożytku,
zwłaszcza gdy się go używa lekkomyślnie, czyli na zasadzie, że ten co blokuje więcej adresów musi
być lepszy. Poniżej opiszę wykorzystanie rozszerzenia &lt;code&gt;ipset&lt;/code&gt;, przy pomocy którego zostanie
zablokowany szereg klas adresów. Całość raczej nie skupia się na implementacji filtra, to tylko
przykład do czego &lt;code&gt;ipset&lt;/code&gt; może posłużyć, a że ja nie umiem teoretycznie pisać, to muszę na
przykładach.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Struktura plików urządzeń usb w katalogu /sys/</title>
      <link>https://morfikov.github.io/post/struktura-plikow-urzadzen-usb-w-katalogu-sys/</link>
      <pubDate>Tue, 23 Jun 2015 20:23:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/struktura-plikow-urzadzen-usb-w-katalogu-sys/</guid>
      <description>&lt;p&gt;Jeśli próbowaliśmy odnaleźć odpowiednią ścieżkę do urządzenia usb w linuxowym drzewie katalogów, to
wiemy, że nie jest to łatwe zadanie. Mamy, co prawda, do dyspozycji polecenie &lt;code&gt;lsusb&lt;/code&gt; ale ono nie
daje nam precyzyjnych informacji na temat tego gdzie dokładnie w katalogu &lt;code&gt;/sys/&lt;/code&gt; znajdują się
określone urządzenia. Na necie natrafiłem na &lt;a href=&#34;http://www.linux-usb.org/&#34;&gt;FAQ&lt;/a&gt; dotyczący tego
zagadnienia i postanowiłem napisać kilka zdań o tym jak zinterpretować ciągi typu &lt;code&gt;2-1.1.2:1.1&lt;/code&gt; oraz
jakie to może być urządzenie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Autosuspend i zasilanie portów usb</title>
      <link>https://morfikov.github.io/post/autosuspend-i-zasilanie-portow-usb/</link>
      <pubDate>Tue, 23 Jun 2015 15:34:50 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/autosuspend-i-zasilanie-portow-usb/</guid>
      <description>&lt;p&gt;Kernel w linuxie odcina zasilanie urządzeniom podpiętym do portów usb jeśli sterownik wspiera tego
typu możliwość oraz samo urządzenie nie jest używane przez pewien okres czasu. W taki oto sposób,
jeśli podłączymy, np. zewnętrzną klawiaturę usb do laptopa, możemy zaobserwować, że przy pisaniu
tekstu gubiony jest zwykle pierwszy znak. Może i klawiatura po przyciśnięciu klawisza wyszła ze
stanu bezczynności ale system nie zareagował na tyle szybko by złapać sygnał przycisku. Na necie
ludzie piszą, że jest to problem niekompatybilności urządzeń i tego typu sytuacja nie powinna się
zdarzać. Jeśli jednak natrafiliśmy na klawiaturę czy myszę, która cierpi z powodu automatycznego
zawieszania jej zasilania, możemy wyłączyć ten ficzer zupełnie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sterowniki do karty TP-LINK Archer T4U (8812au)</title>
      <link>https://morfikov.github.io/post/sterowniki-karty-tp-link-archer-t4u-8812au/</link>
      <pubDate>Tue, 23 Jun 2015 11:45:07 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sterowniki-karty-tp-link-archer-t4u-8812au/</guid>
      <description>&lt;p&gt;Póki co, w kernelu linux&#39;a (4.5) nie ma odpowiednich sterowników do &lt;a href=&#34;http://www.tp-link.com.pl/products/details/cat-11_Archer-T4U.html&#34;&gt;adaptera WiFi Archer
T4U&lt;/a&gt; i trzeba je sobie
skompilować ręcznie. Trochę to dziwne, bo przecie kod sterownika jest na licencji GPLv2 i dostępny
już szmat czasu na &lt;a href=&#34;https://github.com/abperiasamy/rtl8812AU_8821AU_linux&#34;&gt;github&#39;ie&lt;/a&gt;. W każdym
razie, jeśli zakupiliśmy w/w kartę i nie jest ona wykrywana po wsadzeniu jej do portu USB, to czeka
nas proces kompilacji modułu &lt;code&gt;8812au&lt;/code&gt; i jego automatyzacja przy pomocy &lt;a href=&#34;https://morfikov.github.io
/post/dkms-czyli-automatycznie-budowane-moduly/&#34;&gt;mechanizmu
DKMS&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tryb oszczędzania energii w kartach wifi</title>
      <link>https://morfikov.github.io/post/tryb-oszczedzania-energii-w-kartach-wifi/</link>
      <pubDate>Tue, 23 Jun 2015 10:25:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/tryb-oszczedzania-energii-w-kartach-wifi/</guid>
      <description>&lt;p&gt;Niektóre karty wifi znane są z tego, że niezbyt chcą one działać pod systemem operacyjnym linux. Nie
jest to wina samego sprzętu, ani tym bardziej linuxa, tylko raczej faktu, że producent nie potrafi
napisać pod ten OS odpowiednich sterowników. Czasem jednak pod względem programowym wszystko wydaje
się być w porządku, tj. sterowniki zostały zainstalowane, są one dobrej jakości i karta działa
praktycznie bez zarzutu. Niemniej jednak, strony www wydają się ładować jakoś tak ociężale, z pewnym
opóźnieniem. Jeśli doświadczyliśmy tego typu zachowania ze strony naszej karty wifi, prawdopodobnie
oznacza to, że ma ona włączony tryb oszczędzania energii (powersave).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Firewall na linux&#39;owe maszyny klienckie</title>
      <link>https://morfikov.github.io/post/firewall-na-linuxowe-maszyny-klienckie/</link>
      <pubDate>Mon, 22 Jun 2015 23:33:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/firewall-na-linuxowe-maszyny-klienckie/</guid>
      <description>&lt;p&gt;Prędzej czy później, każdy z nas będzie musiał zabezpieczyć dostęp do swojego komputera w sieci. Do
tego zadania na stacjach z linux&#39;em jest oddelegowane narzędzie &lt;code&gt;iptables&lt;/code&gt; wraz z szeregiem
dodatków, jak np. &lt;code&gt;ipset&lt;/code&gt; . By zbudować solidny firewall nie potrzeba zbytnio się wysilać. Niemniej
jednak, temat zapory linux&#39;owej jest &lt;a href=&#34;https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html&#34;&gt;bardzo
rozległy&lt;/a&gt; i nie będziemy tutaj
opisywać wszystkich możliwych scenariuszy jej zastosowania. Zamiast tego skupimy się jedynie na
bazowym skrypcie, który można rozbudować bez przeszkód i dostosować go zarówno pod maszyny klienckie
jak i te serwerowe.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ECryptfs jako alternatywa dla encfs</title>
      <link>https://morfikov.github.io/post/ecryptfs-jako-alternatywa-dla-encfs/</link>
      <pubDate>Mon, 22 Jun 2015 18:58:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ecryptfs-jako-alternatywa-dla-encfs/</guid>
      <description>&lt;p&gt;Dnia 2014-10-07 w Debianie była aktualizacja pakietu &lt;code&gt;encfs&lt;/code&gt; , która to zawierała informację na
temat &lt;a href=&#34;https://defuse.ca/audits/encfs.htm&#34;&gt;audytu bezpieczeństwa&lt;/a&gt; jaki się dokonał parę miesięcy wstecz. Wyniki niezbyt dobrze
wypadły, a nawet można powiedzieć, że wręcz katastrofalnie. Generalnie cały test został skwitowany
słowami, że jeśli szyfrujemy pliki przy pomocy tego narzędzia, to jesteśmy relatywnie bezpieczni,
nawet w przypadku jeśli ktoś te pliki przechwyci. Natomiast jeśli zaczniemy zmieniać/dodawać pliki
i ten ktoś ponownie przechwyci nasz zaszyfrowany katalog, wtedy może on bez problemu odszyfrować
całą jego zawartość. Jeśli wykorzystujemy &lt;code&gt;encfs&lt;/code&gt; lokalnie, to być może nam nic nie grozi, nawet w
przypadku raidu NSA na naszą chałupę. Problem w tym, że ogromna rzesza ludzi wykorzystuje &lt;code&gt;encfs&lt;/code&gt;
do zaszyfrowania plików w chmurze, np. na Dropbox&#39;ie czy MEGA, a jak wiadomo, przy każdej
synchronizacji, zmiany w danym katalogu są przesyłane do chmury i wszelkie zabezpieczenie jakie
daje &lt;code&gt;encfs&lt;/code&gt; diabli biorą. Może najwyższy czas zainteresować się &lt;code&gt;ecryptfs&lt;/code&gt;?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Riseup VPN na straży prywatności</title>
      <link>https://morfikov.github.io/post/riseup-vpn-na-strazy-prywatnosci/</link>
      <pubDate>Sun, 21 Jun 2015 17:05:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/riseup-vpn-na-strazy-prywatnosci/</guid>
      <description>&lt;p&gt;W dobie NSA, podsłuchów rządowych i wszelkiego rodzaju pogwałcenia prawa do prywatności, ludzie
wymyślili &lt;a href=&#34;https://pl.wikipedia.org/wiki/Virtual_Private_Network&#34;&gt;VPN&lt;/a&gt;. VPN to nic innego jak tunel
łączący dwie odległe od siebie maszyny, które chcą wymieniać ze sobą dane w sposób uniemożliwiający
osobom trzecim podejrzenie całej tej komunikacji. Zalety korzystania z takiego dobrodziejstwa natury
są oczywiste. Można obejść cenzorów, gdyż cały ruch z naszej maszyny jest przesyłany do serwera w
postaci szyfrowanej, a dopiero z tego serwera sygnał idzie dalej w świat. Jest wiele komercyjnych
usług, które za drobną opłatą mogą zapewnić nam tego tupu usługi ale ja nie będę tutaj się o nich
rozpisywał. Bez problemu można je znaleźć w góglu. My tutaj za to zajmiemy się VPN jaki zapewnia
&lt;a href=&#34;https://riseup.net/&#34;&gt;riseup&lt;/a&gt;. By móc korzystać z ich usług, trzeba założyć na ich stronie konto, a
to z kolei jest przyznawane tym, którzy w jakiś sposób działają na rzecz szeroko pojętej wolności.
Ja wysłałem zgłoszenie i konto zostało mi przyznane. Dlatego też opiszę jak wygląda konfiguracja VPN
na ich przykładzie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Szyfrowanie poczty przy pomocy enigmail</title>
      <link>https://morfikov.github.io/post/szyfrowanie-poczty-przy-pomocy-enigmail/</link>
      <pubDate>Sun, 21 Jun 2015 15:55:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/szyfrowanie-poczty-przy-pomocy-enigmail/</guid>
      <description>&lt;p&gt;Szyfrowanie wiadomości email można uznać za paranoiczne podejście do kwestii wymiany informacji, bo
zwykły człowiek mówi sobie: &amp;quot;ja przecie za pomocą poczty nie wysyłam nic ważnego, nawet swoich
nagich fotek, a nawet jeśli już, to są one od pasa w dół. Poza tym, gmail jest szyfrowany, bo używa
SSL/TLS&amp;quot;. SSL/TLS, co prawda, jest ale ogranicza się do szyfrowania tego co robimy na gmailu. Same
wiadomości natomiast są przesyłane między różnymi serwerami i niekoniecznie są szyfrowane. Poza tym
google kiedyś wspominał, że w przypadku gdy policja będzie żądała dostępu do naszej skrzynki
pocztowej, to nie dość, że on im to umożliwi, to jeszcze wyciągnie wszelkie maile jakie przez tę
skrzynkę zostały przepuszczone -- zarówno te odebrane jak i wysłane.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Błędy bootloadera grub</title>
      <link>https://morfikov.github.io/post/bledy-bootloadera-grub/</link>
      <pubDate>Sun, 21 Jun 2015 00:33:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/bledy-bootloadera-grub/</guid>
      <description>&lt;p&gt;Grub to najpopularniejszy bootloader w systemach linuxowych. Dorobił się tego miejsca na podium
głównie ze względu na swoją pełną automatyzację. Potrafi obsłużyć pokaźną ilości systemów plików,
no i również nie zostaje w tyle w stosunku do aktualnych standardów partycjonowania dysków -- mowa
oczywiście o tablicy partycji GPT. Przeglądając internet w poszukiwaniu odpowiedzi na temat jednego
z błędów jaki grub wyrzucił mi podczas startu systemu, znalazłem &lt;a href=&#34;http://www.uruk.org/orig-grub/errors.html&#34;&gt;ten oto
artykuł&lt;/a&gt;. Zawarte są tam dokładnie wszystkie możliwe
błędy jakie grub potrafi zwrócić wraz z krótkim wyjaśnieniem ich przyczyny. Postanowiłem sobie je
przejrzeć i dorobić do nich polskie tłumaczenie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Jakość miniaturek zdjęć</title>
      <link>https://morfikov.github.io/post/wordpress-jakosc-miniaturek-zdjec/</link>
      <pubDate>Fri, 19 Jun 2015 21:23:31 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-jakosc-miniaturek-zdjec/</guid>
      <description>&lt;p&gt;Przy umieszczaniu zdjęć czy też różnego rodzaju grafik na blogu, możemy zauważyć, że owe fotki nie
są umieszczane w postach w oryginalnych rozmiarach. Zamiast nich są &lt;a href=&#34;https://codex.wordpress.org/Post_Thumbnails&#34;&gt;używane
miniaturki&lt;/a&gt;, które mają konfigurowalny rozmiar.
Naturalnie możemy nakazać WordPressowi by umieszczał obrazki w pełnym ich wymiarze, choć jednak ze
względów estetycznych lepiej zachować określone ich rozmiary i jeśli jakaś grafika wychodzi po za
nie, to powinna zostać przycięta. Taka miniaturka powinna linkować do obrazka pełnowymiarowego,
gdzie można zobaczyć więcej szczegółów. Taki jest przynajmniej schemat tego działania w WordPressie.
Problem jest jednak z jakością samych miniaturek.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Udevil i montowanie zasobów bez uprawnień root</title>
      <link>https://morfikov.github.io/post/udevil-i-montowanie-zasobow-bez-uprawnien-root/</link>
      <pubDate>Fri, 19 Jun 2015 20:11:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/udevil-i-montowanie-zasobow-bez-uprawnien-root/</guid>
      <description>&lt;p&gt;Linux jest bezpiecznym środowiskiem operacyjnym ale to nie ze względu na to, że jego kod jest jakoś
mniej podatny na błędy czy coś w tym stylu, tylko przez restrykcyjną politykę dostępu do szeregu
miejsc w systemie. Jednym z nich są wszelkie urządzenia, w skład których wchodzą również i dyski
twarde, pendrive czy napędy cd/dvd. Oczywiście tych urządzeń może być o wile więcej ale my w tym
wpisie omówimy sobie dostęp tylko do tych trzech wymienionych wyżej. Standardowo zwykły użytkownik w
systemie nie ma możliwości przeprowadzenia szeregu czynności pod kątem większości z tych urządzeń i
wliczyć w to można, np. montowanie zasobów. Tego typu operacje może przeprowadzać jedynie
administrator. Ma to na celu ochronę bezpieczeństwa systemu. Jeśli chodzi o nośniki wymienne takie
jak płytki cd/dvd czy pendrive, to na nich może znajdować się podejrzane oprogramowanie i po
zamontowaniu takiego nośnika w systemie, wirusy, trojany czy keyloggery mogą się wgrać do systemu
zagrażając tym samym prywatności wszystkich użytkowników.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Autostart i automatyczne montowanie nośników</title>
      <link>https://morfikov.github.io/post/autostart-i-automatyczne-montowanie-nosnikow/</link>
      <pubDate>Fri, 19 Jun 2015 17:17:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/autostart-i-automatyczne-montowanie-nosnikow/</guid>
      <description>&lt;p&gt;Menadżery plików potrafią automatycznie montować nośniki wymienne w oparciu o pakiet
&lt;a href=&#34;https://www.freedesktop.org/wiki/Software/udisks/&#34;&gt;udisks2&lt;/a&gt;. Potrafią także uruchamiać odpowiednie
aplikacje zlokalizowane na tych urządzeniach. Może to prowadzić do oczywistych zagrożeń i jeśli nasz
system ma być bezpieczny, to musimy wyłączyć obie te opcje. W różnych menadżerach plików, ten proces
przebiega inaczej. Ja korzystam ze &lt;a href=&#34;https://ignorantguru.github.io/spacefm/&#34;&gt;spacefm&lt;/a&gt; i w jego
przypadku mamy dość rozbudowany mechanizm polityki dotyczącej tych dwóch powyższych kwestii.
Niemniej jednak, w przypadku każdego z menadżera plików, proces postępowania powinien przebiegać
mniej więcej w ten sam sposób.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dzielenie pliku i łączenie jego części w całość</title>
      <link>https://morfikov.github.io/post/dzielenie-pliku-i-laczenie-jego-czesci-w-calosc/</link>
      <pubDate>Fri, 19 Jun 2015 13:24:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dzielenie-pliku-i-laczenie-jego-czesci-w-calosc/</guid>
      <description>&lt;p&gt;Obecnie technika podziału jednego pliku na szereg mniejszych nie jest już tak szeroko stosowana jak
parę lat temu gdy internet dopiero zaczynał pojawiać się w naszych domach. Głównym powodem jest
postęp technologii i dziś już mało kto posiada łącza 128Kbit/s, wobec czego przesłanie pliku, który
waży nawet kilka GiB nie jest niczym niezwykłym i nie ma potrzeby go dzielić na części. Niemniej
jednak, z jakichś powodów ludzie chcą mieć taką możliwość i zastanawiają się &lt;a href=&#34;https://unix.stackexchange.com/questions/24630/whats-the-best-way-to-join-files-again-after-splitting-them&#34;&gt;jak podzielić plik na
kilka
części&lt;/a&gt;
na jednej maszynie i połączyć je na innym komputerze.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przestrzeń wymiany SWAP jako plik</title>
      <link>https://morfikov.github.io/post/przestrzen-wymiany-swap-jako-plik/</link>
      <pubDate>Thu, 18 Jun 2015 22:11:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przestrzen-wymiany-swap-jako-plik/</guid>
      <description>&lt;p&gt;Każdy system operacyjny musi być przygotowany na ewentualność wyczerpania się pamięci operacyjnej
RAM. W przypadku gdyby nie był, groziłoby mu powieszenie się. Są różne metody ochrony maszyn z
linuxami na pokładzie przed tego typu sytuacją. Jedne z nich zakładają wykorzystanie wbudowanych w
kernel mechanizmów takich jak choćby &lt;a href=&#34;https://pl.wikipedia.org/wiki/Brak_pami%C4%99ci&#34;&gt;oom-killer&lt;/a&gt;,
który ma za zadanie zabijać te najbardziej żarłoczne procesy. Są również bardziej łagodne sposoby na
uchronienie komputera przed zbyt szybkim wyczerpaniem się pamięci i w tym wpisie omówimy sobie
przestrzeń wymiany SWAP.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DNScrypt-proxy, czyli szyfrowanie zapytań DNS</title>
      <link>https://morfikov.github.io/post/dnscrypt-proxy-czyli-szyfrowanie-zapytan-dns/</link>
      <pubDate>Thu, 18 Jun 2015 20:00:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dnscrypt-proxy-czyli-szyfrowanie-zapytan-dns/</guid>
      <description>&lt;p&gt;Do protokołów SSL/TLS w serwisach www chyba wszyscy już przywykli. Obecnie praktycznie na każdej
stronie, gdzie jest okienko logowania, mamy do czynienia z szyfrowaniem danych przesyłanych w
różnego rodzaju formularzach. Co prawda, klucze nie są zbyt długie (512-2048 bitów) ale zawsze to
lepsze niż nic. O ile dane służące do logowania czy też wszelkie operacje dokonywane w panelach
administracyjnych da radę ukryć bez większego problemu, o tyle zapytania DNS są przesyłane otwartym
tekstem i każdy może je sobie podejrzeć. Pytanie tylko, po co szyfrować ruch DNS? Czy są tam
przesyłane jakieś ważne informacje? Jeśli przyjrzymy się jak działa system DNS, możemy dojść do
wniosku, że szyfrowanie zapytań jest pozbawione sensu, bo z reguły nazwa domeny oznacza konkretny
adres IP. Znając adres IP, możemy ustalić kto na jakie strony wchodzi. Nie do końca jest to prawdą,
poza tym istnieją jeszcze inne czynniki, które sprawiają, że ukrycie zapytań DNS ma jak najbardziej
sens. W tym wpisie zaimplementujemy sobie na naszych linux&#39;ach szyfrowanie zapytań DNS przy
wykorzystaniu &lt;a href=&#34;https://dnscrypt.org/&#34;&gt;narzędzia dnscrypt-proxy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Etykieta systemu plików i jej dostosowanie</title>
      <link>https://morfikov.github.io/post/etykieta-systemu-plikow-i-jej-dostosowanie/</link>
      <pubDate>Thu, 18 Jun 2015 18:32:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/etykieta-systemu-plikow-i-jej-dostosowanie/</guid>
      <description>&lt;p&gt;W poprzednim wpisie dostosowywaliśmy &lt;a href=&#34;https://morfikov.github.io
/post/zarezerwowane-miejsce-w-systemie-plikow-ext4/&#34;&gt;zarezerwowane
miejsce&lt;/a&gt; na określonych
partycjach dla systemowych procesów. Okazuje się także, że zmiana etykiety systemu plików może
przysporzyć wiele problemów początkującym użytkownikom linuxa. Choć jeśli chodzi akurat o nadawanie
czy zmianę etykiet, to tutaj już mamy możliwość przeprowadzenia tej operacji z poziomu narzędzi GUI,
takich jak &lt;code&gt;gparted&lt;/code&gt; , z tym, że niektóre jego komunikaty mogą nieco odstraszać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zarezerwowane miejsce w systemie plików ext4</title>
      <link>https://morfikov.github.io/post/zarezerwowane-miejsce-w-systemie-plikow-ext4/</link>
      <pubDate>Thu, 18 Jun 2015 17:29:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zarezerwowane-miejsce-w-systemie-plikow-ext4/</guid>
      <description>&lt;p&gt;Zwykle nie zwracamy uwagi na to jak formatujemy partycje w systemie linux i akceptujemy domyślne
ustawienia jakie przyjęli sobie deweloperzy danej dystrybucji. Nie ma tutaj znaczenia czy
instalujemy świeży system za pośrednictwem instalatora i przy jego pomocy kroimy dysk, czy też
tworzymy partycje indywidualnie już z poziomu jakiegoś zainstalowanego systemu, bądź też płytki czy
pendrive live. Domyślne ustawienia mają spełniać oczekiwania jak największej liczby odbiorców i nie
zawsze nam one odpowiadają. W przypadku formatowania dysku, problematyczne może być rezerwowanie
miejsca dla procesów użytkownika root.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatyczne wylogowanie użytkownika z konsoli</title>
      <link>https://morfikov.github.io/post/automatyczne-wylogowanie-uzytkownika-z-konsoli/</link>
      <pubDate>Wed, 17 Jun 2015 22:06:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/automatyczne-wylogowanie-uzytkownika-z-konsoli/</guid>
      <description>&lt;p&gt;Każdemu z nas zdarzyło się zostawić włączoną konsolę, na której byliśmy zalogowani jako
administrator systemu root. Być może nie zdajemy sobie sprawy jak często potrafimy popełnić tego
typu gafę. Jedną z metod obrony jest oczywiście wyłączenie konta root w systemie i korzystanie z
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Sudo&#34;&gt;sudo&lt;/a&gt;. Ja jednak wolę inne rozwiązanie, które zakłada
ograniczenie czasu bezczynności, po którym to użytkownik zostanie automatycznie wylogowany.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sprawdzanie błędów systemu plików ext4</title>
      <link>https://morfikov.github.io/post/sprawdzanie-bledow-systemu-plikow-ext4/</link>
      <pubDate>Wed, 17 Jun 2015 20:59:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/sprawdzanie-bledow-systemu-plikow-ext4/</guid>
      <description>&lt;p&gt;Systemy plików stosuje się dla różnych nośników danych, takich jak dyski twarde, czy pendrive albo
nawet płyty cd/dvd. Z formalnego punktu widzenia, system plików jest to metoda przechowywania danych
i uzyskiwania do nich dostępu. Bez tego mechanizmu, informacje umieszczone na nośniku przypominały
by jedynie ciąg bitów i nie wiedzielibyśmy gdzie zaczyna się jakiś plik i gdzie się on kończy.
Czasami jednak zdarzają się błędy w systemie plików, które mogą doprowadzić do poważnych awarii
systemu operacyjnego. Dlatego też linux co kilkanaście lub kilkadziesiąt uruchomień sprawdza stan
systemu plików na każdej partycji i naprawia ewentualne błędy. W przypadku gdyby nie były one
naprawiane, mogą pojawić się nowe błędy doprowadzając tym samym do całkowitej zapaści systemu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Reinstalacja bootloadera grub</title>
      <link>https://morfikov.github.io/post/reinstalacja-bootloadera-grub/</link>
      <pubDate>Tue, 16 Jun 2015 21:13:57 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/reinstalacja-bootloadera-grub/</guid>
      <description>&lt;p&gt;Domyślnym bootloaderem w systemie linux jest &lt;a href=&#34;https://www.gnu.org/software/grub/&#34;&gt;grub&lt;/a&gt; i jako, że
to oprogramowanie jest ładowane do pamięci jako pierwsze, ma ono kluczowe zadanie w procesie startu
systemu operacyjnego. Przy jego pomocy możemy także przekazać szereg parametrów dla modułów kernela,
tym samym odpowiednio go konfigurując. Czasem z pewnych przyczyn, najczęściej gdy inny system
nadpisze MBR, system operacyjny nie chce się podnieść i musimy przeinstalować bootloader,
zakładając, że problem tkwi w nim.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konwersja tablicy partycji GPT na MS-DOS</title>
      <link>https://morfikov.github.io/post/konwersja-tablicy-partycji-gpt-na-ms-dos/</link>
      <pubDate>Tue, 16 Jun 2015 20:16:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konwersja-tablicy-partycji-gpt-na-ms-dos/</guid>
      <description>&lt;p&gt;W poprzednim wpisie poruszyłem temat &lt;a href=&#34;https://morfikov.github.io
/post/konwersja-tablicy-partycji-ms-dos-na-gpt/&#34;&gt;konwersji tablicy partycji MS-DOS (MBR) na
GPT&lt;/a&gt;. Jak można było zauważyć, ten
proces nie był skomplikowany i niemalże automatyczny. Nie towarzyszyło mu także zjawisko utraty
jakichkolwiek danych, jedynie w przypadku posiadania systemu operacyjnego, trzeba było
przeinstalować bootloader. Nasuwa się zatem pytanie, czy również w tak prosty sposób można
przerobić tablicę partycji GPT na MS-DOS? Jest to wykonalne z tym, że trzeba odpowiednio
przygotować sobie do tego celu dysk.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konwersja tablicy partycji MS-DOS na GPT</title>
      <link>https://morfikov.github.io/post/konwersja-tablicy-partycji-ms-dos-na-gpt/</link>
      <pubDate>Tue, 16 Jun 2015 19:26:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konwersja-tablicy-partycji-ms-dos-na-gpt/</guid>
      <description>&lt;p&gt;Od jakiegoś czasu nosiłem się z zamiarem utworzenia na swoim dysku tablicy partycji GPT. Problem w
tym, że tam jest wgranych sporo cennych danych i nie mam gdzie ich przenieść. Jedyne co mi wpadło do
głowy to konwersja tablicy MS-DOS (&lt;a href=&#34;https://superuser.com/questions/700770/mbr-equals-msdos-for-gparted&#34;&gt;zwanej też
MBR&lt;/a&gt;) na GPT. Nie żebym jakoś
tego potrzebował ale tak z ciekawości chciałem zobaczyć czy da się to zrobić w sposób łatwy i
bezproblemowy. Z tego co wyczytałem na necie, to taka konwersja nie powinna sprawić problemów,
zarówno przy przechodzeniu z MS-DOS na GPT jak i odwrotnie, choć w tym drugim przypadku trzeba się
trochę bardziej wysilić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bad sektor w dzienniku systemu plików ext4</title>
      <link>https://morfikov.github.io/post/bad-sektor-w-dzienniku-systemu-plikow-ext4/</link>
      <pubDate>Mon, 15 Jun 2015 22:28:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/bad-sektor-w-dzienniku-systemu-plikow-ext4/</guid>
      <description>&lt;p&gt;Parę dni temu opisywałem jak udało mi się &lt;a href=&#34;https://morfikov.github.io
/post/uszkodzony-sektor-na-dysku-i-jego-realokoacja/&#34;&gt;realokować uszkodzony
sektor&lt;/a&gt; z dysku, który już
przepracował dość długi okres czasu. Nie było to znowu jakoś specjalnie trudne, z tym, że cały
problem dotyczył jakiegoś losowego sektora gdzieś w środku partycji. Jako, że domyślnym systemem
plików na linuxie są te z rodziny &lt;code&gt;ext&lt;/code&gt; (ext2, ext3, ext4) , oraz, że &lt;a href=&#34;https://en.wikipedia.org/wiki/Ext3&#34;&gt;trzecia
wersja&lt;/a&gt; tego systemu plików została wyposażona w dziennik
(journal), to trzeba by się zastanowić, co w przypadku gdy taki uszkodzony sektor trafi się właśnie
w dzienniku tego systemu plików?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Keyfile trzymany w głębokim ukryciu</title>
      <link>https://morfikov.github.io/post/keyfile-trzymany-w-glebokim-ukryciu/</link>
      <pubDate>Mon, 15 Jun 2015 19:53:56 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/keyfile-trzymany-w-glebokim-ukryciu/</guid>
      <description>&lt;p&gt;Pisząc ostatni &lt;a href=&#34;https://morfikov.github.io
/post/udev-czyli-jak-pisac-reguly-dla-urzadzen/&#34;&gt;artykuł na temat
udeva&lt;/a&gt; i montowania przy jego
pomocy zaszyfrowanego kontenera, wpadł mi do głowy ciekawy pomysł na trzymanie pliku klucza
(keyfile) w czymś co się potocznie nazywa &amp;quot;głębokim ukryciem&amp;quot;. Z reguły ludzie nie chcą używać haseł
do odblokowywania swoich systemów czy partycji i zamiast nich wolą stosować keyfile, czyli małe
pliki, zwykle o rozmiarze paru KiB, które, jakby nie patrzeć, są dość unikatowe i odporne na ataki
słownikowe czy inne formy przemocy. Jedyny problem z jakim człowiek musi się zmierzyć, to z
zabezpieczeniem takiego keyfile i tutaj sprawa nie wygląda wcale dobrze. Takie pliki klucze są
trzymane zwykle na tym samym urządzeniu, do których mają zapewniać bezpieczny dostęp, a nawet jeśli
nie na tym samym, to w pobliżu takich urządzeń, dając nam tym samym jedynie fałszywe poczucie
bezpieczeństwa.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uszkodzony sektor na dysku i jego realokoacja</title>
      <link>https://morfikov.github.io/post/uszkodzony-sektor-na-dysku-i-jego-realokoacja/</link>
      <pubDate>Mon, 15 Jun 2015 19:18:01 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uszkodzony-sektor-na-dysku-i-jego-realokoacja/</guid>
      <description>&lt;p&gt;Uszkodzone sektory w przypadku dysków HDD, to jak sama nazwa wskazuje, sektory, które z jakichś
przyczyn nie działają tak jak powinny. Doprowadza to z reguły do niestabilności systemu operacyjnego
objawiającej się jego zawieszaniem w momencie próby odczytu danych z takiego padniętego sektora.
Przyczyny mogą być różne. Zwykle jest to jednak fizyczne uszkodzenie powierzchni nośnika, np w
wyniku wstrząsu, czy też zwyczajne zmęczenie materiału. Jest wielce prawdopodobne, że nie jesteśmy w
stanie nic poradzić w tego typu sytuacji, a ci bardziej zaawansowani użytkownicy zalecają jak
najszybszą wymianę dysku, bo pierwszy bad sektor oznacza, że niedługo będzie ich więcej. Czasem
jednak błędy odczytu mogą być programowe, tj. fizycznie każdy sektor jest w porządku ale z jakiegoś
powodu system nie potrafi odczytać z nich danych. Przy odrobinie szczęścia jesteśmy w stanie
odblokować taki sektor.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problematyczny parametr &#34;Offline Uncorrectable&#34;</title>
      <link>https://morfikov.github.io/post/problematyczny-parametr-offline-uncorrectable/</link>
      <pubDate>Mon, 15 Jun 2015 18:30:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problematyczny-parametr-offline-uncorrectable/</guid>
      <description>&lt;p&gt;Udało mi się znaleźć trochę informacji ma temat parametru S.M.A.R.T &lt;code&gt;198&lt;/code&gt; , tj. &lt;code&gt;Offline Uncorrectable&lt;/code&gt; . Wychodzi na to, że część dysków nie resetuje go, nawet po pomyślnym przejściu testu
&lt;code&gt;offline&lt;/code&gt;. Za to demon &lt;code&gt;smartd&lt;/code&gt; domyślnie ma ustawione informowanie o niezerowej wartości tego
atrybutu w logu systemowym i prawdopodobnie chyba nie da się nic zrobić w tej sprawie ale można
poinstruować &lt;code&gt;smartd&lt;/code&gt; by wyrzucał komunikat tylko w przypadku gdy wartość tego atrybutu zostanie
zwiększona w stosunku do wartości zapisanej przy poprzednim skanowaniu, czyli jeśli teraz mamy
wartość, np. &lt;code&gt;2&lt;/code&gt;, to ostrzeżenie pojawi się gdy będzie tam widniało &lt;code&gt;3&lt;/code&gt; i więcej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Suma kontrolna nagranego obrazu .iso</title>
      <link>https://morfikov.github.io/post/suma-kontrolna-nagranego-obrazu-iso/</link>
      <pubDate>Mon, 15 Jun 2015 15:20:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/suma-kontrolna-nagranego-obrazu-iso/</guid>
      <description>&lt;p&gt;Suma kontrolna daje możliwość sprawdzenia czy dane zawarte w pliku nie zostały zmienione podczas
transferu z jednego medium informacyjnego na inne. Jeśli weźmiemy przykład pakietów sieciowych, to
pliki przesyłane między dwoma punktami są dzielone na mniejsze kawałki. W każdym z nich są zawarte
sumy kontrole danych, które zawierają. Komputer odbierający taki pakiet generuje własną sumę
kontrolą i porównuje ją z tą otrzymaną w pakiecie. W przypadku gdy suma kontrolna się nie zgadza,
mamy do czynienia z błędami przesyłu, tj. pakiet został uszkodzony gdzieś po drodze. W tej sytuacji
maszyna odbierająca dane prosi o ponowne przesłanie uszkodzonego segmentu. Ta sytuacja może się
zdarzyć ale błędy są automatycznie naprawiane. Problem jest taki, że przy pobieraniu plików z
internetu nie zawsze korzystamy z bezpiecznych połączeń, poza tym, zawsze ktoś może uzyskać dostęp
do serwera i podmienić pliki. Czy możemy zatem mieć pewność, że dany plik trafił do nas w formie
takiej jak powinien?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>RAM, cache i dirty pages</title>
      <link>https://morfikov.github.io/post/ram-cache-i-dirty-pages/</link>
      <pubDate>Mon, 15 Jun 2015 15:03:21 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ram-cache-i-dirty-pages/</guid>
      <description>&lt;p&gt;Wiele czasu zajęło mi opanowanie w końcu tych bestii zwanych &lt;a href=&#34;https://www.kernel.org/doc/Documentation/sysctl/vm.txt&#34;&gt;dirty
pages&lt;/a&gt;, które to są trzymane w cache pamięci
RAM i potrafią dać się nieźle we znaki, zwłaszcza gdy ma się mało pamięci operacyjnej i maszynę &lt;a href=&#34;https://lwn.net/Articles/572911/&#34;&gt;64
bitową&lt;/a&gt;. Chodzi o to, że podczas kopiowania plików z/na pendrive,
system zaczyna się strasznie przycinać, bo następuje zrzucanie danych innych procesów z RAM do SWAP
by zrobić miejsce pod te dane, które są aktualnie kopiowane.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja GPG w pliku gpg.conf</title>
      <link>https://morfikov.github.io/post/konfiguracja-gpg-w-pliku-gpg-conf/</link>
      <pubDate>Sun, 14 Jun 2015 23:19:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-gpg-w-pliku-gpg-conf/</guid>
      <description>&lt;p&gt;Narzędzie &lt;code&gt;gpg&lt;/code&gt; posiada swój własny plik konfiguracyjnych, który zwykle jest zlokalizowany w
&lt;code&gt;~/.gnupg/gpg.conf&lt;/code&gt; . Można w nim sprecyzować większość z opcji, które zwykle są podawane w
terminalu przy wywoływaniu polecenia &lt;code&gt;gpg&lt;/code&gt; . Po zdefiniowaniu odpowiednich wpisów w pliku
konfiguracyjnym, nie będziemy musieli już wyraźnie podawać tych parametrów ilekroć będziemy chcieli
skorzystać z &lt;code&gt;gpg&lt;/code&gt; . Przy okazji szukania info o kluczach GPG, natknąłem się na dość ciekawy
&lt;a href=&#34;https://riseup.net/security/message-security/openpgp/best-practices&#34;&gt;artykuł na temat GnuPG&lt;/a&gt;. Jest
tam sporo informacji, które są wielce użyteczne w procesie konfiguracji tego narzędzia poprawiając
tym samym dość znacznie bezpieczeństwo komunikacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>UDEV, czyli jak pisać reguły dla urządzeń</title>
      <link>https://morfikov.github.io/post/udev-czyli-jak-pisac-reguly-dla-urzadzen/</link>
      <pubDate>Sun, 14 Jun 2015 18:13:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/udev-czyli-jak-pisac-reguly-dla-urzadzen/</guid>
      <description>&lt;p&gt;Zapuszczając się w coraz to i głębsze warstwy systemu podczas dążenia do zbadania jak on tak
naprawdę działa, zacząłem się stykać z regułami &lt;a href=&#34;https://wiki.archlinux.org/index.php/Udev&#34;&gt;udeva&lt;/a&gt;
(tymi umieszczanymi w katalogu /etc/udev/rules.d/ ). Jako, że nazbierało mi się już ich kilka,
zaistniała potrzeba przebadania tego co ten katalog tak naprawdę zawiera. Na dobrą sprawę nigdy się
nad tym nie zastanawiałem, jedynie kopiowałem rozwiązania z internetu i wklejałem je do
odpowiedniego pliku i jeśli ono działało, to odznaczałem problem jako rozwiązany. Zwykle takich
reguł się nie potrzebuje, temu praktycznie niewielu ludzi w ogóle się orientuje jak ogarnąć tego
całego udeva. Są przypadki kiedy przepisanie nazw urządzeń czy wykonanie określonych akcji po
podłączeniu jakiegoś sprzętu do komputera jest wielce niezbędne i nie ma innej opcji jak tylko
zrozumieć co udev tak naprawdę robi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Obsługa wielu partycji w module loop</title>
      <link>https://morfikov.github.io/post/obsluga-wielu-partycji-w-module-loop/</link>
      <pubDate>Sun, 14 Jun 2015 16:37:34 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/obsluga-wielu-partycji-w-module-loop/</guid>
      <description>&lt;p&gt;Wszelkie obrazy &lt;code&gt;.iso&lt;/code&gt; płyt cd/dvd czy nawet pliki &lt;code&gt;.img&lt;/code&gt; zawierające strukturę obrazów live możemy
zamontować lokalnie na komputerze uzyskując tym samym dostęp do ich systemu plików. W większości
przypadków, każdy taki obraz zawiera tylko jedną partycję, czasem lekko przesuniętą względem
początku ale generalnie nie ma większych problemów z zamontowaniem tego typu plików. Najwyżej
trzeba podać jeden dodatkowy parametr, tj. &lt;code&gt;offset&lt;/code&gt; . A co w przypadku obrazów dysków, które zwykle
mają więcej niż jedną partycję? Gdybyśmy spróbowali zamontować taki plik w systemie, to zostanie nam
zwrócony błąd, no bo przecież kernel nie wie za bardzo jak taki plik ma odczytać. Możemy za to
skorzystać z urządzeń &lt;code&gt;loop&lt;/code&gt; , które po odpowiedniej konfiguracji, są w stanie nam takie obrazy z
powodzeniem zamontować na naszym linux&#39;ie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana rozmiaru obrazu .img</title>
      <link>https://morfikov.github.io/post/zmiana-rozmiaru-obrazu-img/</link>
      <pubDate>Sun, 14 Jun 2015 13:05:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-rozmiaru-obrazu-img/</guid>
      <description>&lt;p&gt;Struktura pliku &lt;code&gt;.img&lt;/code&gt; czy &lt;code&gt;.iso&lt;/code&gt; niczym nie odbiega od struktury przeciętnego dysku twardego. W obu
przypadkach mamy dokładnie taki sam schemat budowy, tj. mamy obecny
&lt;a href=&#34;https://morfikov.github.io
/post/mbr-ebr-i-tablica-partycji-dysku-twardego/&#34;&gt;MBR&lt;/a&gt; i partycje, z których
pierwsza zwykle jest wyrównana do 1MiB, zostawiając tym samym 2047 sektorów wolnego miejsca z
początku pliku, tuż za MBR, tzw. MBR-GAP. Obraz &lt;code&gt;.img&lt;/code&gt; można poddać edycji, np. utworzyć wewnątrz
niego inne partycje, zmienić rozmiar ich systemu plików, a nawet można manipulować rozmiarem samego
obrazu &lt;code&gt;.img&lt;/code&gt; . Taki plik możemy również zamontować w systemie przy pomocy narzędzia &lt;code&gt;mount&lt;/code&gt; ale też
trzeba odpowiednio podejść do tego zadania, bo przez fakt, że mamy z początku MBR i trochę wolnego
miejsca, to linux zwyczajnie nie potrafi rozpoznać systemu plików, który znajduje się w obrazie
&lt;code&gt;.img&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bezpieczny klucz GPG</title>
      <link>https://morfikov.github.io/post/bezpieczny-klucz-gpg/</link>
      <pubDate>Sun, 14 Jun 2015 11:55:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/bezpieczny-klucz-gpg/</guid>
      <description>&lt;p&gt;W poprzednim wpisie przygotowywaliśmy sobie &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-gpg-w-pliku-gpg-conf/&#34;&gt;plik
gpg.conf&lt;/a&gt;. Opcje w nim ustawione są
niezbędne do wygenerowania dobrego pod względem bezpieczeństwa klucza GPG. Taki klucz GPG nie
powinien być krótszy niż 4096 bitów. Dodatkowo, nie powinno się ustawiać daty ważności dłuższej niż
2 lata, a to z tego powodu, że zawszę tę datę można zmienić i to nawet w przypadku gdy klucz straci
ważność. Chodzi generalnie o ustawienie jakiegoś mechanizmu zabezpieczającego na wypadek gdyby nasz
klucz GPG wpadł w niepowołane ręce i stracilibyśmy nad nim panowanie. Wtedy po jakimś czasie
automatycznie się on unieważni i nie będziemy musieli się martwić czy ktoś może przez przypadek go
używać. Jest również szereg innych rzecz, o które powinniśmy się zatroszczyć i tej tematyce będzie
poświęcony ten wpis, który w dużej mierze powstał w oparciu o te
&lt;a href=&#34;https://www.gnupg.org/gph/en/manual/book1.html&#34;&gt;dwa&lt;/a&gt;
&lt;a href=&#34;https://riseup.net/security/message-security/openpgp/best-practices&#34;&gt;linki&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rzeczywista pojemność pendrive i kart SD</title>
      <link>https://morfikov.github.io/post/rzeczywista-pojemnosc-pendrive-i-kart-sd/</link>
      <pubDate>Sun, 14 Jun 2015 09:08:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/rzeczywista-pojemnosc-pendrive-i-kart-sd/</guid>
      <description>&lt;p&gt;Parę dni temu &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=26668&#34;&gt;jednemu z użytkowników forum DUG&lt;/a&gt;
przytrafiła się niezbyt miła sytuacja. Rozchodzi się o to iż zakupił on kartę SD i, jak sprzedawca
zapewniał, miała mieć pojemność 128 GiB. Wszyscy wiemy, że sprzedawcy nieco zawyżają te numerki na
opakowaniach, bo operują na potęgach o podstawie 10, a nie 2, i tak ze 100 GB robi się zaraz 93 GiB.
Do tego oczywiście jeszcze dochodzi rezerwacja miejsca na potrzebę obsługi systemu plików. Niemniej
jednak, w tym przypadku, różnica była trochę większa i tutaj mamy do czynienia z czymś co się nazywa
&lt;a href=&#34;http://www.ebay.com/gds/All-About-Fake-Flash-Drives-2013-/10000000177553258/g.html&#34;&gt;fake flash&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Jest taka żelazna zasada, by po zakupie jakiegoś sprzętu, sprawdzić go czy aby działa jak należy i
czy jest z nim wszystko w porządku. Jest to wręcz obowiązek przy zakupie pamięci opartych o
technologię flash, bez znaczenia z jakiego to źródła by one nie pochodziły.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MBR, EBR i tablica partycji dysku twardego</title>
      <link>https://morfikov.github.io/post/mbr-ebr-i-tablica-partycji-dysku-twardego/</link>
      <pubDate>Fri, 12 Jun 2015 18:44:53 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mbr-ebr-i-tablica-partycji-dysku-twardego/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Master_boot_record&#34;&gt;MBR&lt;/a&gt; to pierwszy sektor dysku twardego, który
może ma jedynie 512 bajtów ale jest to bardzo krytyczny obszar nośnika, po którego uszkodzeniu czy
nadpisaniu tracimy dostęp do wszystkich partycji znajdujących się na dysku. Ci bardziej przezorni
użytkownicy robią sobie backup tego kluczowego punktu, tak by w przypadku problemów mogli go sobie
przywrócić. Nie zawsze jednak potrzebujemy przywracać cały sektor MBR, w większości przypadków
będziemy potrzebować jedynie kodu bootloadera lub samej tablicy partycji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Własny system live i tworzenie go od podstaw</title>
      <link>https://morfikov.github.io/post/wlasny-system-live-i-tworzenie-go-od-podstaw/</link>
      <pubDate>Fri, 12 Jun 2015 15:48:19 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wlasny-system-live-i-tworzenie-go-od-podstaw/</guid>
      <description>&lt;p&gt;Jeśli mamy nieco odbiegające od standardowych oczekiwania dotyczące systemów live, np. wynikają one
z braku obecności pewnych pakietów w obrazie wygenerowanym przez developerów jakiejś konkretnej
dystrybucji, to możemy sobie stworzyć własny obraz live, gdzie mamy możliwość dostosowania całej
konfiguracji takiego systemu wliczając w to również i instalację brakujących pakietów. Obrazy, które
są &lt;a href=&#34;https://www.debian.org/CD/live/&#34;&gt;dostępne na stronie debiana&lt;/a&gt;, zawierają wydanie stabilne i jak
wiadomo, nie jest ono zbyt aktualne pod względem oprogramowania. Natomiast jeśli chodzi o tworzenie
własnych obrazów live, to możemy zdefiniować sobie gałąź, z której mają być pobierane pakiety użyte
w procesie budowania, jak i również dograć te pakiety, które nie są w żaden sposób powiązane z daną
dystrybucją.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przygotowanie środowiska chroot do pracy</title>
      <link>https://morfikov.github.io/post/przygotowanie-srodowiska-chroot-do-pracy/</link>
      <pubDate>Thu, 11 Jun 2015 23:24:07 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przygotowanie-srodowiska-chroot-do-pracy/</guid>
      <description>&lt;p&gt;Linuxy mają tę właściwość, że bardzo ciężko jest stracić do któregoś z nich dostęp, nawet w
przypadku kompletnego zawału systemu. Jeżeli dysponujemy jakimś alternatywnym środowiskiem w postaci
płytki live cd/dvd czy pendrive albo też posiadamy gdzieś zainstalowanego innego linuxa, to istnieje
spore prawdopodobieństwo, że uda się nam reanimować nasz główny system. Wszystko za sprawą narzędzia
jakim jest &lt;a href=&#34;https://pl.wikipedia.org/wiki/Chroot&#34;&gt;chroot&lt;/a&gt; , przy którego to pomocy możemy zmienić
główny katalog systemu plików ( &lt;code&gt;/&lt;/code&gt; ) dla wykonywanych procesów bez potrzeby przechodzenia całej
skomplikowanej procedury uruchamiania systemu operacyjnego. Jeśli tylko uda nam się uzyskać dostęp
do shella, to nie ma takiej możliwości by system nie stanął na nogi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Persistence czyli zachowanie zmian w systemie live</title>
      <link>https://morfikov.github.io/post/persistence-czyli-zachowanie-zmian-w-systemie-live/</link>
      <pubDate>Thu, 11 Jun 2015 19:12:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/persistence-czyli-zachowanie-zmian-w-systemie-live/</guid>
      <description>&lt;p&gt;Systemy live mają jedną ale za to dość dającą się odczuć wadę, mianowicie chodzi o to, że po
wypaleniu takiego obrazu, nie mamy możliwości zachowania zmian. Nawet jeśli doinstalujemy nowy
pakiet czy wyedytujemy jakiś plik, to zmiany wprowadzone przez nas są jedynie tymczasowe, bo
dokonywane w pamięci operacyjnej RAM. W efekcie jeśli uruchomimy taki system ponownie, będziemy
zmuszeni przeprowadzać raz jeszcze wszystkie poprzednie czynności pod kątem jego dostosowania. W
przypadku cd/dvd nie mamy praktycznie żadnego pola manewru. Inaczej jednak ma się sprawa jeśli
chodzi o pendrive, bo tutaj możemy utworzyć osobną partycję, gdzie będą przechowywane wszystkie
zmiany jakich dokonamy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Squashfs jako system plików obrazów live</title>
      <link>https://morfikov.github.io/post/squashfs-jako-system-plikow-obrazow-live/</link>
      <pubDate>Thu, 11 Jun 2015 17:06:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/squashfs-jako-system-plikow-obrazow-live/</guid>
      <description>&lt;p&gt;System live to nic innego jak spakowany system plików jakieś zainstalowanej dystrybucji, który
podczas startu maszyny jest montowany w trybie tylko do odczytu, a potrzebne pliki są wypakowywane w
czasie rzeczywistym w pamięci operacyjnej RAM. Do implementacji takiego rozwiązania stosuje się
&lt;a href=&#34;https://pl.wikipedia.org/wiki/SquashFS&#34;&gt;squashfs&lt;/a&gt; i jako, że jest to system plików tylko do
odczytu, nie można go jako tako edytować. Nie jesteśmy też zupełnie na straconej pozycji, bo możemy
skorzystać z dwóch rozwiązań:
&lt;a href=&#34;https://morfikov.github.io
/post/persistence-czyli-zachowanie-zmian-w-systemie-live/&#34;&gt;persistence&lt;/a&gt; lub możemy
pokusić się o przepakowanie systemu plików.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wgrać system live na uszkodzony pendrive</title>
      <link>https://morfikov.github.io/post/jak-wgrac-system-live-na-uszkodzony-pendrive/</link>
      <pubDate>Thu, 11 Jun 2015 14:43:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wgrac-system-live-na-uszkodzony-pendrive/</guid>
      <description>&lt;p&gt;Każdy z nas spotkał się już chyba w swoim życiu z systemami live. To taki wynalazek zawierający
domyślne oprogramowanie, tak skonfigurowane, by system zdołał się odpalić na większość maszyn w ich
pamięci operacyjnej, oczywiście zakładając, że wymagania sprzętowe zostaną zaspokojone, głównie
chodzi o pamięć RAM. Takie systemy live są dostarczane w postaci kilku rodzajów obrazów: iso, hdd
oraz hybryda. Pierwszy z nich zwykle wypala się na płytkach, drugi na pendrive, z kolei hybrydowy
obraz można wgrać na każdy rodzaj urządzenia i nawet wykorzystać w przypadku maszyn wirtualnych i
zwykle spotkamy się z tym ostatnim typem, nawet jeśli plik ma rozszerzenie &lt;code&gt;.iso&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatycznie generowane hasło do serwisu www</title>
      <link>https://morfikov.github.io/post/automatycznie-generowane-haslo-do-serwisu-www/</link>
      <pubDate>Wed, 10 Jun 2015 20:51:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/automatycznie-generowane-haslo-do-serwisu-www/</guid>
      <description>&lt;p&gt;Każdy z nas dla wygody, albo raczej przez lenistwo, stara się nie używać zbyt skomplikowanych haseł.
Zwykle też korzystamy z tego samego hasła do większości kont online w internecie. Jeśli zdarzyło nam
się tworzyć proste, krótkie i do tego łatwe do przewidzenia hasła, np. w oparciu o datę urodzenia
lub inne tego typu informacji, to przydałoby się nieco popracować nad zabezpieczeniami tych poufnych
danych, tak by nie były proste do odgadnięcia czy też i złamania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jedna reguła udev&#39;a realizująca dwa zadania</title>
      <link>https://morfikov.github.io/post/jedna-regula-udeva-realizujaca-dwa-zadania/</link>
      <pubDate>Wed, 10 Jun 2015 10:45:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jedna-regula-udeva-realizujaca-dwa-zadania/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem jak podejść do &lt;a href=&#34;https://morfikov.github.io
/post/udev-czyli-jak-pisac-reguly-dla-urzadzen/&#34;&gt;pisania
reguł&lt;/a&gt; dla
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Udev&#34;&gt;udev&#39;a&lt;/a&gt; . W tamtym przypadku wykorzystywana reguła składała się
tak naprawdę z dwóch mniejszych, z których jedna miała ustawioną zmienną &lt;code&gt;ACTION&lt;/code&gt; na &lt;code&gt;add&lt;/code&gt; , z kolei
zaś druga na &lt;code&gt;remove&lt;/code&gt; i w ten oto sposób pierwsza z nich była aplikowana podczas podłączania
określonego urządzenia do komputera, a druga przy jego odłączaniu. Okazuje się jednak, że dwie
reguły nie są konieczne w przypadku gdy mają one dotyczyć tego samego sprzętu i możemy zamiast nich
stworzyć jedną regułę, która będzie stosowana zarówno przy podłączaniu jak i odłączeniu danego
urządzenia.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kiedy żywot pendrive dobiega końca...</title>
      <link>https://morfikov.github.io/post/kiedy-zywot-pendrive-dobiega-konca/</link>
      <pubDate>Tue, 09 Jun 2015 20:47:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kiedy-zywot-pendrive-dobiega-konca/</guid>
      <description>&lt;p&gt;Pendrive to jedno z cenniejszych urządzeń w obecnych czasach. Jest mały, poręczny i potrafi
przechować parę set GiB danych oraz jako, że nie ma części ruchomych, można nie obchodzić się z nim
jak z jajkiem i to bez ryzyka utraty danych. Często wykorzystuje się go jako środek transportu na
krótkie odległości między kilkoma maszynami, gdzie z pewnych powodów nie można pociągnąć kabla
sieciowego, nie wspominając przy tym o wifi. Systemy live wręcz nie mogą się bez nich obejść.
Jesteśmy w sumie uzależnieni od tych małych urządzeń tak bardzo, że dostrzegamy to dopiero w chwili
gdy, któryś pendrive zaczyna odmawiać posłuszeństwa.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dokładna data instalacji systemu linux</title>
      <link>https://morfikov.github.io/post/dokladna-data-instalacji-systemu-linux/</link>
      <pubDate>Mon, 08 Jun 2015 20:21:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dokladna-data-instalacji-systemu-linux/</guid>
      <description>&lt;p&gt;Czy zadawaliście sobie kiedyś pytanie na temat tego jaka jest dokładna data instalacji aktualnie
używanego przez was systemu operacyjnego? To chyba powinna być jedna z podstawowych danych, do
których użytkownik powinien mieć swobodny dostęp, by wiedział kiedy instalował swój system. Jednak
w przypadku linux&#39;a z jakiegoś powodu ciężko jest ten fakt ustalić. Postaramy się zatem ocenić
możliwie dokładnie to kiedy proces instalacji linux&#39;a mógł mieć miejsce.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przecinek vs. kropka na klawiaturze numerycznej</title>
      <link>https://morfikov.github.io/post/przecinek-vs-kropka-na-klawiaturze-numerycznej/</link>
      <pubDate>Mon, 08 Jun 2015 16:02:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przecinek-vs-kropka-na-klawiaturze-numerycznej/</guid>
      <description>&lt;p&gt;Jak możemy &lt;a href=&#34;https://en.wikipedia.org/wiki/Decimal_mark&#34;&gt;przeczytać pod tym linkiem&lt;/a&gt; , zróżnicowanie
pod względem zapisu większych liczb jak i części dziesiętnych różni się w zależności od kraju. Jedne
do oddzielania od siebie tysięcy wykorzystują kropki, inne zaś przecinki i vice versa w przypadku
części niecałkowitej. Nie będę tutaj się rozpisywał na temat wyższości kropki nad przecinkiem, bo
problem dotyczy zupełnie czegoś innego, mianowicie, tego jak system interpretuje znaki pochodzące z
klawiatury numerycznej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klawiatura multimedialna i niedziałające klawisze</title>
      <link>https://morfikov.github.io/post/klawiatura-multimedialna-i-niedzialajace-klawisze/</link>
      <pubDate>Mon, 08 Jun 2015 12:51:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/klawiatura-multimedialna-i-niedzialajace-klawisze/</guid>
      <description>&lt;p&gt;Bardzo ciężko spotkać wypasioną klawiaturę, po której podłączeniu wszystkie przyciski będą
funkcjonować jak należy, a to z tego względu, że nie do końca są one wykrywane przez nasz system.
Zwykle są to klawisze multimedialne lub inne niestandardowe przyciski, które nie pasują do układu
104 klawiszy. W większości przypadków &lt;a href=&#34;https://morfikov.github.io
/post/klawiatura-i-jej-konfiguracja-pod-debianem/&#34;&gt;odpowiednie skonfigurowanie modelu
klawiatury&lt;/a&gt; powinno rozwiązać
nasze problemy. Nie zawsze jednak posiadany przez nas model jest do wyboru. Czasami nawet i jego
wskazanie nie pomaga i najzwyczajniej w świecie niektóre klawisze po prostu nie zostaną wykryte
przez system.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Ciasteczka i ich czas żywotności</title>
      <link>https://morfikov.github.io/post/wordpress-ciasteczka-i-ich-czas-zywotnosci/</link>
      <pubDate>Sat, 06 Jun 2015 18:50:51 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-ciasteczka-i-ich-czas-zywotnosci/</guid>
      <description>&lt;p&gt;Ciasteczka w WordPresie są bardzo ważne, bo wykorzystuje się je w procesie uwierzytelniania
logujących się i powracających użytkowników. Domyślnie czas ważności generowanych ciasteczek to &lt;code&gt;2&lt;/code&gt;
dni, chyba, że człowiek zaznaczy opcję &amp;quot;Pamiętaj&amp;quot; w formularzu logowania, wtedy ten okres ważności
ulega przedłużeniu do &lt;code&gt;14&lt;/code&gt; dni. Chodzi o to, że w przypadku gdyby ciasteczka nie posiadały terminu
ważności, to jeśli ktoś by wszedł w ich posiadanie, to mógłby się zalogować w serwisie bez większych
problemów, a tego przecież nie chcemy. Są jednak sytuacje, w których 2 czy nawet 14 dni, to ździebko
za mało (lub za dużo) i w tym wpisie postaramy się dostosować żywotność ciasteczek, tak by
odpowiadała naszym upodobaniom.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Komunikat błędnego logowania</title>
      <link>https://morfikov.github.io/post/wordpress-komunikat-blednego-logowania/</link>
      <pubDate>Sat, 06 Jun 2015 13:05:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-komunikat-blednego-logowania/</guid>
      <description>&lt;p&gt;Jest kilka rzeczy, które mogą zdradzić dane logowania do serwisu WordPressa. Nie będę tutaj opisywał
tej najbardziej oczywistej, czyli &lt;a href=&#34;https://morfikov.github.io
/post/wordpress-administrator-bloga/&#34;&gt;posługiwania się loginem bezpośrednio na
blogu&lt;/a&gt;, tylko skupię się na nieco bardziej
chytrej opcji, która zakłada odpytywanie formularza logowania w celu ustalenia, które loginy są
dostępne w bazie danych. To tak jak grać w statki i strzelać na oślep, aż w końcu się trafi w
któryś z nich, a skąd wiemy, że trafiliśmy? Po zwracanej odpowiedzi od drugiego gracza. I podobnie
jest w przypadku formularza logowania WordPressa, z tym, że jeśli chodzi o strony www, to mamy nieco
zawężone pole strzału, bo administrator/użytkownik zwykle wybiera niezbyt skomplikowany login często
kojarzący się z pewnymi elementami jego życia, a gdy potencjalny atakujący ustali taki login, to
będzie w stanie dokonać ataku Brute Force na hasło do tego konta.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Ograniczone prawa dostępu</title>
      <link>https://morfikov.github.io/post/wordpress-ograniczone-prawa-dostepu/</link>
      <pubDate>Sat, 06 Jun 2015 11:41:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-ograniczone-prawa-dostepu/</guid>
      <description>&lt;p&gt;Mając już zainstalowanego i wstępnie skonfigurowanego WordPress&#39;a, przydałoby się zadbać &lt;a href=&#34;https://codex.wordpress.org/Changing_File_Permissions&#34;&gt;prawa
dostępu do jego plików&lt;/a&gt; jak i również
ograniczyć nieco dostęp do samej bazy danych, tak by możliwie najmniejsze uprawnienia zostały
nadane, co poprawi znacznie bezpieczeństwo naszej witryny. Jeśli opanowaliśmy już operowanie na
instalacji WordPress&#39;a przy pomocy
&lt;a href=&#34;https://morfikov.github.io
/post/wordpress-wiersz-polecen-wp-cli/&#34;&gt;skryptu&lt;/a&gt;
&lt;a href=&#34;https://morfikov.github.io
/post/wordpress-instalacja-przy-pomocy-wp-cli/&#34;&gt;wp-cli&lt;/a&gt; , to możemy bez wahania
dokręcić śrubę naszemu serwisowi. Jeśli nie zaznajomiliśmy się jeszcze z powyższym narzędziem, to
ograniczenie praw może spowodować problemy z aktualizacją rdzennych plików WordPress&#39;a, jak i
instalacją/konfiguracją jego pluginów czy motywów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Klucze zabezpieczające ciasteczka</title>
      <link>https://morfikov.github.io/post/wordpress-klucze-zabezpieczajace-ciasteczka/</link>
      <pubDate>Sat, 06 Jun 2015 06:36:59 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-klucze-zabezpieczajace-ciasteczka/</guid>
      <description>&lt;p&gt;WordPress stara się dbać o bezpieczeństwo swoich użytkowników najlepiej jak potrafi. Dowodem na to
mogą być unikalne klucze i sole uwierzytelniające (Authentication Unique Keys and Salts) wprowadzone
w wersji 2.5 oraz nieco rozbudowane w wersji 2.7. Ten mechanizm nie wykorzystuje sesji PHP do
śledzenia np. statusu zalogowania, tylko zaprzęga do tego celu ciasteczka, by utrudnić (albo raczej
uniemożliwić) potencjalnemu atakującemu dostęp do witryny. Bez tych kluczy i soli jesteśmy w stanie
przewidzieć wszystkie składowe hasha danego ciasteczka, dlatego też powinniśmy pokusić się o ich
implementację na swojej stronie. Niemniej jednak, na necie jest bardzo dużo niskiej jakości
informacji na temat działania mechanizmu walidacji ciasteczek, a artykuły, które
&lt;a href=&#34;https://boren.blog/2008/07/14/ssl-and-cookies-in-wordpress-26/&#34;&gt;potrafią&lt;/a&gt;
&lt;a href=&#34;http://www.securitysift.com/understanding-wordpress-auth-cookies/&#34;&gt;go&lt;/a&gt;
&lt;a href=&#34;http://codeseekah.com/2012/04/09/why-wordpress-authentication-unique-keys-and-salts-are-important/&#34;&gt;opisać&lt;/a&gt;
w szerszym stopniu, są już lekko nieaktualne, bo zmienia się on praktycznie z każdą nową wersją
WordPressa. Zanim jednak przejdziemy do samych kluczy/soli, powinniśmy się zaznajomić ze sposobem w
jaki WordPress generuje i sprawdza wspomniane ciasteczka, na podstawie których to autoryzowane są
działania użytkowników naszego bloga.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kompaktowanie katalogów w Thunderbird</title>
      <link>https://morfikov.github.io/post/kompaktowanie-katalogow-w-thunderbird/</link>
      <pubDate>Thu, 04 Jun 2015 15:51:37 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/kompaktowanie-katalogow-w-thunderbird/</guid>
      <description>&lt;p&gt;Postanowiłem się w końcu wziąć za porządki związane z wiadomościami pocztowymi i RSS&#39;ami, bo katalog
Thunderbird&#39;a już zajmował prawie 650 MiB. Jakby nie patrzeć, to trochę dużo, biorąc pod uwagę, że
są to głównie wiadomości tekstowe. W sumie to miałem tam archiwum wszystkich maili z 4-5 ostatnich
lat i trochę się tego nazbierało. Nie byłoby tego wpisu gdyby nie fakt, że nawet usunięcie 120 tyś.
wiadomości praktycznie nie wpłynęło na zajmowane przez nie przestrzeni na dysku.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Graficzne emotikonki</title>
      <link>https://morfikov.github.io/post/wordpress-graficzne-emotikonki/</link>
      <pubDate>Wed, 03 Jun 2015 19:14:23 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-graficzne-emotikonki/</guid>
      <description>&lt;p&gt;Począwszy od wersji 4.2, WordPress wstawia pliki powiązane z
&lt;a href=&#34;https://codex.wordpress.org/Emoji&#34;&gt;Emoji&lt;/a&gt; bezpośrednio do nagłówka strony. Jest to porcja 1600
znaków, która ma służyć zamianie tekstowych emotikonek na ich graficzne odpowiedniki. Jeśli z nich
nie korzystamy albo wolimy zamiast nich kilka znaków tekstowych, to ten kod jest dla nas kompletnie
zbędny i zaśmieca tylko nagłówek, wobec czego powinniśmy się jak najszybciej pozbyć tego balastu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Wyłączenie protokołu XML-RPC</title>
      <link>https://morfikov.github.io/post/wordpress-wylaczenie-protokolu-xml-rpc/</link>
      <pubDate>Wed, 03 Jun 2015 13:55:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-wylaczenie-protokolu-xml-rpc/</guid>
      <description>&lt;p&gt;Jeśli publikujemy posty na swoim blogu, to pierw musimy je gdzieś sporządzić. Możemy to robić w
zwykłym notatniku lub też bezpośrednio w formularzu WordPressa dostępnego przy edycji postu.
Istnieje też inna możliwość, mianowicie korzystanie ze specjalnie przeznaczonego do tego celu
oprogramowania -- klientów blogowych działających w oparciu o protokół
&lt;a href=&#34;https://codex.wordpress.org/XML-RPC_Support&#34;&gt;XML-RPC&lt;/a&gt;. Jest to mechanizm podobny tego znanego
choćby z poczty internetowej, czyli mamy konto email, np. na gmailu ale do tworzenia i zarządzania
wiadomościami wykorzystujemy np. Thunderbirda. Podobnie możemy postępować z treścią pojawiającą się
na blogu i nawet nie musimy być w tym czasie online. Jednym z bardziej znanych klientów, przy pomocy
którego możemy wrzucać posty na bloga, to &lt;a href=&#34;https://en.wordpress.com/windows-live-writer/&#34;&gt;Windows Live Writer
(WLW)&lt;/a&gt;. Poza tym, protokół XML-RPC wykorzystywany
jest także przez część serwisów internetowych, np.
&lt;a href=&#34;https://www.flickr.com/services/api/request.xmlrpc.html&#34;&gt;Flickr&lt;/a&gt; , co umożliwia im zamieszczanie
postów w naszej witrynie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Krótki link do umieszczenia na Twitterze</title>
      <link>https://morfikov.github.io/post/wordpress-krotki-link-do-umieszczenia-na-twitterze/</link>
      <pubDate>Wed, 03 Jun 2015 10:13:38 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-krotki-link-do-umieszczenia-na-twitterze/</guid>
      <description>&lt;p&gt;W chwili gdy zabierałem się za rozpracowywanie szeregu zagadnień związanych z oczyszczaniem nagłówka
generowanego przez WordPress, nie miałem pojęcia, że niektóre opcje nie są dostępne w standardowej
instalacji, którą każdy może sobie pobrać z ich strony i wgrać do siebie na serwer. Chodzi
oczywiście o &lt;a href=&#34;https://en.wikipedia.org/wiki/URL_shortening&#34;&gt;krótkie odnośniki&lt;/a&gt; (shortlinks). Ich
głównym celem jest skracanie linków do paru znaków, tak by można je umieścić np. na Twitterze
gdzie długość wiadomości jest znacznie ograniczona i raczej wklejanie tam linku, który by zjadł
wszystkie dostępne znaki nie jest zbytnio pożądane.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Edycja i modyfikacja plików dodatków</title>
      <link>https://morfikov.github.io/post/wordpress-edycja-i-modyfikacja-plikow-dodatkow/</link>
      <pubDate>Tue, 02 Jun 2015 19:33:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-edycja-i-modyfikacja-plikow-dodatkow/</guid>
      <description>&lt;p&gt;Na necie widziałem wiele tutoriali na temat zmiany konfiguracji stylów czy motywów WordPressa i w
większości z nich ludzie dokonywali poprawek w kodzie źródłowym bezpośrednio przez panel
administracyjny. Ni to wygodne, ani bezpieczne. Prze wszystkim, jeśli jakiś robak uzyskałby dostęp
do konta administracyjnego naszego bloga, to pierwsze co mu przyjdzie do głowy, to edycja plików
właśnie za pomocą wbudowanego w WordPress edytora (Appearance =&amp;gt; Editor). Dlatego ze względów
bezpieczeństwa kluczowe jest &lt;a href=&#34;https://codex.wordpress.org/Editing_wp-config.php#Disable_Plugin_and_Theme_Update_and_Installation&#34;&gt;wyłączenie tej
opcji&lt;/a&gt;
i jeśli potrzebujemy zmieniać określone pliki WordPressa, to róbmy to poza samym skryptem i
najlepiej przy pomocy zwykłego notatnika co potrafi kolorować składnię, by uniknąć również
ewentualnych literówek.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Kosz i jego cykliczne opróżnianie</title>
      <link>https://morfikov.github.io/post/wordpress-kosz-i-jego-cykliczne-oproznianie/</link>
      <pubDate>Tue, 02 Jun 2015 18:21:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-kosz-i-jego-cykliczne-oproznianie/</guid>
      <description>&lt;p&gt;Jeśli piszemy dużo na swoim blogu i mamy sporo treści, którą trzeba uaktualnić, to prawdopodobnie
często wprowadzamy poprawki polegające na usuwaniu starych wpisów i tworzeniu szkiców nowych
artykułów. Tego typu rotacja sprawia, że sporo wiadomości ląduje w koszu, z tym, że jeśli chodzi o
bazę danych, to jej jest bez różnicy czy przenieśliśmy dany post do kosza, przynajmniej do momentu
gdy faktycznie on wyleci z bazy danych. Także pod względem objętości bazy nic się nie zmienia. Poza
tym, WordPress potrafi opróżniać kosz co pewien czas i dla jednych ten interwał może być za krótki,
a dla innych za długi. Postaramy się więc go dostosować.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uwierzytelniające klucze SSH</title>
      <link>https://morfikov.github.io/post/uwierzytelniajace-klucze-ssh/</link>
      <pubDate>Tue, 02 Jun 2015 15:35:53 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uwierzytelniajace-klucze-ssh/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://wiki.archlinux.org/index.php/SSH_keys&#34;&gt;Klucze SSH&lt;/a&gt; mogą być wykorzystane jako sposób
identyfikacji danej osoby przy logowaniu się do zdalnego serwera SSH. Te klucze zawsze występują w
parach -- jeden prywatny, drugi publiczny. Pierwszy z nich jest znany tylko nam i powinien być
trzymany w sekrecie i pilnie strzeżony. Klucz publiczny z kolei zaś jest przesyłany na każdy serwer
SSH, z którym chcemy się połączyć. Gdy serwer jest w posiadaniu naszego klucza publicznego i widzi
przy tym, że próbujemy nawiązać połączenie, używa on tego klucza by wysłać do nas zapytanie
(challange) -- jest ono zakodowane i musi na nie zostać udzielona odpowiednia odpowiedź, a tej może
dokonać ktoś, kto jest w posiadaniu klucza prywatnego. Nie ma innej opcji by rozkodować wiadomość,
dlatego też nikt inny nie może udzielić na nią prawidłowej odpowiedzi. To rozwiązanie eliminuje
wrażliwość na różne formy podsłuchu -- ten kto nasłuchuje nie będzie w stanie przechwycić pakietów
zawierających hasło, bo ono nie jest nigdy transmitowane prze sieć. No i oczywiście jeśli chodzi o
samo hasło -- odpadają nam ataki typu Brute Force pod kątem jego złamania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Instalacja przy pomocy wp-cli</title>
      <link>https://morfikov.github.io/post/wordpress-instalacja-przy-pomocy-wp-cli/</link>
      <pubDate>Tue, 02 Jun 2015 14:43:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-instalacja-przy-pomocy-wp-cli/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/wordpress-wiersz-polecen-wp-cli/&#34;&gt;Ostatnio opisywałem skrypt wp-cli&lt;/a&gt; , który
posiada ciekawe możliwości pod względem zarządzania instalacją i konfiguracją WordPressa. W tym
artykule postaram się przebrnąć przez ten proces wykorzystując jedynie powyższe narzędzie. Nie mam
zamiaru korzystać z przeglądarki i nie będę przy tym nawet potrzebował odwiedzać strony WordPressa w
celu pobrania jakichkolwiek plików. Wszystkie poniższe kroki zostaną przeprowadzone w terminalu na
serwerze i mam nadzieję, że uda mi się pobrać, zainstalować i przygotować WordPressa do pracy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wordpress: Wiersz poleceń wp-cli</title>
      <link>https://morfikov.github.io/post/wordpress-wiersz-polecen-wp-cli/</link>
      <pubDate>Tue, 02 Jun 2015 09:36:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-wiersz-polecen-wp-cli/</guid>
      <description>&lt;p&gt;Narzędzie &lt;a href=&#34;http://wp-cli.org/&#34;&gt;wp-cli&lt;/a&gt; to wiersz poleceń upchnięty w pliku &lt;code&gt;.phar&lt;/code&gt; (PHP Archive),
przy pomocy którego możemy zarządzać instalacją WordPressa bez potrzeby zaprzęgania do tego
przeglądarki. Przy pomocy tego skryptu będziemy w stanie instalować i aktualizować rdzenne pliki
WordPressa, jego wtyczki i motywy, a także dokonywać szeregu operacji na bazie danych. Projekt jest
na licencji MIT, zaś jego źródła są dostępne na &lt;a href=&#34;https://github.com/wp-cli/wp-cli&#34;&gt;githubie&lt;/a&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Ukrycie wp-login.php oraz wp-admin/</title>
      <link>https://morfikov.github.io/post/wordpress-ukrycie-wp-login-php-oraz-wp-admin/</link>
      <pubDate>Sun, 31 May 2015 16:19:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-ukrycie-wp-login-php-oraz-wp-admin/</guid>
      <description>&lt;p&gt;By dokonywać jakichkolwiek zmian w WordPressie (i mowa tu nie tylko o dodawaniu treści ale także
zmianie jego plików źródłowych), to musimy uzyskać dostęp do panelu administracyjnego, a tu z kolei
możemy się dostać tylko za pośrednictwem formularza logowania. Panel admina możemy wywołać przez
dopisanie do adresu strony &lt;code&gt;wp-admin/&lt;/code&gt; , z tym, że jeśli nie jesteśmy zalogowani, to automatycznie
zostaniemy przekierowani na &lt;code&gt;wp-login.php&lt;/code&gt; . Nie oznacza to bynajmniej, że nie możemy wykonać
zapytania do plików znajdujących się w katalogu &lt;code&gt;wp-admin/&lt;/code&gt; . Obie te powyższe lokalizacje muszą być
traktowane ze szczególną ostrożnością, a dostęp do nich limitowany i bardzo restrykcyjny.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Wersja obecna w kodzie źródłowym</title>
      <link>https://morfikov.github.io/post/wordpress-wersja-obecna-w-kodzie-zrodlowym/</link>
      <pubDate>Sun, 31 May 2015 11:38:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-wersja-obecna-w-kodzie-zrodlowym/</guid>
      <description>&lt;p&gt;Standardowo WordPress dorzuca nieco informacji na swój temat bezpośrednio do kodu wygenerowanej
witryny. Jednym z bardziej niebezpiecznych takich dodatkowych wpisów jest wskazówka na temat
zainstalowanej wersji skryptu. Oczywiście, że powinniśmy aktualizować WordPressa na bieżąco i
możliwie od razu jak tylko zostanie wypuszczona jego nowa wersja ale nie zawsze możemy nadążyć za
tymi wszystkimi zmianami i wyrobić się w terminach. Ja jestem też zdania, że kluczowe oprogramowanie
(zwłaszcza w internecie) powinno posiadać wersję nie do ustalenia, albo chociaż jakiś mylący ciąg
znaków, tak by automatyczne ataki opierające się o wersję danej aplikacji, nie tyle zostawiły nas w
spokoju, co zaczęły popełniać błędy, które będą widoczne w logach. Przynajmniej takie jest
optymistyczne założenie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DKMS, czyli automatycznie budowane moduły</title>
      <link>https://morfikov.github.io/post/dkms-czyli-automatycznie-budowane-moduly/</link>
      <pubDate>Sat, 30 May 2015 21:05:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dkms-czyli-automatycznie-budowane-moduly/</guid>
      <description>&lt;p&gt;Jeśli zamierzamy kupić sprzęt, który dopiero co trafił na półki w sklepach, to prawdopodobnie zaraz
po podłączeniu go do naszego komputera okaże się, że to urządzenie nie jest nawet wykrywane przez
system operacyjny. W przypadku gdy jego producent zapewnia w miarę przyzwoity support, to być może
problemy, których doświadczamy, zostaną rozwiązane wraz z instalacją najnowszego kernela. Co jednak
w przypadku gdy nawet po aktualizacji kernela nie jesteśmy w stanie odpalić, np. nowo zakupionej
karty WiFi? Jako, że te wszystkie sprzęty działają w oparciu określone moduły, wystarczy taki moduł
pozyskać, skompilować i załadować w systemie. Problem w tym, że z każdą nową wersją jądra
operacyjnego, która trafi do repo debiana, będziemy musieli ręcznie budować moduł na nowo i właśnie
w tym artykule opiszę jak nauczyć system, by sam przeprowadzał tę mozolną czynność bez naszego
udziału.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Domyślny język instalacji</title>
      <link>https://morfikov.github.io/post/wordpress-domyslny-jezyk-instalacji/</link>
      <pubDate>Sat, 30 May 2015 17:59:03 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-domyslny-jezyk-instalacji/</guid>
      <description>&lt;p&gt;WordPress, jako jeden z popularniejszych CMSów, &lt;a href=&#34;https://make.wordpress.org/polyglots/teams/&#34;&gt;został przetłumaczony na wiele
języków&lt;/a&gt;, w tym też i na
&lt;a href=&#34;https://pl.wordpress.org/&#34;&gt;polski&lt;/a&gt;. Czasem jednak przez zwykłe roztargnienie (lub też i z innych
przyczyn) możemy nie przestawić opcji odpowiedzialnej za język, wobec czego zainstaluje nam się
angielska wersja WordPressa. W tym krótkim wpisie zostanie zawartych kilka informacji na temat tego
jak zmienić język, na wypadek gdybyśmy odziedziczyli angielską wersję skryptu oraz też jak przebiega
sam proces lokalizacji tekstu w WordPressie i co się tak naprawdę dzieje po wybraniu innego języka.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Zapomniane hasło administratora</title>
      <link>https://morfikov.github.io/post/wordpress-zapomniane-haslo-administratora/</link>
      <pubDate>Thu, 28 May 2015 17:44:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-zapomniane-haslo-administratora/</guid>
      <description>&lt;p&gt;Być może kiedyś zdarzy się nam taka sytuacja, gdzie zwyczajnie zapomnimy hasła do konta admina na
naszym blogu opartym o skrypt Wordpressa. Standardowo ten CMS nie wymaga od nas byśmy podawali hasło
przy przeprowadzaniu szeregu operacji w panelu administracyjnym, w przeciwieństwie do usług
świadczonych choćby przez google. Jeśli zdarzy nam się zgubić albo zapomnieć takie hasło, to mamy
&lt;a href=&#34;https://codex.wordpress.org/Resetting_Your_Password&#34;&gt;cały wachlarz rozwiązań&lt;/a&gt;, z którego możemy
skorzystać, by hasło odzyskać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Typografia, czyli zawinięte ogonki</title>
      <link>https://morfikov.github.io/post/wordpress-typografia-czyli-zawiniete-ogonki/</link>
      <pubDate>Thu, 28 May 2015 14:59:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-typografia-czyli-zawiniete-ogonki/</guid>
      <description>&lt;p&gt;Typografia ma na celu wprowadzenie pewnego rodzaju urozmaiceń do pisanego tekstu, takich jak np.
bardziej zawinięte ogonki w cudzysłowach, albo zmianę ich pozycji (lewy dolny róg, zamiast górnego),
czy też mniejszy odstęp między trzema kropkami lub ewentualnie łączenie kilku myślników w jeden
dłuższy. W WordPressie ten mechanizm automatycznie będzie przepisywał nam te powyższe znaki (i
wiele innych), co w przypadku systemów linuxowych nie zawsze jest rzeczą pożądaną, a to z tego
względu, że np. skrypty shellowe, czy polecenia systemowe, korzystają jedynie z prostych apostrofów
&lt;code&gt;&#39;&lt;/code&gt; oraz prostych cudzysłowów &lt;code&gt;&amp;quot;&lt;/code&gt; i wszelkie inne odpowiedniki, to inny numerek w tablicy kodowej, a
więc i inny znak. Wobec czego, tak skopiowany tekst (czy skrypt) będzie zawierał błędy składni.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatyczne wyciszanie dźwięku w PulseAudio</title>
      <link>https://morfikov.github.io/post/automatyczne-wyciszanie-dzwieku-w-pulseaudio/</link>
      <pubDate>Thu, 28 May 2015 11:43:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/automatyczne-wyciszanie-dzwieku-w-pulseaudio/</guid>
      <description>&lt;p&gt;Wszystkie główne dystrybucje, a może raczej ich środowiska graficzne, wykorzystują do odtwarzania
dźwięku &lt;a href=&#34;https://www.freedesktop.org/wiki/Software/PulseAudio/&#34;&gt;serwer PulseAudio&lt;/a&gt; . Niektóre wręcz
są tak z nim zżyte, że nie idzie ich oddzielić od siebie. Ja generalnie uważam, że ten kawałek
oprogramowania jest jak najbardziej przydatny człowiekowi i potrafi realizować kilka kwestii, które
bez niego, albo by nie były możliwe do osiągnięcia, albo trzeba by się natrudzić przy ich
implementacji, np. przesyłanie dźwięku przez sieć. U siebie na debianie nigdy nie miałem większych
problemów z PulseAudio, z kolei zaś te, które się przytrafiały na drodze jego użytkowania, szło w
miarę prosty sposób wyeliminować. Jest jednak jeden problem, z którym prawdopodobnie spotkaliśmy się
wszyscy, przynajmniej jeśli wykorzystujemy mikrofon w stopniu większym niż przeciętny użytkownik
komputera. Chodzi o to, że po odpaleniu pewnych aplikacji (lub też i w trakcie ich działania),
takich jak np. Skype, Mumble, czy TeamSpeak3, dźwięk we wszystkich pozostałych programach potrafi
zwyczajnie zdechnąć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Tryb debugowania</title>
      <link>https://morfikov.github.io/post/wordpress-tryb-debugowania/</link>
      <pubDate>Wed, 27 May 2015 12:08:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-tryb-debugowania/</guid>
      <description>&lt;p&gt;Gdy wprowadzamy sporo zmian na swoim blogu i nie mam tutaj na myśli dodawania/edytowania/usuwania
postów, a jedynie przeróbki dotyczące zmiany wyglądu motywu czy też instalowanie i konfigurowanie
nowych wtyczek, to istnieje spore prawdopodobieństwo, że gdzieś wystąpi jakiś błąd, który może
zagrażać bezpieczeństwu całej witryny. Dlatego też warto wiedzieć, że WordPress &lt;a href=&#34;https://codex.wordpress.org/Debugging_in_WordPress&#34;&gt;posiada obsługę
trybu debug&lt;/a&gt;, który może nam te wszystkie
problemy z działaniem serwisu uwidocznić. Nie jest on jednak standardowo włączony, z oczywistych
względów ale jeśli zajdzie taka potrzeba, to możemy sobie ten tryb debugowania aktywować i sprawdzić
czy są jakieś błędy, ostrzeżenia czy też inne dodatkowe informacje, które mogą nam w jakiś sposób
pomóc.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Zmiana interwału auto zapisu postów</title>
      <link>https://morfikov.github.io/post/wordpress-zmiana-interwalu-auto-zapisu-postow/</link>
      <pubDate>Tue, 26 May 2015 19:35:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-zmiana-interwalu-auto-zapisu-postow/</guid>
      <description>&lt;p&gt;WordPress dysponuje bardzo rozbudowanym edytorem, przy pomocy którego można tworzyć dość
zaawansowane posty. Ten edytor potrafi nawet automatycznie zapisywać stan artykułu przesyłając w ten
sposób zmiany do bazy danych, co zapobiega utracie treści. Oczywiście, że potrzebna będzie dodatkowa
przestrzeń w samej bazie by kolejną kopię postu przechować ale wydaje się to niebyt wygórowaną ceną
za minimalizowanie ryzyka utraty części albo i całego wpisu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Wyłączenie systemu rewizji postów</title>
      <link>https://morfikov.github.io/post/wordpress-wylaczenie-systemu-rewizji-postow/</link>
      <pubDate>Tue, 26 May 2015 16:40:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-wylaczenie-systemu-rewizji-postow/</guid>
      <description>&lt;p&gt;System rewizji postów to nic innego jak wersjowanie kolejnych zmian tworzonych artykułów za pomocą
WordPress&#39;owego edytora. Domyślnie &lt;a href=&#34;https://codex.wordpress.org/Revision_Management&#34;&gt;ten ficzer jest
włączony&lt;/a&gt; i powoduje nadmierne rozrastanie się
bazy danych, a to z tego powodu, że każda drobna poprawka, to kolejna wersja artykułu, która wędruje
do bazy. Nie ma przy tym żadnego ograniczenia co do ilości przechowywanych rewizji. Tego typu
mechanizm jest w wielu przypadkach bardzo użyteczny, no bo przecie mamy podgląd wszelkich zmian
wprowadzanych do postów i dodatkowo możemy te zmiany śledzić na przestrzeni tygodni, miesięcy czy
nawet i lat.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problemy wynikające z używania pliku .htaccess</title>
      <link>https://morfikov.github.io/post/problemy-wynikajace-z-uzywania-pliku-htaccess/</link>
      <pubDate>Tue, 26 May 2015 13:25:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problemy-wynikajace-z-uzywania-pliku-htaccess/</guid>
      <description>&lt;p&gt;Na stronie Apache jest &lt;a href=&#34;http://httpd.apache.org/docs/2.0/howto/htaccess.html#when&#34;&gt;kawałek ciekawego
artykułu&lt;/a&gt; na temat zagrożeń jakie niesie
ze sobą stosowanie pliku &lt;code&gt;.htaccess&lt;/code&gt; w katalogach stron trzymanych na serwerze wwww. Oczywiście, w
pewnych sytuacjach, takich jak np. hostingi, nie będziemy mieć innego wyboru jak zdać się na ten
plik ale jeśli mamy bezpośredni dostęp do konfiguracji Apache, możemy przenieść wszystkie te wpisy z
pliku &lt;code&gt;.htaccess&lt;/code&gt; i poprawić tym bezpieczeństwo witryny jak i po części wydajność samego serwera
www.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wymuszenie SSL/TLS przy pomocy vhost&#39;ów w Apache2</title>
      <link>https://morfikov.github.io/post/wymuszenie-ssl-tls-przy-pomocy-vhostow-apache2/</link>
      <pubDate>Tue, 26 May 2015 11:24:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wymuszenie-ssl-tls-przy-pomocy-vhostow-apache2/</guid>
      <description>&lt;p&gt;Mając na stronie www formularze logowania czy rejestracji (ewentualnie panele administracyjne),
rozmyślnym krokiem jest implementacja protokołu SSL/TLS. Jeśli mamy potrzebę, możemy także pokusić
się o zaszyfrowanie całego ruchu w obrębie naszej witryny. Problem w tym, że odwiedzający naszą
stronę użytkownicy mogą korzystać z linków, czy wpisywać adresy, które nie rozpoczynają się od
&lt;code&gt;https://&lt;/code&gt; , a jedynie od &lt;code&gt;http://&lt;/code&gt; . W takim przypadku, nawet jeśli szyfrujemy ruch w serwisie, to
odwiedzenie tego typu adresu zwróci nam stronę kanałem nieszyfrowanym, co może godzić w
bezpieczeństwo samej strony jak i również w naszą/czyjąś prywatność. W tym krótki artykule
spróbujemy tak skonfigurować serwer Apache2, by przekierował tego typu zapytania i słał je
szyfrowanym tunelem.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Jak zmienić prefiks bazy danych</title>
      <link>https://morfikov.github.io/post/wordpress-jak-zmienic-prefiks-bazy-danych/</link>
      <pubDate>Mon, 25 May 2015 20:02:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-jak-zmienic-prefiks-bazy-danych/</guid>
      <description>&lt;p&gt;Każda instalacja tych popularniejszych (i wszystkich pozostałych) CMS&#39;ów powinna być w miarę
niepowtarzalna, by utrudnić automatyzację ataków. Blog WordPress&#39;a opiera się o bazę danych. Mamy
tam kilka tabel, z których każda jest poprzedzona pewnym prefiksem. Czy zmiana tego prefiksu &lt;code&gt;wp_&lt;/code&gt;
na jakiś losowo wybrany przez nas ma jakiś sens? Czy ochroni nas to przed jakimiś formami ataku? W
tym wpisie postaramy się prześledzić proces zmiany prefiksu do tabel w bazie danych.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Zmiana domyślnych nazw folderów</title>
      <link>https://morfikov.github.io/post/wordpress-zmiana-domyslnych-nazw-folderow/</link>
      <pubDate>Mon, 25 May 2015 15:03:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-zmiana-domyslnych-nazw-folderow/</guid>
      <description>&lt;p&gt;Internet to bardzo niebezpieczne miejsce i do tego pełne różnego rodzaju botów szukających
ujawnionych już podatności i niekoniecznie rozchodzi się o kod WordPressa. Tak czy inaczej,
WodrPress to bardzo popularny CMS, którego instalacja przebiega (i wygląda) praktycznie tak samo i
to bez znaczenia gdzie nie zostałby on zainstalowany. Chodzi o to, że zawsze mamy do czynienia z
tymi samymi skryptami czy nazwami katalogów. Nie zmieniają się także ścieżki to plików, no i
oczywiście pluginy, których większa ilość może zagrozić bezpieczeństwu naszej strony. Nie chodzi mi
tutaj o pilnowanie instalacji i ciągłe aktualizowanie kodu, bo to rozumie się samo przez się. Chodzi
mi generalnie o &lt;a href=&#34;https://codex.wordpress.org/Editing_wp-config.php#Moving_wp-content_folder&#34;&gt;zmodyfikowanie nieco samej instalacji&lt;/a&gt; WordPress&#39;a, tak by nie przypominała
wszystkich pozostałych. W ten sposób możemy się uchronić przed zautomatyzowanymi robotami (i innym
syfem), które są w stanie podrzucić coś nam na stronę o ile ta ma domyślne ścieżki. Im wcześniej
zabierzemy się za zmianę domyślnych nazw katalogów, tym lepiej, bo jeśli w przyszłości będziemy
zmieniać te nazwy i to na blogu czy w serwisie gdzie mamy sporo kontentu w postaci grafiki czy innej
załączonej treści, wtedy trzeba będzie te linki przepisać, bo przestaną zwyczajnie działać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Logjam, czyli nowa podatność w SSL/TLS</title>
      <link>https://morfikov.github.io/post/logjam-czyli-nowa-podatnosc-w-ssltls/</link>
      <pubDate>Mon, 25 May 2015 08:12:39 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/logjam-czyli-nowa-podatnosc-w-ssltls/</guid>
      <description>&lt;p&gt;Jak donoszą &lt;a href=&#34;https://blog.cryptographyengineering.com/2015/05/22/attack-of-week-logjam/&#34;&gt;ostatnio&lt;/a&gt;
&lt;a href=&#34;https://niebezpiecznik.pl/post/logjam-nowa-podatnosc-w-protokolach-https-ssh-i-ipsec/&#34;&gt;media&lt;/a&gt;, mamy
kolejną dziurę (&lt;em&gt;&lt;strong&gt;logjam&lt;/strong&gt;&lt;/em&gt;) dotyczącą szyfrowania SSL/TLS, a konkretnie rozchodzi się o
powszechnie stosowany na całym świecie protokół
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Protok%C3%B3%C5%82_Diffiego-Hellmana&#34;&gt;Diffiego-Hellmana&lt;/a&gt; . I znów
jest podobny scenariusz, bo ten problem nie powinien mieć miejsca ale z powodu wstecznej
kompatybilności, tj. zapewnienie wsparcia dla wszystkich tych przestarzałych szyfrów tak by te
przedwieczne systemy/maszyny mogły działać, można doprowadzić do osłabienie mechanizmów, które
powinny być wykorzystywane obecnie. OK, może nie tyle osłabić, co wykorzystać te słabsze
odpowiedniki zamiast tych mocniejszych.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Szyfrowanie SSL/TLS</title>
      <link>https://morfikov.github.io/post/wordpress-szyfrowanie-ssltls/</link>
      <pubDate>Sun, 24 May 2015 19:54:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-szyfrowanie-ssltls/</guid>
      <description>&lt;p&gt;W dzisiejszych czasach bez szyfrowania ani rusz i na dobrą sprawę by prowadzić jakikolwiek serwis
www, trzeba wliczyć w koszty overhead jaki niesie ze sobą zaszyfrowanie zawartości takiej witryny.
Oczywiście, niektórzy minimalizują straty ograniczając się jedynie do zaszyfrowania formularza
rejestracji/logowania lub też i ewentualnego panelu administracyjnego. Tak czy inaczej, &lt;a href=&#34;https://codex.wordpress.org/Administration_Over_SSL&#34;&gt;WordPress
domyślnie nie szyfruje niczego&lt;/a&gt; i przydałoby
się zmienić nieco jego konfigurację.&lt;/p&gt;
&lt;p&gt;Poniższe instrukcje zadziałają jedynie w przypadku gdy pod serwer mamy już podpięty certyfikat. Nie
będę tutaj opisywał jak poprawnie skonfigurować serwer Apache by włączyć w nim obsługę szyfrowania
SSL/TLS. Jak znajdę trochę czasu, to na pewno wstawię tutaj link do przystępnego opisu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Odnośniki bezpośrednie (permalinks)</title>
      <link>https://morfikov.github.io/post/wordpress-odnosniki-bezposrednie-permalinks/</link>
      <pubDate>Sun, 24 May 2015 13:33:53 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-odnosniki-bezposrednie-permalinks/</guid>
      <description>&lt;p&gt;Permalinks, czyli &lt;a href=&#34;https://codex.wordpress.org/Using_Permalinks&#34;&gt;odnośniki bezpośrednie&lt;/a&gt;, stosowane
są głównie w celach estetycznych oraz by poprawić nieco
&lt;a href=&#34;https://pl.wikipedia.org/wiki/Optymalizacja_dla_wyszukiwarek_internetowych&#34;&gt;SEO&lt;/a&gt; danego artykułu
czy postu. Jeśli chodzi o efekty wizualne, to raczej wszyscy się zgodzimy, że link w postaci
&lt;code&gt;morfitronik.pl/wordpress-administrator-bloga/&lt;/code&gt; jest o wiele prostszy do odszyfrowania dla człowieka
niż link typu &lt;code&gt;morfitronik.pl/?p=1&lt;/code&gt; . Natomiast w przypadku SEO mamy kluczowe słowa czy fazy
bezpośrednio w linku, który jest indeksowany i wyświetlany przez wyszukiwarki, np. google. W tym
wpisie postaramy skonfigurować sobie właśnie te odnośniki.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: Administrator bloga</title>
      <link>https://morfikov.github.io/post/wordpress-administrator-bloga/</link>
      <pubDate>Sun, 24 May 2015 11:28:16 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-administrator-bloga/</guid>
      <description>&lt;p&gt;Domyślna konfiguracja użytkowników w WordPress&#39;ie nie należy do bezpiecznych. Samą nazwę
administratora witryny możemy naturalnie zmienić podczas instalacji tego CMS&#39;a i prawdopodobnie ten
zabieg wystarczy większości blogerom. Jednak z punktu widzenia bezpieczeństwa instalacji naszego
bloga, nie powinniśmy się ograniczać jedynie do zmiany nazwy konta administracyjnego. Administrator
ma za zadanie zarządzać blogiem, natomiast konta autorów wpisów podlegają już pod osobną grupę i o
nie również powinniśmy się zatroszczyć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WordPress: &#34;Briefly unavailable for scheduled maintenance&#34;</title>
      <link>https://morfikov.github.io/post/wordpress-briefly-unavailable-for-scheduled-maintenance/</link>
      <pubDate>Sat, 23 May 2015 11:55:52 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wordpress-briefly-unavailable-for-scheduled-maintenance/</guid>
      <description>&lt;p&gt;Prawdopodobnie przyjdzie nam kiedyś zobaczyć komunikat &lt;code&gt;Briefly unavailable for scheduled maintenance. Check back in a minute.&lt;/code&gt; podczas przeglądania zawartości naszej strony www czy też
bloga opartego na skrypcie WordPressa. Ja początkowo myślałem, że aktualizacja pluginów (lub też i
samego WordPressa) zajmuje dłużej niż zwykle ale okazało się jednak, że sam update zakończył się
powodzeniem i to z grubsza od razu. Niemniej jednak, ten komunikat widniał na stronie głównej mojego
testowego bloga i nie szło wbić nawet do panelu admina by coś w tej sytuacji zaradzić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja kluczy GPG w repozytorium GIT</title>
      <link>https://morfikov.github.io/post/implementacja-kluczy-gpg-repozytorium-git/</link>
      <pubDate>Sun, 17 May 2015 21:11:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-kluczy-gpg-repozytorium-git/</guid>
      <description>&lt;p&gt;W tym artykule zostanie przedstawiony sposób na wykorzystanie kluczy GPG w przypadku
przeprowadzanych działań w repozytorium GIT. Będziemy w ten sposób w stanie podpisać swoje commit&#39;y
czy tagi, by było wiadomo, że zmiany, które zostały poczynione pochodzą naprawdę od konkretnego
użytkownika. Oczywiście to może się wydać przesadą dla wielu ludzi ale skoro mamy udostępnioną
możliwość wykorzystania kluczy GPG, to czemu z tej opcji nie skorzystać? Potrzebne będą nam tylko
&lt;a href=&#34;https://morfikov.github.io
/post/bezpieczny-klucz-gpg/&#34;&gt;klucze GPG&lt;/a&gt;. Sposób ich tworzenia jak i &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-gpg-w-pliku-gpg-conf/&#34;&gt;konfiguracja
zdefiniowana w pliku gpg.conf&lt;/a&gt; nie
zostaną tutaj opisane. Zamiast tego skupimy się jedynie na implementacji samych kluczy GPG.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Github z obsługą kluczy SSH</title>
      <link>https://morfikov.github.io/post/github-z-obsluga-kluczy-ssh/</link>
      <pubDate>Sun, 17 May 2015 21:06:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/github-z-obsluga-kluczy-ssh/</guid>
      <description>&lt;p&gt;W końcu przyszedł czas na eksperymenty z serwisem github. Jakby nie patrzeć, do tej pory jedyne co
potrafiłem zrobić w przypadku samego gita, to wydać jedno polecenie, którym było &lt;code&gt;git clone&lt;/code&gt; .
Wszelkie inne rzeczy, choć nie było ich wcale tak dużo, robiłem via panel www, co trochę było
upierdliwe. Postanowiłem nauczyć się obsługi gita i nieco uprościć sobie życie. Jeśli chodzi o samą
naukę, to tutaj jest dostępny &lt;a href=&#34;https://git-scm.com/book/en/v2&#34;&gt;dość obszerny pdf&lt;/a&gt; (prawie 500
stron). Nie będę tutaj przerabiał wyżej podlinkowanej książki, bo w sumie jeszcze jej nie
przeczytałem, tylko zajmę się ciekawym tematem jakim jest implementacja kluczy SSH, tak by operować
na gicie bez zbędnych haseł.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Skryptowa nakładka na kernelowski moduł ZRAM</title>
      <link>https://morfikov.github.io/post/skryptowa-nakladka-na-kernelowski-modul-zram/</link>
      <pubDate>Sun, 17 May 2015 21:01:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/skryptowa-nakladka-na-kernelowski-modul-zram/</guid>
      <description>&lt;p&gt;ZRAM to moduł kernela, który tworzy wirtualne urządzenia w pamięci operacyjnej komputera, a te z
kolei można wykorzystać pod system plików lub też i pod przestrzeń wymiany SWAP. Dane w takim
urządzeniu są kompresowane, dzięki czemu mamy do dyspozycji więcej miejsca w pamięci. Jeśli mamy
niepierwszej jakości dysk twardy, lub też wykorzystujemy szyfrowanie i nie mamy przy tym procka ze
wsparciem dla AES, to operacje zapisu/odczytu mogą zająć wieki. Możemy w dość znacznym stopniu
odciążyć dysk przenosząc pliki do pamięci RAM, który jest o wiele szybszy, no i dane w nim nie
podlegają szyfrowaniu. Jeśli mamy dużo pamięci operacyjnej, to ZRAM raczej będzie zbędny i tylko
podniesie nam rachunek za prąd. Natomiast jeśli nasz komputer nie szasta zbytnio pamięcią, możemy
rozszerzyć ją 2-3 krotnie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bezpieczeństwo Xserver&#39;a pod linux&#39;em</title>
      <link>https://morfikov.github.io/post/bezpieczenstwo-xservera-pod-linuxem/</link>
      <pubDate>Sat, 09 May 2015 17:21:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/bezpieczenstwo-xservera-pod-linuxem/</guid>
      <description>&lt;p&gt;Prawdopodobnie każdy z nas korzysta, lub też i korzystał, ze skrótu klawiszy Ctrl-Alt-Backspace do
resetowania środowiska graficznego na linux&#39;ie. Może i to jest wygodny sposób na szybki restart
&lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-xservera-na-debianie-xorg/&#34;&gt;sesji graficznej Xserver&#39;a&lt;/a&gt; ale
&lt;a href=&#34;https://www.jwz.org/xscreensaver/faq.html#no-ctl-alt-bs&#34;&gt;nie do końca jest on bezpieczny&lt;/a&gt;. Nie
mówię tutaj o samej utracie danych towarzyszącej takiej akcji ale o możliwości obejścia ekranu
logowania o ile ta kombinacja klawiszy nie jest wyłączona. Jest też kilka innych rzeczy, które mogą
skompromitować źle zabezpieczony Xserver i tej kwestii będzie poświęcony niniejszy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Info/Kontakt</title>
      <link>https://morfikov.github.io/page/info-kontakt/</link>
      <pubDate>Fri, 01 May 2015 00:00:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/page/info-kontakt/</guid>
      <description>Mikhail Morfikov (Morfik) to mój pseudonim artystyczny, który sobie obrałem lata temu i pod tym nazwiskiem występuję w sieci. Stworzenie tej wirtualnej tożsamości miało na celu odseparowanie mojego życia prywatnego od tego internetowego. Z jednej strony miał to być jedynie eksperyment socjologiczny, przy pomocy którego starałem się odpowiedzieć na pytanie, czy w obecnych czasach da radę uciec przed coraz to bardziej zaglądającą w nasze życie prywatne inwigilacją. Jakby nie patrzeć, postępująca technologia ułatwia zbieranie coraz to większej ilości informacji na nasz temat i do tego umożliwia to na taką skalę, że nawet filozofom się o tym nie śniło.</description>
    </item>
    
    <item>
      <title>Wsparcie</title>
      <link>https://morfikov.github.io/page/wsparcie/</link>
      <pubDate>Fri, 01 May 2015 00:00:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/page/wsparcie/</guid>
      <description>Blog powstał z chęci dzielenia się zdobytą (i zdobywaną) wiedzą z osobami o podobnych zainteresowaniach. Wszelkie materiały w serwisie są publikowane na wolnej licencji umożliwiającej ich kopiowanie. Na blogu nie ma reklam i nigdy ich nie będzie i to nie dlatego, że kompletnie nie mam pojęcia jak się zabrać za ich implementację. xD Wierzę, że jeśli idea jest słuszna, to znajdą się również i ludzie, którzy będą chcieli ją finansować.</description>
    </item>
    
  </channel>
</rss>