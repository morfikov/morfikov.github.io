<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>debian on Morfitronik</title>
    <link>https://morfikov.github.io/tags/debian/</link>
    <description>Recent content in debian on Morfitronik</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pl-PL</language>
    <lastBuildDate>Mon, 10 Aug 2020 18:15:00 +0000</lastBuildDate>
    
	<atom:link href="https://morfikov.github.io/tags/debian/feed.xml" rel="self" type="application/rss" />
    
    
    <item>
      <title>Jak włączyć w Firefox ESNI (Encrypted SNI)</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-w-firefox-esni-encrypted-sni/</link>
      <pubDate>Mon, 10 Aug 2020 18:15:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-w-firefox-esni-encrypted-sni/</guid>
      <description>&lt;p&gt;Obecnie szyfrowanie zapytań DNS staje się powoli normą za sprawą protokołu DoH (&lt;a href=&#34;https://en.wikipedia.org/wiki/DNS_over_HTTPS&#34;&gt;DNS over HTTPS&lt;/a&gt;)
lub DoT (&lt;a href=&#34;https://en.wikipedia.org/wiki/DNS_over_TLS&#34;&gt;DNS over TLS&lt;/a&gt;). Można by zatem pomyśleć, że wraz z implementacją szyfrowania tego
kluczowego dla działania internetu protokołu (przynajmniej z naszego ludzkiego punktu widzenia),
poprawie ulegnie również nasza prywatność w kwestii odwiedzanych przez nas stron WWW. Niemniej
jednak, w dalszym ciągu można bez problemu wyciągnąć adresy domen, które zamierzamy odwiedzić. Nie
ma przy tym żadnego znaczenia ile stron jest hostowanych na danym adresie IP, ani nawet fakt, że
ruch do serwera WWW będzie szyfrowany (w pasku adresu wpiszemy &lt;code&gt;https://&lt;/code&gt; ) z wykorzystaniem
protokołu SSL/TLS (w tym również TLS v1.3). Wszystko przez rozszerzenie SNI (&lt;a href=&#34;https://en.wikipedia.org/wiki/Server_Name_Indication&#34;&gt;Server Name
Indication&lt;/a&gt;), którego to zadaniem jest umożliwienie jednemu serwerowi na prezentowanie wielu
certyfikatów hostowanych w jego obrębie domen. Dzięki takiemu rozwiązaniu, każda domena może
szyfrować ruch niezależnie od siebie na linii serwer&amp;lt;-&amp;gt;klient (używać innych kluczy szyfrujących).
Niemniej jednak, podczas nawiązywania szyfrowanego połączenia, w pakiecie ClientHello przesyłanym
do takiego serwera musi znaleźć się nazwa domeny, której to certyfikat serwer będzie musiał nam
przedstawić. Niestety ten pakiet jest przesyłany przez sieć otwartym tekstem, przez co każdy, kto
podsłuchuje naszą komunikację (w tym też nasz ISP), bez problemu może ustalić na jakie strony
internetowe wchodzimy. Ostatnimi czasy jednak pojawiły się dwa rozszerzenia ECH (&lt;a href=&#34;https://en.wikipedia.org/wiki/Server_Name_Indication#Encrypted_Client_Hello&#34;&gt;Encrypted Client
Hello&lt;/a&gt;) oraz ESNI (&lt;a href=&#34;https://tools.ietf.org/html/draft-ietf-tls-esni-07&#34;&gt;Encrypted SNI&lt;/a&gt;), które mają zaadresować problemy związane z prywatnością
przez pełne zaszyfrowanie pakietu ClientHello lub też zaszyfrowanie jedynie pola SNI w tym pakiecie.
Póki co, prace nad tymi rozszerzeniami nie są jeszcze skończone ale Firefox w połączeniu z
CloudFlare powoli testują ESNI. Postanowiłem zatem dobrowolnie przyłączyć się do grupy testerów i
wdrożyć na swoim linux&#39;ie to rozszerzenie ESNI dla przeglądarki Firefox.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zmienić rozmiar obrazu maszyny wirtualnej QEMU/KVM</title>
      <link>https://morfikov.github.io/post/jak-zmienic-rozmiar-obrazu-maszyny-wirtualnej-qemu-kvm/</link>
      <pubDate>Sun, 09 Aug 2020 13:45:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zmienic-rozmiar-obrazu-maszyny-wirtualnej-qemu-kvm/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio &lt;a href=&#34;https://morfikov.github.io
/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/&#34;&gt;maszynami wirtualnymi na bazie QEMU/KVM&lt;/a&gt;, zauważyłem, że sugerowany rozmiar
pliku &lt;code&gt;.qcow2&lt;/code&gt; waha się w okolicach 25 GiB. Nie jest to może jakoś specjalnie dużo ale mało to też
nie jest, zwłaszcza jeśli tworzymy maszyny wirtualne na dysku swojego laptopa. Co jeśli
przeholowaliśmy z szacunkami co do rozmiaru takiego obrazu i po zainstalowaniu systemu operacyjnego
gościa okazało się, że w sumie to ten obraz można by zmniejszyć o połowę? Albo też i w drugą stronę,
tj. co w przypadku, gdy stworzony obraz maszyny wirtualnej okazał się zbyt mały i teraz zachodzi
potrzeba jego powiększenia? Czy w takiej sytuacji musimy na nowo tworzyć maszynę wirtualną
odpowiednio zwiększając lub zmniejszając jej przestrzeń na pliki? A może istnieje jakiś sposób na
zmianę rozmiaru tych istniejących już obrazów maszyn wirtualnych? Postaramy się ten fakt
zweryfikować, a cały proces zostanie opisany przy wykorzystaniu systemu Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja HugePages pod maszyny wirtualne QEMU/KVM</title>
      <link>https://morfikov.github.io/post/konfiguracja-hugepages-pod-maszyny-wirtualne-qemu-kvm/</link>
      <pubDate>Sun, 09 Aug 2020 11:11:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-hugepages-pod-maszyny-wirtualne-qemu-kvm/</guid>
      <description>&lt;p&gt;W linux rozmiar stron pamięci operacyjnej RAM ma domyślnie 4096 bajtów (4 KiB). Maszyny wirtualne
QEMU/KVM mają to do siebie, że wykorzystują dość spore zasoby pamięci (wile GiB), przez co mały
rozmiar strony może niekorzystnie wpływać na wydajność systemów gościa. Chodzi generalnie o to, że
rozrostowi ulega tablica stron, której przeszukiwanie jest czasochłonną operacją. By temu zaradzić,
wymyślono TLB (&lt;a href=&#34;https://en.wikipedia.org/wiki/Translation_lookaside_buffer&#34;&gt;Translation Lookaside Buffer&lt;/a&gt;), który ulokowany jest albo w CPU albo gdzieś
pomiędzy CPU i główną pamięcią operacyjną. TLB to mały ale za to bardzo szybki cache. W przypadku
systemów z duża ilością pamięci RAM, niewielki rozmiar TLB sprawia, że odpowiedzi na zapytania nie
są brane z cache, tylko system wraca do przeszukiwania normalnej tablicy stron zlokalizowanej w
pamięci RAM (TLB miss). Taka sytuacja jest bardzo kosztowna, spowalnia cały system i dlatego trzeba
jej unikać. Na szczęście jest &lt;a href=&#34;https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt&#34;&gt;mechanizm HugePages&lt;/a&gt;, który pozwala na zwiększenie rozmiaru
strony pamięci z domyślnych 4 KiB do 2 MiB lub nawet do 1 GiB w zależności od właściwości głównego
procesora. W tym artykule postaramy się skonfigurować HugePages na potrzeby maszyn wirtualnych dla
systemu Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wirtualizacja QEMU/KVM (libvirt) na Debian Linux</title>
      <link>https://morfikov.github.io/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/</link>
      <pubDate>Sat, 08 Aug 2020 14:55:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wirtualizacja-qemu-kvm-libvirt-na-debian-linux/</guid>
      <description>&lt;p&gt;Prawdopodobnie dla większości użytkowników linux&#39;a, wirtualizacja kojarzy się w zasadzie z jednym
oprogramowaniem, tj. VirtualBox. &lt;a href=&#34;https://www.virtualbox.org/&#34;&gt;Niby strona VBox&#39;a podaje, że jest on na licencji GPL-2&lt;/a&gt; ale
w Debianie nie ma go w głównym repozytorium (jest on obecny w sekcji &lt;code&gt;contrib&lt;/code&gt; ). Problem z
VirtualBox&#39;em jest taki, że &lt;a href=&#34;https://salsa.debian.org/pkg-virtualbox-team/virtualbox/-/blob/master/debian/copyright&#34;&gt;wymaga on kompilatora Open Watcom&lt;/a&gt;, który już wolnym
oprogramowaniem nie jest. VBox też nie jest jedynym oprogramowaniem, które na linux można
wykorzystać w roli hiperwizora do obsługi maszyn wirtualnych. Jest o wiele lepsze rozwiązanie,
mianowicie QEMU, które jest w stanie zrobić użytek z maszyny wirtualnej kernela (Kernel Virtual
Machine, KVM) i realizować dokładnie to samo zadanie, które zwykł ogarniać VirtualBox.
Wirtualizacja na bazie QEMU/KVM jest w pełni OpenSource, co ucieszy pewnie fanów wolnego i
otwartego oprogramowania, choć zarządzanie maszynami wirtualnymi odbywa się za sprawą konsoli.
Oczywiście, osoby które korzystają z VirtualBox&#39;a zdają sobie sprawę, że to narzędzie oferuje
graficzny menadżer maszyn wirtualnych (Virtual Machine Manager, VMM), który usprawnia i znacznie
ułatwia zarządzanie wirtualnymi maszynami. Jeśli GUI jest dla nas ważnym elementem środowiska pracy
i nie uśmiecha nam się konfigurować maszyn wirtualnych przy pomocy terminala, to jest i dobra
wiadomość dla takich osób, bo istnieje &lt;code&gt;virt-manager&lt;/code&gt; , który jest dość rozbudowanym menadżerem
maszyn wirtualnych pozwalającym na ich tworzenie, konfigurowanie i zarządzanie nimi przy
wykorzystaniu graficznego interfejsu użytkownika. W tym artykule postaramy się skonfigurować
naszego Debiana w taki sposób, by przygotować go do pracy z maszynami wirtualnymi posługując się
&lt;code&gt;qemu&lt;/code&gt;/&lt;code&gt;libvirt&lt;/code&gt;/&lt;code&gt;virt-manager&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>BootHole nie taki straszny, o ile ma się własne klucze EFI/UEFI</title>
      <link>https://morfikov.github.io/post/boothole-nie-taki-straszny-o-ile-ma-sie-wlasne-klucze-efi-uefi/</link>
      <pubDate>Fri, 31 Jul 2020 21:07:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/boothole-nie-taki-straszny-o-ile-ma-sie-wlasne-klucze-efi-uefi/</guid>
      <description>&lt;p&gt;Dnia 29-07-2020 do publicznej wiadomości zostały podane informacje na temat podatności BootHole,
która to za sprawą bootloader&#39;a GRUB2 w różnych dystrybucjach linux&#39;a jest w stanie obejść
mechanizm bezpieczeństwa EFI/UEFI, tj. Secure Boot. &lt;a href=&#34;https://www.debian.org/security/2020-GRUB-UEFI-SecureBoot/&#34;&gt;Z informacji&lt;/a&gt;, które opublikował Debian,
sprawa nie wygląda miło jako, że poza aktualizacją GRUB2, shim, jądra linux, Fwupdate oraz Fwupd,
unieważnieniu podlegają również klucze dystrybucji Debian/Ubuntu, przez co praktycznie cały soft
podpisany tymi kluczami (w tym systemy live) przestaną działać w trybie Secure Boot. Czy jest się
czego obawiać i co użytkownik korzystający z mechanizmu SB powinien w takiej sytuacji zrobić?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problem z aktualizacją zmiennych PK, KEK, db i dbx via efi-updatevar</title>
      <link>https://morfikov.github.io/post/problem-z-aktualizacja-zmiennych-pk-kek-db-dbx-efi-updatevar/</link>
      <pubDate>Thu, 30 Jul 2020 20:30:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problem-z-aktualizacja-zmiennych-pk-kek-db-dbx-efi-updatevar/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/&#34;&gt;konfigurację własnych kluczy EFI/UEFI&lt;/a&gt;, którymi można zastąpić te
wbudowane standardowo w firmware naszego komputera. W tamtym artykule napotkałem jednak dość dziwny
problem, za sprawą którego nie można było zaktualizować zmiennych &lt;code&gt;PK&lt;/code&gt; , &lt;code&gt;KEK&lt;/code&gt; , &lt;code&gt;db&lt;/code&gt; i &lt;code&gt;dbx&lt;/code&gt; przy
pomocy &lt;code&gt;efi-updatevar&lt;/code&gt; z poziomu działającego linux&#39;a. Gdy próbowało się te zmienne przepisać,
dostawało się błąd typu &lt;code&gt;Operation not permitted&lt;/code&gt; . Niby system został uruchomiony w trybie &lt;code&gt;Setup Mode&lt;/code&gt; ale z jakiegoś powodu odmawiał on współpracy i trzeba było te zmienne aktualizować
bezpośrednio z poziomu firmware EFI/UEFI, co było trochę upierdliwe. Szukając wtedy informacji na
ten temat, jedyne co znalazłem, to fakt, że sporo osób ma podobny problem i najwyraźniej firmware
mojego laptopa jest ździebko niedorobiony, przez co &lt;code&gt;efi-updatevar&lt;/code&gt; nie mógł realizować swojego
zdania. Rzeczywistość okazała się nieco inna, a rozwiązanie samego problemu było wręcz banalne.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czym jest linux kernel driver binding</title>
      <link>https://morfikov.github.io/post/czym-jest-linux-kernel-driver-binding/</link>
      <pubDate>Tue, 28 Jul 2020 19:39:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czym-jest-linux-kernel-driver-binding/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio QEMU/KVM na swoim laptopie z zainstalowanym Debianem natrafiłem na ciekawe
zagadnienie związane z wirtualizacją, tj. z PCI passthrough. Nie chodzi mi tutaj o samą technikę
PCI passthrough ale o dobór sterowników do urządzeń działających pod kontrolą linux. Każdy sprzęt,
który ma działać w systemie, musi mieć załadowany w pamięci RAM stosowny moduł kernela. Te moduły
zwykle są ładowane automatycznie podczas pracy systemu, np. gdy podłączamy nowy sprzęt do komputera
(można też te moduły ładować i ręcznie via &lt;code&gt;modprobe&lt;/code&gt; ). Gdy nasz linux z jakiegoś powodu dobierze
niewłaściwy (z naszego punktu widzenia) moduł dla jakiegoś urządzenia, to możemy to urządzenie
odłączyć od komputera, a moduł bez problemu wyładować, po czym dokonać stosownych poprawek w
systemie. Problem zaczyna się w sytuacji, gdy mamy do czynienia ze sprzętem, którego nie da się od
komputera fizycznie odłączyć, np. wbudowana w płytę główną karta dźwiękowa, czy też wbudowana
grafika bezpośrednio w CPU. Podobnie sprawa wygląda w przypadku wkompilowania modułów na stałe w
kernel -- jak wyładować moduł, którego się nie da wyładować? By w takich sytuacjach zmienić
przypisany urządzeniu sterownik trzeba dodać parę plików w katalogach &lt;code&gt;/etc/modules-load.d/&lt;/code&gt; /
&lt;code&gt;/etc/modprobe.d/&lt;/code&gt; oraz zrestartować maszynę, tak by podczas fazy boot kernel dobrał sprzętowi
pożądane przez nas moduły i ich konfigurację. Niemniej jednak, istnieje prostszy sposób na zmianę
sterownika działającego w systemie sprzętu i to bez potrzeby fizycznego restartowania maszyny.
Chodzi o mechanizm ręcznego przypisywania urządzeń do konkretnych sterowników (&lt;a href=&#34;https://lwn.net/Articles/143397/&#34;&gt;manual driver
binding and unbinding&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Moduł LKRG (Linux Kernel Runtime Guard)</title>
      <link>https://morfikov.github.io/post/modul-lkrg-linux-kernel-runtime-guard/</link>
      <pubDate>Tue, 09 Jun 2020 20:56:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-lkrg-linux-kernel-runtime-guard/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/modul-tpe-trusted-path-execution-dla-kernela-linux/&#34;&gt;moduł TPE&lt;/a&gt; (Trusted Path Execution) dla kernela linux, który jest w
stanie dość znacznie poprawić bezpieczeństwo naszego systemu. Ostatnio jednak natknąłem się na
&lt;a href=&#34;https://www.openwall.com/lkrg/&#34;&gt;moduł LKRG&lt;/a&gt; (Linux Kernel Runtime Guard), którego to zadaniem jest stać na straży samego jądra
operacyjnego i chronić je w czasie rzeczywistym przed różnego rodzaju zagrożeniami poprzez
wykrywanie eksploitów wykorzystujących luki w jego mechanizmach bezpieczeństwa. Jako, że ja
bardzo lubię zbroić swojego Debiana, to postanowiłem się przyjrzeć nieco bliżej temu całemu LKRG i
sprawdzić jego użyteczność. Trzeba jednak wiedzieć, że LKRG jest dostarczany w formie osobnego
modułu zamiast łaty na kernel, przez co trzeba będzie także postarać się o automatyzację pewnych
rzeczy, m.in. procesu budowania modułu przy aktualizacji kernela via DKMS.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pendrive multiboot dla EFI/UEFI z Secure Boot</title>
      <link>https://morfikov.github.io/post/pendrive-multiboot-dla-efi-uefi-z-secure-boot/</link>
      <pubDate>Mon, 23 Mar 2020 21:50:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pendrive-multiboot-dla-efi-uefi-z-secure-boot/</guid>
      <description>&lt;p&gt;Przeniesienie mojego Debiana z laptopa mającego konfigurację BIOS i tablicę partycji MBR/MS-DOS do
maszyny wyposażonej w firmware EFI/UEFI nie było jakoś stosunkowo trudnym zadaniem. Nawet &lt;a href=&#34;https://morfikov.github.io
/post/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/&#34;&gt;kwestia
włączenia Secure Boot&lt;/a&gt; okazała się o wiele mniej skomplikowana niż w rzeczywistości mogłoby się
człowiekowi wydawać. Problem jednak pojawił się w przypadku płytek czy pendrive z systemami live.
Nie chodzi przy tym o uruchamianie nośników z dopiero co wypalonymi obrazami ISO/IMG, bo te również
nie sprawiają kłopotów. Chodzi bardziej o rozwiązanie multiboot, które oferuje wgranie wielu
obrazów live na jedno urządzenie i odpalanie tego systemu, który sobie użytkownik w danym momencie
zażyczy. Do tej pory korzystałem z &lt;a href=&#34;https://github.com/thias/glim&#34;&gt;projektu GLIM&lt;/a&gt; i może on posiada wsparcie dla EFI/UEFI ale
już wsparcia dla Secure Boot mu zabrakło. W efekcie w konfiguracji EFI/UEFI + Secure Boot, GLIM stał
się bezużyteczny i trzeba było rozejrzeć się za nieco innym rozwiązaniem. Okazało się, że nie
trzeba daleko szukać, bo &lt;a href=&#34;https://www.rodsbooks.com/refind/&#34;&gt;rEFInd&lt;/a&gt; jest w stanie natywnie uruchomić system z obrazu ISO
praktycznie każdej dystrybucji linux&#39;a (Ubuntu/Debian/Mint/GParted/CloneZilla) i w zasadzie trzeba
tylko nieco inaczej przygotować nośnik, by móc na nowo cieszyć się korzyściami jakie oferuje
pendrive multiboot.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak dodać własne klucze dla Secure Boot do firmware EFI/UEFI pod linux</title>
      <link>https://morfikov.github.io/post/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/</link>
      <pubDate>Mon, 16 Mar 2020 19:15:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-dodac-wlasne-klucze-dla-secure-boot-do-firmware-efi-uefi-pod-linux/</guid>
      <description>&lt;p&gt;W środowiskach linux&#39;owych Secure Boot nie jest zbyt mile widziany i raczej postrzegany jako
źródło wszelkiego zła na świecie. Sporo użytkowników linux&#39;a dopatruje się w Secure Boot zamachu na
wolność decydowania o swoim sprzęcie, który ma być serwowany przez Microsoft. Niemniej jednak,
odsądzanie tego mechanizmu od czci i wiary jest moim zdaniem lekko nie na miejscu. Niewielu
użytkowników linux&#39;a zdaje sobie sprawę, że od prawie dekady istnieje taki wynalazek jak &lt;a href=&#34;https://github.com/rhboot/shim&#34;&gt;shim&lt;/a&gt;
(no i jest też &lt;a href=&#34;https://blog.hansenpartnership.com/linux-foundation-secure-boot-system-released/&#34;&gt;PreLoader&lt;/a&gt;), który umożliwia dystrybucjom linux&#39;a (jak i ich końcowym
użytkownikom) zaimplementowanie Secure Boot we własnym zakresie. Niemniej jednak, można całkowicie
się obejść bez tych dodatków usuwając wbudowane w firmware EFI/UEFI certyfikaty i dodając na ich
miejsce własnoręcznie wygenerowane klucze kryptograficzne. Takie podejście sprawia, że kod
podpisany tylko i wyłącznie przez nas będzie mógł zostać uruchomiony przez firmware komputera w
trybie Secure Boot, co może ździebko poprawić bezpieczeństwo naszego systemu. Poniższy artykuł ma
na celu pokazać w jaki sposób zastąpić wbudowane w firmware EFI/UEFI klucze swoimi własnymi przy
wykorzystaniu dystrybucji Debiana.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ograniczyć ładowanie baterii w laptopie ThinkPad T430</title>
      <link>https://morfikov.github.io/post/jak-ograniczyc-ladowanie-baterii-w-laptopie-thinkpad-t430/</link>
      <pubDate>Fri, 13 Mar 2020 18:30:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ograniczyc-ladowanie-baterii-w-laptopie-thinkpad-t430/</guid>
      <description>&lt;p&gt;Czy zastanawialiście się może dlaczego baterie w laptopach zużywają się mimo, że w pewnych
przypadkach nie są one praktycznie wykorzystywane? Rozważmy sobie ideę używania laptopa w roli
przeciętnego komputera stacjonarnego. W takiej sytuacji do laptopa ciągle jest podpięty przewód
zasilający, przez co bateria powinna być używana jedynie w momencie braku zasilania z sieci
energetycznej. Zatem niby pobieramy prąd z gniazdka ale bateria i tak się nam zużyje po pewnym
czasie. Niektórzy radzą, by wyciągnąć akumulator z laptopa i używać takiego komputera bez baterii.
Takie postępowanie ma w moim odczuciu jednak same wady i postanowiłem poszukać jakiegoś bardziej
cywilizowanego rozwiązania wzorowanego na &lt;a href=&#34;https://forum.xda-developers.com/android/apps-games/root-battery-charge-limit-t3557002&#34;&gt;aplikacji Battery Charge Limit&lt;/a&gt; spotykanego w
smartfonach z Androidem. Gdyby udało się ustalić limit ładowania akumulatora w moim ThinkPad T430
na max 40%, to wydłużyłoby dość znacznie żywotność jego baterii. Niekiedy oprogramowanie na windows
umożliwia tego typu funkcjonalność ale co w przypadku linux&#39;a? Czy da radę pod linux powstrzymać
laptopa od degradowania baterii za sprawą ładowania jej ciągle do 100%?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Brak bluetooth w ThinkPad T430 (BCM20702A1)</title>
      <link>https://morfikov.github.io/post/brak-bluetooth-w-thinkpad-t430/</link>
      <pubDate>Wed, 11 Mar 2020 21:03:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/brak-bluetooth-w-thinkpad-t430/</guid>
      <description>&lt;p&gt;W moim laptopie Lenovo ThinkPad T430 jest obecny bluetooth &lt;code&gt;Broadcom Corp. BCM20702 Bluetooth 4.0&lt;/code&gt;
o vid/pid &lt;code&gt;0a5c:21e6&lt;/code&gt; . Niestety to urządzenie nie działa za dobrze na Debianie z powodu braku
odpowiedniego firmware (plik &lt;code&gt;BCM20702A1-0a5c-21e6.hcd&lt;/code&gt; ), którego jak na złość nie ma w
repozytorium tej dystrybucji. Przydałoby się coś na to poradzić, by zmusić tę kartę/adapter do
pracy pod linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przygotować dysk pod instalację Debian linux z EFI/UEFI</title>
      <link>https://morfikov.github.io/post/jak-przygotowac-dysk-pod-instalacje-debian-linux-z-efi-uefi/</link>
      <pubDate>Tue, 10 Mar 2020 03:28:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przygotowac-dysk-pod-instalacje-debian-linux-z-efi-uefi/</guid>
      <description>&lt;p&gt;Instalacja linux&#39;a w trybie EFI/UEFI nieco inaczej wygląda niż tradycyjna instalacja systemu, zwana
często dla odróżnienia trybem BIOS, przynajmniej przy wykorzystaniu &lt;code&gt;debootstrap&lt;/code&gt; Jeśli kupujemy
nowego desktopa czy laptopa, to zwykle będziemy mieli na dysku twardym zainstalowanego windows&#39;a i
tym samym przygotowany cały układ partycji niezbędny do prawidłowego uruchomienia systemu w trybie
EFI/UEFI. Co jednak w przypadku, gdy kupimy komputer bez systemu operacyjnego? W takiej sytuacji
trzeba będzie ręcznie podzielić dysk na partycje oraz zainstalować menadżer rozruchu (rEFInd) lub
też bootloader (grub/grub2/syslinux/extlinux) i skonfigurować wszystkie te elementy samodzielnie.
Prawdopodobnie instalator Debiana jest w stanie za nas te kroki przeprowadzić automatycznie ale my
nie będziemy korzystać z automatycznych rozwiązań, bo one nieco odmóżdżają. Spróbujemy za to
stworzyć sobie uniwersalną konfigurację, która pozwoli nam zainstalować i odpalić dowolną
dystrybucję linux&#39;a w trybie EFI/UEFI.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana DPI w Openbox/Xorg dla monitora HiDPI</title>
      <link>https://morfikov.github.io/post/zmiana-dpi-w-openbox-xorg-dla-monitora-hidpi/</link>
      <pubDate>Sun, 08 Mar 2020 19:00:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-dpi-w-openbox-xorg-dla-monitora-hidpi/</guid>
      <description>&lt;p&gt;Jeśli mieliśmy do czynienia z monitorami wysokiej rozdzielczości, to za pewne natrafiliśmy na
problem zbyt małych czcionek, które czyniły interfejs aplikacji w naszym linux&#39;ie mało czytelnym. W
przypadku środowisk graficznych takich jak GNOME czy KDE5/Plasma5 skalowanie interfejsu i czcionek
powinno odbywać się automatycznie (&lt;a href=&#34;https://wiki.gnome.org/HowDoI/HiDpi&#34;&gt;jeśli nasz ekran ma 192+ DPI i rozdzielczość 1200+ pikseli&lt;/a&gt;)
lub też za sprawą drobnej zmiany w konfiguracji, tak by użytkownik mógł w miarę komfortowo
korzystać z systemu. O ile w przypadku tych pełnowymiarowych środowisk graficznych można w zasadzie
przełączyć tylko jedną opcję i wszystkie jego aplikacje powinny zostać z powodzeniem odpowiednio
zeskalowane, o tyle problem zaczyna się w momencie, gdy mamy mieszane aplikacje lub też zwyczajnie
używamy jedynie prostego menadżera okien dla Xserver&#39;a, np. Openbox i do tego jeszcze nasz
wyświetlacz ma mniejsze DPI niż 192. W takiej sytuacji konfiguracja interfejsu użytkownika i
czcionek dla ekranów wysokiej rozdzielczości może być nie lada wyzwaniem.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak załadować firmware karty WiFi przed initrd/initramfs</title>
      <link>https://morfikov.github.io/post/jak-zaladowac-firmware-karty-wifi-przed-initrd-initramfs/</link>
      <pubDate>Fri, 06 Mar 2020 02:45:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zaladowac-firmware-karty-wifi-przed-initrd-initramfs/</guid>
      <description>&lt;p&gt;Każdy kto ma laptopa wyposażonego w kartę WiFi, czy też ogólnie komputer posiadający bezprzewodową
sieciówkę, ten prawdopodobnie spotkał się z błędem podobnym do tego: &lt;code&gt;Direct firmware load for iwlwifi-6000g2a-6.ucode failed with error -2&lt;/code&gt; . W tym przypadku sprawa dotyczyła karty &lt;code&gt;Intel Corporation Centrino Advanced-N 6205 [Taylor Peak]&lt;/code&gt; działającej w oparciu o moduł kernela
&lt;code&gt;iwlwifi&lt;/code&gt; . W takich przypadkach zwykle wystarczy zainstalować firmware od określonego modułu i po
kłopocie. No i faktycznie w Debianie jest dostępny pakiet &lt;code&gt;firmware-iwlwifi&lt;/code&gt; , który zawiera ten
potrzebny plik &lt;code&gt;iwlwifi-6000g2a-6.ucode&lt;/code&gt; . Problem jednak w tym, że instalacja paczki z firmware
niekoniecznie może nam pomóc. Ten powyższy przykład nie jest odosobniony i czasami pliki z firmware
muszą być dostępne w chwili ładowania kernela do pamięci RAM czy też na etapie initramfs/initrd. W
takim przypadku zainstalowanie paczki z firmware w naszym linux&#39;ie nic nam nie da, bo pliki
rezydują na niezamontowanym jeszcze dysku. Jak zatem wybrnąć z tej wydawać by się było patowej
sytuacji?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Memtest86 dla EFI/UEFI i rEFInd</title>
      <link>https://morfikov.github.io/post/memtest86-dla-efi-uefi-i-refind/</link>
      <pubDate>Tue, 03 Mar 2020 04:05:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/memtest86-dla-efi-uefi-i-refind/</guid>
      <description>&lt;p&gt;Zapewne każdy z nas słyszał o narzędziu do testowania pamięci operacyjnej RAM zwanym memtest86. W
Debianie są dostępne dwa pakiety &lt;a href=&#34;https://tracker.debian.org/pkg/memtest86&#34;&gt;memtest86&lt;/a&gt; (&lt;a href=&#34;https://www.memtest86.com/&#34;&gt;strona projektu&lt;/a&gt;) oraz &lt;a href=&#34;https://tracker.debian.org/pkg/memtest86+&#34;&gt;memtest86+&lt;/a&gt;
(&lt;a href=&#34;http://www.memtest.org/&#34;&gt;strona projektu&lt;/a&gt;) , które można sobie zainstalować w systemie. Niemniej jednak, jak się
popatrzy na daty ostatnich wersji obu tych aplikacji (rok 2014), to mamy do czynienia z dość starym
oprogramowaniem. Tak czy inaczej, jeśli dany soft działa, to bez znaczenia powinno być jak stary on
jest. Problem w przypadku memtest86 dostarczanego w tych dwóch pakietach jest taki, że działa on w
zasadzie jedynie w konfiguracji BIOS, a nie EFI/UEFI. Dodatkowo, oryginalny memtest86 został
sprzedany PassMark&#39;owi, który &lt;a href=&#34;https://en.wikipedia.org/wiki/Memtest86&#34;&gt;od wersji 5.0 uczynił go własnościowym softem&lt;/a&gt;. To dlatego w
Debianie nie będzie już nowszej wersji memtest86. W dalszym ciągu memtest86 może działać w
konfiguracji EFI/UEFI ale potrzebna nam jest wersja, która to EFI/UEFI wspiera. Memtest86 zaczął
wspierać EFI/UEFI od wersji 5.0. Jeśli nam nie przeszkadza licencja własnościowa, to możemy sobie
przygotować memtest86, tak by można go było bez problemu odpalić z menadżera rozruchu &lt;a href=&#34;https://www.rodsbooks.com/refind/&#34;&gt;rEFInd&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Linux kernel EFI boot stub i zaszyfrowany Debian (LUKS&#43;LVM)</title>
      <link>https://morfikov.github.io/post/linux-kernel-efi-boot-stub-i-zaszyfrowany-debian-luks-lvm/</link>
      <pubDate>Mon, 02 Mar 2020 03:08:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/linux-kernel-efi-boot-stub-i-zaszyfrowany-debian-luks-lvm/</guid>
      <description>&lt;p&gt;Szukając informacji na temat uruchamiania mojego zaszyfrowanego Debiana (LUKSv2+LVM) na laptopie z
EFI/UEFI, natrafiłem na dość ciekawy mechanizm zwany &lt;a href=&#34;https://www.kernel.org/doc/Documentation/efi-stub.txt&#34;&gt;kernel EFI boot stub&lt;/a&gt;, czasem też zwany
kernel EFISTUB. Zadaniem tego mechanizmu jest uruchomienie linux&#39;a bezpośrednio z poziomu firmware
EFI z pominięciem czy też bez potrzeby stosowania dodatkowych menadżerów rozruchu (rEFInd) czy
bootloader&#39;ów (grub/grub2/syslinux/extlinux). Jakby nie patrzeć bardzo ciekawa alternatywa, która
wymaga, by się z nią zapoznać i ocenić jej przydatność pod kątem użyteczności.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przepisać linki initrd.img{,.old} i vmlinuz{,.old} z / do /boot/</title>
      <link>https://morfikov.github.io/post/jak-przepisac-linki-initrd-img-old-i-vmlinuz-old-do-boot/</link>
      <pubDate>Sun, 01 Mar 2020 20:30:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przepisac-linki-initrd-img-old-i-vmlinuz-old-do-boot/</guid>
      <description>&lt;p&gt;Mając możliwość skonfigurowania EFI/UEFI na moim laptopie, postanowiłem jak najbardziej się za to
przedsięwzięcie zabrać. Okazało się jednak, że w przypadku takiej dystrybucji linux&#39;a jak Debian,
to zadanie może być nieco problematyczne, zwłaszcza gdy chce się korzystać jedynie z menadżera
rozruchu jakim jest &lt;a href=&#34;https://www.rodsbooks.com/refind/&#34;&gt;rEFInd&lt;/a&gt;, czyli bez dodatkowego bootloader&#39;a (grub/grub2/syslinux/extlinux)
instalowanego bezpośrednio na dysku twardym i jednocześnie posiadając w pełni zaszyfrowany system
(LUKSv2 + LVM). Rzecz w tym, że w takiej sytuacji w konfiguracji rEFInd trzeba podawać ścieżki
bezpośrednio do plików &lt;code&gt;initrd.img&lt;/code&gt; oraz &lt;code&gt;vmlinuz&lt;/code&gt; (obecnych na partycji &lt;code&gt;/boot/&lt;/code&gt; ). W Debianie
nazwy tych plików mają format &lt;code&gt;initrd.img-x.x.x-x-amd64&lt;/code&gt; i &lt;code&gt;vmlinuz-x.x.x-x-amd64&lt;/code&gt; . Za każdym
razem, gdy wypuszczany jest nowy kernel, to ten numerek ( &lt;code&gt;x.x.x-x&lt;/code&gt; ) ulega zmianie, co pociąga za
sobą potrzebę ręcznego dostosowania konfiguracji rEFInd. Może i aktualizacje kernela w Debianie nie
są jakoś stosunkowo częste ale może istnieje sposób, by ten problem z dostosowaniem konfiguracji
rozwiązać?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Regulacja obrotów wentylatora w zależności od zmian temperatury w ThinkPad T430</title>
      <link>https://morfikov.github.io/post/regulacja-obrotow-wentylatora-w-zaleznosci-od-zmian-temperatury-w-thinkpad-t430/</link>
      <pubDate>Fri, 28 Feb 2020 23:00:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/regulacja-obrotow-wentylatora-w-zaleznosci-od-zmian-temperatury-w-thinkpad-t430/</guid>
      <description>&lt;p&gt;Ostatnio udało mi się nabyć dość niedrogo laptop Lenovo, a konkretnie był to model ThinkPad T430.
Maszyna jakby nie patrzeć jest bardzo kompatybilna z linux i w zasadzie nie mogę jej nic zarzucić,
przynajmniej póki co. Niemniej jednak, jest pewien szkopuł, który mnie zaczął ździebko irytować od
praktycznie samego początku jak tylko podłączyłem ten komputer do prądu. Chodzi o wentylator
chłodzący radiator procesora, który no troszkę daje o sobie znać i to mimo faktu, że temperatura
CPU jest w granicach 40 stopni. Przeglądając opcje w BIOS nie natrafiłem na nic co mogło by te
obroty wyregulować. Na szczęście w przypadku laptopów Lenovo można programowo zdefiniować obroty
wiatraka posługując się narzędziem &lt;a href=&#34;https://github.com/vmatare/thinkfan&#34;&gt;thinkfan&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak załadować profile AppArmor w fazie initrd/initramfs na Debian Linux</title>
      <link>https://morfikov.github.io/post/jak-zaladowac-profile-apparmor-w-fazie-initrd-initramfs-na-debian-linux/</link>
      <pubDate>Mon, 23 Sep 2019 19:05:21 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zaladowac-profile-apparmor-w-fazie-initrd-initramfs-na-debian-linux/</guid>
      <description>&lt;p&gt;Zapewne wielu użytkowników Debiana zdążyło już zauważyć, że od wydania 10 (Buster), AppArmor jest
włączony domyślnie. Nie powinien on raczej sprawiać żadnych problemów po doinstalowaniu pakietów
&lt;code&gt;apparmor-profiles&lt;/code&gt; oraz &lt;code&gt;apparmor-profiles-extra&lt;/code&gt; , które zawierają szereg profili pod różne
aplikacje użytkowe. Niemniej jednak, pewnych procesów nie da się ograniczyć przez AppArmor,
przynajmniej nie w standardowy sposób. Chodzi o to, że jeśli mamy już odpalony jakiś proces, to nie
ma możliwości zamknąć go w profilu AA do momentu aż zakończy on swoje działanie i zostanie
uruchomiony ponownie. Profile AppArmor&#39;a są ładowane podczas startu systemu w pewnym określonym
momencie ale szereg procesów systemowych startuje sporo wcześniej w stosunku do usługi AppArmor&#39;a.
W taki sposób nawet jeśli w późniejszym czasie profile zostaną załadowane, to i tak część procesów
nie będzie ograniczona bez względu na to czy zdefiniowaliśmy im zestaw reguł. Oczywiście można
próbować restartować usługi lub szeregować je po &lt;code&gt;apparmor.service&lt;/code&gt; ale nie zawsze tak się da
zrobić. Alternatywnym rozwiązaniem tego problemu jest ładowanie polityki AppArmor&#39;a w fazie
initrd/initramfs, czyli w momencie, w którym nasz system nie ma jeszcze nawet uruchomionego procesu
z PID z numerkiem &lt;code&gt;1&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wybudzanie linux&#39;a ze stanu uśpienia za sprawą myszy</title>
      <link>https://morfikov.github.io/post/wybudzanie-linuxa-ze-stanu-uspienia-za-sprawa-myszy/</link>
      <pubDate>Thu, 06 Jun 2019 16:10:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wybudzanie-linuxa-ze-stanu-uspienia-za-sprawa-myszy/</guid>
      <description>&lt;p&gt;Parę dni temu na jednych z forów, które czasem odwiedzam, &lt;a href=&#34;https://forum.linuxmint.pl/showthread.php?tid=323&#34;&gt;pojawił się wątek&lt;/a&gt; dotyczący problemu
jaki może nieść ze sobą budzenie linux&#39;a ze stanu uśpienia/wstrzymania (Suspend to RAM, STR) za
sprawą myszy. O ile w przypadku klawiatury sprawa wybudzania komputera zdaje się być dość oczywista,
to w przypadku tego małego gryzonia już niekoniecznie, bo wystarczy lekko mysz przemieścić po
blacie stołu czy innego biurka i system się nam wybudzi. Część komputerów ma stosowne opcje w
BIOS/UEFI i można za ich sprawą skonfigurować to jakie urządzenia będą mieć możliwość wybudzania
systemu. Niekiedy jednak, opcje w BIOS są tak ubogie, że nie mamy możliwości skonfigurowania tego
aspektu pracy naszej maszyny. Trzeba zatem w nieco inny sposób podejść do tego zagadnienia. Na
necie można się spotkać z radami odnośnie zapisu pliku &lt;code&gt;/proc/acpi/wakeup&lt;/code&gt; przez przesłanie do
niego czteroznakowych kodów, np. &lt;code&gt;EHC1&lt;/code&gt; czy &lt;code&gt;USB1&lt;/code&gt; . Takie rozwiązanie może nieść ze sobą negatywne
konsekwencje i powinno się go unikać. Lepszym rozwiązaniem jest napisanie reguły dla UDEV&#39;a dla
konkretnego urządzenia, gdzie będziemy mogli łatwo sterować (przez plik &lt;code&gt;power/wakeup&lt;/code&gt; ) tym czy
dane urządzenie ma mieć możliwość wybudzania systemu czy też nie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Montowanie dysków jako zwykły użytkownik z UDisks i PolicyKit</title>
      <link>https://morfikov.github.io/post/montowanie-dyskow-jako-zwykly-uzytkownik-z-udisks-i-policykit/</link>
      <pubDate>Fri, 26 Apr 2019 21:10:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/montowanie-dyskow-jako-zwykly-uzytkownik-z-udisks-i-policykit/</guid>
      <description>&lt;p&gt;Jeszcze nie tak dawno temu przeciętnej klasy desktop był wyposażony w pojedynczy i do tego
niewielkiej pojemności dysk twardy, który był w stanie pomieścić wszystkie pliki swojego
właściciela. Obecnie jednak większość maszyn ma tych nośników już kilka. Mowa tutaj nie tylko o
dyskach systemowych, które są fizycznie na stałe zamontowane w komputerze ale również o tych
wszystkich urządzeniach, które można podłączyć do portu USB. Polityka linux&#39;a wymusza, by wszystkie
nośniki pamięci masowej (HDD, SSD, pendrive czy też karty SD) były montowane w systemie jedynie
przez użytkowników posiadających uprawnienia administratora. Domyślnie taki przywilej ma jedynie
root. Zatem by uzyskać dostęp do danych na takim zewnętrznym nośniku musimy logować się na root&#39;a.
Jakby nie patrzeć ma to swoje plusy patrząc z perspektywy bezpieczeństwa, niemniej jednak czy
naprawdę potrzebny nam jest root do wgrania czegoś na nasz ulubiony pendrive? Widać nie tylko ja
zadawałem sobie takie pytanie i ktoś postanowił stworzyć narzędzie UDisks (lub jego nowszą wersję
UDisks2), które za pomocą mechanizmu PolicyKit (zwanym też PolKit) jest w stanie nadać stosowne
uprawnienia konkretnym użytkownikom systemu, przez co można określić zespół akcji, które będą oni w
stanie przeprowadzić bez potrzeby podawania hasła, np. montowanie czy odmontowanie zasobu.
Postanowiłem zatem zobaczyć jak ten duet sobie radzi na moim Debianie przy tradycyjnym użytkowaniu
systemu i ocenić jego stopień przydatności.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mechanizm trigger&#39;ów dla apt/aptitude w Debianie</title>
      <link>https://morfikov.github.io/post/mechanizm-trigger-dla-apt-aptitude-w-debianie/</link>
      <pubDate>Sun, 14 Apr 2019 00:10:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/mechanizm-trigger-dla-apt-aptitude-w-debianie/</guid>
      <description>&lt;p&gt;Czasami pewna niestandardowa konfiguracja naszego linux&#39;a może sprawiać pewne problemy podczas
aktualizacji zainstalowanych w nim pakietów. Dla przykładu, wykorzystując mechanizm AppArmor do
okrojenia profilów Firefox&#39;a, muszę tworzyć osobne twarde dowiązania do binarki tej przeglądarki.
Te dowiązania mają taki problem, że jak usunie się plik, na który wskazywały, np. podczas
aktualizacji paczki, to utworzenie pliku w tym samym miejscu przez menadżer pakietów
&lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;aptitude&lt;/code&gt; nie sprawi, że te dowiązania zaczną ponownie funkcjonować poprawnie (tak jak to
jest w przypadku dowiązań symbolicznych). Z początku usuwałem te stare dowiązania i tworzyłem nowe
ale postanowiłem w końcu &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=30382&#34;&gt;poszukać rozwiązania&lt;/a&gt;,
które by zautomatyzowało cały ten proces i uczyniło go transparentnym dla użytkownika końcowego.
Tak natrafiłem na mechanizm Debianowych
trigger&#39;ów (&lt;a href=&#34;https://manpages.debian.org/unstable/dpkg-dev/deb-triggers.5.en.html&#34;&gt;deb-trigger&lt;/a&gt;),
które aktywują się za każdym razem ilekroć pliki w konkretnych ścieżkach są ruszane w jakiś sposób
przez menadżer pakietów. W tym artykule spróbujemy sobie zaprojektować taki trigger i obadać czy
może on nam się w ogóle do czegoś przydać&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Blokowanie niepożądanej komunikacji z nftables na linux</title>
      <link>https://morfikov.github.io/post/blokowanie-niepozadanej-komunikacji-z-nftables-na-linux/</link>
      <pubDate>Fri, 12 Apr 2019 20:53:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/blokowanie-niepozadanej-komunikacji-z-nftables-na-linux/</guid>
      <description>&lt;p&gt;Minęło już trochę czasu od momentu, w którym postanowiłem się przerzucić z &lt;code&gt;iptables&lt;/code&gt; na &lt;code&gt;nftables&lt;/code&gt;
w swoim Debianie i w zasadzie większość mechanizmów obronnych mojego laptopowego firewall&#39;a została
już z powodzeniem przeportowana na ten nowy filtr pakietów. Poza tymi starymi regułami próbuję
czasem ogarniać nieco bardziej wyrafinowane sposoby na unikanie zagrożeń sieciowych, choć
implementacja niektórych rzeczy nie zawsze jest taka oczywista, z tym, że niekoniecznie niemożliwa
do zrealizowana. Tak było w przypadku mechanizmu automatycznego blokowania hostów próbujących się
łączyć z daną maszyną, która sobie najwyraźniej tego nie życzy. Dla przykładu, jest serwer
udostępniający usługę SSH na porcie &lt;code&gt;11111&lt;/code&gt; i tylko ten port jest wystawiony na świat. Wszelkiego
rodzaju boty próbujące dostać się do maszyn linux&#39;owych próbkują z kolei głównie standardowe porty,
w tym przypadku &lt;code&gt;22&lt;/code&gt; . Ci użytkownicy, którzy powinni mieć dostęp do usługi SSH, wiedzą na jakim
porcie ona nasłuchuje. Można zatem założyć, że wszystkie połączenia na port &lt;code&gt;22&lt;/code&gt; będą dokonywane
przez boty albo przez użytkowników, którzy mają niecne zamiary. Wszystkie te połączenia można by
zatem zablokować tworząc mechanizm automatycznego banowania hostów w oparciu o czas ostatniej próby
połączenia, tak jak to zostało opisane mniej
więcej &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?pid=269383&#34;&gt;w tym wątku na forum&lt;/a&gt;. Problem w tym, że
tamto rozwiązanie dotyczy jedynie &lt;code&gt;iptables&lt;/code&gt; w połączeniu z &lt;code&gt;ipset&lt;/code&gt; , co nieco komplikuje wdrożenie
go w przypadku &lt;code&gt;nftables&lt;/code&gt; ale to zadanie jest jak najbardziej możliwe.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Unikanie SYN/ICMP/UDP/PING flood w linux z nftables</title>
      <link>https://morfikov.github.io/post/unikanie-syn-icmp-udp-ping-flood-w-linux-z-nftables/</link>
      <pubDate>Fri, 12 Apr 2019 20:12:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/unikanie-syn-icmp-udp-ping-flood-w-linux-z-nftables/</guid>
      <description>&lt;p&gt;Obecnie &lt;code&gt;nftables&lt;/code&gt; cierpi dość mocno z powodu pewnych problemów związanych z wydajnością przy
aplikowaniu reguł zapory sieciowej. Niemniej jednak, w stosunku do &lt;code&gt;iptables&lt;/code&gt; , &lt;code&gt;nftables&lt;/code&gt; posiada
tablicę &lt;code&gt;netdev&lt;/code&gt; , która jest w stanie nieco zyskać w oczach tych nieco bardziej wybrednych
użytkowników linux&#39;a. Chodzi generalnie o fakt, że ta tablica jest umieszczona zaraz na początku
drogi pakietów, tuż po odebraniu ich z NIC (interfejsu karty sieciowej), a biorąc pod uwagę fakt,
że ruch sieciowy, który nigdy ma nie trafić do naszej maszyny, powinien być zrzucany jak
najwcześniej (by nie marnować zasobów procesora i pamięci), to ta tablica wydaje się być idealnym
miejscem by zablokować cały niepożądany ruch przychodzący. Przy wykorzystaniu &lt;code&gt;iptables&lt;/code&gt; , takie
pakiety zrzuca się w tablicy &lt;code&gt;raw&lt;/code&gt; . Jeśli zaś chodzi o &lt;code&gt;nftables&lt;/code&gt; , to zrzucanie pakietów w
tablicy &lt;code&gt;netdev&lt;/code&gt; jest ponad dwu lub nawet trzykrotnie bardziej wydajne (szybsze i mniej
zasobożerne). Można zatem dość dobrze poradzić sobie z wszelkiego rodzaju atakami DOS/DDOS, np.
ICMP/PING flood czy SYN flood. Zastanawiające może być natomiast ogarnięcie ataku UDP flood ale
przed tym rodzajem ataku linux również jest w stanie się bez problemu ochronić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ograniczenie su do jednego użytkownika w Debianie</title>
      <link>https://morfikov.github.io/post/ograniczanie-su-do-jednego-uzytkownika-w-debianie/</link>
      <pubDate>Fri, 12 Apr 2019 19:40:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/ograniczanie-su-do-jednego-uzytkownika-w-debianie/</guid>
      <description>&lt;p&gt;W dzisiejszych czasach dystrybucje linux&#39;a wykorzystują mechanizm &lt;code&gt;sudo&lt;/code&gt; do wykonywania operacji
jako administrator systemu. Zanika więc potrzeba stosowania polecenia &lt;code&gt;su&lt;/code&gt; , by zalogować się na
konto root i to z jego poziomu wykonywać wszystkie niezbędne rzeczy. Jednym z argumentów
zwolenników &lt;code&gt;sudo&lt;/code&gt; za takim sanem rzeczy jest możliwość nadania jedynie konkretnym użytkownikom w
systemie uprawnień do wykonywania poleceń jako administrator, podczas gdy inni użytkownicy
(niebędący w grupie &lt;code&gt;sudo&lt;/code&gt; ) nie mogą w ogóle korzystać z tego mechanizmu . No faktycznie, dostęp
do &lt;code&gt;su&lt;/code&gt; jest w zasadzie dla każdego użytkownika w systemie i tylko hasło konta admina dzieli ich od
uzyskania dość szerokich uprawnień. Niewiele jednak osób wie, że można skonfigurować &lt;code&gt;su&lt;/code&gt; w taki
sposób, by dostęp do niego mieli tylko ci
użytkownicy, &lt;a href=&#34;https://wiki.debian.org/WHEEL/PAM&#34;&gt;którzy powinni&lt;/a&gt;, np. ci obecni w grupie &lt;code&gt;wheel&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Format źródeł 3.0 (git) przy budowaniu paczek Debiana</title>
      <link>https://morfikov.github.io/post/format-zrodel-git-przy-budowaniu-paczek-debiana/</link>
      <pubDate>Wed, 27 Mar 2019 05:23:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/format-zrodel-git-przy-budowaniu-paczek-debiana/</guid>
      <description>&lt;p&gt;Pisząc jakiś czas
temu &lt;a href=&#34;https://morfikov.github.io
/post/poradnik-maintainera-czyli-jak-zrobic-pakiet-deb/&#34;&gt;poradnik na temat budowania paczek .deb&lt;/a&gt;
dla dystrybucji linux&#39;a Debian, poruszyłem w nim kwestię związaną z aktualizacją paczki, która
zawierała projekt utrzymywany w systemie kontroli wersji (CVS), np. git. Rozchodzi się tutaj o
format źródeł. Do niedawna myślałem, że są w zasadzie dwa formaty (tych, z których się zwykle
korzysta): &lt;code&gt;3.0 (native)&lt;/code&gt; oraz &lt;code&gt;3.0 (quilt)&lt;/code&gt; . Wszystkie moje pakiety budowane do tej pory miały
ten drugi format. Podglądając ostatnio kilka paczek &lt;code&gt;.deb&lt;/code&gt; , natrafiłem w jednej z nich na format
źródeł &lt;code&gt;3.0 (git)&lt;/code&gt; . Okazuje się, że ten format jest w stanie bardzo łatwo ogarnąć projekty
hostowane w takich serwisach jak GitHub, czy GitLab i można za jego sprawą nieco ułatwić sobie
życie. Wypadałoby zatem rzucić na niego okiem i ocenić go pod kątem przydatności przy budowaniu
pakietów dla Debiana.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problemy z plikiem wymiany SWAP przy hibernacji linux&#39;a</title>
      <link>https://morfikov.github.io/post/problemy-z-plikiem-wymiany-swap-przy-hibernacji-linuxa/</link>
      <pubDate>Sat, 23 Mar 2019 19:30:22 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problemy-z-plikiem-wymiany-swap-przy-hibernacji-linuxa/</guid>
      <description>&lt;p&gt;Po wyjaśnieniu paru rzeczy w kwestii przestrzeni wymiany, a
konkretnie [co jest lepsze: plik SWAP czy osobna partycja]({{ site.baseurl  }}/post/czy-w-linux-plik-swap-jest-lepszy-niz-partycja-wymiany/),
postanowiłem nieco zmienić układ partycji na dysku mojego laptopa (LUKS+LVM) i zaimplementować
sobie przestrzeń wymiany w postaci pliku SWAP. Standardowo jednak plik SWAP nie działa w przypadku
hibernacji linux&#39;a i kernel ma problemy z wybudzeniem maszyny z głębokiego snu. Jeśli zamierzamy
korzystać z hibernacji, to trzeba inaczej skonfigurować system, by nauczyć go korzystać z
przestrzeni wymiany w postaci pliku. W tym artykule rzucimy sobie okiem na ten niezbyt
skomplikowany proces.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Moduł TPE (Trusted Path Execution) dla kernela linux</title>
      <link>https://morfikov.github.io/post/modul-tpe-trusted-path-execution-dla-kernela-linux/</link>
      <pubDate>Fri, 22 Mar 2019 20:10:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modul-tpe-trusted-path-execution-dla-kernela-linux/</guid>
      <description>&lt;p&gt;Użytkownicy linux&#39;a są zwykle chronieni przez mechanizmy bezpieczeństwa, które ten system jest w
stanie zaoferować. Oczywiście deweloperzy różnych dystrybucji, np. Debiana, dokładają wszelkich
możliwych starań, by system jako całość był wstępnie skonfigurowany tak, by końcowy użytkownik nie
musiał za wiele majstrować przy zabezpieczeniach i mógł się czuć i być (przynajmniej względnie)
bezpieczny. No i faktycznie złowrogie oprogramowanie ma czasem spore problemy dostać się do maszyny,
którą operuje linux. Niemniej jednak, gdy już taki syf się do systemu dostanie, to zwykle niewiele
dzieli go od przejęcia kontroli nad komputerem. Może i część zabezpieczeń linux&#39;a zadziała i sprawi,
że taki wirus/trojan czy nawet zwykły skrypt będzie miał ograniczone pole manewru, to i tak będzie
on mógł przeprowadzić te akcje, które zwyczajny użytkownik systemu (nie root) jest zwykle w stanie
poczynić, np. odebrać dźwięk i video ze stosownych urządzeń i przesłać te dane przez sieć. My z
kolei możemy nawet tego faktu nie być świadomi. Jasne, że powinno się zwracać uwagę na to jakie
pliki się pobiera z internetu i nie uruchamiać wszystkiego lekkomyślnie ale też trzeba mieć na
uwadze fakt, że często jedna maszyna jest współdzielona, np. z członkami rodziny i oni już
niekoniecznie muszą władać zaawansowaną wiedza z zakresu IT, by przewidzieć wszystkie możliwe
zagrożenia czyhające na nich w sieci. Można za to postarać się, by uczynić naszą maszynę nieco
bardziej odporną na niezbyt przemyślane zachowania użytkowników jej systemu operacyjnego. Jednym z
kroków, które możemy podjąć, jest wdrożenie mechanizmu Trusted Path Execution (TPE), który póki co
jest dostępny jedynie w &lt;a href=&#34;https://patchwork.kernel.org/patch/9773791/&#34;&gt;formie patch&#39;a&lt;/a&gt; na kernel
linux&#39;a lub też jako jego &lt;a href=&#34;https://github.com/cormander/tpe-lkm&#34;&gt;osobny moduł&lt;/a&gt; oferujący sporo
więcej możliwości w stosunku do wspomnianej wcześniej łaty. W niniejszym artykule rzucimy sobie
okiem na ten cały mechanizm TPE i zobaczymy jak jest on w stanie uchronić nasz OS przed niezbyt
zaawansowaną ludzką inteligencją.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czym jest Online ext4 Metadata Check w linux&#39;owym LVM</title>
      <link>https://morfikov.github.io/post/czym-jest-online-ext4-metadata-check-w-linuxowym-lvm/</link>
      <pubDate>Sun, 17 Mar 2019 19:10:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czym-jest-online-ext4-metadata-check-w-linuxowym-lvm/</guid>
      <description>&lt;p&gt;Przeglądając dzisiaj rano logi systemowe wpadł mi w oczy komunikat, którego treść brzmiała mniej
więcej tak: &lt;code&gt;e2scrub Volume group &amp;quot;wd_blue_label&amp;quot; has insufficient free space (0 extents): 64 required&lt;/code&gt; , po którym z kolei można zanotować &lt;code&gt;e2scrub snapshot FAILED, will not check!&lt;/code&gt; oraz
&lt;code&gt;Failed to start Online ext4 Metadata Check for /media/Debian&lt;/code&gt; . Oczywiście ten punkt montowania to
nazwa partycji odnosząca się do jednego z dysków logicznych struktury LVM. Skąd się te błędy
wzięły? Przecież jeszcze do niedawna (przez ostatnich parę lat) wszystko z moim linux&#39;em
rezydującym na dysku (LUKS+LVM) było w porządku, a teraz nagle takie bardzo niepokojące błędy.
Czym jest w ogóle ten &lt;code&gt;e2scrub&lt;/code&gt; i czym jest ten cały &lt;code&gt;Online ext4 Metadata Check&lt;/code&gt; , który
najwyraźniej ma coś wspólnego ze sprawdzaniem systemu plików voluminów logicznych w locie? No i
najważniejsze chyba pytanie -- czemu to nie działa jak należy?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak na Debianie zrobić pakiet .deb zawierający moduł kernela linux (DKMS)</title>
      <link>https://morfikov.github.io/post/jak-na-debianie-zrobic-pakiet-deb-zawierajacy-modul-kernela-linux-dkms/</link>
      <pubDate>Sun, 17 Mar 2019 09:37:28 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-na-debianie-zrobic-pakiet-deb-zawierajacy-modul-kernela-linux-dkms/</guid>
      <description>&lt;p&gt;Kernel linux&#39;a jest dość złożonym organizmem, który może zostać rozbudowany przy pomocy dodatkowego
kodu ładowanego w postaci zewnętrznych modułów. Czasem ze względu na wczesny etap prac nad nową
funkcjonalnością jądra, taki moduł może zachowywać się dość nieprzewidywalnie, co przekreśla jego
szanse na pojawienie się w stabilnych wydaniach kernela. Czasem też z jakiegoś niezrozumiałego
powodu pewne rzeczy nie są celowo dodawane do jądra operacyjnego. Jedną z nich
jest &lt;a href=&#34;https://github.com/cormander/tpe-lkm&#34;&gt;moduł Trusted Path Execution&lt;/a&gt; (TPE), który jest w
stanie znacznie poprawić bezpieczeństwo systemu uniemożliwiając przeprowadzenie w nim szeregu
podejrzanych działań. W Debianie tego typu niedogodności związane z brakiem pewnych modułów można
obejść przez
zastosowanie &lt;a href=&#34;https://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support&#34;&gt;mechanizmu DKMS&lt;/a&gt;, który
przy instalacji modułu spoza głównego drzewa kernela linux&#39;a jest nam go w stanie automatycznie
zbudować. W repozytorium dystrybucji Debiana znajduje się już szereg pakietów z modułami (mają
końcówki &lt;code&gt;-dkms&lt;/code&gt; ) i w prosty sposób można je sobie doinstalować. Co jednak w przypadku, gdy mamy
moduł, którego nikt jeszcze nie przygotował i nie wrzucił do repozytorium? Co, gdy takich modułów
mamy kilka, a przy tym korzystamy z najnowszego stabilnego kernela, który jest aktualizowany
średnio co kilka dni? Ręczna budowa wszystkich zewnętrznych modułów za każdym razem jak tylko
wyjdzie nowsza wersja kernela, to nie najlepsze wyjście, zwłaszcza jak dojdzie nam do tego
aktualizacja samych modułów. Można za to zrobić sobie paczkę &lt;code&gt;.deb&lt;/code&gt; tak, by przy instalacji nowego
jądra operacyjnego, system nam automatycznie zbudował wszystkie dodatkowe moduły, których nasz
komputer wymaga do poprawnej pracy.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Czy linux&#39;owy firewall powinien blokować pakiety not-syn w stanie NEW</title>
      <link>https://morfikov.github.io/post/czy-linuxowy-firewall-powinien-blokowac-pakiety-not-syn-w-stanie-new/</link>
      <pubDate>Fri, 15 Mar 2019 18:02:21 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/czy-linuxowy-firewall-powinien-blokowac-pakiety-not-syn-w-stanie-new/</guid>
      <description>&lt;p&gt;Od czasu do czasu w logu systemowym mojego Debiana można zanotować szereg pakietów przychodzących,
które są zrzucane przez linux&#39;owy firewall (&lt;code&gt;nftables&lt;/code&gt;/&lt;code&gt;iptables&lt;/code&gt; ). Po krótkiej analizie okazało
się, że są to pakiety protokołu TCP mające stan &lt;code&gt;NEW&lt;/code&gt; (czyli są to nowe połączenia) ale
niezawierające przy tym flagi &lt;code&gt;SYN&lt;/code&gt; . Mój laptop nie ma aktualnie przydzielonego zewnętrznego
routowalnego adresu IPv4/IPv6, więc nasunęło się pytanie o przyczynę takiego stanu
rzeczy -- przecie będąc za NAT, nikt spoza sieci nie powinien być w stanie nawiązać połączenia z
moją maszyną, a ewidentnie co się do jej bram dobija i to nie z adresu lokalnego. Niby mam też
odfiltrowane pakiety w stanie &lt;code&gt;INVALID&lt;/code&gt; (np. te mające niepoprawny zestaw flag) ale widać te
pakiety, o których mowa, nie zaliczają się do tego stanu, więc wygląda na to, że wszystko z nimi
jest w porządku. Czy tego typu pakiety TCP w stanie &lt;code&gt;NEW&lt;/code&gt; niemające ustawionej flagi &lt;code&gt;SYN&lt;/code&gt;
stanowią jakieś zagrożenie dla naszego komputera? Czy powinno się je zablokować, a może przepuścić
w filtrze pakietów? A jeśli zablokować, to czy zwykły &lt;code&gt;DROP&lt;/code&gt; wystarczy czy może powinno się te
pakiety potraktować przy pomocy &lt;code&gt;REJECT&lt;/code&gt; ?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Brak wsparcia dla ipset w nftables</title>
      <link>https://morfikov.github.io/post/brak-wsparcia-dla-ipset-w-nftables/</link>
      <pubDate>Sat, 02 Mar 2019 02:21:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/brak-wsparcia-dla-ipset-w-nftables/</guid>
      <description>&lt;p&gt;Użytkownicy Debiana często w roli firewall&#39;a wykorzystują już dość leciwy &lt;code&gt;iptables&lt;/code&gt; . W zasadzie,
to tej implementacji linux&#39;owego filtra pakietów sieciowych nic nie dolega, no może poza szeregiem
wad konstrukcyjnych, które są obecnie tak ciężkie do zaadresowania, że w sumie trzeba by cały ten
&lt;code&gt;iptables&lt;/code&gt; napisać od początku. Wszystko przez rozwój internetu, za sprawą którego pojawiło się
zapotrzebowanie na tworzenie całej masy reguł (w postaci adresów/portów źródłowych/docelowych),
gdzie w standardowym &lt;code&gt;iptables&lt;/code&gt; trzeba tworzyć osobne wpisy. Im więcej reguł w filtrze, tym
przechodzenie pakietów przez zaporę sieciową trwa dłużej i wiąże się z mocnym obciążeniem dla
procesora (zwłaszcza, gdy tych reguł jest kilkadziesiąt tysięcy). By jakoś uporać się z tymi
problemami (nieznanymi w innych filtrach sieciowych) stworzono &lt;code&gt;ipset&lt;/code&gt; . I faktycznie odciążył on
mocno procesor maszyny ale i tak nie wyeliminował on podstawowych wad &lt;code&gt;iptables&lt;/code&gt; . Dlatego też
zaczęto szukać innego rozwiązania i tak pojawiła się alternatywa m.in. w postaci &lt;code&gt;nftables&lt;/code&gt; . W
przyszłym stabilnym Debianie (buster) &lt;code&gt;nftables&lt;/code&gt; będzie wykorzystywany jako domyślny filtr pakietów
i ci, który korzystali z &lt;code&gt;ipset&lt;/code&gt; mogą się nieco zdziwić, że &lt;code&gt;nftables&lt;/code&gt; nie posiada dla niego
wsparcia. Rzecz w tym, że &lt;code&gt;nftables&lt;/code&gt; potrafi natywnie obsługiwać listy adresów/portów i &lt;code&gt;ipset&lt;/code&gt;
nie jest mu w tym do niczego potrzebny.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przy pomocy USBguard zabezpieczyć porty USB przed złośliwymi urządzeniami</title>
      <link>https://morfikov.github.io/post/jak-przy-pomocy-usbguard-zabezpieczyc-porty-usb-przed-zlosliwymi-urzadzeniami/</link>
      <pubDate>Sun, 24 Feb 2019 12:00:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przy-pomocy-usbguard-zabezpieczyc-porty-usb-przed-zlosliwymi-urzadzeniami/</guid>
      <description>&lt;p&gt;Ostatnio na
Niebezpieczniku &lt;a href=&#34;https://niebezpiecznik.pl/post/zlosliwy-kabel-usb-ktory-zmienia-sie-w-klawiature-i-infekuje-twoj-komputer/&#34;&gt;pojawił się artykuł&lt;/a&gt;
na temat niezbyt przyjaznych urządzeń podłączanych do komputera za sprawą portów USB (opisanych na
przykładzie niepozornego przewodu) i tego jaką szkodę tego typu hardware może nam wyrządzić w
systemie. Ataki z wykorzystaniem podstawionych urządzeń zadziałają nawet na linux, choć pewnie cała
masa użytkowników wyznaje jeszcze mit, że ich komputer jest bezpieczny, bo przecie używają
alternatywnego systemu operacyjnego, który jest OpenSource i za priorytet obrał sobie szeroko
rozumiane bezpieczeństwo. Niestety nie jest tak różowo jakby mogło się co niektórym wydawać ale
można ten stan rzeczy naturalnie zmienić i nie trzeba przy tym rekompilować kernela z zamiarem
wyłączenia obsługi modułu USB, co ten opisany w podlinkowanym artykule atak oczywiście by również
powstrzymało. Zamiast tego możemy zainstalować sobie narzędzie &lt;code&gt;usbguard&lt;/code&gt; i przy jego pomocy
skonfigurować politykę podłączanych do portów USB urządzeń.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak włączyć dźwięk w kontenerze Docker&#39;a za sprawą PulseAudio</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-dzwiek-w-kontenerze-dockera-za-sprawa-pulseaudio/</link>
      <pubDate>Sat, 16 Feb 2019 13:22:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-dzwiek-w-kontenerze-dockera-za-sprawa-pulseaudio/</guid>
      <description>&lt;p&gt;Jakiś czas temu postanowiłem przetestować sposób zamknięcia graficznych aplikacji w kontenerze
Docker&#39;a. Całe rozwiązanie zostało opisane na
przykładzie &lt;a href=&#34;https://morfikov.github.io
/post/uruchamianie-graficznych-aplikacji-w-kontenerach-dockera/&#34;&gt;skonteneryzowania przeglądarki Firefox&lt;/a&gt;.
Ten opisany w podlinkowanym artykule pomysł był nawet całkiem przyzwoity ale nie nadaje się on, gdy
w grę wchodzą programy odtwarzające dźwięk. No może to za dużo powiedziane, że się nie nadaje, ale
z pewnością brakuje mu jednego istotnego elementu. Nawet ta przykładowa przeglądarka internetowa
jest w stanie odtwarzać dźwięki jeśli się odwiedzi stosowną stronę WWW. Standardowo jednak nic nie
usłyszymy w głośnikach, gdy odpalimy dajmy na to stronę YouTube i puścimy jakiś materiał video.
Dlatego też wypadałoby skonfigurować dźwięk i przesłać go do serwera PulseAudio, który będzie
odpalony na naszym linux&#39;owym hoście. Kiedyś już tego typu rozwiązanie nawet opisywałem na
przykładzie &lt;a href=&#34;https://morfikov.github.io
/post/pulseaudio-i-przesylanie-dzwieku-przez-siec/&#34;&gt;zintegrowania PulseAudio z kontenerami LXC&lt;/a&gt;.
Okazuje się, że tamto rozwiązanie znajduje również zastosowanie w przypadku Docker&#39;a. Trzeba tylko
nieco inaczej skonfigurować kontener i właśnie tej kwestii będzie dotyczył niniejszy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migracja z iptables na nftables w Debianie</title>
      <link>https://morfikov.github.io/post/migracja-z-iptables-na-nftables-w-debianie/</link>
      <pubDate>Sat, 16 Feb 2019 11:05:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/migracja-z-iptables-na-nftables-w-debianie/</guid>
      <description>&lt;p&gt;Zgodnie z &lt;a href=&#34;http://ral-arturo.org/2018/06/16/nfws2018.html&#34;&gt;informacją&lt;/a&gt;, która pojawiła się już ponad pół roku temu, dystrybucje linux&#39;a powoli
zaczynają odchodzić od &lt;code&gt;iptables&lt;/code&gt; . Prawdopodobnie w niedługim czasie &lt;code&gt;iptables&lt;/code&gt; zostanie już
całkowicie wyparty i zastąpiony przez &lt;code&gt;nftables&lt;/code&gt; , przynajmniej jeśli chodzi o desktopy. Nawet
&lt;a href=&#34;https://wiki.debian.org/nftables#Current_status&#34;&gt;Debian zakomunikował&lt;/a&gt;, że następne wydanie stabilne tej dystrybucji (Buster) będzie domyślnie
wykorzystywało &lt;code&gt;nftables&lt;/code&gt; . Wypadałoby zatem się przenieść na ten nowy framework i przygotować
sobie kilka podstawowych reguł firewall&#39;a, które zabezpieczoną naszą maszynę przed nieautoryzowanym
dostępem z sieci.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak sklonować duże repozytorium git na niestabilnym łączu sieciowym</title>
      <link>https://morfikov.github.io/post/jak-sklonowac-duze-repozytorium-git-na-niestabilnym-laczu-sieciowym/</link>
      <pubDate>Sat, 16 Feb 2019 05:29:25 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-sklonowac-duze-repozytorium-git-na-niestabilnym-laczu-sieciowym/</guid>
      <description>&lt;p&gt;Połączenie z internetem, z którego ostatnio przyszło mi korzystać, nie należało zbytnio do tych
najbardziej wydajnych pod względem prędkości przesyłu danych. O ile szybkość transferu można by
jeszcze przemilczeć, to owe łącze nie należało też do tych najstabilniejszych i czasem kontakt
ze światem był zwyczajnie zrywany. Krótko rzecz ujmując, ten net nadawał się chyba jedynie do
przeglądania stron WWW. Pech jednak chciał, że potrzebowałem zassać na takim
połączeniu &lt;a href=&#34;https://salsa.debian.org/kernel-team/linux&#34;&gt;repozytorium git&#39;a z patch&#39;ami Debiana&lt;/a&gt;
nakładanymi na kernel linux&#39;a. To repozytorium nie należy do największych ale też do małych ono
się nie zalicza -- waży około 2 GiB. Oczywiście można by zrobić jedynie płytki klon takiego repo za
sprawą &lt;code&gt;git clone --depth=1&lt;/code&gt; , co skutkowałoby pobraniem plików w wersji z ostatniego commit&#39;a, co
z kolei zredukowałoby w znacznym stopniu wielkość pobieranych danych (parę-paręnaście MiB). Co
jednak zrobić w przypadku, gdy musimy sklonować sporych rozmiarów repozytorium git, a dysponujemy
przy tym dość wolnym połączeniem sieciowym? Czy jest to w ogóle możliwe, bo przecież git nie ma
zaimplementowanej opcji wznawiania przerwanej synchronizacji i każde zakłócenie tego procesu
skutkować będzie tym, że całe repozytorium trzeba będzie pobrać jeszcze raz i to bez względu na to,
czy proces się zawiesi zaraz na początku, czy też pod koniec operacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak włączyć IPv6 Privacy Extensions w Debianie (SLAAC)</title>
      <link>https://morfikov.github.io/post/jak-wlaczyc-ipv6-privacy-extensions-w-debianie-slaac/</link>
      <pubDate>Sun, 10 Feb 2019 08:22:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wlaczyc-ipv6-privacy-extensions-w-debianie-slaac/</guid>
      <description>&lt;p&gt;Protokół IPv6 został opracowany już dość dawno temu, a jednak ilość hostów w internecie
komunikujących się za jego pomocą wciąż nie jest zbyt wysoka
i &lt;a href=&#34;https://www.google.com/intl/en/ipv6/statistics.html&#34;&gt;oscyluje w granicach 25%&lt;/a&gt;. Faktem jest, że
migracja z IPv4 na IPv6 może być sporym kosztem dla niektórych podmiotów jeśli chodzi o kwestię
związaną z wymianą sprzętu i ze zmianą konfiguracji sieci, co pewnie zniechęca część ISP do
wdrożenia tego protokołu. Użytkownicy korzystający z sieci z kolei nie wiedzieć czemu też
preferują IPv4 nad IPv6. Jakiś czas temu czytałem nawet artykuł na temat zagrożenia prywatności
jakie może nieść ze sobą protokół IPv6. Chodzi generalnie o to, że obecnie wszyscy przywykliśmy do
rozwiązania jakie oferuje nam NAT, które jest w stanie utrudnić nieco naszą identyfikację i analizę
naszej aktywności w internecie. W przypadku IPv6 adresy IP są dość unikatowe w skali globalnej, a
część odpowiedzialna za identyfikację hosta (ostatnie 64 bity) stanowi identyfikator EUI64, który z
kolei jest generowany na podstawie adresu MAC karty sieciowej. W taki oto sposób interfejs tej
karty będzie miał stały identyfikator EUI64, a hosta będzie można zidentyfikować bez problemu i
bez względu na to u którego ISP podłączymy nasz komputer. Rozwiązaniem tego problemu jest mechanizm
zwany IPv6 Privacy Extensions. Przydałoby się zatem rzucić na niego okiem i jeśli okaże się
użyteczny, to wypadałoby go włączyć w naszym Debian Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ustalić nazwę procesu korzystającego z sieci</title>
      <link>https://morfikov.github.io/post/jak-ustalic-nazwe-procesu-korzystajacego-z-sieci/</link>
      <pubDate>Fri, 08 Feb 2019 20:10:41 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ustalic-nazwe-procesu-korzystajacego-z-sieci/</guid>
      <description>&lt;p&gt;Konfigurując filtr pakietów &lt;code&gt;iptables&lt;/code&gt;/&lt;code&gt;nftables&lt;/code&gt; na Debianie zwykle nie przykładamy większej wagi
do procesów, które chcą nawiązać połączenia wychodzące z naszego linux&#39;owego hosta. Mamy przecież
&amp;quot;skonfigurowany&amp;quot; firewall w łańcuchach &lt;code&gt;INPUT&lt;/code&gt; i &lt;code&gt;FORWARD&lt;/code&gt; i wszelkie zagrożenia z sieci nie
powinny nas dotyczyć. Problem w tym, że jeśli jakiś złowrogi proces zostanie uruchomiony w naszym
systemie, to jest on w stanie komunikować się ze światem zewnętrznym praktycznie bez żadnych
ograniczeń za sprawą braku jakichkolwiek reguł w łańcuchu &lt;code&gt;OUTPUT&lt;/code&gt; . Można oczywiście temu zaradzić
budując zaporę sieciową na bazie &lt;code&gt;cgroups&lt;/code&gt; , gdzie każda aplikacja będzie miała oznaczone pakiety,
przez co będzie można je rozróżnić i zablokować albo przepuścić przez filter. W tym wpisie jednak
nie będziemy się zajmować konstrukcją tego typu FW, tylko spróbujemy sobie odpowiedzieć na pytanie
jak namierzyć proces, który komunikuje się z siecią (lub też próbuje), posiadając jedynie log
&lt;code&gt;iptables&lt;/code&gt;/&lt;code&gt;nftables&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak uruchomić kilka usług w kontenerze Docker&#39;a</title>
      <link>https://morfikov.github.io/post/jak-uruchomic-kilka-uslug-w-kontenerze-dockera/</link>
      <pubDate>Sat, 02 Feb 2019 07:20:43 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-uruchomic-kilka-uslug-w-kontenerze-dockera/</guid>
      <description>&lt;p&gt;W kontenerach Docker&#39;a nie powinno się uruchamiać więcej usług niż jedna. Czasami jednak zachodzi
potrzeba, by właśnie uruchomić kilka niezależnych od siebie procesów, które będą ze sobą
współpracować w obrębie takiego pojedynczego kontenera. Weźmy sobie na przykład serwer WWW Apache2
i bazę danych MySQL/MariaDB. Każda z tych usług posiada swój dedykowany kontener (nawet oficjalny)
i generalnie skonfigurowanie komunikacji między tymi dwoma kontenerami Docker&#39;a nie jest niczym
trudnym. Jeśli jednak ktoś by się uparł, to może stworzyć sobie taki kontener, który będzie
uruchamiał obie te usługi. Oczywiście w tym przypadku raczej nikt nie będzie łączył tych dwóch
kontenerów w jeden ale są pewne sytuacje, w których będziemy chcieli uruchomić więcej niż jeden
proces wewnątrz kontenera i gdy ten czas nadejdzie, to wypadałoby wiedzieć jak się do tego
przedsięwzięcia zabrać.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak zalogować błędy podczas zamykania systemu Debian Linux</title>
      <link>https://morfikov.github.io/post/jak-zalogowac-bledy-podczas-zamykania-systemu-debian-linux/</link>
      <pubDate>Sat, 02 Feb 2019 06:12:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-zalogowac-bledy-podczas-zamykania-systemu-debian-linux/</guid>
      <description>&lt;p&gt;By wyłączyć komputer, jego system operacyjny musi pierw zatrzymać (lub też ubić siłowo) wszystkie
działające usługi za wyjątkiem tego mającego PID z numerkiem 1. Zwykle proces zamykania się systemu
Debian Linux nie trwa więcej niż parę sekund ale czasami pojawiają się dziwne problemy, które mogą
to zadanie utrudnić lub też całkowicie uniemożliwić. Nawet jeśli system będzie się w stanie
zresetować, to zanim to nastąpi, to na konsoli mogą pojawić się komunikaty mogące pomóc nam w
zdiagnozowaniu dolegliwości, która doskwiera naszej maszynie. Problem w tym, że część tych
wiadomości nie zostanie nigdy zalogowana do pliku, gdzie moglibyśmy ich poszukać. Dzieje się tak
dlatego, że w pewnym określonym momencie zamykania się systemu trzeba wyłączyć usługę logowania, co
zwykle widać w logu jako &lt;code&gt;systemd-journald[]: Journal stopped&lt;/code&gt; . Gdy dziennik zostanie zatrzymany,
żadna wiadomość, która od tego momentu pojawi się na ekranie, nie zostanie już zalogowana do pliku.
Jeśli teraz pojawią nam się ostrzeżenia lub błędy, a po chwili komputer się zresetuje, to możemy
mieć nie lada problem z ustaleniem przyczyny mimo, że system nam ją zgłasza. Przydałoby się zapisać
te komunikaty, tylko jak to zrobić, skoro usługa logowania jest już nieaktywna?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Uruchamianie graficznych aplikacji w kontenerach Docker&#39;a</title>
      <link>https://morfikov.github.io/post/uruchamianie-graficznych-aplikacji-w-kontenerach-dockera/</link>
      <pubDate>Sun, 27 Jan 2019 11:32:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/uruchamianie-graficznych-aplikacji-w-kontenerach-dockera/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://morfikov.github.io
/post/jak-uruchomic-firefoxa-w-osobnej-przestrzeni-nazw-sieciowych/&#34;&gt;Bawiąc się ostatnio na Debianie przestrzeniami nazw sieciowych&lt;/a&gt;,
wpadł mi do głowy pomysł na nieco bardziej zautomatyzowaną formę separacji procesów użytkownika od
pozostałej części systemu. Co by nie mówić, opisany w podlinkowanym artykule sposób uruchomienia
Firefox&#39;a niezbyt mi przypadł do gustu. Nowy sposób separacji zakłada za to wykorzystanie
kontenerów Docker&#39;a, w których to będzie uruchamiany dowolny proces, np. Firefox, a całym
przedsięwzięciem związanym z procesem konteneryzacji będzie zajmował się już Docker. W ten sposób
uruchomienie dowolnej aplikacji, w tym też tych graficznych (GUI), będzie sprowadzać się do wydania
w terminalu tylko jednego polecenia. Zatem do dzieła.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ręcznie zweryfikować sygnaturę modułu kernela linux</title>
      <link>https://morfikov.github.io/post/jak-recznie-zweryfikowac-sygnature-modulu-kernela-linux/</link>
      <pubDate>Sat, 26 Jan 2019 10:10:12 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-recznie-zweryfikowac-sygnature-modulu-kernela-linux/</guid>
      <description>&lt;p&gt;Bawiąc się ostatnio kernelem linux na dystrybucji Debian i opcjami mającymi poprawić jego
bezpieczeństwo, włączyłem
sobie &lt;a href=&#34;https://morfikov.github.io
/post/automatyczne-podpisywanie-modulow-kernela-przez-dkms/&#34;&gt;mechanizm podpisywania modułów&lt;/a&gt;.
W ten sposób żaden zewnętrzny moduł nie zostanie załadowany przez jądro operacyjne, no chyba, że
taki moduł będzie podpisany przez ten sam klucz co i kernel. Zdziwiłem się odrobinę, gdy moim
oczom pokazał się hash &lt;code&gt;md4&lt;/code&gt; w wyjściu polecenia &lt;code&gt;modinfo&lt;/code&gt; . Jak się okazało później, to niezbyt
dokładne zinterpretowanie wiadomości PKCS#7 przez &lt;code&gt;kmod&lt;/code&gt; było (i nadal jest) wynikiem &lt;a href=&#34;https://bugzilla.redhat.com/show_bug.cgi?id=1320921&#34;&gt;błędu
obecnego w tym pakiecie od już paru lat&lt;/a&gt;. W
efekcie &lt;code&gt;modinfo&lt;/code&gt; nie jest w stanie zweryfikować tej sygnatury, a w moim umyśle zaistniało pytanie:
czy istnieje w ogóle możliwość manualnego sprawdzenia czy ta sygnatura jest w porządku? Kernel co
prawda ten cały zabieg przeprowadza automatycznie ale przydałoby się ręcznie zweryfikować
poprawność sygnatury modułu i przy okazji obadać sobie co tak naprawdę się dzieje podczas tego
procesu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak uruchomić Firefox&#39;a w osobnej przestrzeni nazw sieciowych</title>
      <link>https://morfikov.github.io/post/jak-uruchomic-firefoxa-w-osobnej-przestrzeni-nazw-sieciowych/</link>
      <pubDate>Sun, 20 Jan 2019 21:10:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-uruchomic-firefoxa-w-osobnej-przestrzeni-nazw-sieciowych/</guid>
      <description>&lt;p&gt;Domyślnie każdy proces uruchomiony na linux (w tym przypadku Debian) dziedziczy swoją przestrzeń
nazw sieciowych (network namespaces) od procesu nadrzędnego, standardowo od procesu init (tego z
pid 1). W takim przypadku, wszystkie procesy współdzielą tę samą przestrzeń nazw sieciowych, przez
co mają dostęp do tych samych interfejsów sieciowych, tych samych tras routingu, a reguły
firewall&#39;a czy ustawienia serwerów DNS w jednakowym stopniu dotyczą wszystkich procesów i
zmieniając sieciową konfigurację systemu robimy to globalnie dla wszystkich tych procesów
jednocześnie. Czasami tego typu mechanika działania sieci nie jest zbyt pożądana z punktu
widzenia bezpieczeństwa lub też prywatności użytkownika. Przykładem mogą być przeglądarki
internetowe, np. Firefox, Opera czy Google Chrome/Chromium, które mogą zdradzić nasz lokalny adres
IP (w przypadku stosowania NAT). Jako, że też zostawiamy wszędzie nasz namiar w postaci
zewnętrznego adresu IP, to oba te adresy mogą nas bez większego problemu zidentyfikować w
internecie. Można jednak postarać się, by ten adres lokalny, który zwróci przeglądarka
internetowa, różnił się od tego, który przydziela nam nasz operator ISP.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatyczne podpisywanie modułów kernela przez DKMS</title>
      <link>https://morfikov.github.io/post/automatyczne-podpisywanie-modulow-kernela-przez-dkms/</link>
      <pubDate>Sat, 05 Jan 2019 04:10:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/automatyczne-podpisywanie-modulow-kernela-przez-dkms/</guid>
      <description>&lt;p&gt;Budując kernel linux&#39;a trzeba zastanowić się nad kwestią modułów, które nie są wbudowane
bezpośrednio w samo jądro operacyjne. Nie chodzi tutaj bezpośrednio o funkcjonalność kernela,
którą można zbudować jako moduł w procesie jego kompilacji ale raczej o wszystkie zewnętrzne
moduły, które przez zespół kernela są traktowane jako &lt;code&gt;out-of-tree&lt;/code&gt; . By poprawić nieco
bezpieczeństwo związane z takimi modułami, można wdrożyć podpisy cyfrowe, które takie moduły
muszą okazać podczas próby załadowania ich w systemie. Gdy moduł nie został podpisany, to kernel
go nie załaduje zwracając przy tym błąd &lt;code&gt;modprobe: ERROR: could not insert &#39;module&#39;: Required key not available&lt;/code&gt; . W ten sposób można ochronić się przed częścią ataków, w których moduły pochodzenia
trzeciego mogą zostać załadowane i poczynić nam ogromne spustoszenie w systemie. Problem w tym, że
w dystrybucji Debian wykorzystywany jest mechanizm DKMS (Dynamic Kernel Module Support). Może i
mamy dzięki niemu możliwość instalacji w systemie całej masy dodatkowych modułów ale ich również
nie będzie można załadować, bo nie zostały podpisane kluczem, którego certyfikat został zaszyty
w kernelu. Można jednak zmusić mechanizm DKMS, by wskazane przez nas moduły podpisywał
automatycznie przy ich instalacji i aktualizacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Budowanie kernela linux dla konkretnej maszyny z Debianem</title>
      <link>https://morfikov.github.io/post/budowanie-kernela-linux-dla-konkretnej-maszyny-z-debianem/</link>
      <pubDate>Thu, 27 Dec 2018 22:14:00 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/budowanie-kernela-linux-dla-konkretnej-maszyny-z-debianem/</guid>
      <description>&lt;p&gt;Każda maszyna działająca pod kontrolą dystrybucji linux ma na swoim pokładzie kernel, czyli jądro
operacyjne, które zarządza praktycznie każdym aspektem pracy takiego komputera. W dystrybucji
Debian, kernel jest dostarczany w pakietach mających nazwy zaczynające się od &lt;code&gt;linux-image-*&lt;/code&gt;.
Te pakiety są budowane przez odpowiednie osoby z zespołu Debiana i udostępniane do łatwej
instalacji użytkownikowi końcowemu. Niemniej jednak, taki kernel ma za zadanie działać na jak
największej ilości komputerów, a przez to posiada całą masę modułów, które na naszej maszynie nigdy
nie będą wykorzystane. Ten fakt nie wpływa w jakimś ogromnym stopniu na pracę maszyny, ale gdy
później zachodzi potrzeba skonfigurowania kernela w nieco inny sposób, np. włączenie jednej czy
dwóch opcji czy też nałożenie patch&#39;a, który nie został zaaplikowany przez dev&#39;ów Debiana, to
trzeba taki kernel na nowo skompilować już samodzielnie, a to zajmie nam bardzo dużo czasu. Zamiast
tego można pokusić się o przygotowanie kernela pod konkretny hardware wyłączając przy tym całą masę
zbędnych rzeczy i ograniczając przy tym czas jaki jest potrzebny na zbudowanie całego jądra
operacyjnego. Czy istnieje jakiś prosty sposób, by taki kernel zbudować sobie samemu mając przy tym
minimalną wiedzę co do opcji kernela, które mogą nas przysporzyć o ból... głowy? Okazuje się, że
tak i w tym artykule prześledzimy sobie cały ten proces.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja serwera XMPP/Jabber pod linux (ejabberd)</title>
      <link>https://morfikov.github.io/post/konfiguracja-serwer-xmpp-jabber-linux-ejabberd/</link>
      <pubDate>Mon, 20 Mar 2017 20:26:15 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-serwer-xmpp-jabber-linux-ejabberd/</guid>
      <description>&lt;p&gt;Użytkownicy internetu mają całą masę różnych sposobów na komunikację miedzy sobą. Kiedyś wszyscy
korzystali z komunikatorów typu Gadu-Gadu. Ja byłem jedyną osobą, która od samego początku wolała
alternatywne rozwiązania i jechałem na komunikatorze Tlen (ten od O2), a w niedługim czasie
przesiadłem się na Jabber&#39;a i tak z niego korzystam do dziś. W zasadzie GG i Tlen są obecnie już
chyba na wymarciu, bo większość ludzi (jak nie wszyscy) przerzuciła się na Facebook&#39;a czy Twitter&#39;a.
Niemniej jednak, pisanie o sprawach prywatnych w tych serwisach nie jest najlepszym rozwiązaniem.
Jeśli chcemy zadbać o poufność przesyłanych przez internet komunikatów, to trzeba to robić na inne
sposoby. Jednym z nich jest właśnie korzystanie z &lt;a href=&#34;https://xmpp.org/&#34;&gt;protokołu XMPP/Jabber&lt;/a&gt;. To co
odróżnia Jabber&#39;a od innych technologii na rynku, to fakt zdecentralizowania sieci, czyli mamy całą
masę serwerów Jabber&#39;a, na których możemy sobie stworzyć konto. Uwalenie jednego serwera nie wpływa
na działanie pozostałych. Google także wykorzystuje protokół XMPP/Jabber i mając konto na gmail&#39;u,
mamy również stosowny JID w postaci adresu email, który możemy sobie wklepać do jednego z klientów
Jabber&#39;a, np. &lt;a href=&#34;https://xmpp.org/software/clients.html&#34;&gt;PSI czy Gajim&lt;/a&gt;, i jesteśmy już w stanie
rozmawiać z osobami, które mają konta na innych serwerach. Właśnie, inne serwery, a może by tak
sobie postawić własny serwer Jabber&#39;a? Tak się składa, że w repozytorium Debiana znajduje się
&lt;a href=&#34;https://www.ejabberd.im/&#34;&gt;oprogramowanie ejabberd&lt;/a&gt;, które jest nam w stanie umożliwić realizację
tego przedsięwzięcia.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Android Studio i Android SDK pod linux</title>
      <link>https://morfikov.github.io/post/android-studio-i-android-sdk-pod-linux/</link>
      <pubDate>Sun, 29 Jan 2017 18:29:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/android-studio-i-android-sdk-pod-linux/</guid>
      <description>&lt;p&gt;Rozpoczynając przygodę z Androidem (tylko taką nieco bardziej deweloperską) trzeba posiadać w
systemie szereg niezbędnych narzędzi. Chodzi tutaj oczywiście o Android SDK. Metod na instalację
tego pakietu na linux&#39;ie, a konkretnie w dystrybucji Debian, jest co najmniej kilka. Chodzi o to, że
Google udostępnia paczkę &lt;code&gt;.zip&lt;/code&gt; z Android SDK, którą można pobrać sobie z oficjalnej strony
Androida. Dodatkowo, na tej samej stronie mamy coś o nazwie Android Studio, które również jest w
stanie nam potrzebne narzędzia dostarczyć. Poza tym, te narzędzia można także skompilować sobie ze
źródeł Androida, jak i również zainstalować bezpośrednio z repozytorium samego Debiana. Niemniej
jednak, część z tych sposobów nie jest zbytnio wygodna, a pozostała część zakłada, że korzystamy z
najnowszej wersji Androida (obecnie Nougat). A co w przypadku, gdybyśmy chcieli operować na
Androidzie 5.1 (Lollipop) czy 6.0 (Marshmallow)? Jak zainstalować pasujące wersje narzędzi, by nic
nam się nie gryzło ze sobą?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Redshift i dostosowanie temperatury kolorów ekranu</title>
      <link>https://morfikov.github.io/post/redshift-i-dostosowanie-temperatury-kolorow-ekranu/</link>
      <pubDate>Sun, 22 Jan 2017 18:48:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/redshift-i-dostosowanie-temperatury-kolorow-ekranu/</guid>
      <description>&lt;p&gt;Pewnie spotkaliście się już wiele razy z informacją, że ekrany naszych smartfonów, tabletów czy
komputerów szkodzą naszym oczom. Chodzi generalnie o to, że wyświetlacze LCD emitują światło
niebieskie, które w nadmiarze nie wpływa dla nas (i naszego wzroku) korzystnie, a przecie każdy z
nas siedzi godzinami przed komputerem. W zasadzie te negatywne efekty ciągłego spoglądania na
wyświetlacz nasilają się zwłaszcza wieczorami i w nocy. Jeśli pracujemy na laptopie do późna i przy
okazji mamy na tej maszynie zainstalowaną jakąś dystrybucję linux&#39;a, np. Debian, to możemy złagodzić
skutki zmęczenia oczu przez dobór nieco innej temperatury kolorów wyświetlanego obrazu. W tym
zadaniu może nam pomóc oprogramowanie &lt;a href=&#34;http://jonls.dk/redshift/&#34;&gt;redshift&lt;/a&gt; i to jemu będzie
poświęcony poniższy wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować połączenie VPN przez SSH</title>
      <link>https://morfikov.github.io/post/jak-skonfigurowac-polaczenie-vpn-przez-ssh/</link>
      <pubDate>Sun, 11 Dec 2016 15:59:06 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-skonfigurowac-polaczenie-vpn-przez-ssh/</guid>
      <description>&lt;p&gt;Szukając informacji na &lt;a href=&#34;https://morfikov.github.io
/post/jak-ukryc-ruch-openvpn-przy-pomocy-stunnel/&#34;&gt;temat ukrycia ruchu generowanego przez
OpenVPN&lt;/a&gt;, natrafiłem także na
sposób, który &lt;a href=&#34;https://help.ubuntu.com/community/SSH_VPN&#34;&gt;wykorzystuje do tego celu połączenie SSH&lt;/a&gt;.
W efekcie jesteśmy w stanie upodobnić ruch VPN do tego, który zwykle służy do zarządzania zdalnymi
systemami linux. Jako, że temat maskowania połączenia VPN jest kluczowy w walce z cenzurą internetu,
to im więcej sposobów, by taki zabieg przeprowadzić, tym lepiej. Dlatego też postanowiłem odświeżyć
nieco podlinkowany wyżej artykuł i sprawdzić czy jest on jeszcze aktualny. Wprawdzie nie dysponuję
Ubuntu, a jedynie dystrybucją Debian ale raczej nie powinno być problemów z odwzorowaniem
konfiguracji na tym systemie, choć artykuł jest dość leciwy już i pewnie trzeba będzie kilka rzeczy
zaktualizować.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak ukryć ruch OpenVPN przy pomocy stunnel</title>
      <link>https://morfikov.github.io/post/jak-ukryc-ruch-openvpn-przy-pomocy-stunnel/</link>
      <pubDate>Sat, 10 Dec 2016 15:18:18 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-ukryc-ruch-openvpn-przy-pomocy-stunnel/</guid>
      <description>&lt;p&gt;Ci z nas, którzy korzystają codziennie z internetu, wiedzą, że większość nawiązywanych połączeń
między dwoma punktami w tej sieci globalnej przechodzi przez szereg węzłów i jest podatnych na
przechwycenie i podsłuchanie. Nawet jeśli ruch z określonymi serwisami jest szyfrowany, to w dalszym
ciągu nie jesteśmy w stanie ukryć pewnych newralgicznych informacji, takich jak docelowy adres IP i
port, na którym nasłuchuje zdalna usługa. Wszystkie połączenia sieciowe zestawiane z naszego
komputera czy routera domowego przechodzą przez infrastrukturę ISP, u którego mamy wykupiony
internet. Tacy ISP są nam w stanie pod naciskiem rządu zablokować połączenia z konkretnymi adresami
wprowadzając na terenie danego kraju cenzurę treści dostępnej w internecie, czego obecnie jesteśmy
świadkami w Europie, no i w Polsce. Można oczywiście posiłkować się rozwiązaniami opartymi o VPN,
np. &lt;a href=&#34;https://morfikov.github.io
/post/jak-skonfigurowac-serwer-vpn-na-debianie-openvpn/&#34;&gt;stawiając serwer OpenVPN w innym
kraju&lt;/a&gt;. Problem jednak w
tym, że ruch OpenVPN różni się od tego, z którym mamy do czynienia w przypadku choćby HTTPS. Jest
zatem możliwość rozpoznania ruchu VPN i zablokowania go stosując &lt;a href=&#34;https://en.wikipedia.org/wiki/Deep_packet_inspection&#34;&gt;głęboką analizę
pakietów&lt;/a&gt; (Deep Packet Inspection, DPI). By
się przed tego typu sytuacją ochronić, trzeba upodobnić ruch generowany przez OpenVPN do zwykłego
ruchu SSL/TLS. Do tego celu służy &lt;a href=&#34;https://www.stunnel.org/index.html&#34;&gt;narzędzie stunnel&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować serwer VPN na Debianie (OpenVPN)</title>
      <link>https://morfikov.github.io/post/jak-skonfigurowac-serwer-vpn-na-debianie-openvpn/</link>
      <pubDate>Tue, 06 Dec 2016 19:22:49 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-skonfigurowac-serwer-vpn-na-debianie-openvpn/</guid>
      <description>&lt;p&gt;Co raz częściej słychać w mediach o próbie cenzurowania internetu i blokowaniu dostępu do kolejnych
serwisów i stron www. Ostatnio znowu podnieśli kwestię blokowania pokemonów bezpośrednio u ISP tak,
by za zgodą ISP (władzy) można przeglądać tego typu serwisy. W sumie mam już tego dość i korzystając
z okazji, że posiadam za granicą niewielkich rozmiarów VPS, który i tak nie jest zbytnio obciążony,
to postanowiłem sobie skonfigurować na nim serwer VPN w oparciu o &lt;a href=&#34;https://openvpn.net/index.php/open-source/documentation/howto.html&#34;&gt;oprogramowanie
OpenVPN&lt;/a&gt;, które jest standardowo
dostępne w każdej dystrybucji linux&#39;a. Proces konfiguracji serwera jak i klienta z zainstalowanym
Debianem zostanie opisany poniżej. Niemniej jednak, inne urządzenia takie jak routery WiFi i
smartfony również wymagają zaimplementowania w nich mechanizmu szyfrującego ruch ale te rozwiązania
zostaną opisane w osobnych wątkach.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przesyłanie dźwięku i plików ze smartfona przez bluetooth</title>
      <link>https://morfikov.github.io/post/przesylanie-dzwieku-plikow-ze-smartfona-bluetooth/</link>
      <pubDate>Sat, 19 Nov 2016 19:40:24 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przesylanie-dzwieku-plikow-ze-smartfona-bluetooth/</guid>
      <description>&lt;p&gt;Praktycznie każdy telefon czy komputer/laptop jest wyposażony już w adapter bluetooth. Obecnie coraz
rzadziej ten protokół jest wykorzystywany do przesyłania plików jako takich, bo przecie mamy WiFi.
Niemniej jednak, w starszych modelach urządzeń bluetooth może być dla nas jedyną opcją, by przesłać
pliki bezprzewodowo. Nawet jeśli dysponujemy smartfonem z jednym z nowszych Androidów, to i tak są
pewne sytuacje, w których bluetooth może znaleźć ciekawe zastosowanie, np. streaming dźwięku.
Urządzenia bluetooth bardzo często sprawiają problemy pod linux i przydałoby się zebrać trochę
informacji na temat ich konfiguracji, by przesyłanie dźwięku i plików nie stanowiło dla nas
większego wyzwania w sytuacjach podbramkowych, gdzie wszelkie inne alternatywy komunikacji zawodzą.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Smartfon z Androidem pod linux&#39;em (MTP/PTP)</title>
      <link>https://morfikov.github.io/post/smartfon-android-linux-mtp-ptp/</link>
      <pubDate>Thu, 22 Sep 2016 21:54:23 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/smartfon-android-linux-mtp-ptp/</guid>
      <description>&lt;p&gt;Wpadł mi w łapki &lt;a href=&#34;http://www.neffos.pl/product/details/C5&#34;&gt;smartfon Neffos C5&lt;/a&gt; od TP-LINK, który ma
na pokładzie Androida. Chciałem nim zrobić parę fotek, tylko pojawił się problem uzyskania dostępu
do zasobów tego telefonu. Samo urządzenie pod linux&#39;em identyfikowane jest jako &lt;code&gt;idVendor=2357&lt;/code&gt; oraz
&lt;code&gt;idProduct=0314&lt;/code&gt; ale po jego podłączeniu do portu USB komputera nie pojawiły się żadne nowe dyski,
które można by przejrzeć w celu zgania ich zawartości. Problem tkwił w konfiguracji mojego Debiana,
w którym to brakowało obsługi protokołu MTP. Po chwili rozgryzłem tę zagadkę instalując w systemie
pakiet &lt;code&gt;jmtpfs&lt;/code&gt; , co umożliwiło interakcję z systemem plików telefonu i zgranie zrobionych zdjęć.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Debian: Profilowanie sieci z guessnet, ifplugd i wpasupplicant</title>
      <link>https://morfikov.github.io/post/debian-profilowanie-sieci-guessnet-ifplugd-wpasupplicant/</link>
      <pubDate>Mon, 05 Sep 2016 13:01:08 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/debian-profilowanie-sieci-guessnet-ifplugd-wpasupplicant/</guid>
      <description>&lt;p&gt;Kilka dni temu na &lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=28903&#34;&gt;forum dug.net.pl&lt;/a&gt; pojawił się
ciekawy wątek dotyczący problemu skonfigurowania profilowanych sieci. Chodzi o to, że praktycznie
każdy z nas jest po części w jakiś sposób mobilny i zabiera laptopa ze sobą w dziwne miejsca. Sieci
w tych lokalizacjach mogą cechować się różnym poziomem bezpieczeństwa. Dlatego też zamiast korzystać
z jednej konfiguracji sieci na linux&#39;ie, można stworzyć szereg profili i w oparciu o nie dostosować
sobie połączenie sieciowe. W tym artykule spróbujemy zaimplementować takie rozwiązanie na Debianie
wyposażonym w menadżer okien Openbox. W skrócie stworzymy automat, który będzie nam działał w
oparciu o pakiety guessnet, &lt;a href=&#34;http://0pointer.de/lennart/projects/ifplugd/&#34;&gt;ifplugd&lt;/a&gt; oraz
&lt;a href=&#34;https://w1.fi/wpa_supplicant/&#34;&gt;wpasupplicant&lt;/a&gt;. Cała konfiguracja zaś sprowadzać się będzie jedynie
do edycji plików &lt;code&gt;/etc/network/interfaces&lt;/code&gt; oraz &lt;code&gt;/etc/wpa_supplicant/wpa_supplicant.conf&lt;/code&gt; .&lt;/p&gt;
&lt;p&gt;Niniejszy artykuł został nieco przerobiony po fazach eksperymentów. Przede wszystkim, zrezygnowałem
z zaprzęgania &lt;code&gt;guessnet&lt;/code&gt; do rozpoznawania sieci WiFi i aplikowania roamingu. Zamiast tego zostały
wykorzystane natywne rozwiązania roamingowe oferowane przez &lt;code&gt;wpa_supplicant&lt;/code&gt; . Zaowocowało to
uproszczeniem całej konfiguracji, co przełożyło się na wyeliminowanie pewnych błędów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Metryki tras interfejsów eth0 i wlan0 w laptopie (metric)</title>
      <link>https://morfikov.github.io/post/metryki-tras-interfejsow-eth0-wlan0-laptop-metric/</link>
      <pubDate>Fri, 02 Sep 2016 17:50:11 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/metryki-tras-interfejsow-eth0-wlan0-laptop-metric/</guid>
      <description>&lt;p&gt;W obecnych czasach posiadanie komputera, który dysponuje kilkoma interfejsami sieciowymi nie jest
niczym niezwykłym. Praktycznie każdy laptop posiada już na pokładzie co najmniej jedną kartę WiFi i
minimum jeden port ethernet. W efekcie czego jesteśmy w stanie podłączyć się do sieci zarówno
przewodowo jak i bezprzewodowo. Problem jednak pojawia się w momencie, gdy chcemy wykorzystywać oba
te interfejsy, z tym, że dysponujemy jedynie niezbyt zaawansowanym menadżerem okien Openbox. Takie
środowiska zwykle nie mają na pokładzie automatów pokroju Network Manager, przez co bardziej
zaawansowana konfiguracja sieci może być dość skomplikowana. Do tej pory wykorzystywałem &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-interfejsow-bond-bonding/&#34;&gt;interfejs
bond0&lt;/a&gt;, by mieć możliwość łatwego
przełączania się miedzy sieciami. Istnieje inny sposób konfiguracji interfejsów &lt;code&gt;eth0&lt;/code&gt; i &lt;code&gt;wlan0&lt;/code&gt; w
pliku &lt;code&gt;/etc/network/interfaces&lt;/code&gt; tak, by działały one nam równolegle i nie powodowały problemów z
połączeniem, a wszystko za sprawą opcji &lt;code&gt;metric&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dynamiczna konfiguracja sieci w oparciu o ifplugd</title>
      <link>https://morfikov.github.io/post/dynamiczna-konfiguracja-sieci-ifplugd/</link>
      <pubDate>Thu, 01 Sep 2016 12:24:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dynamiczna-konfiguracja-sieci-ifplugd/</guid>
      <description>&lt;p&gt;Sporo użytkowników różnego rodzaju linux&#39;ów, zwłaszcza dystrybucji Debian, niezbyt chwali sobie
automaty konfigurujące połączenie sieciowe typu &lt;a href=&#34;https://wiki.gnome.org/Projects/NetworkManager&#34;&gt;Network
Manager&lt;/a&gt;. W sumie nigdy się jemu bliżej nie
przyglądałem ale na necie nie cieszy się on najlepszą opinią. Niemniej jednak, Network Manager
potrafi automatyzować pewne aspekty pracy w sieci. Weźmy przykład korzystania z dwóch różnych pod
względem parametrów sieci przewodowych. Jak się zachowa nasz OS w chwili przełączania się między
tymi sieciami w przypadku, gdy nie będziemy mieli zainstalowanego jakiegoś automatu dynamicznie
konfigurującego połączenie? W przypadku jednej sieci, połączenie będzie nam działać, w przypadku
drugiej zaś napotkamy problemy. W lekkich środowiskach opartych o menadżery okien, np. Openbox, nie
musimy instalować Network Manager&#39;a, by ogarnąć tę kwestię konfiguracyjną. Możemy posiłkować się
demonem &lt;code&gt;ifplugd&lt;/code&gt; i to tym narzędziu będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chroot Apache2 vs dyrektywa open_basedir w PHP</title>
      <link>https://morfikov.github.io/post/chroot-apache2-vs-dyrektywa-open_basedir-w-php/</link>
      <pubDate>Mon, 22 Aug 2016 22:03:02 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/chroot-apache2-vs-dyrektywa-open_basedir-w-php/</guid>
      <description>&lt;p&gt;Kilka dni temu wpadł mi w oko artykuł na temat wykonania &lt;a href=&#34;https://nfsec.pl/root/5874&#34;&gt;chroot serwera
Apache2&lt;/a&gt;. Problem z tamtym tekstem jest taki, że nie uwzględnia on
serwera bazy danych MySQL. W efekcie, taki chroot&#39;owany Apache2 będzie miał problemy z połączeniem
się do bazy, a nasz serwis bez niej raczej nie będzie działał prawidłowo. Przydałoby się zatem
dopracować nieco ten artykuł i wypracować takie rozwiązanie, które nie popsuje przy okazji naszego
serwisu www. Dlatego też w tym wpisie wykonamy sobie chroot zarówno serwera Apache2 z obsługą PHP i
bazy danych MySQL za sprawą modułu &lt;code&gt;unixd&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Debian: Bezpieczne pobieranie aktualizacji (apt-transport-https)</title>
      <link>https://morfikov.github.io/post/debian-bezpieczne-pobieranie-aktualizacji-apt-transport-https/</link>
      <pubDate>Tue, 09 Aug 2016 16:04:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/debian-bezpieczne-pobieranie-aktualizacji-apt-transport-https/</guid>
      <description>&lt;p&gt;Posiadanie aktualnego systemu za sprawą regularnych aktualizacji może znacząco przyczynić się do
poprawy bezpieczeństwa naszego linux&#39;a. Niemniej jednak, niezabezpieczony proces aktualizacji może
zdradzić pewne informacje, które mogą się okazać przydatne dla potencjalnego atakującego. Dlatego
też menadżer pakietów &lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;aptitude&lt;/code&gt; w Debianie wyposażony jest w dodatkowe transporty
umożliwiające komunikację z serwerem repozytorium w oparciu o różne protokoły. Standardowy
protokół, którym posługują się maszyny mające na pokładzie dystrybucję Debian, to HTTP
(ewentualnie FTP). Oba z nich ślą wszelkie informacje w postaci czystego tekstu, który nadaje się do
analizy przez człowieka. Możemy jednak skorzystać z protokołu SSL/TLS i zaszyfrować proces
pobierania aktualizacji za sprawą pakietu &lt;code&gt;apt-transport-https&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wybrać optymalny mirror repozytorium Debiana</title>
      <link>https://morfikov.github.io/post/jak-wybrac-optymalny-mirror-repozytorium-debiana/</link>
      <pubDate>Sun, 07 Aug 2016 15:15:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wybrac-optymalny-mirror-repozytorium-debiana/</guid>
      <description>&lt;p&gt;Debian to dość stara i rozbudowana dystrybucja linux&#39;a, którą można spotkać praktycznie w każdym
zakątku naszego globu. Dziesiątki tysięcy pakietów dostępne w oficjalnych repozytoriach tylko
czekają aż je pobierzemy i zainstalujemy w swoim systemie. Problem zaczyna się jednak w momencie,
gdy wielu użytkowników w tym samym czasie zaczyna pobierać pakiety i to z tego samego serwera. Wtedy
aktualizacja Debiana może trwać dłużej niż zazwyczaj. By zaadresować ten problem, developerzy tej
dystrybucji stawiają serwery lustrzane (mirror) w różnych częściach świata i rozładowują w ten
sposób ruch, który by powędrował do głównego serwera. Spora część krajów ma kilka własnych
mirror&#39;ów ale ich jakość może czasami zostawić wiele do życzenia. Co w przypadku, gdy taki mirror,
z którego my korzystamy, ulegnie awarii? Trzeba będzie poddać edycji plik &lt;code&gt;/etc/apt/sources.list&lt;/code&gt; i
zmienić adres repozytorium przez dostosowanie w nim części odpowiedzialnej za lokalizację, np.
&lt;code&gt;ftp.pl&lt;/code&gt; czy &lt;code&gt;ftp.us&lt;/code&gt; . Istnieje jednak sposób, który dostosuje lokalizację serwera lustrzanego
automatycznie, a my już nie będziemy musieli sobie głowy zawracać edycją wspomnianego wyżej pliku.&lt;/p&gt;
&lt;p&gt;Projekt, o którym traktuje poniższy wpis, nie jest już rozwijany przez Debiana. Więcej info
&lt;a href=&#34;https://wiki.debian.org/DebianGeoMirror&#34;&gt;tutaj&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Debian: Anonimowe pobieranie aktualizacji (apt-transport-tor)</title>
      <link>https://morfikov.github.io/post/debian-anonimowe-pobieranie-aktualizacji-apt-transport-tor/</link>
      <pubDate>Sun, 07 Aug 2016 13:06:03 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/debian-anonimowe-pobieranie-aktualizacji-apt-transport-tor/</guid>
      <description>&lt;p&gt;Dystrybucja linux&#39;a Debian oferuje możliwość pobierania pakietów &lt;code&gt;.deb&lt;/code&gt; za pomocą sieci TOR. W ten
sposób jesteśmy w stanie ukryć nieco informacji na temat zainstalowanego w naszym systemie
oprogramowania. Jakby nie patrzeć, aplikacje mają pełno dziur i nie wszystkie z tych programików są
łatane natychmiast po opublikowaniu podatności. Z chwilą dokonywania aktualizacji systemu,
potencjalny atakujący może dowiedzieć się zatem z jakich programów korzystamy, wliczając w to ich
wersje. Znając te dane, można ocenić czy system posiada jakieś błędy. By zaimplementować w
menadżerze pakietów &lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;aptitude&lt;/code&gt; możliwość korzystania z &lt;a href=&#34;https://www.torproject.org/&#34;&gt;sieci
TOR&lt;/a&gt;, musimy posiadać w systemie skonfigurowanego klienta TOR oraz
zainstalować pakiet &lt;code&gt;apt-transport-tor&lt;/code&gt; . W tym artykule postaramy się skonfigurować ten cały
mechanizm TOR&#39;owych aktualizacji.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Problemy z dyrektywą SSLOpenSSLConfCmd w Apache2</title>
      <link>https://morfikov.github.io/post/problemy-z-dyrektywa-sslopensslconfcmd-w-apache2/</link>
      <pubDate>Fri, 05 Aug 2016 15:52:05 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/problemy-z-dyrektywa-sslopensslconfcmd-w-apache2/</guid>
      <description>&lt;p&gt;W stabilnej dystrybucji linux&#39;a debian niewiele rzeczy ulega zmianie w przeciągu roku czy dwóch lat.
Dlatego też ta gałąź jest wykorzystywana głównie w przypadku serwerów, min. na tym VPS. Na co dzień
jednak korzystam z debiana SID, czyli gałęzi niestabilnej, która jest nieco bardziej aktualna i
przystosowana do otaczającej nas tej wirtualnej rzeczywistości. Chodzi generalnie o nowsze
oprogramowanie implementujące całą masę ficzerów, których starsze wersje nie posiadają. W tym
przypadku problem dotyczy serwera Apache2, który ostatnimi czasy wypracował szereg mechanizmów
obronnych adresujących ataki na protokół SSL/TLS. Jedną z podatności jest słaba liczba pierwsza
wykorzystywana w &lt;a href=&#34;https://pl.wikipedia.org/wiki/Protok%C3%B3%C5%82_Diffiego-Hellmana&#34;&gt;protokole
Diffie-Hellman&#39;a&lt;/a&gt;. Ten problem
można stosunkowo łatwo poprawić w nowszej wersji Apache2 wykorzystując dyrektywę &lt;code&gt;SSLOpenSSLConfCmd&lt;/code&gt;
. W starszych wersjach ona niestety nie działa. Niemniej jednak, w dalszym ciągu możemy użyć
własnych parametrów dla protokołu Diffie-Hellman&#39;a, z tym, że trzeba to zrobić nieco inaczej.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak wyczyścić tablicę conntrack&#39;a w debianie</title>
      <link>https://morfikov.github.io/post/jak-wyczyscic-tablice-conntrack-w-debianie/</link>
      <pubDate>Sun, 05 Jun 2016 12:34:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-wyczyscic-tablice-conntrack-w-debianie/</guid>
      <description>&lt;p&gt;Sporo użytkowników lunux&#39;a, zwłaszcza dystrybucji debian, korzysta z własnych skryptów firewall&#39;a
aplikujących reguły &lt;code&gt;iptables&lt;/code&gt; . Tego typu rozwiązanie ma jednak swoje wady i zalety. Niewątpliwie
do zalet można zaliczyć brak dodatkowego oprogramowania obsługującego zaporę sieciową. Jeśli chodzi
zaś o wady, to niestety cały skrypt trzeba sobie dobrze przemyśleć przed zaaplikowaniem. Ludzie
często zapominają tutaj o śledzeniu połączeń przez kernel. To właśnie na podstawie wpisów w
&lt;code&gt;/proc/net/ip_conntrack&lt;/code&gt; lub &lt;code&gt;/proc/net/nf_conntrack&lt;/code&gt; system wie, które pakiety należy na zaporze
przepuścić, a które zablokować. Jeśli teraz dodajemy reguły do filtra &lt;code&gt;iptables&lt;/code&gt; , to nowa polityka
zapory nie będzie odnosić się do tych nawiązanych już połączeń, które są określone w tablicy
conntrack&#39;a. By się upewnić, że tego typu scenariusz nigdy nas nie spotka, musimy tę tablicę
opróżnić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja trybu AP kart WiFi na debianie</title>
      <link>https://morfikov.github.io/post/konfiguracja-trybu-ap-kart-wifi-na-debianie/</link>
      <pubDate>Sat, 04 Jun 2016 15:26:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-trybu-ap-kart-wifi-na-debianie/</guid>
      <description>&lt;p&gt;Jakiś czas temu dokonałem zakupu adaptera WiFi &lt;a href=&#34;https://morfikov.github.io
/post/recenzja-karta-wifi-tp-link-tl-wn722n/&#34;&gt;TP-Link
TL-WN722n&lt;/a&gt;, a to z tego względu, że
potrzebowałem zewnętrznej karty sieciowej do mojego laptopa. Chodziło generalnie o to, że ten
wbudowany w niego broadcom nie był w stanie robić kilku użytecznych rzeczy, min. testów
penetracyjnych mojej bezprzewodowej sieci domowej. Jak się później okazało, ten zakupiony adapter
posiada też dodatkowy ficzer, którym jest tryb AP (Access Point). Wprawdzie ta karta nie może się
równać z routerami WiFi, bo te zwykle mają więcej anten, z których każda jest lepszej jakości ale
jesteśmy w stanie połączyć ze sobą bezprzewodowo kilka stacji roboczych. Trzeba jednak wziąć po
uwagę, że zasięg jak i transfer będą w dużej mierze ograniczone. W tym wpisie postaramy się
przerobić zwykłą maszynę, na której jest zainstalowany debian, na punkt dostępowy sieci WiFi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Równoważenie ruchu łącz kilku ISP (load balancing)</title>
      <link>https://morfikov.github.io/post/rownowazenie-ruchu-lacz-kilku-isp-load-balancing/</link>
      <pubDate>Sun, 22 May 2016 13:40:04 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/rownowazenie-ruchu-lacz-kilku-isp-load-balancing/</guid>
      <description>&lt;p&gt;Podłączenie pojedynczego komputera do sieci raczej nie stanowi żadnego problemu dla przeciętnego
użytkownika linux&#39;a. Wystarczy jedynie skonfigurować kilka parametrów i możemy oglądać swoje
ulubione serwisy www. Co jednak w przypadku, gdy mamy do dyspozycji kilka łącz internetowych? Jedną
z opcji jest używanie łącza tego ISP, które jest lepsze gabarytowo, a pozostałe łącza trzymać na
wypadek awarii tego pierwszego. Nie jest to zbytnio satysfakcjonujące rozwiązanie, zwłaszcza w
przypadku, gdy tym providerom płacimy za świadczone nam usługi. W taki sposób płacimy, np. za dwa
łącza, a korzystamy z jednego w danej chwili. W linux&#39;ie obsługa wielu łącz różnych ISP jest dość
skomplikowana. By taki mechanizm zaimplementować sobie, trzeba stworzyć kilka tablic routingu.
Następnie ruch sieciowy musi zostać oznaczony w &lt;code&gt;iptables&lt;/code&gt; i przekierowany do tych tablic przez
kernel. Przy odrobienie wysiłku jesteśmy jednak w stanie zaprojektować sobie load balancer, który
będzie równoważył obciążenie łącza między kilku ISP. Dodatkowo, jeśli jedno z łączy nam nawali, to
automatycznie zostaniemy przełączeni na drugie łącze (failover). W tym artykule postaramy się
zaprojektować taki właśnie mechanizm.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SMStools i smsd, czyli automat do wysyłania SMS</title>
      <link>https://morfikov.github.io/post/smstools-smsd-automat-wysylania-sms/</link>
      <pubDate>Fri, 06 May 2016 20:33:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/smstools-smsd-automat-wysylania-sms/</guid>
      <description>&lt;p&gt;Pod linux&#39;em jest całe mnóstwo oprogramowania, które może realizować zadanie odbierania i wysyłania
wiadomości SMS. Są również narzędzia, dzięki którym cały proces związany z przetwarzaniem SMS&#39;ów
można zautomatyzować. Jakiś czas temu opisywałem tego typu funkcjonalność na przykładzie
&lt;a href=&#34;https://morfikov.github.io
/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/&#34;&gt;gammu-smsd&lt;/a&gt;. Nadal uważam, że
jest to przyzwoite narzędzie ale jakby nie patrzeć wymaga ono wielu zależności. Właśnie przez nie
&lt;code&gt;gammu-smsd&lt;/code&gt; nie nadaje się do zastosowań, gdzie ma się do dyspozycji niewiele miejsca. Niemniej
jednak, w przypadku OpenWRT mamy tam możliwość zainstalowania pakietu &lt;code&gt;smstool3&lt;/code&gt; , w którym jest
dostępny demon &lt;code&gt;smsd&lt;/code&gt; . Tak się też składa, że debian również ma swoich repozytoriach to narzędzie
posiada, z tym, że w pakiecie &lt;a href=&#34;http://smstools3.kekekasvi.com/index.php?p=blacklist&#34;&gt;smstools&lt;/a&gt;. W
tym wpisie skonfigurujemy sobie działającą bramkę SMS, która będzie automatycznie odbierać
wiadomości SMS i podejmować stosowne działanie w zależności od numeru czy treści otrzymanego
komunikatu.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak przypisać losowy adres MAC do interfejsu</title>
      <link>https://morfikov.github.io/post/jak-przypisac-losowy-adres-mac-interfejsu/</link>
      <pubDate>Fri, 29 Apr 2016 16:42:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/jak-przypisac-losowy-adres-mac-interfejsu/</guid>
      <description>&lt;p&gt;Interfejsy kart sieciowych, które są instalowane w komputerach, posiadają adres MAC (&lt;a href=&#34;https://en.wikipedia.org/wiki/MAC_address&#34;&gt;Media Access
Control&lt;/a&gt;). Jest to unikalny identyfikator, który wyróżnia
nasz komputer spośród tłumu. Na podstawie tego adresu można nie tylko określić markę sprzętu, którą
się posługujemy ale także można sklasyfikować cały nasz ruch sieciowy. W ten sposób bardzo prosto
możemy zostać zidentyfikowani wymieniając dane przez darmowe hotspoty sieci bezprzewodowych WiFi.
Niemniej jednak, jesteśmy się w stanie obronić przed tego typu inwigilacją zmieniając adres MAC
naszego komputera. Nie jest to zbytnio trudne ale trzeba uważać, by znowu nie przesadzić w drugą
stronę i czasem nie zostać zidentyfikowanym przez naszą &amp;quot;odmienność&amp;quot;. W tym wpisie postaramy się
wypracować taki mechanizm, który zmieni nam adres MAC przy każdym podłączeniu do sieci i przy
zachowaniu zdroworozsądkowych zasad.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Obsługa kodów USSD w modemach LTE</title>
      <link>https://morfikov.github.io/post/obsluga-kodow-ussd-w-modemach-lte/</link>
      <pubDate>Wed, 20 Apr 2016 15:31:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/obsluga-kodow-ussd-w-modemach-lte/</guid>
      <description>&lt;p&gt;Każdy, kto ma lub miał prepaid&#39;a, prędzej czy później musiał nauczyć się obsługi &lt;a href=&#34;https://pl.wikipedia.org/wiki/Unstructured_Supplementary_Service_Data&#34;&gt;kodów
USSD&lt;/a&gt;. To za ich pomocą
jesteśmy w stanie sprawdzić stan konta czy też aktywować poszczególne usługi. Co się jednak stanie,
gdy taki prepaid zostanie umieszczony w modemie LTE? Teoretycznie modem powinien nam zapewnić
połączenie LTE ale to jest nieco inna technologia niż GSM czy UMTS, a to za ich pomocą mogą być
przesyłane zarówno kody USSD i SMS. Niby modemy LTE potrafią operować również na UMTS i GSM ale pod
linux&#39;em przesyłanie kodów USSD może być nieco problematyczne. Jedynym oprogramowaniem będącym w
stanie operować na tych kodach był &lt;code&gt;modem-manager-gui&lt;/code&gt; . Problem w tym, że zajmuje on praktycznie
cały modem dla siebie, co w pewnych sytuacjach może nie być pożądane. Zatem jakie alternatywy nam
pozostają? W jaki sposób operować na tych kodach USSD pod linux&#39;em?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wvdial i PPP, czyli modem LTE w trybie RAS</title>
      <link>https://morfikov.github.io/post/wvdial-ppp-czyli-modem-lte-w-trybie-ras/</link>
      <pubDate>Thu, 14 Apr 2016 19:01:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wvdial-ppp-czyli-modem-lte-w-trybie-ras/</guid>
      <description>&lt;p&gt;Jak wielu użytkowników linux&#39;a zapewne wie, modem GSM/UMTS/LTE może pracować w kilku trybach.
Najpopularniejszym z nich jest tryb RAS wykorzystujący interfejsy udostępniane przez to urządzenie
w katalogu &lt;code&gt;/dev/&lt;/code&gt; , zwykle &lt;code&gt;ttyUSB0&lt;/code&gt; , &lt;code&gt;ttyUSB1&lt;/code&gt; , etc. By taki modem mógł nawiązać połączenie z
siecią, potrzebny jest demon &lt;a href=&#34;https://pl.wikipedia.org/wiki/Point_to_Point_Protocol&#34;&gt;PPP&lt;/a&gt;. O trybie
RAS wspominałem już parokrotnie, min. we wpisach dotyczących &lt;a href=&#34;https://morfikov.github.io
/post/darmowy-internet-lte-od-rbmplay/&#34;&gt;konfiguracji połączenia LTE w
RBM/Play&lt;/a&gt; jak i przy omawianiu &lt;a href=&#34;https://morfikov.github.io
/post/aero2-w-polaczeniu-z-dnsmasq-dnscrypt-proxy/&#34;&gt;problemów
z resolver&#39;em DNS w przypadku
Aero2&lt;/a&gt;. Generalnie ten tryb
różni się trochę od &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-modemu-lte-w-trybie-ndis-ncm/&#34;&gt;trybu
NDIS(NCM)&lt;/a&gt; głównie tym, że tutaj
nie uzyskamy większych prędkości niż 20-30 mbit/s. Niemniej jednak, jeśli nie mamy dobrej jakości
połączenia LTE, lub nasz modem z jakiegoś powodu pod linux&#39;em nie potrafi pracować w trybie NDIS,
to możemy skonfigurować połączenie w trybie RAS wykorzystując do tego celu &lt;code&gt;wvdial&lt;/code&gt; oraz demona PPP.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wysyłanie i odbieranie SMS w wammu</title>
      <link>https://morfikov.github.io/post/wysylanie-odbieranie-sms-w-wammu/</link>
      <pubDate>Mon, 11 Apr 2016 20:19:26 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/wysylanie-odbieranie-sms-w-wammu/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://wammu.eu/&#34;&gt;Wammu&lt;/a&gt; to aplikacja, przy pomocy której jesteśmy w stanie zarządzać swoim
telefonem komórkowym. Można ją także wykorzystać do zarządzania modemami USB, tymi samymi, które są
w stanie nam dostarczyć połączenie LTE. Przy pomocy &lt;code&gt;wammu&lt;/code&gt; nie damy rady jednak nawiązać połączenia
internetowego ale jest kilka rzeczy, do których ten soft może nam się przydać. Karta SIM obecna w
takim modemie może mieć zapisane kontakty, które możemy edytować, usuwać i ewentualnie dodawać nowe.
Ważniejszym ficzerem, który oferuje &lt;code&gt;wammu&lt;/code&gt; , jest możliwość wysyłania i odbierania wiadomości SMS.
Wcześniej opisywałem &lt;a href=&#34;https://morfikov.github.io
/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/&#34;&gt;wysyłanie i odbieranie SMS za pomocą
gammu-smsd&lt;/a&gt;, niemniej jednak, w
przypadku &lt;code&gt;wammu&lt;/code&gt; nie będziemy uruchamiać żadnej usługi systemowej. Same wiadomości SMS odbiera i
wysyła się na podobnej zasadzie co w telefonie komórkowym. Przyjrzymy się zatem bliżej temu
kawałkowi oprogramowania.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gammu-smsd, czyli wysyłanie i odbieranie SMS</title>
      <link>https://morfikov.github.io/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/</link>
      <pubDate>Sat, 09 Apr 2016 18:53:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/gammu-smsd-czyli-wysylanie-odbieranie-sms/</guid>
      <description>&lt;p&gt;Eksperymentując ostatnio z modemem Huawei E3372s-153 w wersji NON-HiLink, pomyślałem, że przydałoby
się zaprojektować jakiś prosty system do odbioru i wysyłania SMS. Nie chodzi tutaj o zaprzęgnięcie
do pracy oprogramowania takiego jak &lt;a href=&#34;https://linuxonly.ru/cms/page.php?7&#34;&gt;modem-manager-gui&lt;/a&gt; czy też
&lt;a href=&#34;https://wammu.eu/wammu/&#34;&gt;wammu&lt;/a&gt; ale bardziej o przekazywanie tych wiadomości SMS, które trafiają na
modem, na inny numer telefonu komórkowego. Czyli stworzenie takiego telefonicznego proxy, które te
SMS będzie przekazywał dalej. Tego typu funkcjonalność można zaimplementować praktycznie w każdym
linux&#39;ie, tylko wymagane jest posiadanie odpowiednich narzędzi. W tym przypadku rozchodzi się o
&lt;code&gt;gammu-smsd&lt;/code&gt; i to o nim będzie ten wpis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zmiana nazwy interfejsu modemu ttyUSB0</title>
      <link>https://morfikov.github.io/post/zmiana-nazwy-interfejsu-modemu-ttyusb0/</link>
      <pubDate>Sat, 09 Apr 2016 18:50:19 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/zmiana-nazwy-interfejsu-modemu-ttyusb0/</guid>
      <description>&lt;p&gt;Spora część osób posiada różnego rodzaju urządzenia do komunikacji GSM/UMTS/LTE. Mogą to być
smartfony, czy też modemy USB. Zwykle po podpięciu takiego urządzenia do portu USB, system wykrywa
je i oddaje nam do dyspozycji kilka interfejsów w katalogu &lt;code&gt;/dev/&lt;/code&gt; . W przypadku modemu Huawei
E3372s-153 w wersji NON-HiLink, standardowo są dwa interfejsy: &lt;code&gt;ttyUSB0&lt;/code&gt; oraz &lt;code&gt;ttyUSB1&lt;/code&gt; . Gdy
podłączamy tylko jedno urządzenie, to nie mamy problemy z tymi nazwami. Co się jednak stanie w
przypadku, gdzie tych urządzeń będzie więcej i podepniemy je w losowej kolejności? Nawet jeśli
będziemy wiedzieć które interfejsy są od jakich urządzeń, to i tak trzeba będzie przepisywać pliki
konfiguracyjne różnych aplikacji pod kątem dostosowania tych nazw. Możemy jednak stworzyć unikalne
nazwy interfejsów w oparciu o &lt;a href=&#34;https://en.wikipedia.org/wiki/Udev&#34;&gt;reguły udev&#39;a&lt;/a&gt; i tym zajmiemy się
w niniejszym wpisie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Modem LTE HUAWEI E3372 bez usb-modeswitch</title>
      <link>https://morfikov.github.io/post/modem-lte-huawei-e3372-bez-usb-modeswitch/</link>
      <pubDate>Wed, 06 Apr 2016 18:51:58 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/modem-lte-huawei-e3372-bez-usb-modeswitch/</guid>
      <description>&lt;p&gt;Ten artykuł, podobnie jak kilka poprzednich, powstał w oparciu o moje badania przeprowadzane nad
modemem LTE HUAWEI E3372s-153 w wersji NON-HiLink. Niby rozwiązań dotyczących konfiguracji modemów
pod linux&#39;em jest pełno w sieci ale zasadniczą różnicą niżej opisanego sposobu jest kompletne
pozbycie się pakietu &lt;code&gt;usb-modeswitch&lt;/code&gt; . Dla przypomnienia, ten pakiet odpowiada za przełączanie
trybu modemu. Zwykle są dostępne dwa tryby. Pierwszy z nich jest w stanie dostarczyć sterowniki (pod
windows), po instalacji których modem przechodzi w drugi tryb, już ten właściwy. Na linux&#39;ach to
przełączanie jest realizowane via &lt;code&gt;usb-modeswitch&lt;/code&gt; . I tu się nasuwa pytanie, czy ten modem
faktycznie trzeba przełączać? A może istnieje sposób, który by automatycznie ustawił modem na taki
tryb, który linux&#39;y lubią najbardziej? Okazało się, że istnieje i w tym wpisie zostanie on
przestawiony.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja modemu LTE w trybie NDIS (NCM)</title>
      <link>https://morfikov.github.io/post/konfiguracja-modemu-lte-w-trybie-ndis-ncm/</link>
      <pubDate>Tue, 05 Apr 2016 15:45:10 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-modemu-lte-w-trybie-ndis-ncm/</guid>
      <description>&lt;p&gt;Sporo modemów LTE potrafi pracować w kilku trybach. Weźmy na przykład modem Huawei E3372s-153 w
wersji NON-HiLink. Standardowo obsługuje on tryb RAS (&lt;a href=&#34;https://en.wikipedia.org/wiki/Remote_Access_Service&#34;&gt;Remote Access
Services&lt;/a&gt;) jak i NDIS (&lt;a href=&#34;https://en.wikipedia.org/wiki/Network_Driver_Interface_Specification&#34;&gt;Network Driver
Interface Specification&lt;/a&gt;).
Domyślnie też włączony jest NDIS ale, by móc z tego trybu korzystać na debianie, musimy nieco
inaczej skonfigurować sobie połączenie sieciowe. Gdy w grę wchodzą modemy LTE, to użytkownicy zwykli
korzystać z narzędzia &lt;code&gt;wvdial&lt;/code&gt; , który zaprzęga do pracy demona PPP i w ten sposób modem zaczyna
pracować w trybie RAS, a nie NDIS. W tym wpisie skonfigurujemy sobie połączenie sieciowe na debianie
w taki sposób, by wykorzystywało ono potencjał trybu NDIS.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Darmowy internet LTE od RBM (Play)</title>
      <link>https://morfikov.github.io/post/darmowy-internet-lte-od-rbmplay/</link>
      <pubDate>Sun, 03 Apr 2016 14:57:40 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/darmowy-internet-lte-od-rbmplay/</guid>
      <description>&lt;p&gt;We wpisie dotyczącym &lt;a href=&#34;https://morfikov.github.io
/post/aero2-w-polaczeniu-z-dnsmasq-dnscrypt-proxy/&#34;&gt;konfiguracji serwerów DNS na potrzeby
Aero2&lt;/a&gt; wspomniałem, że ten
operator daje możliwość korzystania z internetu LTE praktycznie za darmo. Trzeba tam, co prawda,
złożyć wniosek i zapłacić jakieś grosze za przysłanie karty SIM ale opłat jako takich za
połączenie internetowe nie ma żadnych. Uporczywy może być jedynie kod CAPTCHA, który trzeba
wpisywać co 60 minut. Szukając na necie informacji na temat darmowego internetu LTE &lt;a href=&#34;http://jdtech.pl/2015/09/darmowy-internet-lte-w-redbullmobile-porady-2015.html&#34;&gt;doszukałem się
tego oto wpisu&lt;/a&gt;.
Jest tam przedstawiony sposób na włączenie bezpłatnej usługi internetu LTE u operatora RBM (Play). Z
początku wydawało mi się to niezbyt wiarygodne, by tego typu oferta była w ogóle dostępna ale
okazało się jednak, że nie ma tutaj żadnego haczyka i ten internet LTE faktycznie można włączyć i
korzystać z niego za free. W tym wpisie postaramy się skonfigurować Debiana właśnie na potrzeby tej
usługi.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementacja protokołu SSL/TLS w vsftpd</title>
      <link>https://morfikov.github.io/post/implementacja-protokolu-ssltls-w-vsftpd/</link>
      <pubDate>Sat, 13 Feb 2016 22:30:54 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/implementacja-protokolu-ssltls-w-vsftpd/</guid>
      <description>&lt;p&gt;Kwestię &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-vsftpd-w-debianie/&#34;&gt;konfiguracji serwera FTP na debianie w oparciu o
vsftpd&lt;/a&gt; już przerabialiśmy. Została nam
jeszcze do omówienia implementacja protokołu SSL/TLS. FTP nie jest bezpiecznym protokołem i wszelkie
dane logowania są przesyłane przez sieć otwartym tekstem. W przypadku, gdy stawiamy lokalny serwer
FTP w zaufanej sieci lub też będziemy korzystać jedynie z dostępu anonimowego, to raczej nie
potrzebujemy szyfrować danych. Trzeba pamiętać, że każde szyfrowanie dość mocno obciąża procesor,
który może stanowić wąskie gardło przy przesyle danych. W tym wpisie założenie jest takie, że
bezpieczeństwo danych, które będziemy przesyłać za pomocą protokołu FTP, jest rzeczą najważniejszą i
dlatego wdrożyć szyfrowanie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja vsftpd w Debianie</title>
      <link>https://morfikov.github.io/post/konfiguracja-vsftpd-w-debianie/</link>
      <pubDate>Fri, 12 Feb 2016 02:39:29 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-vsftpd-w-debianie/</guid>
      <description>&lt;p&gt;Serwery FTP umożliwiają przesyłanie plików przez sieć za pomocą protokołu TCP. Raczej wszyscy
mieliśmy z nimi już do czynienia. Może niekoniecznie zarządzaliśmy takimi serwerami ale na pewno
zdarzyło nam się pobierać pliki za ich pomocą. W tym wpisie jednak postaramy się skonfigurować taki
serwer FTP w oparciu o oprogramowanie &lt;a href=&#34;https://security.appspot.com/vsftpd.html&#34;&gt;vsftpd&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja serwera dźwięku PulseAudio</title>
      <link>https://morfikov.github.io/post/konfiguracja-serwera-dzwieku-pulseaudio/</link>
      <pubDate>Mon, 11 Jan 2016 21:49:37 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-serwera-dzwieku-pulseaudio/</guid>
      <description>&lt;p&gt;Wielu użytkowników linux&#39;a nie przepada zbytnio za PulseAudio, bo ten z jakiegoś powodu sprawia u
nich same kłopoty. U mnie ten serwer dźwięku działa przyzwoicie i zwykle nie ma z nim żadnych
problemów. Obecnie ten projekt jest już na tyle dojrzały, że te większe środowiska graficzne
zwyczajnie polegają na nim w zależnościach. Jeśli jednak &lt;a href=&#34;https://morfikov.github.io
/post/instalacja-debiana-z-wykorzystaniem-debootstrap/&#34;&gt;instalowaliśmy debiana za pomocą narzędzia
debootstrap&lt;/a&gt; i
&lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-xservera-na-debianie-xorg/&#34;&gt;konfigurowaliśmy osobno graficzną sesję
Xserver&#39;a&lt;/a&gt;, &lt;a href=&#34;https://morfikov.github.io
/post/menadzer-logowania-lightdm/&#34;&gt;menadżer logowania
LightDM&lt;/a&gt; czy też &lt;a href=&#34;https://morfikov.github.io
/post/menadzer-okien-openbox/&#34;&gt;menadżer okien
Openbox&lt;/a&gt;, to raczej zależy nam na minimalnym
środowisku, które może się zwyczajnie obejść bez PulseAudio. Niemniej jednak, PulseAudio ma kilka
ciekawych bajerów, których ALSA nie posiada. By się nie rozpisywać zbytnio, mogę wspomnieć choćby o
możliwości&lt;a href=&#34;https://morfikov.github.io
/post/pulseaudio-i-przesylanie-dzwieku-przez-siec/&#34;&gt;przesyłania dźwięku przez
sieć&lt;/a&gt;, czy też o takim
ficzerze jak &lt;a href=&#34;https://morfikov.github.io
/post/normalizacja-glosnosci-w-pulseaudio/&#34;&gt;normalizacja głośności&lt;/a&gt;.
Są to głównie zabawki dla nieco bardziej zaawansowanych użytkowników i gdy ich nie potrzebujemy, to
serwer dźwięku nam się raczej do niczego nie przyda. Warto jednak się zaznajomić z tym nieco
bardziej zaawansowanym kawałkiem oprogramowania i w tym wpisie postaramy się nieco omówić instalację
i konfigurację tego serwera dźwięku.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Menadżer okien Openbox</title>
      <link>https://morfikov.github.io/post/menadzer-okien-openbox/</link>
      <pubDate>Sun, 10 Jan 2016 21:31:47 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/menadzer-okien-openbox/</guid>
      <description>&lt;p&gt;Spora większość środowisk graficznych rozrosła się obecnie nieco i ich instalacja na maszynach
wyposażonych w niewiele pamięci RAM może nie wchodzić w grę. Nie jesteśmy też skazani na życie w
konsoli, ani na kupno nowego sprzętu. Możemy nieco odchudzić instalację pozbywając się zbędnych
usług, których tak naprawdę nie potrzebujemy. Poza tym, praktycznie każde z graficznych narzędzi,
przy pomocy których chcemy konfigurować linux&#39;a, ma tekstowe zamienniki, lub też o wiele lżejsze
alternatywy. Jednak w przypadku, gdy korzystamy z takich rozbudowanych środowisk jak GNOME, to nie
koniecznie da się usunąć szereg tych zasobożernych komponentów. Pozostaje nam zwykle jedna opcja,
którą jest usunięcie całego środowiska graficznego i zainstalowanie potrzebnych nam komponentów
osobno. Jako, że mamy już opisany&lt;a href=&#34;https://morfikov.github.io
/post/instalacja-debiana-z-wykorzystaniem-debootstrap/&#34;&gt;proces instalacji debiana przy pomocy
debootstrap&lt;/a&gt;, &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-xservera-na-debianie-xorg/&#34;&gt;instalację i
konfigurację Xserver&#39;a&lt;/a&gt;, jak i
również &lt;a href=&#34;https://morfikov.github.io
/post/menadzer-logowania-lightdm/&#34;&gt;menadżera okien LightDM&lt;/a&gt;, to przyszedł
czas na omówienie niezbędnego w sesji graficznej &lt;a href=&#34;https://pl.wikipedia.org/wiki/Mened%C5%BCer_okien&#34;&gt;menadżera
okien&lt;/a&gt;. W tym wpisie skupimy się głównie na
instalacji i konfiguracji Openbox&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Menadżer logowania LightDM</title>
      <link>https://morfikov.github.io/post/menadzer-logowania-lightdm/</link>
      <pubDate>Fri, 08 Jan 2016 20:12:46 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/menadzer-logowania-lightdm/</guid>
      <description>&lt;p&gt;Istnieje kilka sposobów na to, by uruchomić sesję graficzną Xserver&#39;a. W przypadku, gdy nie
wykorzystujemy zaawansowanych środowisk graficznych, zwykle korzystamy z polecenia &lt;code&gt;startx&lt;/code&gt;
wydawanego zaraz po zalogowaniu się na konsolę TTY. Niemniej jednak, nawet w tych najprostszych
środowiskach graficznych możemy pokusić się o instalację lekkiego menadżera okien, tak by nie
musieć konfigurować samodzielnie szeregu opcji sesji. Menadżery logowania (display managers) mają
na celu zrobienie dokładnie tego samego co pliki &lt;code&gt;~/.xinitrc&lt;/code&gt; i &lt;code&gt;~/.xserverrc&lt;/code&gt; , z tym, że w nieco
bardziej przyjaznej dla użytkownika formie. W tym wpisie przyjrzymy się nieco dokładniej
&lt;a href=&#34;https://www.freedesktop.org/wiki/Software/LightDM/&#34;&gt;menadżerowi LightDM&lt;/a&gt;. Zostanie także omówiony
sposób blokowania aktywnej sesji Xserver&#39;a bez potrzeby jej zamykania przy pomocy narzędzia
&lt;a href=&#34;https://github.com/the-cavalry/light-locker&#34;&gt;light-locker&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja Xserver&#39;a na debianie (Xorg)</title>
      <link>https://morfikov.github.io/post/konfiguracja-xservera-na-debianie-xorg/</link>
      <pubDate>Fri, 08 Jan 2016 17:53:35 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-xservera-na-debianie-xorg/</guid>
      <description>&lt;p&gt;Dzięki takiemu wynalazkowi jak Xserver (Xorg) mamy możliwość odpalania aplikacji graficznych. Bez
niego wszystko musielibyśmy robić w czarnej konsoli, przez co funkcjonalność naszej maszyny w dość
znacznym stopniu ucierpiałaby. Oczywiście tryb graficzny ma też swoje wady. Niemniej jednak, Xserver
leży póki co u podstaw każdego środowiska graficznego i jeśli chcemy mieć możliwość odpalania, np.
Firefox&#39;a, czy oglądania filmów w VLC, to nie ma innego wyjścia jak skonfigurować sobie Xserver. W
tym wpisie się zajmiemy tym zagadnieniem, przy czym, chcę uprzedzić, że nie będziemy korzystać z
żadnych automatów, które można znaleźć w tych wszystkich zaawansowanych środowiskach graficznych. A
to z tego względu, że ustawienia tych środowisk zwykle nadpisują ustawienia samego Xserver&#39;a.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jak skonfigurować bonding w Debian linux (eth0&#43;wlan0)</title>
      <link>https://morfikov.github.io/post/konfiguracja-interfejsow-bond-bonding/</link>
      <pubDate>Sat, 02 Jan 2016 15:07:13 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-interfejsow-bond-bonding/</guid>
      <description>&lt;p&gt;W artykule poświęconym &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-polaczenia-wifi-pod-debianem/&#34;&gt;konfiguracji sieci WiFi na Debianie z wykorzystaniem narzędzia
wpa_supplicant&lt;/a&gt; wspomniałem parę słów na temat &lt;a href=&#34;https://www.kernel.org/pub/linux/kernel/people/marcelo/linux-2.4/Documentation/networking/bonding.txt&#34;&gt;interfejsu bond&lt;/a&gt;. Bonding na linux
wykorzystywany jest w zasadzie do spięcia kilku interfejsów sieciowych, w tym przewodowych
( &lt;code&gt;eth0&lt;/code&gt; ) i bezprzewodowych ( &lt;code&gt;wlan0&lt;/code&gt; ) w jeden (zwykle &lt;code&gt;bond0&lt;/code&gt; ). Takie rozwiązanie sprawia, że
w przypadku awarii któregoś z podpiętych interfejsów, my nie tracimy połączenia z siecią i nie
musimy nic nigdzie przełączać, by to połączenie przywrócić. To rozwiązanie jest o tyle użyteczne,
że w przypadku, gdy podepniemy przewód do gniazda RJ-45 w naszym laptopie, to komunikacja będzie
odbywać się po kablu. Natomiast jeśli przewód zostanie odłączony, to system automatycznie przejdzie
na komunikację bezprzewodową. W tym wpisie spróbujemy zaprojektować sobie właśnie tego typu
mechanizm zarówno za sprawą pakietu &lt;code&gt;ifupdown&lt;/code&gt; , gdzie konfiguracja interfejsów sieciowych jest
zarządzana przez plik &lt;code&gt;/etc/network/interfaces&lt;/code&gt; , jak i przy pomocy natywnego rozwiązania jakie
oferuje systemd/networkd.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instalacja debiana z wykorzystaniem debootstrap</title>
      <link>https://morfikov.github.io/post/instalacja-debiana-z-wykorzystaniem-debootstrap/</link>
      <pubDate>Sat, 02 Jan 2016 03:52:49 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/instalacja-debiana-z-wykorzystaniem-debootstrap/</guid>
      <description>&lt;p&gt;Instalowanie debiana z wykorzystaniem &lt;code&gt;debootstrap&lt;/code&gt; trochę się różni od instalacji z wykorzystaniem
instalatora. Chodzi generalnie o to, że wszystkie kroki instalacyjne trzeba przeprowadzać ręcznie.
Poza tym, cała konfiguracja będzie wymagać manualnego dostosowania. Plus tego rozwiązania jest
oczywisty, albowiem mamy całkowitą władzę nad tym co się w systemie znajdzie oraz jak będzie on
skonfigurowany. By mieć możliwość przeprowadzenia tego typu instalacji potrzebny będzie nam
działający system. Może to być płytka lub pendrive live z &lt;a href=&#34;https://www.debian.org/CD/live/index.pl.html&#34;&gt;Debianem&lt;/a&gt; czy &lt;a href=&#34;https://www.ubuntu.com/download/desktop/try-ubuntu-before-you-install&#34;&gt;Ubuntu&lt;/a&gt;. Można też
wykorzystać już zainstalowany system operacyjny. Ważne jest tylko to, aby była możliwość
zainstalowania w takim systemie pakietu &lt;code&gt;debootstrap&lt;/code&gt; , no i oczywiście wymagany jest dostęp do
internetu. W przeciwieństwie do instalatora debiana, mamy dostęp do graficznego środowiska, a w nim
do przeglądarki i w przypadku utknięcia gdzieś po drodze podczas instalacji, możemy sobie wygooglać
napotkane problemy nie przerywając przy tym prac instalacyjnych.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Poradnik maintainer&#39;a, czyli jak zrobić pakiet deb</title>
      <link>https://morfikov.github.io/post/poradnik-maintainera-czyli-jak-zrobic-pakiet-deb/</link>
      <pubDate>Mon, 07 Dec 2015 20:26:45 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/poradnik-maintainera-czyli-jak-zrobic-pakiet-deb/</guid>
      <description>&lt;p&gt;Debian posiada bardzo rozbudowany system robienia pakietów. Generalnie rzecz biorąc, to wszystkie z
nich musiały przejść przez ten proces zanim trafiły do głównego repozytorium dystrybucji. Dzięki
takiemu stanu rzeczy, nie musimy ręcznie powielać pracy szeregu innych osób i odpada nam
własnoręczna kompilacja pakietów, a wszyscy wiemy, że zajmuje ona cenny czas i zasoby. Paczki
&lt;code&gt;.deb&lt;/code&gt; są tworzone ze źródeł i instalowane przy pomocy menadżera pakietów &lt;code&gt;aptitude&lt;/code&gt;/&lt;code&gt;apt&lt;/code&gt;/&lt;code&gt;dpkg&lt;/code&gt; .
Nic jednak nie stoi na przeszkodzie by daną aplikację skompilować sobie ręcznie i zainstalować ją
przy pomocy &lt;code&gt;make install&lt;/code&gt; . Problem w tym, że w taki sposób robi się śmietnik w naszym systemie i
śledzenie wszystkich zainstalowanych w ten sposób pakietów w pewnym momencie stanie się wręcz
niemożliwe. Dlatego też przydałby nam się mechanizm, który ułatwiłby nam nieco to zadanie. Debian
udostępnia szereg narzędzi, które są w stanie w pełni zautomatyzować cały ten proces budowy
pakietów. Ten poradnik zaś ma na celu zebranie wszystkich istotniejszych informacji związanych z
obsługą narzędzi takich jak &lt;code&gt;dh_make&lt;/code&gt; , &lt;code&gt;dpkg-buildpackage&lt;/code&gt; , &lt;code&gt;pbuilder&lt;/code&gt; , &lt;code&gt;quilt&lt;/code&gt; czy &lt;code&gt;lintian&lt;/code&gt; ,
tak by tworzyć pakiety w prosty sposób i przy tym równając do najwyższych standardów debiana.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migawka (snapshot) repozytorium debiana</title>
      <link>https://morfikov.github.io/post/migawka-snapshot-repozytorium-debiana/</link>
      <pubDate>Wed, 04 Nov 2015 18:23:36 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/migawka-snapshot-repozytorium-debiana/</guid>
      <description>&lt;p&gt;Aktualizacje systemu niosą ze sobą nowsze wersje pakietów. Czasami mają one błędy, które wychodzą na
jaw po jakimś czasie korzystania z danej aplikacji. W takiej sytuacji zwykle zachodzi potrzeba
cofnięcia wersji kilku pakietów. Jest jednak wielce prawdopodobne, że akurat tej wersji pakietu,
której potrzebujemy, nie znajdziemy z repozytorium debiana. Pobieranie pojedynczych pakietów z
internetu przez klikanie w pierwszy lepszy link, który zostanie nam zwrócony przez wyszukiwarkę, nie
jest dobrym pomysłem. Na szczęście w przypadku debiana nie musimy się aż tak narażać. A to z tego
względu, że &lt;a href=&#34;http://snapshot.debian.org/archive/debian/&#34;&gt;debian robi migawki (shapshots) swoich
repozytoriów&lt;/a&gt; 4 razy dziennie (co 6 godzin). W ten
sposób mamy dostęp do różnych stanów repozytoriów, w tym też tych, które zawierają pakiety
aktualnie niedostępne w repozytoriach. W tym wpisie postaramy się pobrać i zainstalować
nieistniejące pakiety z takich snapshot&#39;ów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja multiarch w dystrybucji Debian</title>
      <link>https://morfikov.github.io/post/konfiguracja-multiarch-na-debianie/</link>
      <pubDate>Mon, 02 Nov 2015 20:20:09 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-multiarch-na-debianie/</guid>
      <description>&lt;p&gt;Posiadając nowszej klasy procesor, jesteśmy w stanie korzystać z 64 bitowego systemu operacyjnego. W
przypadku windowsów uruchamianie aplikacji 32 czy 64 bitowych nie stanowi większego problemu. W na
debianie sprawa wygląda nieco inaczej. Gdy mamy wgranego 64 bitowego debiana, aplikacje 32 bitowe
nie będą chciały się nam odpalić. Wszystkiemu winne są biblioteki 32 bitowe, które są wykorzystywane
przez dany program, a bez nich on zwyczajnie nie może działać. Jednym z rozwiązań tego problemu może
być &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-kontenerow-lxc/&#34;&gt;kontener LXC&lt;/a&gt;, gdzie jesteśmy w stanie
zainstalować 32 bitowy system wewnątrz środowiska 64 bitowego i to z tego systemu możemy uruchamiać
32 bitowe aplikacje. Skonfigurowanie takiego kontenera może być nieco skomplikowane, dlatego też
dużo lepszym rozwiązaniem jest przerobienie naszego 64 bitowego systemu na
&lt;a href=&#34;https://wiki.debian.org/Multiarch&#34;&gt;muliarch&lt;/a&gt;, czyli taki, który jest w stanie obsługiwać wiele
architektur (multiarch).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Manualna weryfikacja pakietu deb w debianie</title>
      <link>https://morfikov.github.io/post/manualna-weryfikacja-pakietu-deb-w-debianie/</link>
      <pubDate>Mon, 02 Nov 2015 00:16:03 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/manualna-weryfikacja-pakietu-deb-w-debianie/</guid>
      <description>&lt;p&gt;W dobie całego tego świata informatycznego zwykliśmy polegać na osobach, których nigdy w życiu na
oczy nie wiedzieliśmy, nie wspominając o jakimkolwiek kontakcie fizycznym. Zaufanie to obecnie chyba
najbardziej krytyczna luka bezpieczeństwa jeśli chodzi o oprogramowanie, z którego korzystamy na co
dzień. My, którzy używamy debiana w swojej pracy, polegamy na mechanizmach jakie oferuje nam &lt;code&gt;apt&lt;/code&gt;
czy &lt;code&gt;aptitude&lt;/code&gt; przy &lt;a href=&#34;https://wiki.debian.org/SecureApt&#34;&gt;weryfikacji pakietów przed ich instalacją&lt;/a&gt; w
systemie. Co się jednak by stało gdyby w tych menadżerach pojawił się błąd, który by uniemożliwiał
poprawną weryfikację pakietów? Skąd wiemy czy te mechanizmy zabezpieczające w ogóle działają? Może
one nam dają jedynie fałszywe poczucie bezpieczeństwa, a tak naprawdę przez niczym nas nie chronią?
W tym wpisie postaramy się odpowiedzieć na te powyższe pytania i sprawdzimy czy manualna weryfikacja
pakietu jest w ogóle możliwa&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klucze do repozytoriów debiana (trusted.gpg)</title>
      <link>https://morfikov.github.io/post/klucze-do-repozytoriow-debiana-trusted-gpg/</link>
      <pubDate>Sun, 01 Nov 2015 19:14:55 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/klucze-do-repozytoriow-debiana-trusted-gpg/</guid>
      <description>&lt;p&gt;Obecnie systemy operacyjne stają się nieco bardziej stabilne i czasy, w których reinstalacja
takiego systemu, czy też nawet format dysku, odchodzą powoli w niebyt. &lt;a href=&#34;https://morfikov.github.io
/post/dokladna-data-instalacji-systemu-linux/&#34;&gt;Data instalacji mojego
linux&#39;a&lt;/a&gt; wskazuje na prawie 2 lata wstecz. Jakby nie patrzeć jest to szmat czasu, w czasie
którego przez mojego Debiana przetoczyła się ogromna ilość oprogramowania. Nie zawsze były to
pakiety, które pochodziły z głównych repozytoriów tej dystrybucji. Niemniej jednak, każde
repozytorium z pakietami jest podpisane i by móc z nich bezpiecznie korzystać, trzeba pozyskać
&lt;a href=&#34;https://pl.wikipedia.org/wiki/GNU_Privacy_Guard&#34;&gt;klucz GPG&lt;/a&gt; i dokonać jego weryfikacji. Prędzej czy później przyjdzie czas, gdy takie klucze GPG
przestaną być ważne lub też zmianie ulegną źródła pakietów. W ten sposób baza danych kluczy
zawierać będzie szereg zbędnych pozycji. Może wielu ludziom nie przeszkadza ten fakt ale raz na
jakiś czas przydałoby się oczyścić keyring ze śmieci, które są już nam do niczego niepotrzebne.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pobieranie pakietów przy pomocy cron-apt</title>
      <link>https://morfikov.github.io/post/pobieranie-pakietow-przy-pomocy-cron-apt/</link>
      <pubDate>Fri, 23 Oct 2015 14:42:17 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/pobieranie-pakietow-przy-pomocy-cron-apt/</guid>
      <description>&lt;p&gt;Jakiś czas temu opisywałem konfigurację dla menadżera pakietów &lt;code&gt;apt&lt;/code&gt; i &lt;code&gt;aptitude&lt;/code&gt; &lt;a href=&#34;https://morfikov.github.io
/post/konfiguracja-apt-i-aptitude-w-pliku-apt-conf/&#34;&gt;w pliku
apt.conf&lt;/a&gt; . Ten wpis również
tyczy się konfiguracji wspomnianych menadżerów, z tym, że zostanie tutaj opisana pewna
funkcjonalność, która może nam zaoszczędzić trochę czasu przy aktualizacji systemu. Chodzi o to,
że pakiety praktycznie zawsze muszą być pobrane na dysk przed ich instalacją. Gdy nie dysponujemy
dobrym pod względem przepustowości łączem, proces pobierania pakietów jest zwykle dłuższy niż sama
ich instalacja. Przydałoby się zatem zaprogramować pobieranie plików w tle, tak by nie musieć ich
pobierać tuż przez przed procesem instalacyjnym.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja apt i aptitude w pliku apt.conf</title>
      <link>https://morfikov.github.io/post/konfiguracja-apt-i-aptitude-w-pliku-apt-conf/</link>
      <pubDate>Sun, 18 Oct 2015 20:04:30 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-apt-i-aptitude-w-pliku-apt-conf/</guid>
      <description>&lt;p&gt;Praktycznie każdy z nas korzysta z menadżera pakietów &lt;code&gt;apt&lt;/code&gt; lub też jego nakładki &lt;code&gt;aptitude&lt;/code&gt; .
Operowanie na debianie bez tych narzędzi raczej by nam nieco utrudniło życie. Sporo osób ogranicza
się jedynie do podstawowych poleceń, typu &lt;code&gt;update&lt;/code&gt; , &lt;code&gt;upgrade&lt;/code&gt; czy &lt;code&gt;dist-upgrade&lt;/code&gt; , pomijając przy
tym całą konfigurację w/w narzędzi. W tym wpisie zostanie zaprezentowanych szereg opcji, które można
zdefiniować na stałe w pliku konfiguracyjnym &lt;code&gt;/etc/apt/apt.conf&lt;/code&gt; , tak by nie trzeba było ich ciągle
wpisywać w terminalu ilekroć tylko korzystamy któregoś menadżera pakietów.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Usuwanie środowiska graficznego</title>
      <link>https://morfikov.github.io/post/usuwanie-srodowiska-graficznego/</link>
      <pubDate>Sun, 18 Oct 2015 17:52:42 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/usuwanie-srodowiska-graficznego/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://forum.dug.net.pl/viewtopic.php?id=27813&#34;&gt;Na forum DUG&#39;a&lt;/a&gt; znów został poruszony ciekawy
wątek, tym razem odnośnie usunięcia całego środowiska graficznego z systemu. Pozornie niby nic
nadzwyczajnego, przecie każdy z nas potrafi odinstalować szereg pakietów via &lt;code&gt;apt&lt;/code&gt; czy &lt;code&gt;aptitude&lt;/code&gt; .
Problematyczne za to mogą się okazać zależne pakiety, które nie zostaną automatycznie usunięte wraz
z konkretnym metapakietem od środowiska graficznego. Jak zatem usunąć te pozostałości?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Konfiguracja połączenia WiFi pod debianem</title>
      <link>https://morfikov.github.io/post/konfiguracja-polaczenia-wifi-pod-debianem/</link>
      <pubDate>Thu, 15 Oct 2015 19:32:48 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/konfiguracja-polaczenia-wifi-pod-debianem/</guid>
      <description>&lt;p&gt;Sieci bezprzewodowe w obecnych czasach to standard i nie ma chyba miejsca na ziemi gdzie nie dałoby
rady ulokować routera WiFi, do którego można by podłączyć szereg urządzeń. Każdy kto próbował
konfigurować sieć bezprzewodową na debianie, wie, że może to być bardzo upierdliwe, zwłaszcza jeśli
mamy dostęp do wielu AP, które posiadają różne konfiguracje. Wynaleziono, co prawda, automaty, które
mają pomagać w ogarnięciu tego całego bezprzewodowego zamieszania, np. &lt;code&gt;network-manager&lt;/code&gt; czy &lt;code&gt;wicd&lt;/code&gt;
ale w przypadku lekkich stacji roboczych, które nie mają wgranego pełnego środowiska graficznego, a
jedynie jakiś menadżer okien, np. Openbox, to instalacja tych powyższych narzędzi może zwyczajnie
nie wchodzić w grę.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aktualizacja systemu i logowanie komunikatów</title>
      <link>https://morfikov.github.io/post/aktualizacja-systemu-logowanie-komunikatow/</link>
      <pubDate>Thu, 08 Oct 2015 12:39:32 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/aktualizacja-systemu-logowanie-komunikatow/</guid>
      <description>&lt;p&gt;Aktualizacja systemu to chyba jedna z bardziej podstawowych czynności, które przeprowadzamy niemalże
codziennie. Tak się złożyło, że chwilę po zakończeniu tego procesu musiałem wyłączyć w pośpiechu
komputer. Nie zdążyłem przy tym przeczytać uważnie informacji, które zwrócił mi terminal. Oczywiście
mógłbym zahibernować maszynę i wrócić do logu instalacji w wolnej chwili ale nie zawsze hibernacja
jest możliwa. Poza tym, na myśl przychodzą mi osoby, które często zakładają wątki na forach o tym,
że aktualizacja uwaliła ich system. Zawsze w takiej sytuacji prosi się danego człowieka o podanie
logu z aktualizacji systemu albo przynajmniej próbuje się wyciągnąć od takiego delikwenta informację
na temat tego co było aktualizowane. W większości przypadków, taki człowiek nie ma o tym kompletnie
pojęcia, a jak już, to podaje bardzo nieprecyzyjne dane. Ten post ma na celu ułatwienie znalezienia
informacji o tym co było przedmiotem aktualizacji, tak by mieć nieco jaśniejszy obraz tego co mogło
nawalić.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tworzenie repozytorium przy pomocy reprepro</title>
      <link>https://morfikov.github.io/post/tworzenie-repozytorium-przy-pomocy-reprepro/</link>
      <pubDate>Wed, 07 Oct 2015 17:37:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/tworzenie-repozytorium-przy-pomocy-reprepro/</guid>
      <description>&lt;p&gt;Ten kto tworzył kiedyś paczki &lt;code&gt;.deb&lt;/code&gt; wie, że cały proces może w końcu człowieka nieco przytłoczyć.
Paczka, jak to paczka, budowana jest ze źródeł i konfigurowana przez jej opiekuna. Z reguły ludzie
instalują kompilowane programy via &lt;code&gt;make install&lt;/code&gt; . Niektórzy idą o krok dalej i używają do tego
celu narzędzi typu &lt;code&gt;checkinstall&lt;/code&gt; . I wszystko jest w miarę w porządku, przynajmniej jeśli chodzi o
utrzymywanie jednej paczki. Przeprowadzamy kompilację tylko raz, po czym instalujemy dany pakiet i
zapominamy o nim. Niemniej jednak, tego typu postępowanie może doprowadzić nasz system na skraj
niestabilności. W tym poście nie będziemy zajmować się zbytnio sposobem w jaki powinno się tworzyć
paczki &lt;code&gt;.deb&lt;/code&gt; , a jedynie tym jak je przechowywać. Do tego celu potrzebne jest nam repozytorium,
które zbudujemy w oparciu o oprogramowanie &lt;code&gt;reprepro&lt;/code&gt; .&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fontconfig i konfiguracja czcionek w Debianie</title>
      <link>https://morfikov.github.io/post/fontconfig-i-konfiguracja-czcionek-w-debianie/</link>
      <pubDate>Wed, 05 Aug 2015 17:10:33 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/fontconfig-i-konfiguracja-czcionek-w-debianie/</guid>
      <description>&lt;p&gt;Od zawsze podobały mi się czcionki windosowskie ale po przejściu na linux&#39;a okazało się, że tutaj
fonty wyglądają zupełnie inaczej i co mogło zdziwić, nie było w standardzie tych moich ulubionych,
tj. Arial, Times New Roman i Courier New. Przez szereg lat miałem obecną w systemie dość dziwną
konfigurację dla fontconfig&#39;a, która działała na takiej zasadzie, że te czcionki aplikacji były w
prządku, natomiast te pobierane z serwisów www (np. w Firefox&#39;ie) dość słabo się renderowały i bez
przeprowadzania kilku zabiegów były one zwyczajnie nieczytelne. Postanowiłem w końcu poczytać trochę
dokumentacji na temat tego jak wygląda konfiguracja czcionek w debianie i po kilku dniach udało mi
się osiągnąć dość zadowalające efekty wizualne.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Przeszukiwanie zawartości pakietów (apt-file)</title>
      <link>https://morfikov.github.io/post/przeszukiwanie-zawartosci-pakietow-apt-file/</link>
      <pubDate>Tue, 30 Jun 2015 12:03:20 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/przeszukiwanie-zawartosci-pakietow-apt-file/</guid>
      <description>&lt;p&gt;Podczas procesu kompilacji pakietów często zdarza się tak, że brakuje jakichś zależności, bez
których dany pakietów nie chce się nam zbudować. W większości przypadków, system powinien nam
podpowiedzieć jaki pakiet powinniśmy doinstalować. Nie zawsze jednak będzie to takie oczywiste i
jedyne co nam zostanie zwrócone, to ścieżka danego pliku lub tylko jego nazwa. Nawet jeśli nie
kompilujemy programów, to podczas zwykłego użytkowania komputera możemy potrzebować odnaleźć pakiet,
który zawiera pewien określony plik binarny czy konfiguracyjny. Jak zatem odnaleźć się w gąszczu
plików i katalogów by efektywnie ustalić pakiet, który zawiera interesujące nas pliki?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DKMS, czyli automatycznie budowane moduły</title>
      <link>https://morfikov.github.io/post/dkms-czyli-automatycznie-budowane-moduly/</link>
      <pubDate>Sat, 30 May 2015 21:05:27 +0000</pubDate>
      
      <guid>https://morfikov.github.io/post/dkms-czyli-automatycznie-budowane-moduly/</guid>
      <description>&lt;p&gt;Jeśli zamierzamy kupić sprzęt, który dopiero co trafił na półki w sklepach, to prawdopodobnie zaraz
po podłączeniu go do naszego komputera okaże się, że to urządzenie nie jest nawet wykrywane przez
system operacyjny. W przypadku gdy jego producent zapewnia w miarę przyzwoity support, to być może
problemy, których doświadczamy, zostaną rozwiązane wraz z instalacją najnowszego kernela. Co jednak
w przypadku gdy nawet po aktualizacji kernela nie jesteśmy w stanie odpalić, np. nowo zakupionej
karty WiFi? Jako, że te wszystkie sprzęty działają w oparciu określone moduły, wystarczy taki moduł
pozyskać, skompilować i załadować w systemie. Problem w tym, że z każdą nową wersją jądra
operacyjnego, która trafi do repo debiana, będziemy musieli ręcznie budować moduł na nowo i właśnie
w tym artykule opiszę jak nauczyć system, by sam przeprowadzał tę mozolną czynność bez naszego
udziału.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>